18/02/28 09:56:20 INFO SparkContext: Running Spark version 2.2.0
18/02/28 09:56:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/02/28 09:56:20 INFO SparkContext: Submitted application: sparklyr
18/02/28 09:56:20 INFO SecurityManager: Changing view acls to: JC
18/02/28 09:56:20 INFO SecurityManager: Changing modify acls to: JC
18/02/28 09:56:20 INFO SecurityManager: Changing view acls groups to: 
18/02/28 09:56:20 INFO SecurityManager: Changing modify acls groups to: 
18/02/28 09:56:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(JC); groups with view permissions: Set(); users  with modify permissions: Set(JC); groups with modify permissions: Set()
18/02/28 09:56:20 INFO Utils: Successfully started service 'sparkDriver' on port 59757.
18/02/28 09:56:20 INFO SparkEnv: Registering MapOutputTracker
18/02/28 09:56:20 INFO SparkEnv: Registering BlockManagerMaster
18/02/28 09:56:20 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/02/28 09:56:20 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/02/28 09:56:20 INFO DiskBlockManager: Created local directory at C:\Users\JC\AppData\Local\Temp\blockmgr-b9a3dcca-7769-40dd-8128-f13e52b0f46a
18/02/28 09:56:21 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/02/28 09:56:21 INFO SparkEnv: Registering OutputCommitCoordinator
18/02/28 09:56:21 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/02/28 09:56:21 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
18/02/28 09:56:21 INFO SparkContext: Added JAR file:/C:/Users/JC/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:59757/jars/sparklyr-2.2-2.11.jar with timestamp 1519840581348
18/02/28 09:56:21 INFO Executor: Starting executor ID driver on host localhost
18/02/28 09:56:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59778.
18/02/28 09:56:21 INFO NettyBlockTransferService: Server created on 127.0.0.1:59778
18/02/28 09:56:21 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/02/28 09:56:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 59778, None)
18/02/28 09:56:21 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:59778 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 59778, None)
18/02/28 09:56:21 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 59778, None)
18/02/28 09:56:21 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 59778, None)
18/02/28 09:56:22 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/02/28 09:56:22 INFO SharedState: loading hive config file: file:/C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
18/02/28 09:56:22 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:\Users\JC\AppData\Local\spark\spark-2.2.0-bin-hadoop2.7\tmp\hive') to the value of spark.sql.warehouse.dir ('C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive').
18/02/28 09:56:22 INFO SharedState: Warehouse path is 'C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive'.
18/02/28 09:56:23 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
18/02/28 09:56:23 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
18/02/28 09:56:23 INFO ObjectStore: ObjectStore, initialize called
18/02/28 09:56:23 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
18/02/28 09:56:23 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
18/02/28 09:56:25 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
18/02/28 09:56:26 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 09:56:26 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 09:56:26 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 09:56:26 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 09:56:26 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
18/02/28 09:56:26 INFO ObjectStore: Initialized ObjectStore
18/02/28 09:56:27 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
18/02/28 09:56:27 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
18/02/28 09:56:27 INFO HiveMetaStore: Added admin role in metastore
18/02/28 09:56:27 INFO HiveMetaStore: Added public role in metastore
18/02/28 09:56:27 INFO HiveMetaStore: No user is added in admin role, since config is empty
18/02/28 09:56:27 INFO HiveMetaStore: 0: get_all_databases
18/02/28 09:56:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_all_databases	
18/02/28 09:56:27 INFO HiveMetaStore: 0: get_functions: db=default pat=*
18/02/28 09:56:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
18/02/28 09:56:27 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 09:56:27 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC
18/02/28 09:56:27 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/Temp/e09e32e2-244d-480a-8d95-0465b2d0c537_resources
18/02/28 09:56:27 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/e09e32e2-244d-480a-8d95-0465b2d0c537
18/02/28 09:56:27 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/e09e32e2-244d-480a-8d95-0465b2d0c537
18/02/28 09:56:27 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/e09e32e2-244d-480a-8d95-0465b2d0c537/_tmp_space.db
18/02/28 09:56:27 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive
18/02/28 09:56:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 09:56:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 09:56:27 INFO HiveMetaStore: 0: get_database: global_temp
18/02/28 09:56:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: global_temp	
18/02/28 09:56:27 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
18/02/28 09:56:28 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/Temp/ee7c473b-b58b-4e9c-8191-50d1b27381c3_resources
18/02/28 09:56:28 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/ee7c473b-b58b-4e9c-8191-50d1b27381c3
18/02/28 09:56:28 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/ee7c473b-b58b-4e9c-8191-50d1b27381c3
18/02/28 09:56:28 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/ee7c473b-b58b-4e9c-8191-50d1b27381c3/_tmp_space.db
18/02/28 09:56:28 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive
18/02/28 09:56:28 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
18/02/28 09:56:28 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 09:56:29 INFO HiveMetaStore: 0: get_database: default
18/02/28 09:56:29 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 09:56:29 INFO HiveMetaStore: 0: get_database: default
18/02/28 09:56:29 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 09:56:29 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 09:56:29 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 09:56:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 09:56:30 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 09:56:30 INFO HiveMetaStore: 0: get_database: default
18/02/28 09:56:30 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 09:56:30 INFO HiveMetaStore: 0: get_database: default
18/02/28 09:56:30 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 09:56:30 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 09:56:30 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 10:17:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:17:44 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 10:17:44 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:17:44 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:17:44 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:17:44 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:17:44 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 10:17:44 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 10:17:45 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 10:17:45 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
18/02/28 10:17:45 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
18/02/28 10:17:45 INFO DAGScheduler: Parents of final stage: List()
18/02/28 10:17:45 INFO DAGScheduler: Missing parents: List()
18/02/28 10:17:45 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55), which has no missing parents
18/02/28 10:17:45 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
18/02/28 10:17:46 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
18/02/28 10:17:46 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:59778 (size: 3.4 KB, free: 366.3 MB)
18/02/28 10:17:46 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
18/02/28 10:17:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0))
18/02/28 10:17:46 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/02/28 10:17:47 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 10:17:47 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/02/28 10:17:47 INFO Executor: Fetching spark://127.0.0.1:59757/jars/sparklyr-2.2-2.11.jar with timestamp 1519840581348
18/02/28 10:17:47 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:59757 after 14 ms (0 ms spent in bootstraps)
18/02/28 10:17:47 INFO Utils: Fetching spark://127.0.0.1:59757/jars/sparklyr-2.2-2.11.jar to C:\Users\JC\AppData\Local\Temp\spark-9bfd20db-2511-4b22-a7d0-a7f35aaa0dc3\userFiles-c724420c-faa0-46ba-be39-6834ad923ef4\fetchFileTemp1632087196432531655.tmp
18/02/28 10:17:47 INFO Executor: Adding file:/C:/Users/JC/AppData/Local/Temp/spark-9bfd20db-2511-4b22-a7d0-a7f35aaa0dc3/userFiles-c724420c-faa0-46ba-be39-6834ad923ef4/sparklyr-2.2-2.11.jar to class loader
18/02/28 10:17:47 INFO CodeGenerator: Code generated in 210.884649 ms
18/02/28 10:17:47 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
18/02/28 10:17:47 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 617 ms on localhost (executor driver) (1/1)
18/02/28 10:17:47 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/02/28 10:17:47 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.634 s
18/02/28 10:17:47 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 2.280412 s
18/02/28 10:17:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:18:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:18:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 10:18:03 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:18:03 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:18:03 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:18:03 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:18:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 10:18:03 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 10:18:03 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 10:18:03 INFO DAGScheduler: Got job 1 (collect at utils.scala:58) with 1 output partitions
18/02/28 10:18:03 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:58)
18/02/28 10:18:03 INFO DAGScheduler: Parents of final stage: List()
18/02/28 10:18:03 INFO DAGScheduler: Missing parents: List()
18/02/28 10:18:03 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at map at utils.scala:55), which has no missing parents
18/02/28 10:18:03 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
18/02/28 10:18:03 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
18/02/28 10:18:03 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:59778 (size: 3.4 KB, free: 366.3 MB)
18/02/28 10:18:03 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
18/02/28 10:18:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0))
18/02/28 10:18:03 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
18/02/28 10:18:03 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 10:18:03 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
18/02/28 10:18:03 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 927 bytes result sent to driver
18/02/28 10:18:03 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 10 ms on localhost (executor driver) (1/1)
18/02/28 10:18:03 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/02/28 10:18:03 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:58) finished in 0.011 s
18/02/28 10:18:03 INFO DAGScheduler: Job 1 finished: collect at utils.scala:58, took 0.019146 s
18/02/28 10:18:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:18:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:18:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 10:18:03 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:18:03 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:18:03 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:18:03 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:18:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 10:18:03 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 10:18:03 INFO SparkSqlParser: Parsing command: FAO
18/02/28 10:18:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:18:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM `FAO` AS `zzz1`
WHERE (0 = 1)
18/02/28 10:18:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:18:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 10:18:03 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:18:03 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:18:03 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:18:03 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:18:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 10:18:03 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 10:18:03 INFO CodeGenerator: Code generated in 14.743617 ms
18/02/28 10:18:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:18:08 INFO SparkSqlParser: Parsing command: SELECT * FROM fao LIMIT 5
18/02/28 10:18:08 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:18:08 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 10:18:08 INFO FileSourceStrategy: Output Data Schema: struct<year: string, production_area: string, country: string, iso: string, source: string ... 8 more fields>
18/02/28 10:18:09 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 10:18:09 INFO CodeGenerator: Code generated in 10.227653 ms
18/02/28 10:18:09 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 282.5 KB, free 366.0 MB)
18/02/28 10:18:09 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 24.1 KB, free 366.0 MB)
18/02/28 10:18:09 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:59778 (size: 24.1 KB, free: 366.3 MB)
18/02/28 10:18:09 INFO SparkContext: Created broadcast 2 from collect at utils.scala:211
18/02/28 10:18:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 81290886 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:18:09 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:18:09 INFO DAGScheduler: Got job 2 (collect at utils.scala:211) with 1 output partitions
18/02/28 10:18:09 INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:211)
18/02/28 10:18:09 INFO DAGScheduler: Parents of final stage: List()
18/02/28 10:18:09 INFO DAGScheduler: Missing parents: List()
18/02/28 10:18:09 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at utils.scala:211), which has no missing parents
18/02/28 10:18:09 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 11.6 KB, free 366.0 MB)
18/02/28 10:18:09 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.8 KB, free 366.0 MB)
18/02/28 10:18:09 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:59778 (size: 6.8 KB, free: 366.3 MB)
18/02/28 10:18:09 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
18/02/28 10:18:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 10:18:09 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
18/02/28 10:18:09 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 6775 bytes)
18/02/28 10:18:09 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
18/02/28 10:18:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1204806, partition values: [empty row]
18/02/28 10:18:09 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:59778 in memory (size: 3.4 KB, free: 366.3 MB)
18/02/28 10:18:09 INFO CodeGenerator: Code generated in 20.198954 ms
18/02/28 10:18:09 INFO ContextCleaner: Cleaned accumulator 49
18/02/28 10:18:09 INFO ContextCleaner: Cleaned accumulator 0
18/02/28 10:18:09 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:59778 in memory (size: 3.4 KB, free: 366.3 MB)
18/02/28 10:18:09 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1791 bytes result sent to driver
18/02/28 10:18:09 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 448 ms on localhost (executor driver) (1/1)
18/02/28 10:18:09 INFO DAGScheduler: ResultStage 2 (collect at utils.scala:211) finished in 0.448 s
18/02/28 10:18:09 INFO DAGScheduler: Job 2 finished: collect at utils.scala:211, took 0.482955 s
18/02/28 10:18:09 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/02/28 10:18:09 INFO CodeGenerator: Code generated in 18.242988 ms
18/02/28 10:19:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:19:11 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 10:19:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:19:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:19:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:19:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:19:11 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 10:19:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 10:19:11 INFO CodeGenerator: Code generated in 9.08059 ms
18/02/28 10:19:11 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 10:19:11 INFO DAGScheduler: Got job 3 (collect at utils.scala:58) with 1 output partitions
18/02/28 10:19:11 INFO DAGScheduler: Final stage: ResultStage 3 (collect at utils.scala:58)
18/02/28 10:19:11 INFO DAGScheduler: Parents of final stage: List()
18/02/28 10:19:11 INFO DAGScheduler: Missing parents: List()
18/02/28 10:19:11 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[17] at map at utils.scala:55), which has no missing parents
18/02/28 10:19:11 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.3 KB, free 366.0 MB)
18/02/28 10:19:11 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.5 KB, free 366.0 MB)
18/02/28 10:19:11 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:59778 (size: 3.5 KB, free: 366.3 MB)
18/02/28 10:19:11 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
18/02/28 10:19:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[17] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0))
18/02/28 10:19:11 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
18/02/28 10:19:11 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
18/02/28 10:19:11 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
18/02/28 10:19:11 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 890 bytes result sent to driver
18/02/28 10:19:11 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 11 ms on localhost (executor driver) (1/1)
18/02/28 10:19:11 INFO DAGScheduler: ResultStage 3 (collect at utils.scala:58) finished in 0.011 s
18/02/28 10:19:11 INFO DAGScheduler: Job 3 finished: collect at utils.scala:58, took 0.019460 s
18/02/28 10:19:11 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/02/28 10:19:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:19:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:19:40 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 10:19:40 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:19:40 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:19:40 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:19:40 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:19:40 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 10:19:40 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 10:19:40 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 10:19:40 INFO DAGScheduler: Got job 4 (collect at utils.scala:58) with 1 output partitions
18/02/28 10:19:40 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:58)
18/02/28 10:19:40 INFO DAGScheduler: Parents of final stage: List()
18/02/28 10:19:40 INFO DAGScheduler: Missing parents: List()
18/02/28 10:19:40 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[22] at map at utils.scala:55), which has no missing parents
18/02/28 10:19:40 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 6.3 KB, free 366.0 MB)
18/02/28 10:19:40 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.5 KB, free 366.0 MB)
18/02/28 10:19:40 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:59778 (size: 3.5 KB, free: 366.3 MB)
18/02/28 10:19:40 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
18/02/28 10:19:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[22] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0))
18/02/28 10:19:40 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
18/02/28 10:19:40 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
18/02/28 10:19:40 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
18/02/28 10:19:40 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 890 bytes result sent to driver
18/02/28 10:19:40 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 7 ms on localhost (executor driver) (1/1)
18/02/28 10:19:40 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/02/28 10:19:40 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:58) finished in 0.008 s
18/02/28 10:19:40 INFO DAGScheduler: Job 4 finished: collect at utils.scala:58, took 0.014559 s
18/02/28 10:19:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:19:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:19:40 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 10:19:40 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:19:40 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:19:40 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:19:40 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:19:40 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 10:19:40 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 10:19:40 INFO SparkSqlParser: Parsing command: FAO
18/02/28 10:19:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:19:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM `FAO` AS `zzz2`
WHERE (0 = 1)
18/02/28 10:19:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:19:41 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 10:19:41 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:19:41 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:19:41 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:19:41 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:19:41 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 10:19:41 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 10:19:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:19:41 INFO SparkSqlParser: Parsing command: SELECT * FROM fao LIMIT 5
18/02/28 10:19:41 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:19:41 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 10:19:41 INFO FileSourceStrategy: Output Data Schema: struct<year: int, production_area: int, country: string, iso: string, source: string ... 8 more fields>
18/02/28 10:19:41 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 10:19:41 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 282.5 KB, free 365.7 MB)
18/02/28 10:19:41 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.7 MB)
18/02/28 10:19:41 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:59778 (size: 24.1 KB, free: 366.2 MB)
18/02/28 10:19:41 INFO SparkContext: Created broadcast 6 from collect at utils.scala:211
18/02/28 10:19:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 81290886 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:19:41 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:19:41 INFO DAGScheduler: Got job 5 (collect at utils.scala:211) with 1 output partitions
18/02/28 10:19:41 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:211)
18/02/28 10:19:41 INFO DAGScheduler: Parents of final stage: List()
18/02/28 10:19:41 INFO DAGScheduler: Missing parents: List()
18/02/28 10:19:41 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[25] at collect at utils.scala:211), which has no missing parents
18/02/28 10:19:41 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 11.6 KB, free 365.7 MB)
18/02/28 10:19:41 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.8 KB, free 365.6 MB)
18/02/28 10:19:41 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:59778 (size: 6.8 KB, free: 366.2 MB)
18/02/28 10:19:41 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
18/02/28 10:19:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[25] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 10:19:41 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
18/02/28 10:19:41 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 6775 bytes)
18/02/28 10:19:41 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
18/02/28 10:19:41 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1204806, partition values: [empty row]
18/02/28 10:19:41 INFO CodeGenerator: Code generated in 20.573786 ms
18/02/28 10:19:41 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1407 bytes result sent to driver
18/02/28 10:19:41 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 38 ms on localhost (executor driver) (1/1)
18/02/28 10:19:41 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:211) finished in 0.039 s
18/02/28 10:19:41 INFO DAGScheduler: Job 5 finished: collect at utils.scala:211, took 0.047566 s
18/02/28 10:19:41 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/02/28 10:19:41 INFO CodeGenerator: Code generated in 14.879375 ms
18/02/28 10:21:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:21:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `FAO`
18/02/28 10:21:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:21:57 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 10:21:57 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:21:57 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:21:57 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:21:57 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:21:57 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 10:21:57 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 10:21:57 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 10:21:57 INFO DAGScheduler: Got job 6 (collect at utils.scala:58) with 1 output partitions
18/02/28 10:21:57 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:58)
18/02/28 10:21:57 INFO DAGScheduler: Parents of final stage: List()
18/02/28 10:21:57 INFO DAGScheduler: Missing parents: List()
18/02/28 10:21:57 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[30] at map at utils.scala:55), which has no missing parents
18/02/28 10:21:57 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 6.3 KB, free 365.6 MB)
18/02/28 10:21:57 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.5 KB, free 365.6 MB)
18/02/28 10:21:57 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:59778 (size: 3.5 KB, free: 366.2 MB)
18/02/28 10:21:57 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
18/02/28 10:21:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[30] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0))
18/02/28 10:21:57 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
18/02/28 10:21:57 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
18/02/28 10:21:57 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
18/02/28 10:21:57 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 933 bytes result sent to driver
18/02/28 10:21:57 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 9 ms on localhost (executor driver) (1/1)
18/02/28 10:21:57 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:58) finished in 0.009 s
18/02/28 10:21:57 INFO DAGScheduler: Job 6 finished: collect at utils.scala:58, took 0.019317 s
18/02/28 10:21:57 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
18/02/28 10:21:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:21:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:21:57 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 10:21:57 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:21:57 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:21:57 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:21:57 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:21:57 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 10:21:57 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 10:21:57 INFO SparkSqlParser: Parsing command: spark_fao
18/02/28 10:21:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:21:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao` AS `zzz3`
WHERE (0 = 1)
18/02/28 10:21:58 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:21:58 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 10:21:58 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:21:58 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:21:58 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:21:58 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:21:58 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 10:21:58 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 10:21:58 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:21:58 INFO SparkSqlParser: Parsing command: SELECT * FROM fao LIMIT 5
18/02/28 10:21:58 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:21:58 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 10:21:58 INFO FileSourceStrategy: Output Data Schema: struct<year: int, production_area: int, country: string, iso: string, source: string ... 8 more fields>
18/02/28 10:21:58 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 10:21:58 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 282.5 KB, free 365.4 MB)
18/02/28 10:21:58 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.3 MB)
18/02/28 10:21:58 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:59778 (size: 24.1 KB, free: 366.2 MB)
18/02/28 10:21:58 INFO SparkContext: Created broadcast 9 from collect at utils.scala:211
18/02/28 10:21:58 INFO FileSourceScanExec: Planning scan with bin packing, max size: 81290886 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:21:58 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:21:58 INFO DAGScheduler: Got job 7 (collect at utils.scala:211) with 1 output partitions
18/02/28 10:21:58 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:211)
18/02/28 10:21:58 INFO DAGScheduler: Parents of final stage: List()
18/02/28 10:21:58 INFO DAGScheduler: Missing parents: List()
18/02/28 10:21:58 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[33] at collect at utils.scala:211), which has no missing parents
18/02/28 10:21:58 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 11.6 KB, free 365.3 MB)
18/02/28 10:21:58 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 6.8 KB, free 365.3 MB)
18/02/28 10:21:58 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:59778 (size: 6.8 KB, free: 366.2 MB)
18/02/28 10:21:58 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
18/02/28 10:21:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[33] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 10:21:58 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
18/02/28 10:21:58 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 6775 bytes)
18/02/28 10:21:58 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
18/02/28 10:21:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1204806, partition values: [empty row]
18/02/28 10:21:58 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1364 bytes result sent to driver
18/02/28 10:21:58 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 9 ms on localhost (executor driver) (1/1)
18/02/28 10:21:58 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:211) finished in 0.010 s
18/02/28 10:21:58 INFO DAGScheduler: Job 7 finished: collect at utils.scala:211, took 0.018110 s
18/02/28 10:21:58 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
18/02/28 10:22:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:22:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao`
18/02/28 10:24:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:24:38 INFO SparkSqlParser: Parsing command: SELECT `year`, `country`, `source`, SUM(`quantity`) AS `quantity`
FROM `spark_fao`
GROUP BY `year`, `country`, `source`
18/02/28 10:24:38 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:24:38 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:24:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:24:38 INFO SparkSqlParser: Parsing command: SELECT `year`, `country`, `source`, SUM(`quantity`) AS `quantity`
FROM `spark_fao`
GROUP BY `year`, `country`, `source`
18/02/28 10:24:38 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:24:38 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:24:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:24:38 INFO SparkSqlParser: Parsing command: SELECT `year`, `country`, `source`, SUM(`quantity`) AS `quantity`
FROM `spark_fao`
GROUP BY `year`, `country`, `source`
18/02/28 10:24:38 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:24:38 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:24:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:24:38 INFO SparkSqlParser: Parsing command: SELECT `year`, `country`, `source`, SUM(`quantity`) AS `quantity`
FROM `spark_fao`
GROUP BY `year`, `country`, `source`
18/02/28 10:24:38 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:24:38 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:24:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:24:38 INFO SparkSqlParser: Parsing command: SELECT `year`, `country`, `source`, SUM(`quantity`) AS `quantity`
FROM `spark_fao`
GROUP BY `year`, `country`, `source`
18/02/28 10:24:38 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:24:38 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:24:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:24:38 INFO SparkSqlParser: Parsing command: SELECT `year`, `country`, `source`, SUM(`quantity`) AS `quantity`
FROM `spark_fao`
GROUP BY `year`, `country`, `source`
LIMIT 1000
18/02/28 10:24:38 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:24:38 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:24:38 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:24:38 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 10:24:38 INFO FileSourceStrategy: Output Data Schema: struct<year: int, country: string, source: string, quantity: int ... 2 more fields>
18/02/28 10:24:38 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 10:24:38 INFO CodeGenerator: Code generated in 30.527455 ms
18/02/28 10:24:38 INFO CodeGenerator: Code generated in 38.480729 ms
18/02/28 10:24:38 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 282.5 KB, free 365.0 MB)
18/02/28 10:24:38 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.0 MB)
18/02/28 10:24:38 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:59778 (size: 24.1 KB, free: 366.2 MB)
18/02/28 10:24:38 INFO SparkContext: Created broadcast 11 from collect at utils.scala:211
18/02/28 10:24:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 81290886 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:24:38 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:24:38 INFO DAGScheduler: Registering RDD 36 (collect at utils.scala:211)
18/02/28 10:24:38 INFO DAGScheduler: Got job 8 (collect at utils.scala:211) with 1 output partitions
18/02/28 10:24:38 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:211)
18/02/28 10:24:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
18/02/28 10:24:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
18/02/28 10:24:38 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[36] at collect at utils.scala:211), which has no missing parents
18/02/28 10:24:38 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 30.8 KB, free 365.0 MB)
18/02/28 10:24:38 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.7 KB, free 365.0 MB)
18/02/28 10:24:38 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:59778 (size: 14.7 KB, free: 366.2 MB)
18/02/28 10:24:38 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
18/02/28 10:24:38 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[36] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:24:38 INFO TaskSchedulerImpl: Adding task set 8.0 with 4 tasks
18/02/28 10:24:38 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 10:24:38 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 9, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 10:24:38 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 10, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 10:24:38 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 11, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 10:24:38 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
18/02/28 10:24:38 INFO Executor: Running task 2.0 in stage 8.0 (TID 10)
18/02/28 10:24:38 INFO Executor: Running task 1.0 in stage 8.0 (TID 9)
18/02/28 10:24:38 INFO Executor: Running task 3.0 in stage 8.0 (TID 11)
18/02/28 10:24:38 INFO CodeGenerator: Code generated in 6.071358 ms
18/02/28 10:24:38 INFO CodeGenerator: Code generated in 5.716625 ms
18/02/28 10:24:38 INFO CodeGenerator: Code generated in 6.492382 ms
18/02/28 10:24:38 INFO CodeGenerator: Code generated in 11.421614 ms
18/02/28 10:24:38 INFO CodeGenerator: Code generated in 6.93809 ms
18/02/28 10:24:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1204806, partition values: [empty row]
18/02/28 10:24:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-321003, partition values: [empty row]
18/02/28 10:24:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-627875, partition values: [empty row]
18/02/28 10:24:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-947694, partition values: [empty row]
18/02/28 10:24:38 INFO CodeGenerator: Code generated in 19.969047 ms
18/02/28 10:24:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 10:24:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-611199, partition values: [empty row]
18/02/28 10:24:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-911561, partition values: [empty row]
18/02/28 10:24:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-298811, partition values: [empty row]
18/02/28 10:24:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-290455, partition values: [empty row]
18/02/28 10:24:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1196479, partition values: [empty row]
18/02/28 10:24:39 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:59778 in memory (size: 6.8 KB, free: 366.2 MB)
18/02/28 10:24:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-605260, partition values: [empty row]
18/02/28 10:24:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-280542, partition values: [empty row]
18/02/28 10:24:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-888132, partition values: [empty row]
18/02/28 10:24:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-271062, partition values: [empty row]
18/02/28 10:24:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-596889, partition values: [empty row]
18/02/28 10:24:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-263566, partition values: [empty row]
18/02/28 10:24:39 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:59778 in memory (size: 3.5 KB, free: 366.2 MB)
18/02/28 10:24:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-1190585, partition values: [empty row]
18/02/28 10:24:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-258735, partition values: [empty row]
18/02/28 10:24:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-864231, partition values: [empty row]
18/02/28 10:24:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-593152, partition values: [empty row]
18/02/28 10:24:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-248403, partition values: [empty row]
18/02/28 10:24:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-240559, partition values: [empty row]
18/02/28 10:24:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-235427, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-572401, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-840496, partition values: [empty row]
18/02/28 10:24:40 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:59778 in memory (size: 6.8 KB, free: 366.2 MB)
18/02/28 10:24:40 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:59778 in memory (size: 3.5 KB, free: 366.2 MB)
18/02/28 10:24:40 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:59778 in memory (size: 3.5 KB, free: 366.2 MB)
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-231704, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-225461, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-555738, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-1185116, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-219609, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-810541, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-215210, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-210314, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-536614, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-1175401, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-507262, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-805147, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-451168, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-1166620, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-800684, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-441782, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-425454, partition values: [empty row]
18/02/28 10:24:40 INFO Executor: Finished task 3.0 in stage 8.0 (TID 11). 2103 bytes result sent to driver
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-799588, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-410697, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-364574, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-1155626, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-359989, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-798172, partition values: [empty row]
18/02/28 10:24:40 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 11) in 1559 ms on localhost (executor driver) (1/4)
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-350556, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-339292, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-331798, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-793415, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-784611, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-1136067, partition values: [empty row]
18/02/28 10:24:40 INFO Executor: Finished task 2.0 in stage 8.0 (TID 10). 2103 bytes result sent to driver
18/02/28 10:24:40 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 10) in 1699 ms on localhost (executor driver) (2/4)
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-722307, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-1128021, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-702541, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-686171, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-1117254, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-670760, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-640361, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-1103802, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-1076645, partition values: [empty row]
18/02/28 10:24:40 INFO Executor: Finished task 1.0 in stage 8.0 (TID 9). 2103 bytes result sent to driver
18/02/28 10:24:40 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 9) in 1867 ms on localhost (executor driver) (3/4)
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-1044232, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-1018463, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-1002968, partition values: [empty row]
18/02/28 10:24:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-975348, partition values: [empty row]
18/02/28 10:24:40 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 2060 bytes result sent to driver
18/02/28 10:24:40 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 2002 ms on localhost (executor driver) (4/4)
18/02/28 10:24:40 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
18/02/28 10:24:40 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:211) finished in 2.003 s
18/02/28 10:24:40 INFO DAGScheduler: looking for newly runnable stages
18/02/28 10:24:40 INFO DAGScheduler: running: Set()
18/02/28 10:24:40 INFO DAGScheduler: waiting: Set(ResultStage 9)
18/02/28 10:24:40 INFO DAGScheduler: failed: Set()
18/02/28 10:24:40 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[39] at collect at utils.scala:211), which has no missing parents
18/02/28 10:24:40 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 28.0 KB, free 365.0 MB)
18/02/28 10:24:40 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 13.4 KB, free 365.0 MB)
18/02/28 10:24:40 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:59778 (size: 13.4 KB, free: 366.2 MB)
18/02/28 10:24:40 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
18/02/28 10:24:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[39] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 10:24:40 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
18/02/28 10:24:40 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 12, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 10:24:40 INFO Executor: Running task 0.0 in stage 9.0 (TID 12)
18/02/28 10:24:40 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:24:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
18/02/28 10:24:40 WARN Executor: Managed memory leak detected; size = 4456448 bytes, TID = 12
18/02/28 10:24:40 INFO Executor: Finished task 0.0 in stage 9.0 (TID 12). 26415 bytes result sent to driver
18/02/28 10:24:40 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 12) in 73 ms on localhost (executor driver) (1/1)
18/02/28 10:24:40 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:211) finished in 0.075 s
18/02/28 10:24:40 INFO DAGScheduler: Job 8 finished: collect at utils.scala:211, took 2.116581 s
18/02/28 10:24:40 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
18/02/28 10:24:40 INFO CodeGenerator: Code generated in 8.713869 ms
18/02/28 10:26:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:26:00 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 10:26:00 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:26:00 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:26:00 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:26:00 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:26:00 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 10:26:00 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 10:26:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:26:00 INFO SparkSqlParser: Parsing command: SELECT * FROM fao LIMIT 5
18/02/28 10:26:00 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:26:00 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 10:26:00 INFO FileSourceStrategy: Output Data Schema: struct<year: int, production_area: int, country: string, iso: string, source: string ... 8 more fields>
18/02/28 10:26:00 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 10:26:00 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 282.5 KB, free 364.7 MB)
18/02/28 10:26:00 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.7 MB)
18/02/28 10:26:00 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:59778 (size: 24.1 KB, free: 366.1 MB)
18/02/28 10:26:00 INFO SparkContext: Created broadcast 14 from collect at utils.scala:211
18/02/28 10:26:00 INFO FileSourceScanExec: Planning scan with bin packing, max size: 81290886 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:26:00 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:26:00 INFO DAGScheduler: Got job 9 (collect at utils.scala:211) with 1 output partitions
18/02/28 10:26:00 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:211)
18/02/28 10:26:00 INFO DAGScheduler: Parents of final stage: List()
18/02/28 10:26:00 INFO DAGScheduler: Missing parents: List()
18/02/28 10:26:00 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[42] at collect at utils.scala:211), which has no missing parents
18/02/28 10:26:00 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 11.6 KB, free 364.7 MB)
18/02/28 10:26:00 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 6.8 KB, free 364.7 MB)
18/02/28 10:26:00 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:59778 (size: 6.8 KB, free: 366.1 MB)
18/02/28 10:26:00 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
18/02/28 10:26:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[42] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 10:26:00 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
18/02/28 10:26:00 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 6775 bytes)
18/02/28 10:26:00 INFO Executor: Running task 0.0 in stage 10.0 (TID 13)
18/02/28 10:26:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1204806, partition values: [empty row]
18/02/28 10:26:00 INFO Executor: Finished task 0.0 in stage 10.0 (TID 13). 1321 bytes result sent to driver
18/02/28 10:26:00 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 13) in 19 ms on localhost (executor driver) (1/1)
18/02/28 10:26:00 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:211) finished in 0.020 s
18/02/28 10:26:00 INFO DAGScheduler: Job 9 finished: collect at utils.scala:211, took 0.025876 s
18/02/28 10:26:00 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
18/02/28 10:26:21 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:59778 in memory (size: 6.8 KB, free: 366.1 MB)
18/02/28 10:26:21 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:59778 in memory (size: 13.4 KB, free: 366.2 MB)
18/02/28 10:26:21 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:26:21 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:59778 in memory (size: 6.8 KB, free: 366.2 MB)
18/02/28 10:26:21 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_fao`
18/02/28 10:26:21 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:59778 in memory (size: 14.7 KB, free: 366.2 MB)
18/02/28 10:26:21 INFO ContextCleaner: Cleaned accumulator 128
18/02/28 10:26:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:26:21 INFO ContextCleaner: Cleaned accumulator 103
18/02/28 10:26:21 INFO ContextCleaner: Cleaned accumulator 236
18/02/28 10:26:21 INFO ContextCleaner: Cleaned accumulator 182
18/02/28 10:26:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:26:21 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:26:21 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_fao`
18/02/28 10:26:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:26:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:26:21 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:26:21 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_fao`
18/02/28 10:26:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:26:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:26:21 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:26:21 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_fao`
18/02/28 10:26:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:26:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:26:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:26:22 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_fao`
18/02/28 10:26:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:26:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:26:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:26:22 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_fao`
LIMIT 1000
18/02/28 10:26:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:26:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:26:22 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:26:22 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 10:26:22 INFO FileSourceStrategy: Output Data Schema: struct<>
18/02/28 10:26:22 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 10:26:22 INFO CodeGenerator: Code generated in 8.827412 ms
18/02/28 10:26:22 INFO CodeGenerator: Code generated in 10.05205 ms
18/02/28 10:26:22 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 282.5 KB, free 364.5 MB)
18/02/28 10:26:22 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.5 MB)
18/02/28 10:26:22 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:59778 (size: 24.1 KB, free: 366.2 MB)
18/02/28 10:26:22 INFO SparkContext: Created broadcast 16 from collect at utils.scala:211
18/02/28 10:26:22 INFO FileSourceScanExec: Planning scan with bin packing, max size: 81290886 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:26:22 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:26:22 INFO DAGScheduler: Registering RDD 45 (collect at utils.scala:211)
18/02/28 10:26:22 INFO DAGScheduler: Got job 10 (collect at utils.scala:211) with 1 output partitions
18/02/28 10:26:22 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:211)
18/02/28 10:26:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
18/02/28 10:26:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
18/02/28 10:26:22 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[45] at collect at utils.scala:211), which has no missing parents
18/02/28 10:26:22 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 13.9 KB, free 364.5 MB)
18/02/28 10:26:22 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 7.9 KB, free 364.5 MB)
18/02/28 10:26:22 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:59778 (size: 7.9 KB, free: 366.2 MB)
18/02/28 10:26:22 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
18/02/28 10:26:22 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[45] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:26:22 INFO TaskSchedulerImpl: Adding task set 11.0 with 4 tasks
18/02/28 10:26:22 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 10:26:22 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 15, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 10:26:22 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 16, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 10:26:22 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 17, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 10:26:22 INFO Executor: Running task 0.0 in stage 11.0 (TID 14)
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1204806, partition values: [empty row]
18/02/28 10:26:22 INFO Executor: Running task 2.0 in stage 11.0 (TID 16)
18/02/28 10:26:22 INFO Executor: Running task 3.0 in stage 11.0 (TID 17)
18/02/28 10:26:22 INFO Executor: Running task 1.0 in stage 11.0 (TID 15)
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-947694, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-321003, partition values: [empty row]
18/02/28 10:26:22 INFO CodeGenerator: Code generated in 15.922768 ms
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-627875, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-611199, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-911561, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1196479, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-298811, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-605260, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-290455, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-888132, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-280542, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-596889, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-271062, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-263566, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-1190585, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-593152, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-864231, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-258735, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-248403, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-240559, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-235427, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-572401, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-1185116, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-555738, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-840496, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-231704, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-225461, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-219609, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-1175401, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-215210, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-810541, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-536614, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-210314, partition values: [empty row]
18/02/28 10:26:22 INFO ContextCleaner: Cleaned accumulator 329
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-805147, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-507262, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-1166620, partition values: [empty row]
18/02/28 10:26:22 INFO Executor: Finished task 3.0 in stage 11.0 (TID 17). 1585 bytes result sent to driver
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-451168, partition values: [empty row]
18/02/28 10:26:22 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 17) in 724 ms on localhost (executor driver) (1/4)
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-441782, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-800684, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-425454, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-1155626, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-410697, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-799588, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-364574, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-1136067, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-359989, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-798172, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-350556, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-793415, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-339292, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-1128021, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-331798, partition values: [empty row]
18/02/28 10:26:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-784611, partition values: [empty row]
18/02/28 10:26:22 INFO Executor: Finished task 2.0 in stage 11.0 (TID 16). 1585 bytes result sent to driver
18/02/28 10:26:22 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 16) in 839 ms on localhost (executor driver) (2/4)
18/02/28 10:26:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-722307, partition values: [empty row]
18/02/28 10:26:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-1117254, partition values: [empty row]
18/02/28 10:26:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-702541, partition values: [empty row]
18/02/28 10:26:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-686171, partition values: [empty row]
18/02/28 10:26:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-1103802, partition values: [empty row]
18/02/28 10:26:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-670760, partition values: [empty row]
18/02/28 10:26:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-1076645, partition values: [empty row]
18/02/28 10:26:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-640361, partition values: [empty row]
18/02/28 10:26:23 INFO Executor: Finished task 1.0 in stage 11.0 (TID 15). 1585 bytes result sent to driver
18/02/28 10:26:23 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 15) in 954 ms on localhost (executor driver) (3/4)
18/02/28 10:26:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-1044232, partition values: [empty row]
18/02/28 10:26:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-1018463, partition values: [empty row]
18/02/28 10:26:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-1002968, partition values: [empty row]
18/02/28 10:26:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-975348, partition values: [empty row]
18/02/28 10:26:23 INFO Executor: Finished task 0.0 in stage 11.0 (TID 14). 1585 bytes result sent to driver
18/02/28 10:26:23 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 14) in 1054 ms on localhost (executor driver) (4/4)
18/02/28 10:26:23 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
18/02/28 10:26:23 INFO DAGScheduler: ShuffleMapStage 11 (collect at utils.scala:211) finished in 1.056 s
18/02/28 10:26:23 INFO DAGScheduler: looking for newly runnable stages
18/02/28 10:26:23 INFO DAGScheduler: running: Set()
18/02/28 10:26:23 INFO DAGScheduler: waiting: Set(ResultStage 12)
18/02/28 10:26:23 INFO DAGScheduler: failed: Set()
18/02/28 10:26:23 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[48] at collect at utils.scala:211), which has no missing parents
18/02/28 10:26:23 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 6.9 KB, free 364.5 MB)
18/02/28 10:26:23 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.5 MB)
18/02/28 10:26:23 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:59778 (size: 3.7 KB, free: 366.1 MB)
18/02/28 10:26:23 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
18/02/28 10:26:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[48] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 10:26:23 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
18/02/28 10:26:23 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 18, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 10:26:23 INFO Executor: Running task 0.0 in stage 12.0 (TID 18)
18/02/28 10:26:23 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:26:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:26:23 INFO Executor: Finished task 0.0 in stage 12.0 (TID 18). 1471 bytes result sent to driver
18/02/28 10:26:23 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 18) in 7 ms on localhost (executor driver) (1/1)
18/02/28 10:26:23 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
18/02/28 10:26:23 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:211) finished in 0.008 s
18/02/28 10:26:23 INFO DAGScheduler: Job 10 finished: collect at utils.scala:211, took 1.076161 s
18/02/28 10:26:23 INFO CodeGenerator: Code generated in 5.305121 ms
18/02/28 10:30:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:30:18 INFO SparkSqlParser: Parsing command: SELECT `year`, count(*) AS `n()`
FROM `spark_fao`
GROUP BY `year`
18/02/28 10:30:18 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:30:18 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:30:18 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:30:18 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 10:30:18 INFO FileSourceStrategy: Output Data Schema: struct<year: int>
18/02/28 10:30:18 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 10:30:18 INFO CodeGenerator: Code generated in 17.345225 ms
18/02/28 10:30:18 INFO CodeGenerator: Code generated in 23.042103 ms
18/02/28 10:30:18 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 282.5 KB, free 364.2 MB)
18/02/28 10:30:18 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.2 MB)
18/02/28 10:30:18 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:59778 (size: 24.1 KB, free: 366.1 MB)
18/02/28 10:30:18 INFO SparkContext: Created broadcast 19 from collect at utils.scala:211
18/02/28 10:30:18 INFO FileSourceScanExec: Planning scan with bin packing, max size: 81290886 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:30:18 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:30:18 INFO DAGScheduler: Registering RDD 51 (collect at utils.scala:211)
18/02/28 10:30:18 INFO DAGScheduler: Got job 11 (collect at utils.scala:211) with 4 output partitions
18/02/28 10:30:18 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:211)
18/02/28 10:30:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
18/02/28 10:30:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
18/02/28 10:30:18 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[51] at collect at utils.scala:211), which has no missing parents
18/02/28 10:30:18 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 25.8 KB, free 364.1 MB)
18/02/28 10:30:18 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 13.0 KB, free 364.1 MB)
18/02/28 10:30:18 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:59778 (size: 13.0 KB, free: 366.1 MB)
18/02/28 10:30:18 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
18/02/28 10:30:18 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[51] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:30:18 INFO TaskSchedulerImpl: Adding task set 13.0 with 4 tasks
18/02/28 10:30:18 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 10:30:18 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 20, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 10:30:18 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 21, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 10:30:18 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 22, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 10:30:18 INFO Executor: Running task 0.0 in stage 13.0 (TID 19)
18/02/28 10:30:18 INFO Executor: Running task 2.0 in stage 13.0 (TID 21)
18/02/28 10:30:18 INFO Executor: Running task 3.0 in stage 13.0 (TID 22)
18/02/28 10:30:18 INFO Executor: Running task 1.0 in stage 13.0 (TID 20)
18/02/28 10:30:18 INFO CodeGenerator: Code generated in 7.154949 ms
18/02/28 10:30:18 INFO CodeGenerator: Code generated in 10.766452 ms
18/02/28 10:30:18 INFO CodeGenerator: Code generated in 14.108555 ms
18/02/28 10:30:18 INFO CodeGenerator: Code generated in 9.015356 ms
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1204806, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-627875, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-321003, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-947694, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-611199, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-605260, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-911561, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-298811, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1196479, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-596889, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-290455, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-888132, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-280542, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-593152, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-271062, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-1190585, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-263566, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-258735, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-248403, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-572401, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-864231, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-240559, partition values: [empty row]
18/02/28 10:30:18 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:59778 in memory (size: 7.9 KB, free: 366.1 MB)
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-235427, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-1185116, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-555738, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-231704, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-225461, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-536614, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-840496, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-219609, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-215210, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-1175401, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-210314, partition values: [empty row]
18/02/28 10:30:18 INFO ContextCleaner: Cleaned accumulator 393
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-507262, partition values: [empty row]
18/02/28 10:30:18 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:59778 in memory (size: 3.7 KB, free: 366.1 MB)
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-810541, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-451168, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-805147, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-1166620, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-441782, partition values: [empty row]
18/02/28 10:30:18 INFO Executor: Finished task 3.0 in stage 13.0 (TID 22). 2060 bytes result sent to driver
18/02/28 10:30:18 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 22) in 395 ms on localhost (executor driver) (1/4)
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-425454, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-800684, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-410697, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-1155626, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-364574, partition values: [empty row]
18/02/28 10:30:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-799588, partition values: [empty row]
18/02/28 10:30:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-359989, partition values: [empty row]
18/02/28 10:30:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-350556, partition values: [empty row]
18/02/28 10:30:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-1136067, partition values: [empty row]
18/02/28 10:30:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-798172, partition values: [empty row]
18/02/28 10:30:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-339292, partition values: [empty row]
18/02/28 10:30:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-331798, partition values: [empty row]
18/02/28 10:30:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-793415, partition values: [empty row]
18/02/28 10:30:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-1128021, partition values: [empty row]
18/02/28 10:30:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-784611, partition values: [empty row]
18/02/28 10:30:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-1117254, partition values: [empty row]
18/02/28 10:30:19 INFO Executor: Finished task 2.0 in stage 13.0 (TID 21). 2060 bytes result sent to driver
18/02/28 10:30:19 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 21) in 521 ms on localhost (executor driver) (2/4)
18/02/28 10:30:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-722307, partition values: [empty row]
18/02/28 10:30:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-1103802, partition values: [empty row]
18/02/28 10:30:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-702541, partition values: [empty row]
18/02/28 10:30:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-686171, partition values: [empty row]
18/02/28 10:30:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-1076645, partition values: [empty row]
18/02/28 10:30:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-670760, partition values: [empty row]
18/02/28 10:30:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-640361, partition values: [empty row]
18/02/28 10:30:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-1044232, partition values: [empty row]
18/02/28 10:30:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-1018463, partition values: [empty row]
18/02/28 10:30:19 INFO Executor: Finished task 1.0 in stage 13.0 (TID 20). 2103 bytes result sent to driver
18/02/28 10:30:19 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 20) in 650 ms on localhost (executor driver) (3/4)
18/02/28 10:30:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-1002968, partition values: [empty row]
18/02/28 10:30:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-975348, partition values: [empty row]
18/02/28 10:30:19 INFO Executor: Finished task 0.0 in stage 13.0 (TID 19). 2060 bytes result sent to driver
18/02/28 10:30:19 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 19) in 716 ms on localhost (executor driver) (4/4)
18/02/28 10:30:19 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
18/02/28 10:30:19 INFO DAGScheduler: ShuffleMapStage 13 (collect at utils.scala:211) finished in 0.716 s
18/02/28 10:30:19 INFO DAGScheduler: looking for newly runnable stages
18/02/28 10:30:19 INFO DAGScheduler: running: Set()
18/02/28 10:30:19 INFO DAGScheduler: waiting: Set(ResultStage 14)
18/02/28 10:30:19 INFO DAGScheduler: failed: Set()
18/02/28 10:30:19 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[54] at collect at utils.scala:211), which has no missing parents
18/02/28 10:30:19 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 24.3 KB, free 364.1 MB)
18/02/28 10:30:19 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 12.2 KB, free 364.1 MB)
18/02/28 10:30:19 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:59778 (size: 12.2 KB, free: 366.1 MB)
18/02/28 10:30:19 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
18/02/28 10:30:19 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 14 (MapPartitionsRDD[54] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:30:19 INFO TaskSchedulerImpl: Adding task set 14.0 with 4 tasks
18/02/28 10:30:19 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 23, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 10:30:19 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 24, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 10:30:19 INFO TaskSetManager: Starting task 2.0 in stage 14.0 (TID 25, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 10:30:19 INFO TaskSetManager: Starting task 3.0 in stage 14.0 (TID 26, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 10:30:19 INFO Executor: Running task 0.0 in stage 14.0 (TID 23)
18/02/28 10:30:19 INFO Executor: Running task 1.0 in stage 14.0 (TID 24)
18/02/28 10:30:19 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:30:19 INFO Executor: Running task 3.0 in stage 14.0 (TID 26)
18/02/28 10:30:19 INFO Executor: Running task 2.0 in stage 14.0 (TID 25)
18/02/28 10:30:19 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:30:19 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:30:19 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:30:19 INFO Executor: Finished task 2.0 in stage 14.0 (TID 25). 2748 bytes result sent to driver
18/02/28 10:30:19 INFO Executor: Finished task 3.0 in stage 14.0 (TID 26). 2768 bytes result sent to driver
18/02/28 10:30:19 INFO Executor: Finished task 0.0 in stage 14.0 (TID 23). 2729 bytes result sent to driver
18/02/28 10:30:19 INFO TaskSetManager: Finished task 2.0 in stage 14.0 (TID 25) in 27 ms on localhost (executor driver) (1/4)
18/02/28 10:30:19 INFO TaskSetManager: Finished task 3.0 in stage 14.0 (TID 26) in 28 ms on localhost (executor driver) (2/4)
18/02/28 10:30:19 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 23) in 31 ms on localhost (executor driver) (3/4)
18/02/28 10:30:19 INFO Executor: Finished task 1.0 in stage 14.0 (TID 24). 2802 bytes result sent to driver
18/02/28 10:30:19 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:59778 in memory (size: 13.0 KB, free: 366.1 MB)
18/02/28 10:30:19 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 24) in 35 ms on localhost (executor driver) (4/4)
18/02/28 10:30:19 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
18/02/28 10:30:19 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:211) finished in 0.036 s
18/02/28 10:30:19 INFO DAGScheduler: Job 11 finished: collect at utils.scala:211, took 0.764601 s
18/02/28 10:30:19 INFO CodeGenerator: Code generated in 5.418311 ms
18/02/28 10:30:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:30:26 INFO SparkSqlParser: Parsing command: SELECT `year`, `source`
FROM `spark_fao`
GROUP BY `year`
18/02/28 10:31:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:31:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao`
18/02/28 10:31:37 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e059753c1e
18/02/28 10:31:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:31:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e059753c1e` AS `zzz4`
WHERE (0 = 1)
18/02/28 10:31:37 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e07d7f675f
18/02/28 10:31:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:31:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e07d7f675f` AS `zzz5`
WHERE (0 = 1)
18/02/28 10:31:38 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e028c06675
18/02/28 10:31:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:31:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e028c06675` AS `zzz6`
WHERE (0 = 1)
18/02/28 10:31:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:31:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e059753c1e`
18/02/28 10:31:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:31:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e059753c1e`
LIMIT 10
18/02/28 10:31:45 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:31:45 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 10:31:45 INFO FileSourceStrategy: Output Data Schema: struct<year: int, production_area: int, country: string, iso: string, source: string ... 8 more fields>
18/02/28 10:31:45 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 10:31:45 INFO CodeGenerator: Code generated in 17.374845 ms
18/02/28 10:31:45 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 282.5 KB, free 363.9 MB)
18/02/28 10:31:45 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 24.1 KB, free 363.9 MB)
18/02/28 10:31:45 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:59778 (size: 24.1 KB, free: 366.1 MB)
18/02/28 10:31:45 INFO SparkContext: Created broadcast 22 from collect at utils.scala:211
18/02/28 10:31:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 81290886 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:31:45 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:31:45 INFO DAGScheduler: Got job 12 (collect at utils.scala:211) with 1 output partitions
18/02/28 10:31:45 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:211)
18/02/28 10:31:45 INFO DAGScheduler: Parents of final stage: List()
18/02/28 10:31:45 INFO DAGScheduler: Missing parents: List()
18/02/28 10:31:45 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[57] at collect at utils.scala:211), which has no missing parents
18/02/28 10:31:45 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 21.2 KB, free 363.8 MB)
18/02/28 10:31:45 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 10.4 KB, free 363.8 MB)
18/02/28 10:31:45 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:59778 (size: 10.4 KB, free: 366.1 MB)
18/02/28 10:31:45 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
18/02/28 10:31:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[57] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 10:31:45 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
18/02/28 10:31:45 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 6775 bytes)
18/02/28 10:31:45 INFO Executor: Running task 0.0 in stage 15.0 (TID 27)
18/02/28 10:31:45 INFO CodeGenerator: Code generated in 19.408034 ms
18/02/28 10:31:45 INFO CodeGenerator: Code generated in 5.667259 ms
18/02/28 10:31:45 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1204806, partition values: [empty row]
18/02/28 10:31:45 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1196479, partition values: [empty row]
18/02/28 10:31:45 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-1190585, partition values: [empty row]
18/02/28 10:31:45 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-1185116, partition values: [empty row]
18/02/28 10:31:45 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:59778 in memory (size: 12.2 KB, free: 366.1 MB)
18/02/28 10:31:45 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-1175401, partition values: [empty row]
18/02/28 10:31:45 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-1166620, partition values: [empty row]
18/02/28 10:31:45 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-1155626, partition values: [empty row]
18/02/28 10:31:45 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-1136067, partition values: [empty row]
18/02/28 10:31:46 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-1128021, partition values: [empty row]
18/02/28 10:31:46 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-1117254, partition values: [empty row]
18/02/28 10:31:46 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-1103802, partition values: [empty row]
18/02/28 10:31:46 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-1076645, partition values: [empty row]
18/02/28 10:31:46 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-1044232, partition values: [empty row]
18/02/28 10:31:46 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-1018463, partition values: [empty row]
18/02/28 10:31:46 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-1002968, partition values: [empty row]
18/02/28 10:31:46 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-975348, partition values: [empty row]
18/02/28 10:31:46 INFO Executor: Finished task 0.0 in stage 15.0 (TID 27). 1826 bytes result sent to driver
18/02/28 10:31:46 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 27) in 1586 ms on localhost (executor driver) (1/1)
18/02/28 10:31:46 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:211) finished in 1.587 s
18/02/28 10:31:46 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
18/02/28 10:31:46 INFO DAGScheduler: Job 12 finished: collect at utils.scala:211, took 1.593067 s
18/02/28 10:31:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:31:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e07d7f675f`
18/02/28 10:31:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:31:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e07d7f675f`
LIMIT 10
18/02/28 10:31:46 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:31:46 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 10:31:46 INFO FileSourceStrategy: Output Data Schema: struct<year: int, production_area: int, country: string, iso: string, source: string ... 8 more fields>
18/02/28 10:31:46 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 10:31:46 INFO CodeGenerator: Code generated in 12.429745 ms
18/02/28 10:31:46 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 282.5 KB, free 363.6 MB)
18/02/28 10:31:46 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 24.1 KB, free 363.6 MB)
18/02/28 10:31:46 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:59778 (size: 24.1 KB, free: 366.1 MB)
18/02/28 10:31:46 INFO SparkContext: Created broadcast 24 from collect at utils.scala:211
18/02/28 10:31:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 81290886 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:31:46 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:31:46 INFO DAGScheduler: Got job 13 (collect at utils.scala:211) with 1 output partitions
18/02/28 10:31:46 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:211)
18/02/28 10:31:46 INFO DAGScheduler: Parents of final stage: List()
18/02/28 10:31:46 INFO DAGScheduler: Missing parents: List()
18/02/28 10:31:46 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[60] at collect at utils.scala:211), which has no missing parents
18/02/28 10:31:46 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 21.2 KB, free 363.6 MB)
18/02/28 10:31:47 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 10.4 KB, free 363.5 MB)
18/02/28 10:31:47 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:59778 (size: 10.4 KB, free: 366.1 MB)
18/02/28 10:31:47 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1006
18/02/28 10:31:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[60] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 10:31:47 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
18/02/28 10:31:47 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 6775 bytes)
18/02/28 10:31:47 INFO Executor: Running task 0.0 in stage 16.0 (TID 28)
18/02/28 10:31:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1204806, partition values: [empty row]
18/02/28 10:31:47 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:59778 in memory (size: 10.4 KB, free: 366.1 MB)
18/02/28 10:31:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1196479, partition values: [empty row]
18/02/28 10:31:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-1190585, partition values: [empty row]
18/02/28 10:31:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-1185116, partition values: [empty row]
18/02/28 10:31:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-1175401, partition values: [empty row]
18/02/28 10:31:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-1166620, partition values: [empty row]
18/02/28 10:31:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-1155626, partition values: [empty row]
18/02/28 10:31:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-1136067, partition values: [empty row]
18/02/28 10:31:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-1128021, partition values: [empty row]
18/02/28 10:31:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-1117254, partition values: [empty row]
18/02/28 10:31:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-1103802, partition values: [empty row]
18/02/28 10:31:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-1076645, partition values: [empty row]
18/02/28 10:31:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-1044232, partition values: [empty row]
18/02/28 10:31:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-1018463, partition values: [empty row]
18/02/28 10:31:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-1002968, partition values: [empty row]
18/02/28 10:31:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-975348, partition values: [empty row]
18/02/28 10:31:48 INFO Executor: Finished task 0.0 in stage 16.0 (TID 28). 1826 bytes result sent to driver
18/02/28 10:31:48 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 28) in 1460 ms on localhost (executor driver) (1/1)
18/02/28 10:31:48 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
18/02/28 10:31:48 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:211) finished in 1.461 s
18/02/28 10:31:48 INFO DAGScheduler: Job 13 finished: collect at utils.scala:211, took 1.466882 s
18/02/28 10:36:00 INFO SparkContext: Invoking stop() from shutdown hook
18/02/28 10:36:00 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
18/02/28 10:36:00 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/02/28 10:36:00 INFO MemoryStore: MemoryStore cleared
18/02/28 10:36:00 INFO BlockManager: BlockManager stopped
18/02/28 10:36:00 INFO BlockManagerMaster: BlockManagerMaster stopped
18/02/28 10:36:00 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/02/28 10:36:00 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-9bfd20db-2511-4b22-a7d0-a7f35aaa0dc3\userFiles-c724420c-faa0-46ba-be39-6834ad923ef4
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-9bfd20db-2511-4b22-a7d0-a7f35aaa0dc3\userFiles-c724420c-faa0-46ba-be39-6834ad923ef4
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1937)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1936)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 10:36:00 INFO SparkContext: Successfully stopped SparkContext
18/02/28 10:36:00 INFO ShutdownHookManager: Shutdown hook called
18/02/28 10:36:00 INFO ShutdownHookManager: Deleting directory C:\Users\JC\AppData\Local\Temp\spark-9bfd20db-2511-4b22-a7d0-a7f35aaa0dc3\userFiles-c724420c-faa0-46ba-be39-6834ad923ef4
18/02/28 10:36:00 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-9bfd20db-2511-4b22-a7d0-a7f35aaa0dc3\userFiles-c724420c-faa0-46ba-be39-6834ad923ef4
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-9bfd20db-2511-4b22-a7d0-a7f35aaa0dc3\userFiles-c724420c-faa0-46ba-be39-6834ad923ef4
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 10:36:00 INFO ShutdownHookManager: Deleting directory C:\Users\JC\AppData\Local\Temp\spark-9bfd20db-2511-4b22-a7d0-a7f35aaa0dc3
18/02/28 10:36:00 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-9bfd20db-2511-4b22-a7d0-a7f35aaa0dc3
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-9bfd20db-2511-4b22-a7d0-a7f35aaa0dc3
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 10:36:18 INFO SparkContext: Running Spark version 2.2.0
18/02/28 10:36:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/02/28 10:36:18 INFO SparkContext: Submitted application: sparklyr
18/02/28 10:36:18 INFO SecurityManager: Changing view acls to: JC
18/02/28 10:36:18 INFO SecurityManager: Changing modify acls to: JC
18/02/28 10:36:18 INFO SecurityManager: Changing view acls groups to: 
18/02/28 10:36:18 INFO SecurityManager: Changing modify acls groups to: 
18/02/28 10:36:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(JC); groups with view permissions: Set(); users  with modify permissions: Set(JC); groups with modify permissions: Set()
18/02/28 10:36:18 INFO Utils: Successfully started service 'sparkDriver' on port 60048.
18/02/28 10:36:18 INFO SparkEnv: Registering MapOutputTracker
18/02/28 10:36:18 INFO SparkEnv: Registering BlockManagerMaster
18/02/28 10:36:18 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/02/28 10:36:18 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/02/28 10:36:18 INFO DiskBlockManager: Created local directory at C:\Users\JC\AppData\Local\Temp\blockmgr-32d28e6c-569a-4196-8656-dee8ec193a2a
18/02/28 10:36:18 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/02/28 10:36:19 INFO SparkEnv: Registering OutputCommitCoordinator
18/02/28 10:36:19 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/02/28 10:36:19 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
18/02/28 10:36:19 INFO SparkContext: Added JAR file:/C:/Users/JC/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:60048/jars/sparklyr-2.2-2.11.jar with timestamp 1519842979274
18/02/28 10:36:19 INFO Executor: Starting executor ID driver on host localhost
18/02/28 10:36:19 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60069.
18/02/28 10:36:19 INFO NettyBlockTransferService: Server created on 127.0.0.1:60069
18/02/28 10:36:19 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/02/28 10:36:19 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 60069, None)
18/02/28 10:36:19 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:60069 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 60069, None)
18/02/28 10:36:19 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 60069, None)
18/02/28 10:36:19 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 60069, None)
18/02/28 10:36:19 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/02/28 10:36:19 INFO SharedState: loading hive config file: file:/C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
18/02/28 10:36:19 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:\Users\JC\AppData\Local\spark\spark-2.2.0-bin-hadoop2.7\tmp\hive') to the value of spark.sql.warehouse.dir ('C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive').
18/02/28 10:36:19 INFO SharedState: Warehouse path is 'C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive'.
18/02/28 10:36:20 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
18/02/28 10:36:21 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
18/02/28 10:36:21 INFO ObjectStore: ObjectStore, initialize called
18/02/28 10:36:21 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
18/02/28 10:36:21 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
18/02/28 10:36:22 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
18/02/28 10:36:23 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 10:36:23 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 10:36:24 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 10:36:24 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 10:36:24 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
18/02/28 10:36:24 INFO ObjectStore: Initialized ObjectStore
18/02/28 10:36:24 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
18/02/28 10:36:24 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
18/02/28 10:36:24 INFO HiveMetaStore: Added admin role in metastore
18/02/28 10:36:24 INFO HiveMetaStore: Added public role in metastore
18/02/28 10:36:24 INFO HiveMetaStore: No user is added in admin role, since config is empty
18/02/28 10:36:24 INFO HiveMetaStore: 0: get_all_databases
18/02/28 10:36:24 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_all_databases	
18/02/28 10:36:24 INFO HiveMetaStore: 0: get_functions: db=default pat=*
18/02/28 10:36:24 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
18/02/28 10:36:24 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 10:36:24 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/Temp/102cbf9a-2817-4c44-8d6b-6ce042460727_resources
18/02/28 10:36:24 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/102cbf9a-2817-4c44-8d6b-6ce042460727
18/02/28 10:36:24 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/102cbf9a-2817-4c44-8d6b-6ce042460727
18/02/28 10:36:25 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/102cbf9a-2817-4c44-8d6b-6ce042460727/_tmp_space.db
18/02/28 10:36:25 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive
18/02/28 10:36:25 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:36:25 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:36:25 INFO HiveMetaStore: 0: get_database: global_temp
18/02/28 10:36:25 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: global_temp	
18/02/28 10:36:25 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
18/02/28 10:36:25 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/Temp/751fd780-51db-4ced-8ede-694aefd4f972_resources
18/02/28 10:36:25 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/751fd780-51db-4ced-8ede-694aefd4f972
18/02/28 10:36:25 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/751fd780-51db-4ced-8ede-694aefd4f972
18/02/28 10:36:25 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/751fd780-51db-4ced-8ede-694aefd4f972/_tmp_space.db
18/02/28 10:36:25 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive
18/02/28 10:36:25 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
18/02/28 10:36:25 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 10:36:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:36:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:36:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:36:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:36:26 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 10:36:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 10:36:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:36:33 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 10:36:33 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:36:33 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:36:33 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:36:33 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:36:33 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 10:36:33 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 10:36:33 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 10:36:33 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
18/02/28 10:36:33 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
18/02/28 10:36:33 INFO DAGScheduler: Parents of final stage: List()
18/02/28 10:36:33 INFO DAGScheduler: Missing parents: List()
18/02/28 10:36:33 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55), which has no missing parents
18/02/28 10:36:34 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
18/02/28 10:36:34 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
18/02/28 10:36:34 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:60069 (size: 3.4 KB, free: 366.3 MB)
18/02/28 10:36:34 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
18/02/28 10:36:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0))
18/02/28 10:36:34 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/02/28 10:36:34 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 10:36:34 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/02/28 10:36:34 INFO Executor: Fetching spark://127.0.0.1:60048/jars/sparklyr-2.2-2.11.jar with timestamp 1519842979274
18/02/28 10:36:34 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:60048 after 22 ms (0 ms spent in bootstraps)
18/02/28 10:36:34 INFO Utils: Fetching spark://127.0.0.1:60048/jars/sparklyr-2.2-2.11.jar to C:\Users\JC\AppData\Local\Temp\spark-9b186b0b-d8f1-4363-aaa6-d6ccaaad6972\userFiles-9fa3e68c-8c06-48a8-9c8f-e79fb16f2acf\fetchFileTemp1481497717935104489.tmp
18/02/28 10:36:34 INFO Executor: Adding file:/C:/Users/JC/AppData/Local/Temp/spark-9b186b0b-d8f1-4363-aaa6-d6ccaaad6972/userFiles-9fa3e68c-8c06-48a8-9c8f-e79fb16f2acf/sparklyr-2.2-2.11.jar to class loader
18/02/28 10:36:34 INFO CodeGenerator: Code generated in 293.301442 ms
18/02/28 10:36:34 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
18/02/28 10:36:34 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 731 ms on localhost (executor driver) (1/1)
18/02/28 10:36:34 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/02/28 10:36:34 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.751 s
18/02/28 10:36:34 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.904327 s
18/02/28 10:36:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:36:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:36:35 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 10:36:35 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:36:35 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:36:35 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:36:35 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:36:35 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 10:36:35 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 10:36:35 INFO SparkSqlParser: Parsing command: spark_fao
18/02/28 10:36:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:36:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao` AS `zzz7`
WHERE (0 = 1)
18/02/28 10:36:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:36:35 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 10:36:35 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:36:35 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:36:35 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:36:35 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:36:35 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 10:36:35 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 10:36:35 INFO CodeGenerator: Code generated in 10.981901 ms
18/02/28 10:36:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:36:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao`
18/02/28 10:36:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:36:40 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_fao`
18/02/28 10:36:40 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:36:40 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:36:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:36:40 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_fao`
18/02/28 10:36:40 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:36:40 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:36:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:36:40 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_fao`
18/02/28 10:36:40 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:36:40 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:36:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:36:40 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_fao`
18/02/28 10:36:40 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:36:40 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:36:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:36:40 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_fao`
18/02/28 10:36:40 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:36:40 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:36:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:36:40 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_fao`
LIMIT 1000
18/02/28 10:36:40 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:36:40 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:36:40 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:36:40 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 10:36:40 INFO FileSourceStrategy: Output Data Schema: struct<>
18/02/28 10:36:40 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 10:36:40 INFO CodeGenerator: Code generated in 17.801511 ms
18/02/28 10:36:40 INFO CodeGenerator: Code generated in 10.632104 ms
18/02/28 10:36:40 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 282.5 KB, free 366.0 MB)
18/02/28 10:36:40 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 24.1 KB, free 366.0 MB)
18/02/28 10:36:40 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:60069 (size: 24.1 KB, free: 366.3 MB)
18/02/28 10:36:40 INFO SparkContext: Created broadcast 1 from collect at utils.scala:211
18/02/28 10:36:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 81290886 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:36:41 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:36:41 INFO DAGScheduler: Registering RDD 7 (collect at utils.scala:211)
18/02/28 10:36:41 INFO DAGScheduler: Got job 1 (collect at utils.scala:211) with 1 output partitions
18/02/28 10:36:41 INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:211)
18/02/28 10:36:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
18/02/28 10:36:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
18/02/28 10:36:41 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at collect at utils.scala:211), which has no missing parents
18/02/28 10:36:41 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:60069 in memory (size: 3.4 KB, free: 366.3 MB)
18/02/28 10:36:41 INFO ContextCleaner: Cleaned accumulator 0
18/02/28 10:36:41 INFO ContextCleaner: Cleaned accumulator 49
18/02/28 10:36:41 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 13.9 KB, free 366.0 MB)
18/02/28 10:36:41 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.9 KB, free 366.0 MB)
18/02/28 10:36:41 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:60069 (size: 7.9 KB, free: 366.3 MB)
18/02/28 10:36:41 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
18/02/28 10:36:41 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:36:41 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks
18/02/28 10:36:41 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 10:36:41 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 10:36:41 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 10:36:41 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 10:36:41 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
18/02/28 10:36:41 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
18/02/28 10:36:41 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
18/02/28 10:36:41 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
18/02/28 10:36:41 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-947694, partition values: [empty row]
18/02/28 10:36:41 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-627875, partition values: [empty row]
18/02/28 10:36:41 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-321003, partition values: [empty row]
18/02/28 10:36:41 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1204806, partition values: [empty row]
18/02/28 10:36:41 INFO CodeGenerator: Code generated in 9.793581 ms
18/02/28 10:36:41 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 10:36:41 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-611199, partition values: [empty row]
18/02/28 10:36:41 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-911561, partition values: [empty row]
18/02/28 10:36:41 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-298811, partition values: [empty row]
18/02/28 10:36:41 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-605260, partition values: [empty row]
18/02/28 10:36:41 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-290455, partition values: [empty row]
18/02/28 10:36:41 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1196479, partition values: [empty row]
18/02/28 10:36:41 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-888132, partition values: [empty row]
18/02/28 10:36:41 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-280542, partition values: [empty row]
18/02/28 10:36:41 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-596889, partition values: [empty row]
18/02/28 10:36:41 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-271062, partition values: [empty row]
18/02/28 10:36:41 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-263566, partition values: [empty row]
18/02/28 10:36:41 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-864231, partition values: [empty row]
18/02/28 10:36:41 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-1190585, partition values: [empty row]
18/02/28 10:36:41 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-593152, partition values: [empty row]
18/02/28 10:36:41 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-258735, partition values: [empty row]
18/02/28 10:36:41 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-248403, partition values: [empty row]
18/02/28 10:36:41 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-240559, partition values: [empty row]
18/02/28 10:36:41 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-572401, partition values: [empty row]
18/02/28 10:36:41 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-840496, partition values: [empty row]
18/02/28 10:36:41 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-235427, partition values: [empty row]
18/02/28 10:36:41 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-1185116, partition values: [empty row]
18/02/28 10:36:41 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-231704, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-225461, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-555738, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-810541, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-219609, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-536614, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-215210, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-805147, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-210314, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-1175401, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-800684, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-507262, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-451168, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-1166620, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-799588, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-441782, partition values: [empty row]
18/02/28 10:36:42 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 1628 bytes result sent to driver
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-425454, partition values: [empty row]
18/02/28 10:36:42 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 888 ms on localhost (executor driver) (1/4)
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-798172, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-410697, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-1155626, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-364574, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-793415, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-359989, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-1136067, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-350556, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-784611, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-339292, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-331798, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-1128021, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-722307, partition values: [empty row]
18/02/28 10:36:42 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1585 bytes result sent to driver
18/02/28 10:36:42 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 972 ms on localhost (executor driver) (2/4)
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-702541, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-1117254, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-686171, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-1103802, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-670760, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-1076645, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-640361, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-1044232, partition values: [empty row]
18/02/28 10:36:42 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1585 bytes result sent to driver
18/02/28 10:36:42 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1067 ms on localhost (executor driver) (3/4)
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-1018463, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-1002968, partition values: [empty row]
18/02/28 10:36:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-975348, partition values: [empty row]
18/02/28 10:36:42 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1628 bytes result sent to driver
18/02/28 10:36:42 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1141 ms on localhost (executor driver) (4/4)
18/02/28 10:36:42 INFO DAGScheduler: ShuffleMapStage 1 (collect at utils.scala:211) finished in 1.142 s
18/02/28 10:36:42 INFO DAGScheduler: looking for newly runnable stages
18/02/28 10:36:42 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/02/28 10:36:42 INFO DAGScheduler: running: Set()
18/02/28 10:36:42 INFO DAGScheduler: waiting: Set(ResultStage 2)
18/02/28 10:36:42 INFO DAGScheduler: failed: Set()
18/02/28 10:36:42 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[10] at collect at utils.scala:211), which has no missing parents
18/02/28 10:36:42 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.9 KB, free 366.0 MB)
18/02/28 10:36:42 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.0 MB)
18/02/28 10:36:42 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:60069 (size: 3.7 KB, free: 366.3 MB)
18/02/28 10:36:42 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
18/02/28 10:36:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 10:36:42 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
18/02/28 10:36:42 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 10:36:42 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
18/02/28 10:36:42 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:36:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
18/02/28 10:36:42 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1514 bytes result sent to driver
18/02/28 10:36:42 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 31 ms on localhost (executor driver) (1/1)
18/02/28 10:36:42 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/02/28 10:36:42 INFO DAGScheduler: ResultStage 2 (collect at utils.scala:211) finished in 0.031 s
18/02/28 10:36:42 INFO DAGScheduler: Job 1 finished: collect at utils.scala:211, took 1.243832 s
18/02/28 10:36:42 INFO CodeGenerator: Code generated in 6.912349 ms
18/02/28 10:36:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:36:53 INFO SparkSqlParser: Parsing command: SELECT `year`, count(*) AS `n()`
FROM `spark_fao`
GROUP BY `year`
18/02/28 10:36:53 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:36:53 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:36:53 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:36:53 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 10:36:53 INFO FileSourceStrategy: Output Data Schema: struct<year: int>
18/02/28 10:36:53 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 10:36:53 INFO CodeGenerator: Code generated in 25.298499 ms
18/02/28 10:36:53 INFO CodeGenerator: Code generated in 37.658779 ms
18/02/28 10:36:53 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 282.5 KB, free 365.7 MB)
18/02/28 10:36:53 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.7 MB)
18/02/28 10:36:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:60069 (size: 24.1 KB, free: 366.2 MB)
18/02/28 10:36:53 INFO SparkContext: Created broadcast 4 from collect at utils.scala:211
18/02/28 10:36:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 81290886 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:36:53 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:36:53 INFO DAGScheduler: Registering RDD 13 (collect at utils.scala:211)
18/02/28 10:36:53 INFO DAGScheduler: Got job 2 (collect at utils.scala:211) with 4 output partitions
18/02/28 10:36:53 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:211)
18/02/28 10:36:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
18/02/28 10:36:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
18/02/28 10:36:53 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[13] at collect at utils.scala:211), which has no missing parents
18/02/28 10:36:53 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 25.8 KB, free 365.6 MB)
18/02/28 10:36:53 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 13.0 KB, free 365.6 MB)
18/02/28 10:36:53 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:60069 (size: 13.0 KB, free: 366.2 MB)
18/02/28 10:36:53 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
18/02/28 10:36:53 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[13] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:36:53 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks
18/02/28 10:36:53 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 10:36:53 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 10:36:53 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 8, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 10:36:53 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 9, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 10:36:53 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)
18/02/28 10:36:53 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)
18/02/28 10:36:53 INFO Executor: Running task 2.0 in stage 3.0 (TID 8)
18/02/28 10:36:53 INFO Executor: Running task 3.0 in stage 3.0 (TID 9)
18/02/28 10:36:53 INFO CodeGenerator: Code generated in 17.585357 ms
18/02/28 10:36:53 INFO CodeGenerator: Code generated in 17.808564 ms
18/02/28 10:36:53 INFO CodeGenerator: Code generated in 7.090421 ms
18/02/28 10:36:53 INFO CodeGenerator: Code generated in 10.487884 ms
18/02/28 10:36:53 INFO CodeGenerator: Code generated in 17.430206 ms
18/02/28 10:36:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-627875, partition values: [empty row]
18/02/28 10:36:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-947694, partition values: [empty row]
18/02/28 10:36:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-321003, partition values: [empty row]
18/02/28 10:36:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1204806, partition values: [empty row]
18/02/28 10:36:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 10:36:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-611199, partition values: [empty row]
18/02/28 10:36:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-911561, partition values: [empty row]
18/02/28 10:36:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-298811, partition values: [empty row]
18/02/28 10:36:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1196479, partition values: [empty row]
18/02/28 10:36:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-605260, partition values: [empty row]
18/02/28 10:36:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-290455, partition values: [empty row]
18/02/28 10:36:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-596889, partition values: [empty row]
18/02/28 10:36:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-280542, partition values: [empty row]
18/02/28 10:36:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-888132, partition values: [empty row]
18/02/28 10:36:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-271062, partition values: [empty row]
18/02/28 10:36:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-1190585, partition values: [empty row]
18/02/28 10:36:53 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:60069 in memory (size: 3.7 KB, free: 366.2 MB)
18/02/28 10:36:53 INFO ContextCleaner: Cleaned accumulator 113
18/02/28 10:36:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-263566, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-864231, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-593152, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-258735, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-248403, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-240559, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-1185116, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-572401, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-840496, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-235427, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-231704, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-1175401, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-810541, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-225461, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-555738, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-219609, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-215210, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-536614, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-805147, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-210314, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-507262, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-1166620, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-451168, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-800684, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-441782, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-799588, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-1155626, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-425454, partition values: [empty row]
18/02/28 10:36:54 INFO Executor: Finished task 3.0 in stage 3.0 (TID 9). 2060 bytes result sent to driver
18/02/28 10:36:54 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 9) in 1085 ms on localhost (executor driver) (1/4)
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-410697, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-798172, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-1136067, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-793415, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-364574, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-1128021, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-359989, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-784611, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-350556, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-1117254, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-722307, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-339292, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-331798, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-702541, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-1103802, partition values: [empty row]
18/02/28 10:36:54 INFO Executor: Finished task 2.0 in stage 3.0 (TID 8). 2103 bytes result sent to driver
18/02/28 10:36:54 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 8) in 1242 ms on localhost (executor driver) (2/4)
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-686171, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-1076645, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-670760, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-1044232, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-640361, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-1018463, partition values: [empty row]
18/02/28 10:36:54 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 2060 bytes result sent to driver
18/02/28 10:36:54 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 1402 ms on localhost (executor driver) (3/4)
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-1002968, partition values: [empty row]
18/02/28 10:36:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-975348, partition values: [empty row]
18/02/28 10:36:54 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 2060 bytes result sent to driver
18/02/28 10:36:54 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 1477 ms on localhost (executor driver) (4/4)
18/02/28 10:36:54 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/02/28 10:36:54 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:211) finished in 1.479 s
18/02/28 10:36:54 INFO DAGScheduler: looking for newly runnable stages
18/02/28 10:36:54 INFO DAGScheduler: running: Set()
18/02/28 10:36:54 INFO DAGScheduler: waiting: Set(ResultStage 4)
18/02/28 10:36:54 INFO DAGScheduler: failed: Set()
18/02/28 10:36:54 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[16] at collect at utils.scala:211), which has no missing parents
18/02/28 10:36:54 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 24.3 KB, free 365.6 MB)
18/02/28 10:36:54 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 12.2 KB, free 365.6 MB)
18/02/28 10:36:54 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:60069 (size: 12.2 KB, free: 366.2 MB)
18/02/28 10:36:54 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
18/02/28 10:36:54 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 4 (MapPartitionsRDD[16] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:36:54 INFO TaskSchedulerImpl: Adding task set 4.0 with 4 tasks
18/02/28 10:36:54 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 10, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 10:36:54 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 11, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 10:36:54 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 12, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 10:36:54 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 13, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 10:36:54 INFO Executor: Running task 1.0 in stage 4.0 (TID 11)
18/02/28 10:36:54 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:36:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 10:36:54 INFO Executor: Running task 3.0 in stage 4.0 (TID 13)
18/02/28 10:36:54 INFO Executor: Running task 0.0 in stage 4.0 (TID 10)
18/02/28 10:36:54 INFO Executor: Running task 2.0 in stage 4.0 (TID 12)
18/02/28 10:36:54 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:36:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:36:54 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:36:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:36:54 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:36:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
18/02/28 10:36:54 INFO Executor: Finished task 2.0 in stage 4.0 (TID 12). 2748 bytes result sent to driver
18/02/28 10:36:54 INFO Executor: Finished task 3.0 in stage 4.0 (TID 13). 2725 bytes result sent to driver
18/02/28 10:36:54 INFO Executor: Finished task 1.0 in stage 4.0 (TID 11). 2759 bytes result sent to driver
18/02/28 10:36:54 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 11) in 33 ms on localhost (executor driver) (1/4)
18/02/28 10:36:54 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 12) in 33 ms on localhost (executor driver) (2/4)
18/02/28 10:36:54 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 13) in 33 ms on localhost (executor driver) (3/4)
18/02/28 10:36:54 INFO Executor: Finished task 0.0 in stage 4.0 (TID 10). 2643 bytes result sent to driver
18/02/28 10:36:54 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 10) in 40 ms on localhost (executor driver) (4/4)
18/02/28 10:36:54 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:211) finished in 0.041 s
18/02/28 10:36:54 INFO DAGScheduler: Job 2 finished: collect at utils.scala:211, took 1.540338 s
18/02/28 10:36:54 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/02/28 10:36:54 INFO CodeGenerator: Code generated in 6.636955 ms
18/02/28 10:39:19 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:60069 in memory (size: 12.2 KB, free: 366.2 MB)
18/02/28 10:39:34 INFO SparkContext: Invoking stop() from shutdown hook
18/02/28 10:39:34 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
18/02/28 10:39:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/02/28 10:39:34 INFO MemoryStore: MemoryStore cleared
18/02/28 10:39:34 INFO BlockManager: BlockManager stopped
18/02/28 10:39:34 INFO BlockManagerMaster: BlockManagerMaster stopped
18/02/28 10:39:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/02/28 10:39:34 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-9b186b0b-d8f1-4363-aaa6-d6ccaaad6972\userFiles-9fa3e68c-8c06-48a8-9c8f-e79fb16f2acf
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-9b186b0b-d8f1-4363-aaa6-d6ccaaad6972\userFiles-9fa3e68c-8c06-48a8-9c8f-e79fb16f2acf
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1937)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1936)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 10:39:34 INFO SparkContext: Successfully stopped SparkContext
18/02/28 10:39:34 INFO ShutdownHookManager: Shutdown hook called
18/02/28 10:39:34 INFO ShutdownHookManager: Deleting directory C:\Users\JC\AppData\Local\Temp\spark-9b186b0b-d8f1-4363-aaa6-d6ccaaad6972\userFiles-9fa3e68c-8c06-48a8-9c8f-e79fb16f2acf
18/02/28 10:39:34 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-9b186b0b-d8f1-4363-aaa6-d6ccaaad6972\userFiles-9fa3e68c-8c06-48a8-9c8f-e79fb16f2acf
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-9b186b0b-d8f1-4363-aaa6-d6ccaaad6972\userFiles-9fa3e68c-8c06-48a8-9c8f-e79fb16f2acf
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 10:39:34 INFO ShutdownHookManager: Deleting directory C:\Users\JC\AppData\Local\Temp\spark-9b186b0b-d8f1-4363-aaa6-d6ccaaad6972
18/02/28 10:39:34 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-9b186b0b-d8f1-4363-aaa6-d6ccaaad6972
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-9b186b0b-d8f1-4363-aaa6-d6ccaaad6972
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 10:41:20 INFO SparkContext: Running Spark version 2.2.0
18/02/28 10:41:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/02/28 10:41:21 INFO SparkContext: Submitted application: sparklyr
18/02/28 10:41:21 INFO SecurityManager: Changing view acls to: JC
18/02/28 10:41:21 INFO SecurityManager: Changing modify acls to: JC
18/02/28 10:41:21 INFO SecurityManager: Changing view acls groups to: 
18/02/28 10:41:21 INFO SecurityManager: Changing modify acls groups to: 
18/02/28 10:41:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(JC); groups with view permissions: Set(); users  with modify permissions: Set(JC); groups with modify permissions: Set()
18/02/28 10:41:21 INFO Utils: Successfully started service 'sparkDriver' on port 60136.
18/02/28 10:41:21 INFO SparkEnv: Registering MapOutputTracker
18/02/28 10:41:21 INFO SparkEnv: Registering BlockManagerMaster
18/02/28 10:41:21 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/02/28 10:41:21 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/02/28 10:41:21 INFO DiskBlockManager: Created local directory at C:\Users\JC\AppData\Local\Temp\blockmgr-63cb5e29-4480-4914-8723-855010b4870c
18/02/28 10:41:21 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/02/28 10:41:21 INFO SparkEnv: Registering OutputCommitCoordinator
18/02/28 10:41:21 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/02/28 10:41:21 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
18/02/28 10:41:21 INFO SparkContext: Added JAR file:/C:/Users/JC/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:60136/jars/sparklyr-2.2-2.11.jar with timestamp 1519843281483
18/02/28 10:41:21 INFO Executor: Starting executor ID driver on host localhost
18/02/28 10:41:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60157.
18/02/28 10:41:21 INFO NettyBlockTransferService: Server created on 127.0.0.1:60157
18/02/28 10:41:21 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/02/28 10:41:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 60157, None)
18/02/28 10:41:21 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:60157 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 60157, None)
18/02/28 10:41:21 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 60157, None)
18/02/28 10:41:21 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 60157, None)
18/02/28 10:41:22 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/02/28 10:41:22 INFO SharedState: loading hive config file: file:/C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
18/02/28 10:41:22 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:\Users\JC\AppData\Local\spark\spark-2.2.0-bin-hadoop2.7\tmp\hive') to the value of spark.sql.warehouse.dir ('C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive').
18/02/28 10:41:22 INFO SharedState: Warehouse path is 'C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive'.
18/02/28 10:41:22 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
18/02/28 10:41:23 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
18/02/28 10:41:23 INFO ObjectStore: ObjectStore, initialize called
18/02/28 10:41:23 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
18/02/28 10:41:23 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
18/02/28 10:41:24 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
18/02/28 10:41:25 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 10:41:25 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 10:41:26 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 10:41:26 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 10:41:26 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
18/02/28 10:41:26 INFO ObjectStore: Initialized ObjectStore
18/02/28 10:41:26 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
18/02/28 10:41:26 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
18/02/28 10:41:26 INFO HiveMetaStore: Added admin role in metastore
18/02/28 10:41:26 INFO HiveMetaStore: Added public role in metastore
18/02/28 10:41:26 INFO HiveMetaStore: No user is added in admin role, since config is empty
18/02/28 10:41:26 INFO HiveMetaStore: 0: get_all_databases
18/02/28 10:41:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_all_databases	
18/02/28 10:41:26 INFO HiveMetaStore: 0: get_functions: db=default pat=*
18/02/28 10:41:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
18/02/28 10:41:26 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 10:41:26 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/Temp/6595d7e7-acd0-4fff-b205-9b1851f409c9_resources
18/02/28 10:41:26 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/6595d7e7-acd0-4fff-b205-9b1851f409c9
18/02/28 10:41:27 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/6595d7e7-acd0-4fff-b205-9b1851f409c9
18/02/28 10:41:27 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/6595d7e7-acd0-4fff-b205-9b1851f409c9/_tmp_space.db
18/02/28 10:41:27 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive
18/02/28 10:41:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:41:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:41:27 INFO HiveMetaStore: 0: get_database: global_temp
18/02/28 10:41:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: global_temp	
18/02/28 10:41:27 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
18/02/28 10:41:27 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/Temp/7f577bca-e8f4-45a3-a923-655937826f64_resources
18/02/28 10:41:27 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/7f577bca-e8f4-45a3-a923-655937826f64
18/02/28 10:41:27 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/7f577bca-e8f4-45a3-a923-655937826f64
18/02/28 10:41:27 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/7f577bca-e8f4-45a3-a923-655937826f64/_tmp_space.db
18/02/28 10:41:27 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive
18/02/28 10:41:27 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
18/02/28 10:41:27 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 10:41:29 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:41:29 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:41:29 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:41:29 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:41:29 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 10:41:29 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 10:41:43 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:41:43 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 10:41:43 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:41:43 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:41:43 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:41:43 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:41:43 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 10:41:43 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 10:41:44 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 10:41:44 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
18/02/28 10:41:44 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
18/02/28 10:41:44 INFO DAGScheduler: Parents of final stage: List()
18/02/28 10:41:44 INFO DAGScheduler: Missing parents: List()
18/02/28 10:41:44 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55), which has no missing parents
18/02/28 10:41:44 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
18/02/28 10:41:44 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
18/02/28 10:41:44 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:60157 (size: 3.4 KB, free: 366.3 MB)
18/02/28 10:41:44 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
18/02/28 10:41:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0))
18/02/28 10:41:44 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/02/28 10:41:44 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 10:41:44 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/02/28 10:41:44 INFO Executor: Fetching spark://127.0.0.1:60136/jars/sparklyr-2.2-2.11.jar with timestamp 1519843281483
18/02/28 10:41:44 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:60136 after 17 ms (0 ms spent in bootstraps)
18/02/28 10:41:44 INFO Utils: Fetching spark://127.0.0.1:60136/jars/sparklyr-2.2-2.11.jar to C:\Users\JC\AppData\Local\Temp\spark-f860167a-2762-4d40-a3be-220f7f163c30\userFiles-61ac4d8e-8acc-485c-a2d7-c9dc9bddb597\fetchFileTemp4737916602406792357.tmp
18/02/28 10:41:44 INFO Executor: Adding file:/C:/Users/JC/AppData/Local/Temp/spark-f860167a-2762-4d40-a3be-220f7f163c30/userFiles-61ac4d8e-8acc-485c-a2d7-c9dc9bddb597/sparklyr-2.2-2.11.jar to class loader
18/02/28 10:41:45 INFO CodeGenerator: Code generated in 247.74863 ms
18/02/28 10:41:45 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
18/02/28 10:41:45 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 664 ms on localhost (executor driver) (1/1)
18/02/28 10:41:45 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/02/28 10:41:45 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.683 s
18/02/28 10:41:45 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.881105 s
18/02/28 10:41:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:41:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:41:45 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 10:41:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:41:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:41:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:41:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:41:45 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 10:41:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 10:41:45 INFO SparkSqlParser: Parsing command: spark_fao
18/02/28 10:41:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:41:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao` AS `zzz8`
WHERE (0 = 1)
18/02/28 10:41:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:41:45 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 10:41:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:41:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:41:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:41:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:41:45 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 10:41:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 10:41:45 INFO CodeGenerator: Code generated in 10.627168 ms
18/02/28 10:41:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:41:50 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_fao`
18/02/28 10:41:50 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:41:50 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:41:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:41:50 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_fao`
18/02/28 10:41:50 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:41:50 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:41:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:41:50 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_fao`
18/02/28 10:41:50 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:41:50 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:41:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:41:50 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_fao`
18/02/28 10:41:50 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:41:50 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:41:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:41:50 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_fao`
18/02/28 10:41:50 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:41:50 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:41:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:41:50 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_fao`
LIMIT 1000
18/02/28 10:41:50 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:41:50 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:41:50 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:41:50 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 10:41:50 INFO FileSourceStrategy: Output Data Schema: struct<>
18/02/28 10:41:50 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 10:41:51 INFO CodeGenerator: Code generated in 19.438006 ms
18/02/28 10:41:51 INFO CodeGenerator: Code generated in 11.189592 ms
18/02/28 10:41:51 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 282.5 KB, free 366.0 MB)
18/02/28 10:41:51 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 24.1 KB, free 366.0 MB)
18/02/28 10:41:51 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:60157 (size: 24.1 KB, free: 366.3 MB)
18/02/28 10:41:51 INFO SparkContext: Created broadcast 1 from collect at utils.scala:211
18/02/28 10:41:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:41:51 INFO ContextCleaner: Cleaned accumulator 0
18/02/28 10:41:51 INFO ContextCleaner: Cleaned accumulator 49
18/02/28 10:41:51 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:41:51 INFO DAGScheduler: Registering RDD 7 (collect at utils.scala:211)
18/02/28 10:41:51 INFO DAGScheduler: Got job 1 (collect at utils.scala:211) with 1 output partitions
18/02/28 10:41:51 INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:211)
18/02/28 10:41:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
18/02/28 10:41:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
18/02/28 10:41:51 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at collect at utils.scala:211), which has no missing parents
18/02/28 10:41:51 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 13.9 KB, free 366.0 MB)
18/02/28 10:41:51 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.9 KB, free 366.0 MB)
18/02/28 10:41:51 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:60157 (size: 7.9 KB, free: 366.3 MB)
18/02/28 10:41:51 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
18/02/28 10:41:51 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:41:51 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks
18/02/28 10:41:51 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:60157 in memory (size: 3.4 KB, free: 366.3 MB)
18/02/28 10:41:51 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 10:41:51 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 10:41:51 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 10:41:51 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 10:41:51 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
18/02/28 10:41:51 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
18/02/28 10:41:51 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
18/02/28 10:41:51 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
18/02/28 10:41:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 10:41:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 10:41:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 10:41:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 10:41:51 INFO CodeGenerator: Code generated in 9.913823 ms
18/02/28 10:41:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 10:41:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 10:41:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 10:41:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 10:41:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 10:41:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 10:41:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 10:41:52 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 1628 bytes result sent to driver
18/02/28 10:41:52 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 892 ms on localhost (executor driver) (1/4)
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 10:41:52 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1628 bytes result sent to driver
18/02/28 10:41:52 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1008 ms on localhost (executor driver) (2/4)
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 10:41:52 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1628 bytes result sent to driver
18/02/28 10:41:52 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1071 ms on localhost (executor driver) (3/4)
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 10:41:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 10:41:52 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1585 bytes result sent to driver
18/02/28 10:41:52 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1122 ms on localhost (executor driver) (4/4)
18/02/28 10:41:52 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/02/28 10:41:52 INFO DAGScheduler: ShuffleMapStage 1 (collect at utils.scala:211) finished in 1.125 s
18/02/28 10:41:52 INFO DAGScheduler: looking for newly runnable stages
18/02/28 10:41:52 INFO DAGScheduler: running: Set()
18/02/28 10:41:52 INFO DAGScheduler: waiting: Set(ResultStage 2)
18/02/28 10:41:52 INFO DAGScheduler: failed: Set()
18/02/28 10:41:52 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[10] at collect at utils.scala:211), which has no missing parents
18/02/28 10:41:52 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.9 KB, free 366.0 MB)
18/02/28 10:41:52 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.0 MB)
18/02/28 10:41:52 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:60157 (size: 3.7 KB, free: 366.3 MB)
18/02/28 10:41:52 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
18/02/28 10:41:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 10:41:52 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
18/02/28 10:41:52 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 10:41:52 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
18/02/28 10:41:52 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:41:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
18/02/28 10:41:52 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1514 bytes result sent to driver
18/02/28 10:41:52 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 30 ms on localhost (executor driver) (1/1)
18/02/28 10:41:52 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/02/28 10:41:52 INFO DAGScheduler: ResultStage 2 (collect at utils.scala:211) finished in 0.031 s
18/02/28 10:41:52 INFO DAGScheduler: Job 1 finished: collect at utils.scala:211, took 1.234290 s
18/02/28 10:41:52 INFO CodeGenerator: Code generated in 6.822432 ms
18/02/28 10:42:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:42:33 INFO SparkSqlParser: Parsing command: SELECT `year`, SUM(`quantity`) AS `sum(quantity)`
FROM `spark_fao`
GROUP BY `year`
18/02/28 10:42:33 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:42:33 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:42:33 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:42:33 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 10:42:33 INFO FileSourceStrategy: Output Data Schema: struct<year: int, quantity: int>
18/02/28 10:42:33 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 10:42:33 INFO CodeGenerator: Code generated in 27.141275 ms
18/02/28 10:42:33 INFO CodeGenerator: Code generated in 42.816153 ms
18/02/28 10:42:33 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 282.5 KB, free 365.7 MB)
18/02/28 10:42:33 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.7 MB)
18/02/28 10:42:33 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:60157 (size: 24.1 KB, free: 366.2 MB)
18/02/28 10:42:33 INFO SparkContext: Created broadcast 4 from collect at utils.scala:211
18/02/28 10:42:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:42:33 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:42:33 INFO DAGScheduler: Registering RDD 13 (collect at utils.scala:211)
18/02/28 10:42:33 INFO DAGScheduler: Got job 2 (collect at utils.scala:211) with 4 output partitions
18/02/28 10:42:33 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:211)
18/02/28 10:42:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
18/02/28 10:42:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
18/02/28 10:42:33 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[13] at collect at utils.scala:211), which has no missing parents
18/02/28 10:42:33 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 28.2 KB, free 365.6 MB)
18/02/28 10:42:33 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 13.9 KB, free 365.6 MB)
18/02/28 10:42:33 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:60157 (size: 13.9 KB, free: 366.2 MB)
18/02/28 10:42:33 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
18/02/28 10:42:33 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[13] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:42:33 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks
18/02/28 10:42:33 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 10:42:33 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 10:42:33 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 8, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 10:42:33 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 9, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 10:42:33 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)
18/02/28 10:42:33 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)
18/02/28 10:42:33 INFO Executor: Running task 2.0 in stage 3.0 (TID 8)
18/02/28 10:42:33 INFO Executor: Running task 3.0 in stage 3.0 (TID 9)
18/02/28 10:42:33 INFO CodeGenerator: Code generated in 10.350364 ms
18/02/28 10:42:33 INFO CodeGenerator: Code generated in 9.452248 ms
18/02/28 10:42:33 INFO CodeGenerator: Code generated in 7.680701 ms
18/02/28 10:42:33 INFO CodeGenerator: Code generated in 20.511725 ms
18/02/28 10:42:33 INFO CodeGenerator: Code generated in 19.170722 ms
18/02/28 10:42:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 10:42:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 10:42:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 10:42:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 10:42:33 INFO CodeGenerator: Code generated in 7.078079 ms
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 10:42:34 INFO ContextCleaner: Cleaned accumulator 113
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 10:42:34 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:60157 in memory (size: 7.9 KB, free: 366.2 MB)
18/02/28 10:42:34 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:60157 in memory (size: 3.7 KB, free: 366.2 MB)
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 10:42:34 INFO Executor: Finished task 3.0 in stage 3.0 (TID 9). 2103 bytes result sent to driver
18/02/28 10:42:34 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 9) in 1096 ms on localhost (executor driver) (1/4)
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 10:42:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 10:42:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 10:42:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 10:42:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 10:42:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 10:42:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 10:42:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 10:42:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 10:42:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 10:42:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 10:42:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 10:42:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 10:42:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 10:42:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 10:42:35 INFO Executor: Finished task 2.0 in stage 3.0 (TID 8). 2060 bytes result sent to driver
18/02/28 10:42:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 10:42:35 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 8) in 1411 ms on localhost (executor driver) (2/4)
18/02/28 10:42:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 10:42:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 10:42:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 10:42:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 10:42:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 10:42:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 10:42:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 10:42:35 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 2103 bytes result sent to driver
18/02/28 10:42:35 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 1536 ms on localhost (executor driver) (3/4)
18/02/28 10:42:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 10:42:35 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 2060 bytes result sent to driver
18/02/28 10:42:35 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 1583 ms on localhost (executor driver) (4/4)
18/02/28 10:42:35 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:211) finished in 1.583 s
18/02/28 10:42:35 INFO DAGScheduler: looking for newly runnable stages
18/02/28 10:42:35 INFO DAGScheduler: running: Set()
18/02/28 10:42:35 INFO DAGScheduler: waiting: Set(ResultStage 4)
18/02/28 10:42:35 INFO DAGScheduler: failed: Set()
18/02/28 10:42:35 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[16] at collect at utils.scala:211), which has no missing parents
18/02/28 10:42:35 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 25.9 KB, free 365.6 MB)
18/02/28 10:42:35 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 12.9 KB, free 365.6 MB)
18/02/28 10:42:35 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/02/28 10:42:35 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:60157 (size: 12.9 KB, free: 366.2 MB)
18/02/28 10:42:35 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
18/02/28 10:42:35 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 4 (MapPartitionsRDD[16] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:42:35 INFO TaskSchedulerImpl: Adding task set 4.0 with 4 tasks
18/02/28 10:42:35 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 10, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 10:42:35 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 11, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 10:42:35 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 12, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 10:42:35 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 13, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 10:42:35 INFO Executor: Running task 0.0 in stage 4.0 (TID 10)
18/02/28 10:42:35 INFO Executor: Running task 1.0 in stage 4.0 (TID 11)
18/02/28 10:42:35 INFO Executor: Running task 2.0 in stage 4.0 (TID 12)
18/02/28 10:42:35 INFO Executor: Running task 3.0 in stage 4.0 (TID 13)
18/02/28 10:42:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:42:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 10:42:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:42:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:42:35 INFO Executor: Finished task 1.0 in stage 4.0 (TID 11). 2708 bytes result sent to driver
18/02/28 10:42:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:42:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:42:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:42:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 10:42:35 INFO Executor: Finished task 3.0 in stage 4.0 (TID 13). 2757 bytes result sent to driver
18/02/28 10:42:35 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 13) in 35 ms on localhost (executor driver) (1/4)
18/02/28 10:42:35 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 11) in 36 ms on localhost (executor driver) (2/4)
18/02/28 10:42:35 INFO Executor: Finished task 2.0 in stage 4.0 (TID 12). 2699 bytes result sent to driver
18/02/28 10:42:35 INFO Executor: Finished task 0.0 in stage 4.0 (TID 10). 2594 bytes result sent to driver
18/02/28 10:42:35 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 12) in 38 ms on localhost (executor driver) (3/4)
18/02/28 10:42:35 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 10) in 40 ms on localhost (executor driver) (4/4)
18/02/28 10:42:35 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:211) finished in 0.041 s
18/02/28 10:42:35 INFO DAGScheduler: Job 2 finished: collect at utils.scala:211, took 1.638734 s
18/02/28 10:42:35 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/02/28 10:42:35 INFO CodeGenerator: Code generated in 6.509307 ms
18/02/28 10:42:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:42:51 INFO SparkSqlParser: Parsing command: SELECT `year`, SUM(`quantity`) AS `sum(quantity, na`.`rm = T)`
FROM `spark_fao`
GROUP BY `year`
18/02/28 10:42:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:42:57 INFO SparkSqlParser: Parsing command: SELECT `year`, SUM(`quantity`) AS `sum(quantity)`
FROM `spark_fao`
GROUP BY `year`
18/02/28 10:42:57 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:42:57 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:42:57 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:42:57 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 10:42:57 INFO FileSourceStrategy: Output Data Schema: struct<year: int, quantity: int>
18/02/28 10:42:57 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 10:42:58 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 282.5 KB, free 365.3 MB)
18/02/28 10:42:58 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.3 MB)
18/02/28 10:42:58 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:60157 (size: 24.1 KB, free: 366.2 MB)
18/02/28 10:42:58 INFO SparkContext: Created broadcast 7 from collect at utils.scala:211
18/02/28 10:42:58 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:42:58 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:42:58 INFO DAGScheduler: Registering RDD 19 (collect at utils.scala:211)
18/02/28 10:42:58 INFO DAGScheduler: Got job 3 (collect at utils.scala:211) with 4 output partitions
18/02/28 10:42:58 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:211)
18/02/28 10:42:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
18/02/28 10:42:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
18/02/28 10:42:58 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[19] at collect at utils.scala:211), which has no missing parents
18/02/28 10:42:58 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 28.2 KB, free 365.3 MB)
18/02/28 10:42:58 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 13.9 KB, free 365.3 MB)
18/02/28 10:42:58 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:60157 (size: 13.9 KB, free: 366.2 MB)
18/02/28 10:42:58 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
18/02/28 10:42:58 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[19] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:42:58 INFO TaskSchedulerImpl: Adding task set 5.0 with 4 tasks
18/02/28 10:42:58 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 10:42:58 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 15, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 10:42:58 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 16, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 10:42:58 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 17, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 10:42:58 INFO Executor: Running task 0.0 in stage 5.0 (TID 14)
18/02/28 10:42:58 INFO Executor: Running task 1.0 in stage 5.0 (TID 15)
18/02/28 10:42:58 INFO Executor: Running task 2.0 in stage 5.0 (TID 16)
18/02/28 10:42:58 INFO Executor: Running task 3.0 in stage 5.0 (TID 17)
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 10:42:58 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:60157 in memory (size: 13.9 KB, free: 366.2 MB)
18/02/28 10:42:58 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:60157 in memory (size: 12.9 KB, free: 366.2 MB)
18/02/28 10:42:58 INFO ContextCleaner: Cleaned accumulator 177
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 10:42:58 INFO Executor: Finished task 3.0 in stage 5.0 (TID 17). 2060 bytes result sent to driver
18/02/28 10:42:58 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 17) in 637 ms on localhost (executor driver) (1/4)
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 10:42:58 INFO Executor: Finished task 2.0 in stage 5.0 (TID 16). 2103 bytes result sent to driver
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 10:42:58 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 16) in 676 ms on localhost (executor driver) (2/4)
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 10:42:58 INFO Executor: Finished task 1.0 in stage 5.0 (TID 15). 2060 bytes result sent to driver
18/02/28 10:42:58 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 15) in 790 ms on localhost (executor driver) (3/4)
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 10:42:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 10:42:58 INFO Executor: Finished task 0.0 in stage 5.0 (TID 14). 2060 bytes result sent to driver
18/02/28 10:42:58 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 14) in 874 ms on localhost (executor driver) (4/4)
18/02/28 10:42:58 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/02/28 10:42:58 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:211) finished in 0.874 s
18/02/28 10:42:58 INFO DAGScheduler: looking for newly runnable stages
18/02/28 10:42:58 INFO DAGScheduler: running: Set()
18/02/28 10:42:58 INFO DAGScheduler: waiting: Set(ResultStage 6)
18/02/28 10:42:58 INFO DAGScheduler: failed: Set()
18/02/28 10:42:58 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[22] at collect at utils.scala:211), which has no missing parents
18/02/28 10:42:58 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 25.9 KB, free 365.3 MB)
18/02/28 10:42:58 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 12.8 KB, free 365.3 MB)
18/02/28 10:42:58 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:60157 (size: 12.8 KB, free: 366.2 MB)
18/02/28 10:42:58 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
18/02/28 10:42:58 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 6 (MapPartitionsRDD[22] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:42:58 INFO TaskSchedulerImpl: Adding task set 6.0 with 4 tasks
18/02/28 10:42:58 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 18, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 10:42:58 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 19, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 10:42:58 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 20, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 10:42:58 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 21, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 10:42:58 INFO Executor: Running task 0.0 in stage 6.0 (TID 18)
18/02/28 10:42:58 INFO Executor: Running task 1.0 in stage 6.0 (TID 19)
18/02/28 10:42:58 INFO Executor: Running task 2.0 in stage 6.0 (TID 20)
18/02/28 10:42:58 INFO Executor: Running task 3.0 in stage 6.0 (TID 21)
18/02/28 10:42:58 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:42:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:42:58 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:42:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:42:58 INFO Executor: Finished task 1.0 in stage 6.0 (TID 19). 2665 bytes result sent to driver
18/02/28 10:42:58 INFO Executor: Finished task 3.0 in stage 6.0 (TID 21). 2671 bytes result sent to driver
18/02/28 10:42:58 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:42:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:42:58 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 19) in 13 ms on localhost (executor driver) (1/4)
18/02/28 10:42:58 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 21) in 15 ms on localhost (executor driver) (2/4)
18/02/28 10:42:58 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:42:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:42:58 INFO Executor: Finished task 2.0 in stage 6.0 (TID 20). 2656 bytes result sent to driver
18/02/28 10:42:58 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 20) in 22 ms on localhost (executor driver) (3/4)
18/02/28 10:42:58 INFO Executor: Finished task 0.0 in stage 6.0 (TID 18). 2637 bytes result sent to driver
18/02/28 10:42:58 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 18) in 25 ms on localhost (executor driver) (4/4)
18/02/28 10:42:58 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:211) finished in 0.026 s
18/02/28 10:42:58 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
18/02/28 10:42:58 INFO DAGScheduler: Job 3 finished: collect at utils.scala:211, took 0.913685 s
18/02/28 10:43:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:43:11 INFO SparkSqlParser: Parsing command: SELECT `year`, SUM(`year`, TRUE AS "na.rm") AS `SUM(x, na`.`rm = TRUE)`
FROM `spark_fao`
GROUP BY `year`
18/02/28 10:43:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:43:19 INFO SparkSqlParser: Parsing command: SELECT `year`, SUM(`quantity`) AS `sum(quantity)`
FROM `spark_fao`
GROUP BY `year`
18/02/28 10:43:19 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:43:19 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:43:19 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:43:19 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 10:43:19 INFO FileSourceStrategy: Output Data Schema: struct<year: int, quantity: int>
18/02/28 10:43:19 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 10:43:19 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 282.5 KB, free 365.0 MB)
18/02/28 10:43:19 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.0 MB)
18/02/28 10:43:19 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:60157 (size: 24.1 KB, free: 366.2 MB)
18/02/28 10:43:19 INFO SparkContext: Created broadcast 10 from collect at utils.scala:211
18/02/28 10:43:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:43:19 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:43:19 INFO DAGScheduler: Registering RDD 25 (collect at utils.scala:211)
18/02/28 10:43:19 INFO DAGScheduler: Got job 4 (collect at utils.scala:211) with 4 output partitions
18/02/28 10:43:19 INFO DAGScheduler: Final stage: ResultStage 8 (collect at utils.scala:211)
18/02/28 10:43:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
18/02/28 10:43:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
18/02/28 10:43:19 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[25] at collect at utils.scala:211), which has no missing parents
18/02/28 10:43:19 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 28.2 KB, free 365.0 MB)
18/02/28 10:43:19 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 13.9 KB, free 365.0 MB)
18/02/28 10:43:19 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:60157 (size: 13.9 KB, free: 366.2 MB)
18/02/28 10:43:19 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
18/02/28 10:43:19 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[25] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:43:19 INFO TaskSchedulerImpl: Adding task set 7.0 with 4 tasks
18/02/28 10:43:19 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 10:43:19 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 23, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 10:43:19 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 24, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 10:43:19 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 25, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 10:43:19 INFO Executor: Running task 0.0 in stage 7.0 (TID 22)
18/02/28 10:43:19 INFO Executor: Running task 1.0 in stage 7.0 (TID 23)
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 10:43:19 INFO Executor: Running task 2.0 in stage 7.0 (TID 24)
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 10:43:19 INFO Executor: Running task 3.0 in stage 7.0 (TID 25)
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 10:43:19 INFO ContextCleaner: Cleaned accumulator 241
18/02/28 10:43:19 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:60157 in memory (size: 12.8 KB, free: 366.2 MB)
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 10:43:19 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:60157 in memory (size: 13.9 KB, free: 366.2 MB)
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 10:43:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 10:43:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 10:43:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 10:43:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 10:43:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 10:43:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 10:43:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 10:43:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 10:43:20 INFO Executor: Finished task 3.0 in stage 7.0 (TID 25). 2060 bytes result sent to driver
18/02/28 10:43:20 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 25) in 577 ms on localhost (executor driver) (1/4)
18/02/28 10:43:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 10:43:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 10:43:20 INFO Executor: Finished task 2.0 in stage 7.0 (TID 24). 2103 bytes result sent to driver
18/02/28 10:43:20 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 24) in 591 ms on localhost (executor driver) (2/4)
18/02/28 10:43:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 10:43:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 10:43:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 10:43:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 10:43:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 10:43:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 10:43:20 INFO Executor: Finished task 1.0 in stage 7.0 (TID 23). 2060 bytes result sent to driver
18/02/28 10:43:20 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 23) in 660 ms on localhost (executor driver) (3/4)
18/02/28 10:43:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 10:43:20 INFO Executor: Finished task 0.0 in stage 7.0 (TID 22). 2060 bytes result sent to driver
18/02/28 10:43:20 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 22) in 704 ms on localhost (executor driver) (4/4)
18/02/28 10:43:20 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
18/02/28 10:43:20 INFO DAGScheduler: ShuffleMapStage 7 (collect at utils.scala:211) finished in 0.706 s
18/02/28 10:43:20 INFO DAGScheduler: looking for newly runnable stages
18/02/28 10:43:20 INFO DAGScheduler: running: Set()
18/02/28 10:43:20 INFO DAGScheduler: waiting: Set(ResultStage 8)
18/02/28 10:43:20 INFO DAGScheduler: failed: Set()
18/02/28 10:43:20 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[28] at collect at utils.scala:211), which has no missing parents
18/02/28 10:43:20 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 25.9 KB, free 365.0 MB)
18/02/28 10:43:20 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 12.9 KB, free 365.0 MB)
18/02/28 10:43:20 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:60157 (size: 12.9 KB, free: 366.2 MB)
18/02/28 10:43:20 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
18/02/28 10:43:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 8 (MapPartitionsRDD[28] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:43:20 INFO TaskSchedulerImpl: Adding task set 8.0 with 4 tasks
18/02/28 10:43:20 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 26, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 10:43:20 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 27, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 10:43:20 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 28, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 10:43:20 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 29, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 10:43:20 INFO Executor: Running task 0.0 in stage 8.0 (TID 26)
18/02/28 10:43:20 INFO Executor: Running task 1.0 in stage 8.0 (TID 27)
18/02/28 10:43:20 INFO Executor: Running task 3.0 in stage 8.0 (TID 29)
18/02/28 10:43:20 INFO Executor: Running task 2.0 in stage 8.0 (TID 28)
18/02/28 10:43:20 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:43:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:43:20 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:43:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 10:43:20 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:43:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:43:20 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:43:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:43:20 INFO Executor: Finished task 1.0 in stage 8.0 (TID 27). 2665 bytes result sent to driver
18/02/28 10:43:20 INFO Executor: Finished task 2.0 in stage 8.0 (TID 28). 2699 bytes result sent to driver
18/02/28 10:43:20 INFO Executor: Finished task 3.0 in stage 8.0 (TID 29). 2628 bytes result sent to driver
18/02/28 10:43:20 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 27) in 15 ms on localhost (executor driver) (1/4)
18/02/28 10:43:20 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 29) in 15 ms on localhost (executor driver) (2/4)
18/02/28 10:43:20 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 28) in 16 ms on localhost (executor driver) (3/4)
18/02/28 10:43:20 INFO Executor: Finished task 0.0 in stage 8.0 (TID 26). 2594 bytes result sent to driver
18/02/28 10:43:20 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 26) in 19 ms on localhost (executor driver) (4/4)
18/02/28 10:43:20 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
18/02/28 10:43:20 INFO DAGScheduler: ResultStage 8 (collect at utils.scala:211) finished in 0.020 s
18/02/28 10:43:20 INFO DAGScheduler: Job 4 finished: collect at utils.scala:211, took 0.738794 s
18/02/28 10:43:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:43:37 INFO SparkSqlParser: Parsing command: SELECT `year`, SUM(`quantity`) / 1000000.0 AS `sum(quantity)/1e+06`
FROM `spark_fao`
GROUP BY `year`
18/02/28 10:43:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:43:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:43:37 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:43:37 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 10:43:37 INFO FileSourceStrategy: Output Data Schema: struct<year: int, quantity: int>
18/02/28 10:43:37 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 10:43:37 INFO CodeGenerator: Code generated in 20.05438 ms
18/02/28 10:43:37 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 282.5 KB, free 364.7 MB)
18/02/28 10:43:37 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.7 MB)
18/02/28 10:43:37 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:60157 (size: 24.1 KB, free: 366.2 MB)
18/02/28 10:43:37 INFO SparkContext: Created broadcast 13 from collect at utils.scala:211
18/02/28 10:43:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:43:37 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:43:37 INFO DAGScheduler: Registering RDD 31 (collect at utils.scala:211)
18/02/28 10:43:37 INFO DAGScheduler: Got job 5 (collect at utils.scala:211) with 4 output partitions
18/02/28 10:43:37 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:211)
18/02/28 10:43:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
18/02/28 10:43:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
18/02/28 10:43:37 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[31] at collect at utils.scala:211), which has no missing parents
18/02/28 10:43:37 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 28.2 KB, free 364.7 MB)
18/02/28 10:43:37 INFO ContextCleaner: Cleaned accumulator 305
18/02/28 10:43:37 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 13.9 KB, free 364.7 MB)
18/02/28 10:43:37 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:60157 (size: 13.9 KB, free: 366.1 MB)
18/02/28 10:43:37 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
18/02/28 10:43:37 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[31] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:43:37 INFO TaskSchedulerImpl: Adding task set 9.0 with 4 tasks
18/02/28 10:43:37 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:60157 in memory (size: 13.9 KB, free: 366.2 MB)
18/02/28 10:43:37 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 10:43:37 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 31, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 10:43:37 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 32, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 10:43:37 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 33, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 10:43:37 INFO Executor: Running task 0.0 in stage 9.0 (TID 30)
18/02/28 10:43:37 INFO Executor: Running task 1.0 in stage 9.0 (TID 31)
18/02/28 10:43:37 INFO Executor: Running task 2.0 in stage 9.0 (TID 32)
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 10:43:37 INFO Executor: Running task 3.0 in stage 9.0 (TID 33)
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 10:43:37 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:60157 in memory (size: 12.9 KB, free: 366.2 MB)
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 10:43:37 INFO Executor: Finished task 3.0 in stage 9.0 (TID 33). 2060 bytes result sent to driver
18/02/28 10:43:37 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 33) in 332 ms on localhost (executor driver) (1/4)
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 10:43:37 INFO Executor: Finished task 2.0 in stage 9.0 (TID 32). 2060 bytes result sent to driver
18/02/28 10:43:37 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 32) in 529 ms on localhost (executor driver) (2/4)
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 10:43:37 INFO Executor: Finished task 1.0 in stage 9.0 (TID 31). 2060 bytes result sent to driver
18/02/28 10:43:37 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 31) in 590 ms on localhost (executor driver) (3/4)
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 10:43:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 10:43:37 INFO Executor: Finished task 0.0 in stage 9.0 (TID 30). 2060 bytes result sent to driver
18/02/28 10:43:37 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 30) in 669 ms on localhost (executor driver) (4/4)
18/02/28 10:43:37 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
18/02/28 10:43:37 INFO DAGScheduler: ShuffleMapStage 9 (collect at utils.scala:211) finished in 0.674 s
18/02/28 10:43:37 INFO DAGScheduler: looking for newly runnable stages
18/02/28 10:43:37 INFO DAGScheduler: running: Set()
18/02/28 10:43:37 INFO DAGScheduler: waiting: Set(ResultStage 10)
18/02/28 10:43:37 INFO DAGScheduler: failed: Set()
18/02/28 10:43:37 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[34] at collect at utils.scala:211), which has no missing parents
18/02/28 10:43:37 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 28.6 KB, free 364.7 MB)
18/02/28 10:43:37 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 14.2 KB, free 364.7 MB)
18/02/28 10:43:37 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:60157 (size: 14.2 KB, free: 366.2 MB)
18/02/28 10:43:37 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
18/02/28 10:43:37 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 10 (MapPartitionsRDD[34] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:43:37 INFO TaskSchedulerImpl: Adding task set 10.0 with 4 tasks
18/02/28 10:43:37 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 34, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 10:43:37 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 35, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 10:43:37 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 36, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 10:43:37 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 37, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 10:43:37 INFO Executor: Running task 0.0 in stage 10.0 (TID 34)
18/02/28 10:43:37 INFO Executor: Running task 1.0 in stage 10.0 (TID 35)
18/02/28 10:43:37 INFO Executor: Running task 2.0 in stage 10.0 (TID 36)
18/02/28 10:43:37 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:43:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:43:37 INFO Executor: Running task 3.0 in stage 10.0 (TID 37)
18/02/28 10:43:37 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:43:37 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:43:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:43:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:43:37 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:43:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:43:37 INFO Executor: Finished task 0.0 in stage 10.0 (TID 34). 2759 bytes result sent to driver
18/02/28 10:43:37 INFO Executor: Finished task 1.0 in stage 10.0 (TID 35). 2828 bytes result sent to driver
18/02/28 10:43:37 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 34) in 25 ms on localhost (executor driver) (1/4)
18/02/28 10:43:37 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 35) in 26 ms on localhost (executor driver) (2/4)
18/02/28 10:43:37 INFO Executor: Finished task 2.0 in stage 10.0 (TID 36). 2752 bytes result sent to driver
18/02/28 10:43:37 INFO Executor: Finished task 3.0 in stage 10.0 (TID 37). 2736 bytes result sent to driver
18/02/28 10:43:37 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 36) in 42 ms on localhost (executor driver) (3/4)
18/02/28 10:43:37 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 37) in 42 ms on localhost (executor driver) (4/4)
18/02/28 10:43:37 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:211) finished in 0.045 s
18/02/28 10:43:37 INFO DAGScheduler: Job 5 finished: collect at utils.scala:211, took 0.751093 s
18/02/28 10:43:37 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
18/02/28 10:43:37 INFO CodeGenerator: Code generated in 7.077726 ms
18/02/28 10:44:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:44:15 INFO SparkSqlParser: Parsing command: SELECT `year`, SUM(`quantity`) / 1000000.0 AS `sum(quantity)/1e+06`
FROM `spark_fao`
GROUP BY `year`
18/02/28 10:44:15 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:44:15 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:44:15 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:44:15 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 10:44:15 INFO FileSourceStrategy: Output Data Schema: struct<year: int, quantity: int>
18/02/28 10:44:15 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 10:44:15 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 282.5 KB, free 364.4 MB)
18/02/28 10:44:15 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.4 MB)
18/02/28 10:44:15 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:60157 (size: 24.1 KB, free: 366.1 MB)
18/02/28 10:44:15 INFO SparkContext: Created broadcast 16 from collect at utils.scala:211
18/02/28 10:44:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:44:15 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:44:15 INFO DAGScheduler: Registering RDD 37 (collect at utils.scala:211)
18/02/28 10:44:15 INFO DAGScheduler: Got job 6 (collect at utils.scala:211) with 4 output partitions
18/02/28 10:44:15 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:211)
18/02/28 10:44:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
18/02/28 10:44:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
18/02/28 10:44:15 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[37] at collect at utils.scala:211), which has no missing parents
18/02/28 10:44:15 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 28.2 KB, free 364.4 MB)
18/02/28 10:44:15 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 13.9 KB, free 364.4 MB)
18/02/28 10:44:15 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:60157 (size: 13.9 KB, free: 366.1 MB)
18/02/28 10:44:15 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
18/02/28 10:44:15 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[37] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:44:15 INFO TaskSchedulerImpl: Adding task set 11.0 with 4 tasks
18/02/28 10:44:15 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 10:44:15 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 39, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 10:44:15 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 40, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 10:44:15 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 41, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 10:44:15 INFO Executor: Running task 0.0 in stage 11.0 (TID 38)
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 10:44:15 INFO Executor: Running task 1.0 in stage 11.0 (TID 39)
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 10:44:15 INFO ContextCleaner: Cleaned accumulator 369
18/02/28 10:44:15 INFO Executor: Running task 3.0 in stage 11.0 (TID 41)
18/02/28 10:44:15 INFO Executor: Running task 2.0 in stage 11.0 (TID 40)
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 10:44:15 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:60157 in memory (size: 14.2 KB, free: 366.1 MB)
18/02/28 10:44:15 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:60157 in memory (size: 13.9 KB, free: 366.1 MB)
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 10:44:15 INFO Executor: Finished task 3.0 in stage 11.0 (TID 41). 2060 bytes result sent to driver
18/02/28 10:44:15 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 41) in 336 ms on localhost (executor driver) (1/4)
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 10:44:15 INFO Executor: Finished task 2.0 in stage 11.0 (TID 40). 2060 bytes result sent to driver
18/02/28 10:44:15 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 40) in 476 ms on localhost (executor driver) (2/4)
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 10:44:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 10:44:16 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 10:44:16 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 10:44:16 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 10:44:16 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 10:44:16 INFO Executor: Finished task 1.0 in stage 11.0 (TID 39). 2060 bytes result sent to driver
18/02/28 10:44:16 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 39) in 565 ms on localhost (executor driver) (3/4)
18/02/28 10:44:16 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 10:44:16 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 10:44:16 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 10:44:16 INFO Executor: Finished task 0.0 in stage 11.0 (TID 38). 2103 bytes result sent to driver
18/02/28 10:44:16 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 38) in 637 ms on localhost (executor driver) (4/4)
18/02/28 10:44:16 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
18/02/28 10:44:16 INFO DAGScheduler: ShuffleMapStage 11 (collect at utils.scala:211) finished in 0.637 s
18/02/28 10:44:16 INFO DAGScheduler: looking for newly runnable stages
18/02/28 10:44:16 INFO DAGScheduler: running: Set()
18/02/28 10:44:16 INFO DAGScheduler: waiting: Set(ResultStage 12)
18/02/28 10:44:16 INFO DAGScheduler: failed: Set()
18/02/28 10:44:16 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[40] at collect at utils.scala:211), which has no missing parents
18/02/28 10:44:16 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 28.6 KB, free 364.4 MB)
18/02/28 10:44:16 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 14.1 KB, free 364.4 MB)
18/02/28 10:44:16 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:60157 (size: 14.1 KB, free: 366.1 MB)
18/02/28 10:44:16 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
18/02/28 10:44:16 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 12 (MapPartitionsRDD[40] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:44:16 INFO TaskSchedulerImpl: Adding task set 12.0 with 4 tasks
18/02/28 10:44:16 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 42, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 10:44:16 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 43, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 10:44:16 INFO TaskSetManager: Starting task 2.0 in stage 12.0 (TID 44, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 10:44:16 INFO TaskSetManager: Starting task 3.0 in stage 12.0 (TID 45, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 10:44:16 INFO Executor: Running task 0.0 in stage 12.0 (TID 42)
18/02/28 10:44:16 INFO Executor: Running task 1.0 in stage 12.0 (TID 43)
18/02/28 10:44:16 INFO Executor: Running task 3.0 in stage 12.0 (TID 45)
18/02/28 10:44:16 INFO Executor: Running task 2.0 in stage 12.0 (TID 44)
18/02/28 10:44:16 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:44:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:44:16 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:44:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 10:44:16 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:44:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:44:16 INFO Executor: Finished task 0.0 in stage 12.0 (TID 42). 2716 bytes result sent to driver
18/02/28 10:44:16 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:44:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
18/02/28 10:44:16 INFO Executor: Finished task 3.0 in stage 12.0 (TID 45). 2736 bytes result sent to driver
18/02/28 10:44:16 INFO Executor: Finished task 1.0 in stage 12.0 (TID 43). 2785 bytes result sent to driver
18/02/28 10:44:16 INFO Executor: Finished task 2.0 in stage 12.0 (TID 44). 2752 bytes result sent to driver
18/02/28 10:44:16 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 42) in 14 ms on localhost (executor driver) (1/4)
18/02/28 10:44:16 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 43) in 15 ms on localhost (executor driver) (2/4)
18/02/28 10:44:16 INFO TaskSetManager: Finished task 3.0 in stage 12.0 (TID 45) in 15 ms on localhost (executor driver) (3/4)
18/02/28 10:44:16 INFO TaskSetManager: Finished task 2.0 in stage 12.0 (TID 44) in 15 ms on localhost (executor driver) (4/4)
18/02/28 10:44:16 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
18/02/28 10:44:16 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:211) finished in 0.016 s
18/02/28 10:44:16 INFO DAGScheduler: Job 6 finished: collect at utils.scala:211, took 0.668369 s
18/02/28 10:44:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:44:23 INFO SparkSqlParser: Parsing command: SELECT `year`, SUM(`quantity`) / 1000000.0 AS `sum(quantity)/1e+06`
FROM `spark_fao`
GROUP BY `year`
18/02/28 10:44:23 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:44:23 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:44:23 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:44:23 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 10:44:23 INFO FileSourceStrategy: Output Data Schema: struct<year: int, quantity: int>
18/02/28 10:44:23 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 10:44:23 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 282.5 KB, free 364.1 MB)
18/02/28 10:44:23 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.1 MB)
18/02/28 10:44:23 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:60157 (size: 24.1 KB, free: 366.1 MB)
18/02/28 10:44:23 INFO SparkContext: Created broadcast 19 from collect at utils.scala:211
18/02/28 10:44:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:44:23 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:44:23 INFO DAGScheduler: Registering RDD 43 (collect at utils.scala:211)
18/02/28 10:44:23 INFO DAGScheduler: Got job 7 (collect at utils.scala:211) with 4 output partitions
18/02/28 10:44:23 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:211)
18/02/28 10:44:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
18/02/28 10:44:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
18/02/28 10:44:23 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[43] at collect at utils.scala:211), which has no missing parents
18/02/28 10:44:23 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 28.2 KB, free 364.1 MB)
18/02/28 10:44:23 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 13.9 KB, free 364.1 MB)
18/02/28 10:44:23 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:60157 (size: 13.9 KB, free: 366.1 MB)
18/02/28 10:44:23 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
18/02/28 10:44:23 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[43] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:44:23 INFO TaskSchedulerImpl: Adding task set 13.0 with 4 tasks
18/02/28 10:44:23 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 46, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 10:44:23 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 47, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 10:44:23 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 48, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 10:44:23 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 49, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 10:44:23 INFO Executor: Running task 0.0 in stage 13.0 (TID 46)
18/02/28 10:44:23 INFO Executor: Running task 1.0 in stage 13.0 (TID 47)
18/02/28 10:44:23 INFO Executor: Running task 2.0 in stage 13.0 (TID 48)
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 10:44:23 INFO Executor: Running task 3.0 in stage 13.0 (TID 49)
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 10:44:23 INFO ContextCleaner: Cleaned accumulator 433
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 10:44:23 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:60157 in memory (size: 13.9 KB, free: 366.1 MB)
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 10:44:23 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:60157 in memory (size: 14.1 KB, free: 366.1 MB)
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 10:44:23 INFO Executor: Finished task 3.0 in stage 13.0 (TID 49). 2060 bytes result sent to driver
18/02/28 10:44:23 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 49) in 293 ms on localhost (executor driver) (1/4)
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 10:44:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 10:44:24 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 10:44:24 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 10:44:24 INFO Executor: Finished task 2.0 in stage 13.0 (TID 48). 2060 bytes result sent to driver
18/02/28 10:44:24 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 48) in 419 ms on localhost (executor driver) (2/4)
18/02/28 10:44:24 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 10:44:24 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 10:44:24 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 10:44:24 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 10:44:24 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 10:44:24 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 10:44:24 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 10:44:24 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 10:44:24 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 10:44:24 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 10:44:24 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 10:44:24 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 10:44:24 INFO Executor: Finished task 1.0 in stage 13.0 (TID 47). 2060 bytes result sent to driver
18/02/28 10:44:24 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 47) in 582 ms on localhost (executor driver) (3/4)
18/02/28 10:44:24 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 10:44:24 INFO Executor: Finished task 0.0 in stage 13.0 (TID 46). 2060 bytes result sent to driver
18/02/28 10:44:24 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 46) in 617 ms on localhost (executor driver) (4/4)
18/02/28 10:44:24 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
18/02/28 10:44:24 INFO DAGScheduler: ShuffleMapStage 13 (collect at utils.scala:211) finished in 0.617 s
18/02/28 10:44:24 INFO DAGScheduler: looking for newly runnable stages
18/02/28 10:44:24 INFO DAGScheduler: running: Set()
18/02/28 10:44:24 INFO DAGScheduler: waiting: Set(ResultStage 14)
18/02/28 10:44:24 INFO DAGScheduler: failed: Set()
18/02/28 10:44:24 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[46] at collect at utils.scala:211), which has no missing parents
18/02/28 10:44:24 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 28.6 KB, free 364.1 MB)
18/02/28 10:44:24 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 14.2 KB, free 364.1 MB)
18/02/28 10:44:24 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:60157 (size: 14.2 KB, free: 366.1 MB)
18/02/28 10:44:24 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
18/02/28 10:44:24 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 14 (MapPartitionsRDD[46] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:44:24 INFO TaskSchedulerImpl: Adding task set 14.0 with 4 tasks
18/02/28 10:44:24 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 50, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 10:44:24 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 51, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 10:44:24 INFO TaskSetManager: Starting task 2.0 in stage 14.0 (TID 52, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 10:44:24 INFO TaskSetManager: Starting task 3.0 in stage 14.0 (TID 53, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 10:44:24 INFO Executor: Running task 0.0 in stage 14.0 (TID 50)
18/02/28 10:44:24 INFO Executor: Running task 1.0 in stage 14.0 (TID 51)
18/02/28 10:44:24 INFO Executor: Running task 2.0 in stage 14.0 (TID 52)
18/02/28 10:44:24 INFO Executor: Running task 3.0 in stage 14.0 (TID 53)
18/02/28 10:44:24 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:44:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:44:24 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:44:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:44:24 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:44:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:44:24 INFO Executor: Finished task 2.0 in stage 14.0 (TID 52). 2752 bytes result sent to driver
18/02/28 10:44:24 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:44:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:44:24 INFO Executor: Finished task 1.0 in stage 14.0 (TID 51). 2828 bytes result sent to driver
18/02/28 10:44:24 INFO TaskSetManager: Finished task 2.0 in stage 14.0 (TID 52) in 13 ms on localhost (executor driver) (1/4)
18/02/28 10:44:24 INFO Executor: Finished task 0.0 in stage 14.0 (TID 50). 2673 bytes result sent to driver
18/02/28 10:44:24 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 51) in 13 ms on localhost (executor driver) (2/4)
18/02/28 10:44:24 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 50) in 14 ms on localhost (executor driver) (3/4)
18/02/28 10:44:24 INFO Executor: Finished task 3.0 in stage 14.0 (TID 53). 2779 bytes result sent to driver
18/02/28 10:44:24 INFO TaskSetManager: Finished task 3.0 in stage 14.0 (TID 53) in 15 ms on localhost (executor driver) (4/4)
18/02/28 10:44:24 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
18/02/28 10:44:24 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:211) finished in 0.017 s
18/02/28 10:44:24 INFO DAGScheduler: Job 7 finished: collect at utils.scala:211, took 0.651761 s
18/02/28 10:44:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:44:40 INFO SparkSqlParser: Parsing command: SELECT `year`, SUM(`quantity`) / 1000000.0 AS `sum(quantity, na`.`rm = TRUE)/1e+06`
FROM `spark_fao`
GROUP BY `year`
18/02/28 10:44:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:44:52 INFO SparkSqlParser: Parsing command: SELECT `year`, SUM(`quantity`) / 1000000.0 AS `sum(quantity)/1e+06`
FROM `spark_fao`
GROUP BY `year`
18/02/28 10:44:52 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:44:52 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:44:52 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:44:52 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 10:44:52 INFO FileSourceStrategy: Output Data Schema: struct<year: int, quantity: int>
18/02/28 10:44:52 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 10:44:52 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 282.5 KB, free 363.8 MB)
18/02/28 10:44:52 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 24.1 KB, free 363.8 MB)
18/02/28 10:44:52 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:60157 (size: 24.1 KB, free: 366.1 MB)
18/02/28 10:44:52 INFO SparkContext: Created broadcast 22 from collect at utils.scala:211
18/02/28 10:44:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:44:52 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:44:52 INFO DAGScheduler: Registering RDD 49 (collect at utils.scala:211)
18/02/28 10:44:52 INFO DAGScheduler: Got job 8 (collect at utils.scala:211) with 4 output partitions
18/02/28 10:44:52 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:211)
18/02/28 10:44:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
18/02/28 10:44:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 15)
18/02/28 10:44:52 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[49] at collect at utils.scala:211), which has no missing parents
18/02/28 10:44:52 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 28.2 KB, free 363.8 MB)
18/02/28 10:44:52 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 13.9 KB, free 363.8 MB)
18/02/28 10:44:52 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:60157 (size: 13.9 KB, free: 366.1 MB)
18/02/28 10:44:52 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
18/02/28 10:44:52 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[49] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:44:52 INFO TaskSchedulerImpl: Adding task set 15.0 with 4 tasks
18/02/28 10:44:52 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 54, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 10:44:52 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 55, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 10:44:52 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 56, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 10:44:52 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 57, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 10:44:52 INFO Executor: Running task 0.0 in stage 15.0 (TID 54)
18/02/28 10:44:52 INFO Executor: Running task 1.0 in stage 15.0 (TID 55)
18/02/28 10:44:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 10:44:52 INFO Executor: Running task 2.0 in stage 15.0 (TID 56)
18/02/28 10:44:52 INFO Executor: Running task 3.0 in stage 15.0 (TID 57)
18/02/28 10:44:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 10:44:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 10:44:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 10:44:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 10:44:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 10:44:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 10:44:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 10:44:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 10:44:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 10:44:53 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:60157 in memory (size: 13.9 KB, free: 366.1 MB)
18/02/28 10:44:53 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:60157 in memory (size: 14.2 KB, free: 366.1 MB)
18/02/28 10:44:53 INFO ContextCleaner: Cleaned accumulator 497
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 10:44:53 INFO Executor: Finished task 3.0 in stage 15.0 (TID 57). 2060 bytes result sent to driver
18/02/28 10:44:53 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 57) in 357 ms on localhost (executor driver) (1/4)
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 10:44:53 INFO Executor: Finished task 2.0 in stage 15.0 (TID 56). 2060 bytes result sent to driver
18/02/28 10:44:53 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 56) in 426 ms on localhost (executor driver) (2/4)
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 10:44:53 INFO Executor: Finished task 1.0 in stage 15.0 (TID 55). 2060 bytes result sent to driver
18/02/28 10:44:53 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 55) in 507 ms on localhost (executor driver) (3/4)
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 10:44:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 10:44:53 INFO Executor: Finished task 0.0 in stage 15.0 (TID 54). 2060 bytes result sent to driver
18/02/28 10:44:53 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 54) in 641 ms on localhost (executor driver) (4/4)
18/02/28 10:44:53 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
18/02/28 10:44:53 INFO DAGScheduler: ShuffleMapStage 15 (collect at utils.scala:211) finished in 0.641 s
18/02/28 10:44:53 INFO DAGScheduler: looking for newly runnable stages
18/02/28 10:44:53 INFO DAGScheduler: running: Set()
18/02/28 10:44:53 INFO DAGScheduler: waiting: Set(ResultStage 16)
18/02/28 10:44:53 INFO DAGScheduler: failed: Set()
18/02/28 10:44:53 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[52] at collect at utils.scala:211), which has no missing parents
18/02/28 10:44:53 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 28.6 KB, free 363.8 MB)
18/02/28 10:44:53 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 14.2 KB, free 363.8 MB)
18/02/28 10:44:53 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:60157 (size: 14.2 KB, free: 366.1 MB)
18/02/28 10:44:53 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
18/02/28 10:44:53 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 16 (MapPartitionsRDD[52] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:44:53 INFO TaskSchedulerImpl: Adding task set 16.0 with 4 tasks
18/02/28 10:44:53 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 58, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 10:44:53 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 59, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 10:44:53 INFO TaskSetManager: Starting task 2.0 in stage 16.0 (TID 60, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 10:44:53 INFO TaskSetManager: Starting task 3.0 in stage 16.0 (TID 61, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 10:44:53 INFO Executor: Running task 0.0 in stage 16.0 (TID 58)
18/02/28 10:44:53 INFO Executor: Running task 1.0 in stage 16.0 (TID 59)
18/02/28 10:44:53 INFO Executor: Running task 2.0 in stage 16.0 (TID 60)
18/02/28 10:44:53 INFO Executor: Running task 3.0 in stage 16.0 (TID 61)
18/02/28 10:44:53 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:44:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:44:53 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:44:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 10:44:53 INFO Executor: Finished task 3.0 in stage 16.0 (TID 61). 2736 bytes result sent to driver
18/02/28 10:44:53 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:44:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:44:53 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:44:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:44:53 INFO TaskSetManager: Finished task 3.0 in stage 16.0 (TID 61) in 16 ms on localhost (executor driver) (1/4)
18/02/28 10:44:53 INFO Executor: Finished task 2.0 in stage 16.0 (TID 60). 2752 bytes result sent to driver
18/02/28 10:44:53 INFO TaskSetManager: Finished task 2.0 in stage 16.0 (TID 60) in 19 ms on localhost (executor driver) (2/4)
18/02/28 10:44:53 INFO Executor: Finished task 1.0 in stage 16.0 (TID 59). 2785 bytes result sent to driver
18/02/28 10:44:53 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 59) in 22 ms on localhost (executor driver) (3/4)
18/02/28 10:44:53 INFO Executor: Finished task 0.0 in stage 16.0 (TID 58). 2673 bytes result sent to driver
18/02/28 10:44:53 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 58) in 25 ms on localhost (executor driver) (4/4)
18/02/28 10:44:53 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
18/02/28 10:44:53 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:211) finished in 0.026 s
18/02/28 10:44:53 INFO DAGScheduler: Job 8 finished: collect at utils.scala:211, took 0.679661 s
18/02/28 10:47:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:47:05 INFO SparkSqlParser: Parsing command: SELECT MAX(`year`) AS `max(year)`
FROM `spark_fao`
18/02/28 10:47:05 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:47:05 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:47:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:47:05 INFO SparkSqlParser: Parsing command: SELECT MAX(`year`) AS `max(year)`
FROM `spark_fao`
LIMIT 10
18/02/28 10:47:05 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:47:05 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:47:05 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:47:05 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 10:47:05 INFO FileSourceStrategy: Output Data Schema: struct<year: int>
18/02/28 10:47:05 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 10:47:05 INFO CodeGenerator: Code generated in 7.988184 ms
18/02/28 10:47:05 INFO CodeGenerator: Code generated in 7.864415 ms
18/02/28 10:47:05 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 282.5 KB, free 363.5 MB)
18/02/28 10:47:05 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 24.1 KB, free 363.5 MB)
18/02/28 10:47:05 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:60157 (size: 24.1 KB, free: 366.1 MB)
18/02/28 10:47:05 INFO SparkContext: Created broadcast 25 from collect at utils.scala:211
18/02/28 10:47:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:47:05 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:47:05 INFO DAGScheduler: Registering RDD 55 (collect at utils.scala:211)
18/02/28 10:47:05 INFO DAGScheduler: Got job 9 (collect at utils.scala:211) with 1 output partitions
18/02/28 10:47:05 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:211)
18/02/28 10:47:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
18/02/28 10:47:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
18/02/28 10:47:05 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[55] at collect at utils.scala:211), which has no missing parents
18/02/28 10:47:05 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 14.2 KB, free 363.5 MB)
18/02/28 10:47:05 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 8.1 KB, free 363.5 MB)
18/02/28 10:47:05 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:60157 (size: 8.1 KB, free: 366.1 MB)
18/02/28 10:47:05 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
18/02/28 10:47:05 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[55] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:47:05 INFO TaskSchedulerImpl: Adding task set 17.0 with 4 tasks
18/02/28 10:47:05 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 62, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 10:47:05 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 63, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 10:47:05 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 64, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 10:47:05 INFO TaskSetManager: Starting task 3.0 in stage 17.0 (TID 65, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 10:47:05 INFO Executor: Running task 2.0 in stage 17.0 (TID 64)
18/02/28 10:47:05 INFO Executor: Running task 0.0 in stage 17.0 (TID 62)
18/02/28 10:47:05 INFO Executor: Running task 1.0 in stage 17.0 (TID 63)
18/02/28 10:47:05 INFO Executor: Running task 3.0 in stage 17.0 (TID 65)
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 10:47:05 INFO ContextCleaner: Cleaned accumulator 561
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 10:47:05 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:60157 in memory (size: 14.2 KB, free: 366.1 MB)
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 10:47:05 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:60157 in memory (size: 13.9 KB, free: 366.1 MB)
18/02/28 10:47:05 INFO Executor: Finished task 3.0 in stage 17.0 (TID 65). 1628 bytes result sent to driver
18/02/28 10:47:05 INFO TaskSetManager: Finished task 3.0 in stage 17.0 (TID 65) in 231 ms on localhost (executor driver) (1/4)
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 10:47:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 10:47:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 10:47:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 10:47:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 10:47:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 10:47:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 10:47:06 INFO Executor: Finished task 2.0 in stage 17.0 (TID 64). 1628 bytes result sent to driver
18/02/28 10:47:06 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 64) in 302 ms on localhost (executor driver) (2/4)
18/02/28 10:47:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 10:47:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 10:47:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 10:47:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 10:47:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 10:47:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 10:47:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 10:47:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 10:47:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 10:47:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 10:47:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 10:47:06 INFO Executor: Finished task 1.0 in stage 17.0 (TID 63). 1585 bytes result sent to driver
18/02/28 10:47:06 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 63) in 389 ms on localhost (executor driver) (3/4)
18/02/28 10:47:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 10:47:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 10:47:06 INFO Executor: Finished task 0.0 in stage 17.0 (TID 62). 1628 bytes result sent to driver
18/02/28 10:47:06 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 62) in 431 ms on localhost (executor driver) (4/4)
18/02/28 10:47:06 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
18/02/28 10:47:06 INFO DAGScheduler: ShuffleMapStage 17 (collect at utils.scala:211) finished in 0.439 s
18/02/28 10:47:06 INFO DAGScheduler: looking for newly runnable stages
18/02/28 10:47:06 INFO DAGScheduler: running: Set()
18/02/28 10:47:06 INFO DAGScheduler: waiting: Set(ResultStage 18)
18/02/28 10:47:06 INFO DAGScheduler: failed: Set()
18/02/28 10:47:06 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[58] at collect at utils.scala:211), which has no missing parents
18/02/28 10:47:06 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 7.1 KB, free 363.6 MB)
18/02/28 10:47:06 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 3.8 KB, free 363.6 MB)
18/02/28 10:47:06 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:60157 (size: 3.8 KB, free: 366.1 MB)
18/02/28 10:47:06 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
18/02/28 10:47:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[58] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 10:47:06 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
18/02/28 10:47:06 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 66, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 10:47:06 INFO Executor: Running task 0.0 in stage 18.0 (TID 66)
18/02/28 10:47:06 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:47:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:47:06 INFO Executor: Finished task 0.0 in stage 18.0 (TID 66). 1471 bytes result sent to driver
18/02/28 10:47:06 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 66) in 4 ms on localhost (executor driver) (1/1)
18/02/28 10:47:06 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
18/02/28 10:47:06 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:211) finished in 0.004 s
18/02/28 10:47:06 INFO DAGScheduler: Job 9 finished: collect at utils.scala:211, took 0.451959 s
18/02/28 10:47:06 INFO CodeGenerator: Code generated in 6.995919 ms
18/02/28 10:47:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:47:08 INFO SparkSqlParser: Parsing command: SELECT `country`, SUM(`quantity`) AS `sum(quantity, na`.`rm = TRUE)`
FROM `spark_fao`
WHERE (`year` = 2015.0)
GROUP BY `country`
18/02/28 10:47:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:47:13 INFO SparkSqlParser: Parsing command: SELECT `country`, SUM(`quantity`) AS `sum(quantity)`
FROM `spark_fao`
WHERE (`year` = 2015.0)
GROUP BY `country`
18/02/28 10:47:13 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:47:13 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:47:13 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:47:13 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(year#17),(cast(cast(year#17 as decimal(10,0)) as decimal(11,1)) = 2015.0)
18/02/28 10:47:13 INFO FileSourceStrategy: Output Data Schema: struct<year: int, country: string, quantity: int ... 1 more fields>
18/02/28 10:47:13 INFO FileSourceScanExec: Pushed Filters: IsNotNull(year)
18/02/28 10:47:13 INFO CodeGenerator: Code generated in 16.663969 ms
18/02/28 10:47:13 INFO CodeGenerator: Code generated in 29.687874 ms
18/02/28 10:47:13 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 282.5 KB, free 363.3 MB)
18/02/28 10:47:13 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 24.1 KB, free 363.3 MB)
18/02/28 10:47:13 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:60157 (size: 24.1 KB, free: 366.1 MB)
18/02/28 10:47:13 INFO SparkContext: Created broadcast 28 from collect at utils.scala:211
18/02/28 10:47:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:47:13 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:47:13 INFO DAGScheduler: Registering RDD 61 (collect at utils.scala:211)
18/02/28 10:47:13 INFO DAGScheduler: Got job 10 (collect at utils.scala:211) with 4 output partitions
18/02/28 10:47:13 INFO DAGScheduler: Final stage: ResultStage 20 (collect at utils.scala:211)
18/02/28 10:47:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
18/02/28 10:47:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 19)
18/02/28 10:47:13 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[61] at collect at utils.scala:211), which has no missing parents
18/02/28 10:47:13 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 33.2 KB, free 363.2 MB)
18/02/28 10:47:13 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 16.2 KB, free 363.2 MB)
18/02/28 10:47:13 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:60157 (size: 16.2 KB, free: 366.0 MB)
18/02/28 10:47:13 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
18/02/28 10:47:13 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[61] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:47:13 INFO TaskSchedulerImpl: Adding task set 19.0 with 4 tasks
18/02/28 10:47:13 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 67, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 10:47:13 INFO TaskSetManager: Starting task 1.0 in stage 19.0 (TID 68, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 10:47:13 INFO TaskSetManager: Starting task 2.0 in stage 19.0 (TID 69, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 10:47:13 INFO TaskSetManager: Starting task 3.0 in stage 19.0 (TID 70, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 10:47:13 INFO Executor: Running task 0.0 in stage 19.0 (TID 67)
18/02/28 10:47:13 INFO Executor: Running task 2.0 in stage 19.0 (TID 69)
18/02/28 10:47:13 INFO Executor: Running task 3.0 in stage 19.0 (TID 70)
18/02/28 10:47:13 INFO Executor: Running task 1.0 in stage 19.0 (TID 68)
18/02/28 10:47:13 INFO CodeGenerator: Code generated in 8.459984 ms
18/02/28 10:47:13 INFO CodeGenerator: Code generated in 10.68006 ms
18/02/28 10:47:13 INFO CodeGenerator: Code generated in 6.161275 ms
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 10:47:13 INFO CodeGenerator: Code generated in 9.936744 ms
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 10:47:13 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:60157 in memory (size: 8.1 KB, free: 366.0 MB)
18/02/28 10:47:13 INFO ContextCleaner: Cleaned accumulator 625
18/02/28 10:47:13 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:60157 in memory (size: 3.8 KB, free: 366.0 MB)
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 10:47:13 INFO Executor: Finished task 3.0 in stage 19.0 (TID 70). 2036 bytes result sent to driver
18/02/28 10:47:13 INFO TaskSetManager: Finished task 3.0 in stage 19.0 (TID 70) in 471 ms on localhost (executor driver) (1/4)
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 10:47:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 10:47:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 10:47:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 10:47:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 10:47:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 10:47:14 INFO Executor: Finished task 2.0 in stage 19.0 (TID 69). 1993 bytes result sent to driver
18/02/28 10:47:14 INFO TaskSetManager: Finished task 2.0 in stage 19.0 (TID 69) in 581 ms on localhost (executor driver) (2/4)
18/02/28 10:47:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 10:47:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 10:47:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 10:47:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 10:47:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 10:47:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 10:47:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 10:47:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 10:47:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 10:47:14 INFO Executor: Finished task 1.0 in stage 19.0 (TID 68). 1993 bytes result sent to driver
18/02/28 10:47:14 INFO TaskSetManager: Finished task 1.0 in stage 19.0 (TID 68) in 676 ms on localhost (executor driver) (3/4)
18/02/28 10:47:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 10:47:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 10:47:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 10:47:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 10:47:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 10:47:14 INFO Executor: Finished task 0.0 in stage 19.0 (TID 67). 2122 bytes result sent to driver
18/02/28 10:47:14 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 67) in 824 ms on localhost (executor driver) (4/4)
18/02/28 10:47:14 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
18/02/28 10:47:14 INFO DAGScheduler: ShuffleMapStage 19 (collect at utils.scala:211) finished in 0.825 s
18/02/28 10:47:14 INFO DAGScheduler: looking for newly runnable stages
18/02/28 10:47:14 INFO DAGScheduler: running: Set()
18/02/28 10:47:14 INFO DAGScheduler: waiting: Set(ResultStage 20)
18/02/28 10:47:14 INFO DAGScheduler: failed: Set()
18/02/28 10:47:14 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[64] at collect at utils.scala:211), which has no missing parents
18/02/28 10:47:14 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 28.6 KB, free 363.2 MB)
18/02/28 10:47:14 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 14.1 KB, free 363.2 MB)
18/02/28 10:47:14 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:60157 (size: 14.1 KB, free: 366.0 MB)
18/02/28 10:47:14 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1006
18/02/28 10:47:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 20 (MapPartitionsRDD[64] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:47:14 INFO TaskSchedulerImpl: Adding task set 20.0 with 4 tasks
18/02/28 10:47:14 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 71, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 10:47:14 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 72, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 10:47:14 INFO TaskSetManager: Starting task 2.0 in stage 20.0 (TID 73, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 10:47:14 INFO TaskSetManager: Starting task 3.0 in stage 20.0 (TID 74, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 10:47:14 INFO Executor: Running task 2.0 in stage 20.0 (TID 73)
18/02/28 10:47:14 INFO Executor: Running task 0.0 in stage 20.0 (TID 71)
18/02/28 10:47:14 INFO Executor: Running task 3.0 in stage 20.0 (TID 74)
18/02/28 10:47:14 INFO Executor: Running task 1.0 in stage 20.0 (TID 72)
18/02/28 10:47:14 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 10:47:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:47:14 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 10:47:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 10:47:14 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 10:47:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 10:47:14 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 10:47:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:47:14 INFO Executor: Finished task 3.0 in stage 20.0 (TID 74). 3777 bytes result sent to driver
18/02/28 10:47:14 INFO Executor: Finished task 2.0 in stage 20.0 (TID 73). 4138 bytes result sent to driver
18/02/28 10:47:14 INFO Executor: Finished task 1.0 in stage 20.0 (TID 72). 3785 bytes result sent to driver
18/02/28 10:47:14 INFO TaskSetManager: Finished task 3.0 in stage 20.0 (TID 74) in 8 ms on localhost (executor driver) (1/4)
18/02/28 10:47:14 INFO TaskSetManager: Finished task 2.0 in stage 20.0 (TID 73) in 8 ms on localhost (executor driver) (2/4)
18/02/28 10:47:14 INFO Executor: Finished task 0.0 in stage 20.0 (TID 71). 3749 bytes result sent to driver
18/02/28 10:47:14 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 72) in 10 ms on localhost (executor driver) (3/4)
18/02/28 10:47:14 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 71) in 11 ms on localhost (executor driver) (4/4)
18/02/28 10:47:14 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
18/02/28 10:47:14 INFO DAGScheduler: ResultStage 20 (collect at utils.scala:211) finished in 0.011 s
18/02/28 10:47:14 INFO DAGScheduler: Job 10 finished: collect at utils.scala:211, took 0.846372 s
18/02/28 10:47:14 INFO CodeGenerator: Code generated in 3.996912 ms
18/02/28 10:47:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:47:25 INFO SparkSqlParser: Parsing command: SELECT `country`, SUM(`quantity`) AS `sum(quantity)`
FROM `spark_fao`
WHERE (`year` = 2015.0)
GROUP BY `country`
18/02/28 10:47:25 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:47:25 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:47:25 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:47:25 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(year#17),(cast(cast(year#17 as decimal(10,0)) as decimal(11,1)) = 2015.0)
18/02/28 10:47:25 INFO FileSourceStrategy: Output Data Schema: struct<year: int, country: string, quantity: int ... 1 more fields>
18/02/28 10:47:25 INFO FileSourceScanExec: Pushed Filters: IsNotNull(year)
18/02/28 10:47:25 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 282.5 KB, free 363.0 MB)
18/02/28 10:47:25 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:60157 in memory (size: 16.2 KB, free: 366.1 MB)
18/02/28 10:47:25 INFO ContextCleaner: Cleaned accumulator 690
18/02/28 10:47:25 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:60157 in memory (size: 14.1 KB, free: 366.1 MB)
18/02/28 10:47:25 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 24.1 KB, free 363.0 MB)
18/02/28 10:47:25 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:60157 (size: 24.1 KB, free: 366.0 MB)
18/02/28 10:47:25 INFO SparkContext: Created broadcast 31 from collect at utils.scala:211
18/02/28 10:47:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:47:25 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:47:25 INFO DAGScheduler: Registering RDD 67 (collect at utils.scala:211)
18/02/28 10:47:25 INFO DAGScheduler: Got job 11 (collect at utils.scala:211) with 4 output partitions
18/02/28 10:47:25 INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:211)
18/02/28 10:47:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
18/02/28 10:47:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 21)
18/02/28 10:47:25 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[67] at collect at utils.scala:211), which has no missing parents
18/02/28 10:47:25 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 33.2 KB, free 363.0 MB)
18/02/28 10:47:25 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 16.2 KB, free 363.0 MB)
18/02/28 10:47:25 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:60157 (size: 16.2 KB, free: 366.0 MB)
18/02/28 10:47:25 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
18/02/28 10:47:25 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[67] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:47:25 INFO TaskSchedulerImpl: Adding task set 21.0 with 4 tasks
18/02/28 10:47:25 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 75, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 10:47:25 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 76, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 10:47:25 INFO TaskSetManager: Starting task 2.0 in stage 21.0 (TID 77, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 10:47:25 INFO TaskSetManager: Starting task 3.0 in stage 21.0 (TID 78, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 10:47:25 INFO Executor: Running task 1.0 in stage 21.0 (TID 76)
18/02/28 10:47:25 INFO Executor: Running task 0.0 in stage 21.0 (TID 75)
18/02/28 10:47:25 INFO Executor: Running task 2.0 in stage 21.0 (TID 77)
18/02/28 10:47:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 10:47:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 10:47:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 10:47:25 INFO Executor: Running task 3.0 in stage 21.0 (TID 78)
18/02/28 10:47:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 10:47:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 10:47:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 10:47:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 10:47:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 10:47:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 10:47:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 10:47:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 10:47:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 10:47:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 10:47:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 10:47:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 10:47:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 10:47:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 10:47:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 10:47:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 10:47:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 10:47:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 10:47:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 10:47:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 10:47:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 10:47:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 10:47:26 INFO Executor: Finished task 3.0 in stage 21.0 (TID 78). 2079 bytes result sent to driver
18/02/28 10:47:26 INFO TaskSetManager: Finished task 3.0 in stage 21.0 (TID 78) in 349 ms on localhost (executor driver) (1/4)
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 10:47:26 INFO Executor: Finished task 2.0 in stage 21.0 (TID 77). 1993 bytes result sent to driver
18/02/28 10:47:26 INFO TaskSetManager: Finished task 2.0 in stage 21.0 (TID 77) in 506 ms on localhost (executor driver) (2/4)
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 10:47:26 INFO Executor: Finished task 1.0 in stage 21.0 (TID 76). 1993 bytes result sent to driver
18/02/28 10:47:26 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 76) in 613 ms on localhost (executor driver) (3/4)
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 10:47:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 10:47:26 INFO Executor: Finished task 0.0 in stage 21.0 (TID 75). 2122 bytes result sent to driver
18/02/28 10:47:26 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 75) in 684 ms on localhost (executor driver) (4/4)
18/02/28 10:47:26 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
18/02/28 10:47:26 INFO DAGScheduler: ShuffleMapStage 21 (collect at utils.scala:211) finished in 0.684 s
18/02/28 10:47:26 INFO DAGScheduler: looking for newly runnable stages
18/02/28 10:47:26 INFO DAGScheduler: running: Set()
18/02/28 10:47:26 INFO DAGScheduler: waiting: Set(ResultStage 22)
18/02/28 10:47:26 INFO DAGScheduler: failed: Set()
18/02/28 10:47:26 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[70] at collect at utils.scala:211), which has no missing parents
18/02/28 10:47:26 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 28.6 KB, free 362.9 MB)
18/02/28 10:47:26 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 14.1 KB, free 362.9 MB)
18/02/28 10:47:26 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:60157 (size: 14.1 KB, free: 366.0 MB)
18/02/28 10:47:26 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1006
18/02/28 10:47:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 22 (MapPartitionsRDD[70] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:47:26 INFO TaskSchedulerImpl: Adding task set 22.0 with 4 tasks
18/02/28 10:47:26 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 79, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 10:47:26 INFO TaskSetManager: Starting task 1.0 in stage 22.0 (TID 80, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 10:47:26 INFO TaskSetManager: Starting task 2.0 in stage 22.0 (TID 81, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 10:47:26 INFO TaskSetManager: Starting task 3.0 in stage 22.0 (TID 82, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 10:47:26 INFO Executor: Running task 1.0 in stage 22.0 (TID 80)
18/02/28 10:47:26 INFO Executor: Running task 0.0 in stage 22.0 (TID 79)
18/02/28 10:47:26 INFO Executor: Running task 2.0 in stage 22.0 (TID 81)
18/02/28 10:47:26 INFO Executor: Running task 3.0 in stage 22.0 (TID 82)
18/02/28 10:47:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 10:47:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 10:47:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 10:47:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:47:26 INFO Executor: Finished task 3.0 in stage 22.0 (TID 82). 3777 bytes result sent to driver
18/02/28 10:47:26 INFO Executor: Finished task 2.0 in stage 22.0 (TID 81). 4138 bytes result sent to driver
18/02/28 10:47:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 10:47:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
18/02/28 10:47:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 10:47:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:47:26 INFO Executor: Finished task 1.0 in stage 22.0 (TID 80). 3828 bytes result sent to driver
18/02/28 10:47:26 INFO TaskSetManager: Finished task 3.0 in stage 22.0 (TID 82) in 19 ms on localhost (executor driver) (1/4)
18/02/28 10:47:26 INFO TaskSetManager: Finished task 2.0 in stage 22.0 (TID 81) in 20 ms on localhost (executor driver) (2/4)
18/02/28 10:47:26 INFO TaskSetManager: Finished task 1.0 in stage 22.0 (TID 80) in 21 ms on localhost (executor driver) (3/4)
18/02/28 10:47:26 INFO Executor: Finished task 0.0 in stage 22.0 (TID 79). 3749 bytes result sent to driver
18/02/28 10:47:26 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 79) in 23 ms on localhost (executor driver) (4/4)
18/02/28 10:47:26 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
18/02/28 10:47:26 INFO DAGScheduler: ResultStage 22 (collect at utils.scala:211) finished in 0.024 s
18/02/28 10:47:26 INFO DAGScheduler: Job 11 finished: collect at utils.scala:211, took 0.719079 s
18/02/28 10:50:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:50:46 INFO SparkSqlParser: Parsing command: SELECT `x`, `y`, SUM(`quantity`) AS `fillname`
FROM (SELECT `year`, `production_area`, `country`, `iso`, `source`, `species`, `common_name`, `sci_name`, `quantity`, `value`, (max(`year`) OVER () - min(`year`) OVER () / 100.0 * CASE WHEN (CAST(FLOOR((`year` - min(`year`) OVER ()) / max(`year`) OVER () - min(`year`) OVER () / 100.0) AS INT) = 100.0) THEN (CAST(FLOOR((`year` - min(`year`) OVER ()) / max(`year`) OVER () - min(`year`) OVER () / 100.0) AS INT) - 1.0) WHEN NOT(CAST(FLOOR((`year` - min(`year`) OVER ()) / max(`year`) OVER () - min(`year`) OVER () / 100.0) AS INT) = 100.0) THEN (CAST(FLOOR((`year` - min(`year`) OVER ()) / max(`year`) OVER () - min(`year`) OVER () / 100.0) AS INT)) END) + min(`year`) OVER () AS `x`, (max(`country`) OVER () - min(`country`) OVER () / 100.0 * CASE WHEN (CAST(FLOOR((`country` - min(`country`) OVER ()) / max(`country`) OVER () - min(`country`) OVER () / 100.0) AS INT) = 100.0) THEN (CAST(FLOOR((`country` - min(`country`) OVER ()) / max(`country`) OVER () - min(`country`) OVER () / 100.0) AS INT) - 1.0) WHEN NOT(CAST(FLOOR((`country` - min(`country`) OVER ()) / max(`country`) OVER () - min(`country`) OVER () / 100.0) AS INT) = 100.0) THEN (CAST(FLOOR((`country` - min(`country`) OVER ()) / max(`country`) OVER () - min(`country`) OVER () / 100.0) AS INT)) END) + min(`country`) OVER () AS `y`
FROM `spark_fao`) `eedjsqsuap`
GROUP BY `x`, `y`
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:50:46 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:50:47 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:50:47 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 10:50:47 INFO FileSourceStrategy: Output Data Schema: struct<year: int, country: string, quantity: int ... 1 more fields>
18/02/28 10:50:47 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 10:50:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
18/02/28 10:50:47 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
18/02/28 10:50:47 INFO CodeGenerator: Code generated in 77.863099 ms
18/02/28 10:50:47 INFO CodeGenerator: Code generated in 6.265649 ms
18/02/28 10:50:47 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 282.5 KB, free 362.6 MB)
18/02/28 10:50:47 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 24.1 KB, free 362.6 MB)
18/02/28 10:50:47 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:60157 (size: 24.1 KB, free: 366.0 MB)
18/02/28 10:50:47 INFO SparkContext: Created broadcast 34 from collect at utils.scala:211
18/02/28 10:50:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:50:47 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:50:47 INFO DAGScheduler: Registering RDD 73 (collect at utils.scala:211)
18/02/28 10:50:47 INFO DAGScheduler: Got job 12 (collect at utils.scala:211) with 1 output partitions
18/02/28 10:50:47 INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:211)
18/02/28 10:50:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
18/02/28 10:50:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 23)
18/02/28 10:50:47 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[73] at collect at utils.scala:211), which has no missing parents
18/02/28 10:50:47 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 13.7 KB, free 362.6 MB)
18/02/28 10:50:47 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 7.8 KB, free 362.6 MB)
18/02/28 10:50:47 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:60157 (size: 7.8 KB, free: 366.0 MB)
18/02/28 10:50:47 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
18/02/28 10:50:47 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[73] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:50:47 INFO TaskSchedulerImpl: Adding task set 23.0 with 4 tasks
18/02/28 10:50:47 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 83, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 10:50:47 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 84, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 10:50:47 INFO TaskSetManager: Starting task 2.0 in stage 23.0 (TID 85, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 10:50:47 INFO TaskSetManager: Starting task 3.0 in stage 23.0 (TID 86, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 10:50:47 INFO Executor: Running task 0.0 in stage 23.0 (TID 83)
18/02/28 10:50:47 INFO Executor: Running task 3.0 in stage 23.0 (TID 86)
18/02/28 10:50:47 INFO Executor: Running task 1.0 in stage 23.0 (TID 84)
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 10:50:47 INFO Executor: Running task 2.0 in stage 23.0 (TID 85)
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 10:50:47 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:60157 in memory (size: 14.1 KB, free: 366.0 MB)
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 10:50:47 INFO ContextCleaner: Cleaned accumulator 755
18/02/28 10:50:47 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:60157 in memory (size: 16.2 KB, free: 366.0 MB)
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 10:50:47 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 10:50:48 INFO Executor: Finished task 3.0 in stage 23.0 (TID 86). 1427 bytes result sent to driver
18/02/28 10:50:48 INFO TaskSetManager: Finished task 3.0 in stage 23.0 (TID 86) in 536 ms on localhost (executor driver) (1/4)
18/02/28 10:50:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 10:50:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 10:50:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 10:50:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 10:50:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 10:50:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 10:50:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 10:50:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 10:50:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 10:50:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 10:50:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 10:50:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 10:50:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 10:50:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 10:50:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 10:50:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 10:50:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 10:50:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 10:50:48 INFO Executor: Finished task 2.0 in stage 23.0 (TID 85). 1427 bytes result sent to driver
18/02/28 10:50:48 INFO TaskSetManager: Finished task 2.0 in stage 23.0 (TID 85) in 709 ms on localhost (executor driver) (2/4)
18/02/28 10:50:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 10:50:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 10:50:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 10:50:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 10:50:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 10:50:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 10:50:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 10:50:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 10:50:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 10:50:48 INFO Executor: Finished task 1.0 in stage 23.0 (TID 84). 1427 bytes result sent to driver
18/02/28 10:50:48 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 84) in 842 ms on localhost (executor driver) (3/4)
18/02/28 10:50:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 10:50:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 10:50:48 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 10:50:48 INFO Executor: Finished task 0.0 in stage 23.0 (TID 83). 1427 bytes result sent to driver
18/02/28 10:50:48 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 83) in 928 ms on localhost (executor driver) (4/4)
18/02/28 10:50:48 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
18/02/28 10:50:48 INFO DAGScheduler: ShuffleMapStage 23 (collect at utils.scala:211) finished in 0.929 s
18/02/28 10:50:48 INFO DAGScheduler: looking for newly runnable stages
18/02/28 10:50:48 INFO DAGScheduler: running: Set()
18/02/28 10:50:48 INFO DAGScheduler: waiting: Set(ResultStage 24)
18/02/28 10:50:48 INFO DAGScheduler: failed: Set()
18/02/28 10:50:48 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[77] at collect at utils.scala:211), which has no missing parents
18/02/28 10:50:48 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 99.4 KB, free 362.6 MB)
18/02/28 10:50:48 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 36.1 KB, free 362.6 MB)
18/02/28 10:50:48 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:60157 (size: 36.1 KB, free: 366.0 MB)
18/02/28 10:50:48 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1006
18/02/28 10:50:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[77] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 10:50:48 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
18/02/28 10:50:48 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 87, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 10:50:48 INFO Executor: Running task 0.0 in stage 24.0 (TID 87)
18/02/28 10:50:48 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:50:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:50:48 INFO CodeGenerator: Code generated in 12.515079 ms
18/02/28 10:50:48 INFO CodeGenerator: Code generated in 16.663969 ms
18/02/28 10:50:48 INFO CodeGenerator: Code generated in 24.489596 ms
18/02/28 10:50:48 INFO CodeGenerator: Code generated in 16.312763 ms
18/02/28 10:50:48 INFO CodeGenerator: Code generated in 12.215002 ms
18/02/28 10:50:48 INFO CodeGenerator: Code generated in 7.122861 ms
18/02/28 10:50:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (0  time so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (1  time so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (2  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (3  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (4  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (5  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (6  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (7  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (8  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (9  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (10  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (11  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (12  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (13  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (14  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (15  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (16  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (17  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (18  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (19  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (20  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (21  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (22  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (23  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (24  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (25  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (26  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (27  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (28  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (29  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (30  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (31  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (32  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (33  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (34  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (35  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (36  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (37  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (38  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (39  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (40  times so far)
18/02/28 10:50:48 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:48 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (41  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (42  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (43  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (44  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (45  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (46  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (47  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (48  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (49  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (50  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (51  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (52  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (53  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (54  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (55  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (56  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (57  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (58  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (59  times so far)
18/02/28 10:50:49 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:60157 in memory (size: 7.8 KB, free: 366.0 MB)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (60  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (61  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (62  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (63  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (64  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (65  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (66  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (67  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (68  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (69  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (70  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (71  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (72  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (73  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (74  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (75  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (76  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (77  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (78  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (79  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (80  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (81  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (82  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (83  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (84  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (85  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (86  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (87  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (88  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (89  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (90  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (91  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (92  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (93  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (94  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (95  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (96  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (97  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (98  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (99  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (100  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (101  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (102  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (103  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (104  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (105  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (106  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (107  times so far)
18/02/28 10:50:49 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 10:50:49 INFO UnsafeExternalSorter: Thread 113 spilling sort data of 4.1 MB to disk (108  times so far)
18/02/28 10:50:58 INFO Executor: Finished task 0.0 in stage 24.0 (TID 87). 2627 bytes result sent to driver
18/02/28 10:50:58 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 87) in 10473 ms on localhost (executor driver) (1/1)
18/02/28 10:50:58 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
18/02/28 10:50:58 INFO DAGScheduler: ResultStage 24 (collect at utils.scala:211) finished in 10.473 s
18/02/28 10:50:58 INFO DAGScheduler: Job 12 finished: collect at utils.scala:211, took 11.416593 s
18/02/28 10:50:58 INFO CodeGenerator: Code generated in 5.734609 ms
18/02/28 10:51:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:51:52 INFO SparkSqlParser: Parsing command: SELECT `production_area`, SUM(`quantity`) AS `sum(quantity)`
FROM `spark_fao`
WHERE (`year` = 2015.0)
GROUP BY `production_area`
18/02/28 10:51:52 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:51:52 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:51:52 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:51:52 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(year#17),(cast(cast(year#17 as decimal(10,0)) as decimal(11,1)) = 2015.0)
18/02/28 10:51:52 INFO FileSourceStrategy: Output Data Schema: struct<year: int, production_area: int, quantity: int ... 1 more fields>
18/02/28 10:51:52 INFO FileSourceScanExec: Pushed Filters: IsNotNull(year)
18/02/28 10:51:52 INFO CodeGenerator: Code generated in 24.865486 ms
18/02/28 10:51:52 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 282.5 KB, free 362.3 MB)
18/02/28 10:51:52 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 24.1 KB, free 362.3 MB)
18/02/28 10:51:52 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:60157 (size: 24.1 KB, free: 366.0 MB)
18/02/28 10:51:52 INFO SparkContext: Created broadcast 37 from collect at utils.scala:211
18/02/28 10:51:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:51:52 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:51:52 INFO DAGScheduler: Registering RDD 80 (collect at utils.scala:211)
18/02/28 10:51:52 INFO DAGScheduler: Got job 13 (collect at utils.scala:211) with 4 output partitions
18/02/28 10:51:52 INFO DAGScheduler: Final stage: ResultStage 26 (collect at utils.scala:211)
18/02/28 10:51:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
18/02/28 10:51:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 25)
18/02/28 10:51:52 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[80] at collect at utils.scala:211), which has no missing parents
18/02/28 10:51:52 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 32.8 KB, free 362.2 MB)
18/02/28 10:51:52 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 15.9 KB, free 362.2 MB)
18/02/28 10:51:52 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:60157 (size: 15.9 KB, free: 365.9 MB)
18/02/28 10:51:52 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1006
18/02/28 10:51:52 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[80] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:51:52 INFO TaskSchedulerImpl: Adding task set 25.0 with 4 tasks
18/02/28 10:51:52 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 88, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 10:51:52 INFO TaskSetManager: Starting task 1.0 in stage 25.0 (TID 89, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 10:51:52 INFO TaskSetManager: Starting task 2.0 in stage 25.0 (TID 90, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 10:51:52 INFO TaskSetManager: Starting task 3.0 in stage 25.0 (TID 91, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 10:51:52 INFO Executor: Running task 0.0 in stage 25.0 (TID 88)
18/02/28 10:51:52 INFO Executor: Running task 3.0 in stage 25.0 (TID 91)
18/02/28 10:51:52 INFO Executor: Running task 1.0 in stage 25.0 (TID 89)
18/02/28 10:51:52 INFO Executor: Running task 2.0 in stage 25.0 (TID 90)
18/02/28 10:51:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 10:51:52 INFO CodeGenerator: Code generated in 7.835852 ms
18/02/28 10:51:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 10:51:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 10:51:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 10:51:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 10:51:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 10:51:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 10:51:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 10:51:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 10:51:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 10:51:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 10:51:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 10:51:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 10:51:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 10:51:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 10:51:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 10:51:53 INFO Executor: Finished task 3.0 in stage 25.0 (TID 91). 1993 bytes result sent to driver
18/02/28 10:51:53 INFO TaskSetManager: Finished task 3.0 in stage 25.0 (TID 91) in 572 ms on localhost (executor driver) (1/4)
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 10:51:53 INFO Executor: Finished task 2.0 in stage 25.0 (TID 90). 1993 bytes result sent to driver
18/02/28 10:51:53 INFO TaskSetManager: Finished task 2.0 in stage 25.0 (TID 90) in 684 ms on localhost (executor driver) (2/4)
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 10:51:53 INFO Executor: Finished task 1.0 in stage 25.0 (TID 89). 2036 bytes result sent to driver
18/02/28 10:51:53 INFO TaskSetManager: Finished task 1.0 in stage 25.0 (TID 89) in 789 ms on localhost (executor driver) (3/4)
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 10:51:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 10:51:53 INFO Executor: Finished task 0.0 in stage 25.0 (TID 88). 2122 bytes result sent to driver
18/02/28 10:51:53 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 88) in 875 ms on localhost (executor driver) (4/4)
18/02/28 10:51:53 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
18/02/28 10:51:53 INFO DAGScheduler: ShuffleMapStage 25 (collect at utils.scala:211) finished in 0.880 s
18/02/28 10:51:53 INFO DAGScheduler: looking for newly runnable stages
18/02/28 10:51:53 INFO DAGScheduler: running: Set()
18/02/28 10:51:53 INFO DAGScheduler: waiting: Set(ResultStage 26)
18/02/28 10:51:53 INFO DAGScheduler: failed: Set()
18/02/28 10:51:53 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[83] at collect at utils.scala:211), which has no missing parents
18/02/28 10:51:53 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 28.3 KB, free 362.2 MB)
18/02/28 10:51:53 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 14.0 KB, free 362.2 MB)
18/02/28 10:51:53 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:60157 (size: 14.0 KB, free: 365.9 MB)
18/02/28 10:51:53 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1006
18/02/28 10:51:53 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 26 (MapPartitionsRDD[83] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:51:53 INFO TaskSchedulerImpl: Adding task set 26.0 with 4 tasks
18/02/28 10:51:53 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 92, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 10:51:53 INFO TaskSetManager: Starting task 1.0 in stage 26.0 (TID 93, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 10:51:53 INFO TaskSetManager: Starting task 2.0 in stage 26.0 (TID 94, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 10:51:53 INFO TaskSetManager: Starting task 3.0 in stage 26.0 (TID 95, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 10:51:53 INFO Executor: Running task 0.0 in stage 26.0 (TID 92)
18/02/28 10:51:53 INFO Executor: Running task 3.0 in stage 26.0 (TID 95)
18/02/28 10:51:53 INFO Executor: Running task 1.0 in stage 26.0 (TID 93)
18/02/28 10:51:53 INFO Executor: Running task 2.0 in stage 26.0 (TID 94)
18/02/28 10:51:53 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 10:51:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:51:53 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 10:51:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 10:51:53 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 10:51:53 INFO Executor: Finished task 3.0 in stage 26.0 (TID 95). 2619 bytes result sent to driver
18/02/28 10:51:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 10:51:53 INFO TaskSetManager: Finished task 3.0 in stage 26.0 (TID 95) in 5 ms on localhost (executor driver) (1/4)
18/02/28 10:51:53 INFO Executor: Finished task 0.0 in stage 26.0 (TID 92). 2554 bytes result sent to driver
18/02/28 10:51:53 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 92) in 7 ms on localhost (executor driver) (2/4)
18/02/28 10:51:53 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 10:51:53 INFO Executor: Finished task 2.0 in stage 26.0 (TID 94). 2627 bytes result sent to driver
18/02/28 10:51:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:51:53 INFO TaskSetManager: Finished task 2.0 in stage 26.0 (TID 94) in 8 ms on localhost (executor driver) (3/4)
18/02/28 10:51:53 INFO Executor: Finished task 1.0 in stage 26.0 (TID 93). 2647 bytes result sent to driver
18/02/28 10:51:53 INFO TaskSetManager: Finished task 1.0 in stage 26.0 (TID 93) in 9 ms on localhost (executor driver) (4/4)
18/02/28 10:51:53 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
18/02/28 10:51:53 INFO DAGScheduler: ResultStage 26 (collect at utils.scala:211) finished in 0.011 s
18/02/28 10:51:53 INFO DAGScheduler: Job 13 finished: collect at utils.scala:211, took 0.901810 s
18/02/28 10:52:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:52:09 INFO SparkSqlParser: Parsing command: SELECT `production_area`, SUM(`quantity`) AS `sum(quantity)`
FROM `spark_fao`
WHERE (`year` = 2015.0)
GROUP BY `production_area`
18/02/28 10:52:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:52:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:52:09 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:52:09 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(year#17),(cast(cast(year#17 as decimal(10,0)) as decimal(11,1)) = 2015.0)
18/02/28 10:52:09 INFO FileSourceStrategy: Output Data Schema: struct<year: int, production_area: int, quantity: int ... 1 more fields>
18/02/28 10:52:09 INFO FileSourceScanExec: Pushed Filters: IsNotNull(year)
18/02/28 10:52:09 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 282.5 KB, free 361.9 MB)
18/02/28 10:52:09 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 24.1 KB, free 361.9 MB)
18/02/28 10:52:09 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:60157 (size: 24.1 KB, free: 365.9 MB)
18/02/28 10:52:09 INFO SparkContext: Created broadcast 40 from collect at utils.scala:211
18/02/28 10:52:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:52:09 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:52:09 INFO DAGScheduler: Registering RDD 86 (collect at utils.scala:211)
18/02/28 10:52:09 INFO DAGScheduler: Got job 14 (collect at utils.scala:211) with 4 output partitions
18/02/28 10:52:09 INFO DAGScheduler: Final stage: ResultStage 28 (collect at utils.scala:211)
18/02/28 10:52:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)
18/02/28 10:52:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 27)
18/02/28 10:52:09 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[86] at collect at utils.scala:211), which has no missing parents
18/02/28 10:52:09 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 32.8 KB, free 361.9 MB)
18/02/28 10:52:09 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 15.9 KB, free 361.8 MB)
18/02/28 10:52:09 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:60157 (size: 15.9 KB, free: 365.9 MB)
18/02/28 10:52:09 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
18/02/28 10:52:09 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[86] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:52:09 INFO TaskSchedulerImpl: Adding task set 27.0 with 4 tasks
18/02/28 10:52:09 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 96, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 10:52:09 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 97, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 10:52:09 INFO TaskSetManager: Starting task 2.0 in stage 27.0 (TID 98, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 10:52:09 INFO TaskSetManager: Starting task 3.0 in stage 27.0 (TID 99, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 10:52:09 INFO Executor: Running task 0.0 in stage 27.0 (TID 96)
18/02/28 10:52:09 INFO Executor: Running task 1.0 in stage 27.0 (TID 97)
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 10:52:09 INFO Executor: Running task 2.0 in stage 27.0 (TID 98)
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 10:52:09 INFO Executor: Running task 3.0 in stage 27.0 (TID 99)
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 10:52:09 INFO ContextCleaner: Cleaned accumulator 884
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 10:52:09 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:60157 in memory (size: 14.0 KB, free: 365.9 MB)
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 10:52:09 INFO Executor: Finished task 3.0 in stage 27.0 (TID 99). 1993 bytes result sent to driver
18/02/28 10:52:09 INFO TaskSetManager: Finished task 3.0 in stage 27.0 (TID 99) in 398 ms on localhost (executor driver) (1/4)
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 10:52:09 INFO Executor: Finished task 2.0 in stage 27.0 (TID 98). 1993 bytes result sent to driver
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 10:52:09 INFO TaskSetManager: Finished task 2.0 in stage 27.0 (TID 98) in 498 ms on localhost (executor driver) (2/4)
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 10:52:09 INFO Executor: Finished task 1.0 in stage 27.0 (TID 97). 1993 bytes result sent to driver
18/02/28 10:52:09 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 97) in 599 ms on localhost (executor driver) (3/4)
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 10:52:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 10:52:09 INFO Executor: Finished task 0.0 in stage 27.0 (TID 96). 2122 bytes result sent to driver
18/02/28 10:52:09 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 96) in 679 ms on localhost (executor driver) (4/4)
18/02/28 10:52:09 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
18/02/28 10:52:09 INFO DAGScheduler: ShuffleMapStage 27 (collect at utils.scala:211) finished in 0.680 s
18/02/28 10:52:09 INFO DAGScheduler: looking for newly runnable stages
18/02/28 10:52:09 INFO DAGScheduler: running: Set()
18/02/28 10:52:09 INFO DAGScheduler: waiting: Set(ResultStage 28)
18/02/28 10:52:09 INFO DAGScheduler: failed: Set()
18/02/28 10:52:09 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[89] at collect at utils.scala:211), which has no missing parents
18/02/28 10:52:09 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 28.3 KB, free 361.9 MB)
18/02/28 10:52:09 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 14.0 KB, free 361.8 MB)
18/02/28 10:52:09 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:60157 (size: 14.0 KB, free: 365.9 MB)
18/02/28 10:52:09 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1006
18/02/28 10:52:09 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 28 (MapPartitionsRDD[89] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:52:09 INFO TaskSchedulerImpl: Adding task set 28.0 with 4 tasks
18/02/28 10:52:09 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 100, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 10:52:09 INFO TaskSetManager: Starting task 1.0 in stage 28.0 (TID 101, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 10:52:09 INFO TaskSetManager: Starting task 2.0 in stage 28.0 (TID 102, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 10:52:09 INFO TaskSetManager: Starting task 3.0 in stage 28.0 (TID 103, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 10:52:09 INFO Executor: Running task 0.0 in stage 28.0 (TID 100)
18/02/28 10:52:09 INFO Executor: Running task 1.0 in stage 28.0 (TID 101)
18/02/28 10:52:09 INFO Executor: Running task 2.0 in stage 28.0 (TID 102)
18/02/28 10:52:09 INFO Executor: Running task 3.0 in stage 28.0 (TID 103)
18/02/28 10:52:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 10:52:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 10:52:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 10:52:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 10:52:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 10:52:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:52:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 10:52:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:52:09 INFO Executor: Finished task 1.0 in stage 28.0 (TID 101). 2647 bytes result sent to driver
18/02/28 10:52:09 INFO Executor: Finished task 0.0 in stage 28.0 (TID 100). 2597 bytes result sent to driver
18/02/28 10:52:09 INFO Executor: Finished task 3.0 in stage 28.0 (TID 103). 2662 bytes result sent to driver
18/02/28 10:52:09 INFO Executor: Finished task 2.0 in stage 28.0 (TID 102). 2627 bytes result sent to driver
18/02/28 10:52:09 INFO TaskSetManager: Finished task 1.0 in stage 28.0 (TID 101) in 8 ms on localhost (executor driver) (1/4)
18/02/28 10:52:09 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 100) in 9 ms on localhost (executor driver) (2/4)
18/02/28 10:52:09 INFO TaskSetManager: Finished task 2.0 in stage 28.0 (TID 102) in 9 ms on localhost (executor driver) (3/4)
18/02/28 10:52:09 INFO TaskSetManager: Finished task 3.0 in stage 28.0 (TID 103) in 9 ms on localhost (executor driver) (4/4)
18/02/28 10:52:09 INFO DAGScheduler: ResultStage 28 (collect at utils.scala:211) finished in 0.010 s
18/02/28 10:52:09 INFO DAGScheduler: Job 14 finished: collect at utils.scala:211, took 0.705929 s
18/02/28 10:52:09 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
18/02/28 10:53:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:53:01 INFO SparkSqlParser: Parsing command: SELECT `production_area`, SUM(`quantity`) / 1000000.0 AS `sum(quantity)/1e+06`
FROM `spark_fao`
GROUP BY `production_area`
18/02/28 10:53:01 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:53:01 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:53:01 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:53:01 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 10:53:01 INFO FileSourceStrategy: Output Data Schema: struct<production_area: int, quantity: int>
18/02/28 10:53:01 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 10:53:01 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 282.5 KB, free 361.6 MB)
18/02/28 10:53:01 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 24.1 KB, free 361.5 MB)
18/02/28 10:53:01 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:60157 (size: 24.1 KB, free: 365.9 MB)
18/02/28 10:53:01 INFO SparkContext: Created broadcast 43 from collect at utils.scala:211
18/02/28 10:53:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:53:01 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:53:01 INFO DAGScheduler: Registering RDD 92 (collect at utils.scala:211)
18/02/28 10:53:01 INFO DAGScheduler: Got job 15 (collect at utils.scala:211) with 4 output partitions
18/02/28 10:53:01 INFO DAGScheduler: Final stage: ResultStage 30 (collect at utils.scala:211)
18/02/28 10:53:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
18/02/28 10:53:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 29)
18/02/28 10:53:01 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[92] at collect at utils.scala:211), which has no missing parents
18/02/28 10:53:01 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 28.2 KB, free 361.5 MB)
18/02/28 10:53:01 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 13.9 KB, free 361.5 MB)
18/02/28 10:53:01 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:60157 (size: 13.9 KB, free: 365.9 MB)
18/02/28 10:53:01 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1006
18/02/28 10:53:01 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[92] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:53:01 INFO TaskSchedulerImpl: Adding task set 29.0 with 4 tasks
18/02/28 10:53:01 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 104, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 10:53:01 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 105, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 10:53:01 INFO TaskSetManager: Starting task 2.0 in stage 29.0 (TID 106, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 10:53:01 INFO TaskSetManager: Starting task 3.0 in stage 29.0 (TID 107, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 10:53:01 INFO Executor: Running task 0.0 in stage 29.0 (TID 104)
18/02/28 10:53:01 INFO Executor: Running task 1.0 in stage 29.0 (TID 105)
18/02/28 10:53:01 INFO Executor: Running task 2.0 in stage 29.0 (TID 106)
18/02/28 10:53:01 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 10:53:02 INFO Executor: Running task 3.0 in stage 29.0 (TID 107)
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 10:53:02 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:60157 in memory (size: 15.9 KB, free: 365.9 MB)
18/02/28 10:53:02 INFO ContextCleaner: Cleaned accumulator 949
18/02/28 10:53:02 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:60157 in memory (size: 14.0 KB, free: 365.9 MB)
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 10:53:02 INFO Executor: Finished task 3.0 in stage 29.0 (TID 107). 2103 bytes result sent to driver
18/02/28 10:53:02 INFO TaskSetManager: Finished task 3.0 in stage 29.0 (TID 107) in 253 ms on localhost (executor driver) (1/4)
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 10:53:02 INFO Executor: Finished task 2.0 in stage 29.0 (TID 106). 2060 bytes result sent to driver
18/02/28 10:53:02 INFO TaskSetManager: Finished task 2.0 in stage 29.0 (TID 106) in 342 ms on localhost (executor driver) (2/4)
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 10:53:02 INFO Executor: Finished task 1.0 in stage 29.0 (TID 105). 2103 bytes result sent to driver
18/02/28 10:53:02 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 105) in 449 ms on localhost (executor driver) (3/4)
18/02/28 10:53:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 10:53:02 INFO Executor: Finished task 0.0 in stage 29.0 (TID 104). 2060 bytes result sent to driver
18/02/28 10:53:02 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 104) in 536 ms on localhost (executor driver) (4/4)
18/02/28 10:53:02 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
18/02/28 10:53:02 INFO DAGScheduler: ShuffleMapStage 29 (collect at utils.scala:211) finished in 0.537 s
18/02/28 10:53:02 INFO DAGScheduler: looking for newly runnable stages
18/02/28 10:53:02 INFO DAGScheduler: running: Set()
18/02/28 10:53:02 INFO DAGScheduler: waiting: Set(ResultStage 30)
18/02/28 10:53:02 INFO DAGScheduler: failed: Set()
18/02/28 10:53:02 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[95] at collect at utils.scala:211), which has no missing parents
18/02/28 10:53:02 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 28.6 KB, free 361.6 MB)
18/02/28 10:53:02 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 14.2 KB, free 361.5 MB)
18/02/28 10:53:02 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:60157 (size: 14.2 KB, free: 365.9 MB)
18/02/28 10:53:02 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1006
18/02/28 10:53:02 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 30 (MapPartitionsRDD[95] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:53:02 INFO TaskSchedulerImpl: Adding task set 30.0 with 4 tasks
18/02/28 10:53:02 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 108, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 10:53:02 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 109, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 10:53:02 INFO TaskSetManager: Starting task 2.0 in stage 30.0 (TID 110, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 10:53:02 INFO TaskSetManager: Starting task 3.0 in stage 30.0 (TID 111, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 10:53:02 INFO Executor: Running task 0.0 in stage 30.0 (TID 108)
18/02/28 10:53:02 INFO Executor: Running task 1.0 in stage 30.0 (TID 109)
18/02/28 10:53:02 INFO Executor: Running task 2.0 in stage 30.0 (TID 110)
18/02/28 10:53:02 INFO Executor: Running task 3.0 in stage 30.0 (TID 111)
18/02/28 10:53:02 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:53:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:53:02 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:53:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 10:53:02 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:53:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:53:02 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:53:02 INFO Executor: Finished task 3.0 in stage 30.0 (TID 111). 2640 bytes result sent to driver
18/02/28 10:53:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:53:02 INFO TaskSetManager: Finished task 3.0 in stage 30.0 (TID 111) in 8 ms on localhost (executor driver) (1/4)
18/02/28 10:53:02 INFO Executor: Finished task 2.0 in stage 30.0 (TID 110). 2647 bytes result sent to driver
18/02/28 10:53:02 INFO Executor: Finished task 1.0 in stage 30.0 (TID 109). 2582 bytes result sent to driver
18/02/28 10:53:02 INFO Executor: Finished task 0.0 in stage 30.0 (TID 108). 2521 bytes result sent to driver
18/02/28 10:53:02 INFO TaskSetManager: Finished task 2.0 in stage 30.0 (TID 110) in 10 ms on localhost (executor driver) (2/4)
18/02/28 10:53:02 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 109) in 11 ms on localhost (executor driver) (3/4)
18/02/28 10:53:02 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 108) in 13 ms on localhost (executor driver) (4/4)
18/02/28 10:53:02 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
18/02/28 10:53:02 INFO DAGScheduler: ResultStage 30 (collect at utils.scala:211) finished in 0.013 s
18/02/28 10:53:02 INFO DAGScheduler: Job 15 finished: collect at utils.scala:211, took 0.559608 s
18/02/28 10:53:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:53:22 INFO SparkSqlParser: Parsing command: SELECT `production_area`, SUM(`quantity`) / 1000000.0 AS `sum(quantity)/1e+06`
FROM `spark_fao`
WHERE (`year` = 2015.0)
GROUP BY `production_area`
18/02/28 10:53:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:53:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:53:22 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:53:22 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(year#17),(cast(cast(year#17 as decimal(10,0)) as decimal(11,1)) = 2015.0)
18/02/28 10:53:22 INFO FileSourceStrategy: Output Data Schema: struct<year: int, production_area: int, quantity: int ... 1 more fields>
18/02/28 10:53:22 INFO FileSourceScanExec: Pushed Filters: IsNotNull(year)
18/02/28 10:53:22 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 282.5 KB, free 361.3 MB)
18/02/28 10:53:22 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 24.1 KB, free 361.2 MB)
18/02/28 10:53:22 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:60157 (size: 24.1 KB, free: 365.8 MB)
18/02/28 10:53:22 INFO SparkContext: Created broadcast 46 from collect at utils.scala:211
18/02/28 10:53:22 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:53:23 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:53:23 INFO DAGScheduler: Registering RDD 98 (collect at utils.scala:211)
18/02/28 10:53:23 INFO DAGScheduler: Got job 16 (collect at utils.scala:211) with 4 output partitions
18/02/28 10:53:23 INFO DAGScheduler: Final stage: ResultStage 32 (collect at utils.scala:211)
18/02/28 10:53:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
18/02/28 10:53:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 31)
18/02/28 10:53:23 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[98] at collect at utils.scala:211), which has no missing parents
18/02/28 10:53:23 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 32.8 KB, free 361.2 MB)
18/02/28 10:53:23 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 15.9 KB, free 361.2 MB)
18/02/28 10:53:23 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:60157 (size: 15.9 KB, free: 365.8 MB)
18/02/28 10:53:23 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1006
18/02/28 10:53:23 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[98] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:53:23 INFO TaskSchedulerImpl: Adding task set 31.0 with 4 tasks
18/02/28 10:53:23 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 112, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 10:53:23 INFO TaskSetManager: Starting task 1.0 in stage 31.0 (TID 113, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 10:53:23 INFO TaskSetManager: Starting task 2.0 in stage 31.0 (TID 114, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 10:53:23 INFO TaskSetManager: Starting task 3.0 in stage 31.0 (TID 115, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 10:53:23 INFO Executor: Running task 0.0 in stage 31.0 (TID 112)
18/02/28 10:53:23 INFO Executor: Running task 1.0 in stage 31.0 (TID 113)
18/02/28 10:53:23 INFO Executor: Running task 2.0 in stage 31.0 (TID 114)
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 10:53:23 INFO Executor: Running task 3.0 in stage 31.0 (TID 115)
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 10:53:23 INFO ContextCleaner: Cleaned accumulator 1013
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 10:53:23 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:60157 in memory (size: 14.2 KB, free: 365.8 MB)
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 10:53:23 INFO Executor: Finished task 3.0 in stage 31.0 (TID 115). 1993 bytes result sent to driver
18/02/28 10:53:23 INFO TaskSetManager: Finished task 3.0 in stage 31.0 (TID 115) in 298 ms on localhost (executor driver) (1/4)
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 10:53:23 INFO Executor: Finished task 2.0 in stage 31.0 (TID 114). 1993 bytes result sent to driver
18/02/28 10:53:23 INFO TaskSetManager: Finished task 2.0 in stage 31.0 (TID 114) in 380 ms on localhost (executor driver) (2/4)
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 10:53:23 INFO Executor: Finished task 1.0 in stage 31.0 (TID 113). 1993 bytes result sent to driver
18/02/28 10:53:23 INFO TaskSetManager: Finished task 1.0 in stage 31.0 (TID 113) in 561 ms on localhost (executor driver) (3/4)
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 10:53:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 10:53:23 INFO Executor: Finished task 0.0 in stage 31.0 (TID 112). 2122 bytes result sent to driver
18/02/28 10:53:23 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 112) in 671 ms on localhost (executor driver) (4/4)
18/02/28 10:53:23 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
18/02/28 10:53:23 INFO DAGScheduler: ShuffleMapStage 31 (collect at utils.scala:211) finished in 0.672 s
18/02/28 10:53:23 INFO DAGScheduler: looking for newly runnable stages
18/02/28 10:53:23 INFO DAGScheduler: running: Set()
18/02/28 10:53:23 INFO DAGScheduler: waiting: Set(ResultStage 32)
18/02/28 10:53:23 INFO DAGScheduler: failed: Set()
18/02/28 10:53:23 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[101] at collect at utils.scala:211), which has no missing parents
18/02/28 10:53:23 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 29.9 KB, free 361.2 MB)
18/02/28 10:53:23 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 14.7 KB, free 361.2 MB)
18/02/28 10:53:23 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:60157 (size: 14.7 KB, free: 365.8 MB)
18/02/28 10:53:23 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1006
18/02/28 10:53:23 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 32 (MapPartitionsRDD[101] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:53:23 INFO TaskSchedulerImpl: Adding task set 32.0 with 4 tasks
18/02/28 10:53:23 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 116, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 10:53:23 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 117, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 10:53:23 INFO TaskSetManager: Starting task 2.0 in stage 32.0 (TID 118, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 10:53:23 INFO TaskSetManager: Starting task 3.0 in stage 32.0 (TID 119, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 10:53:23 INFO Executor: Running task 3.0 in stage 32.0 (TID 119)
18/02/28 10:53:23 INFO Executor: Running task 2.0 in stage 32.0 (TID 118)
18/02/28 10:53:23 INFO Executor: Running task 0.0 in stage 32.0 (TID 116)
18/02/28 10:53:23 INFO Executor: Running task 1.0 in stage 32.0 (TID 117)
18/02/28 10:53:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 10:53:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:53:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 10:53:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:53:23 INFO Executor: Finished task 0.0 in stage 32.0 (TID 116). 2626 bytes result sent to driver
18/02/28 10:53:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 10:53:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
18/02/28 10:53:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 10:53:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:53:23 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 116) in 6 ms on localhost (executor driver) (1/4)
18/02/28 10:53:23 INFO Executor: Finished task 3.0 in stage 32.0 (TID 119). 2729 bytes result sent to driver
18/02/28 10:53:23 INFO TaskSetManager: Finished task 3.0 in stage 32.0 (TID 119) in 7 ms on localhost (executor driver) (2/4)
18/02/28 10:53:23 INFO Executor: Finished task 1.0 in stage 32.0 (TID 117). 2680 bytes result sent to driver
18/02/28 10:53:23 INFO Executor: Finished task 2.0 in stage 32.0 (TID 118). 2731 bytes result sent to driver
18/02/28 10:53:23 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 117) in 9 ms on localhost (executor driver) (3/4)
18/02/28 10:53:23 INFO TaskSetManager: Finished task 2.0 in stage 32.0 (TID 118) in 9 ms on localhost (executor driver) (4/4)
18/02/28 10:53:23 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
18/02/28 10:53:23 INFO DAGScheduler: ResultStage 32 (collect at utils.scala:211) finished in 0.009 s
18/02/28 10:53:23 INFO DAGScheduler: Job 16 finished: collect at utils.scala:211, took 0.691139 s
18/02/28 10:53:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:53:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao`
18/02/28 10:53:30 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e0322c5ea7
18/02/28 10:53:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:53:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0322c5ea7` AS `zzz9`
WHERE (0 = 1)
18/02/28 10:53:30 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e01e262ae1
18/02/28 10:53:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:53:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e01e262ae1` AS `zzz10`
WHERE (0 = 1)
18/02/28 10:53:30 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e0371e469b
18/02/28 10:53:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:53:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0371e469b` AS `zzz11`
WHERE (0 = 1)
18/02/28 10:53:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:53:34 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e0322c5ea7`
18/02/28 10:53:34 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:53:34 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:53:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:53:34 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e0322c5ea7`
18/02/28 10:53:34 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:53:34 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:53:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:53:34 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e0322c5ea7`
18/02/28 10:53:34 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:53:34 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:53:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:53:34 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e0322c5ea7`
18/02/28 10:53:34 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:53:34 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:53:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:53:34 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e0322c5ea7`
18/02/28 10:53:34 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:53:34 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:53:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:53:34 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e0322c5ea7`
LIMIT 1000
18/02/28 10:53:34 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:53:34 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:53:34 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:53:34 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 10:53:34 INFO FileSourceStrategy: Output Data Schema: struct<year: int, production_area: int, country: string, iso: string, source: string ... 8 more fields>
18/02/28 10:53:34 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 10:53:34 INFO CodeGenerator: Code generated in 15.190736 ms
18/02/28 10:53:34 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 282.5 KB, free 360.9 MB)
18/02/28 10:53:34 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 24.1 KB, free 360.9 MB)
18/02/28 10:53:34 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:60157 (size: 24.1 KB, free: 365.8 MB)
18/02/28 10:53:34 INFO SparkContext: Created broadcast 49 from collect at utils.scala:211
18/02/28 10:53:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:53:34 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:53:34 INFO DAGScheduler: Registering RDD 104 (collect at utils.scala:211)
18/02/28 10:53:34 INFO DAGScheduler: Got job 17 (collect at utils.scala:211) with 1 output partitions
18/02/28 10:53:34 INFO DAGScheduler: Final stage: ResultStage 34 (collect at utils.scala:211)
18/02/28 10:53:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
18/02/28 10:53:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 33)
18/02/28 10:53:34 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[104] at collect at utils.scala:211), which has no missing parents
18/02/28 10:53:34 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 24.5 KB, free 360.9 MB)
18/02/28 10:53:34 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 12.1 KB, free 360.9 MB)
18/02/28 10:53:34 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:60157 (size: 12.1 KB, free: 365.8 MB)
18/02/28 10:53:34 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1006
18/02/28 10:53:34 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[104] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:53:34 INFO TaskSchedulerImpl: Adding task set 33.0 with 4 tasks
18/02/28 10:53:34 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 120, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 10:53:34 INFO TaskSetManager: Starting task 1.0 in stage 33.0 (TID 121, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 10:53:34 INFO TaskSetManager: Starting task 2.0 in stage 33.0 (TID 122, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 10:53:34 INFO TaskSetManager: Starting task 3.0 in stage 33.0 (TID 123, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 10:53:34 INFO Executor: Running task 0.0 in stage 33.0 (TID 120)
18/02/28 10:53:34 INFO Executor: Running task 1.0 in stage 33.0 (TID 121)
18/02/28 10:53:34 INFO Executor: Running task 2.0 in stage 33.0 (TID 122)
18/02/28 10:53:34 INFO Executor: Running task 3.0 in stage 33.0 (TID 123)
18/02/28 10:53:34 INFO CodeGenerator: Code generated in 13.576808 ms
18/02/28 10:53:34 INFO CodeGenerator: Code generated in 9.657824 ms
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 10:53:34 INFO CodeGenerator: Code generated in 19.080452 ms
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 10:53:34 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:60157 in memory (size: 14.7 KB, free: 365.8 MB)
18/02/28 10:53:34 INFO ContextCleaner: Cleaned accumulator 1078
18/02/28 10:53:34 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:60157 in memory (size: 15.9 KB, free: 365.8 MB)
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 10:53:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 10:53:35 INFO Executor: Finished task 3.0 in stage 33.0 (TID 123). 2395 bytes result sent to driver
18/02/28 10:53:35 INFO TaskSetManager: Finished task 3.0 in stage 33.0 (TID 123) in 890 ms on localhost (executor driver) (1/4)
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 10:53:35 INFO Executor: Finished task 2.0 in stage 33.0 (TID 122). 2395 bytes result sent to driver
18/02/28 10:53:35 INFO TaskSetManager: Finished task 2.0 in stage 33.0 (TID 122) in 1337 ms on localhost (executor driver) (2/4)
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 10:53:35 INFO Executor: Finished task 1.0 in stage 33.0 (TID 121). 2395 bytes result sent to driver
18/02/28 10:53:35 INFO TaskSetManager: Finished task 1.0 in stage 33.0 (TID 121) in 1614 ms on localhost (executor driver) (3/4)
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 10:53:35 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 10:53:36 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 10:53:36 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 10:53:36 INFO Executor: Finished task 0.0 in stage 33.0 (TID 120). 2395 bytes result sent to driver
18/02/28 10:53:36 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 120) in 1892 ms on localhost (executor driver) (4/4)
18/02/28 10:53:36 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
18/02/28 10:53:36 INFO DAGScheduler: ShuffleMapStage 33 (collect at utils.scala:211) finished in 1.892 s
18/02/28 10:53:36 INFO DAGScheduler: looking for newly runnable stages
18/02/28 10:53:36 INFO DAGScheduler: running: Set()
18/02/28 10:53:36 INFO DAGScheduler: waiting: Set(ResultStage 34)
18/02/28 10:53:36 INFO DAGScheduler: failed: Set()
18/02/28 10:53:36 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[107] at collect at utils.scala:211), which has no missing parents
18/02/28 10:53:36 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 6.9 KB, free 360.9 MB)
18/02/28 10:53:36 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 3.7 KB, free 360.9 MB)
18/02/28 10:53:36 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:60157 (size: 3.7 KB, free: 365.8 MB)
18/02/28 10:53:36 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1006
18/02/28 10:53:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[107] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 10:53:36 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
18/02/28 10:53:36 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 124, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 10:53:36 INFO Executor: Running task 0.0 in stage 34.0 (TID 124)
18/02/28 10:53:36 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:53:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:53:36 INFO Executor: Finished task 0.0 in stage 34.0 (TID 124). 1471 bytes result sent to driver
18/02/28 10:53:36 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 124) in 4 ms on localhost (executor driver) (1/1)
18/02/28 10:53:36 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
18/02/28 10:53:36 INFO DAGScheduler: ResultStage 34 (collect at utils.scala:211) finished in 0.004 s
18/02/28 10:53:36 INFO DAGScheduler: Job 17 finished: collect at utils.scala:211, took 1.902678 s
18/02/28 10:55:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:55:10 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0322c5ea7`
18/02/28 10:55:10 INFO SparkSqlParser: Parsing command: training
18/02/28 10:55:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:55:10 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training` AS `zzz12`
WHERE (0 = 1)
18/02/28 10:55:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:55:10 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 10:55:10 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:55:10 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:55:10 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:55:10 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:55:10 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 10:55:10 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 10:55:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:55:29 INFO SparkSqlParser: Parsing command: CACHE TABLE `training`
18/02/28 10:55:29 INFO SparkSqlParser: Parsing command: `training`
18/02/28 10:55:29 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:55:29 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 10:55:29 INFO FileSourceStrategy: Output Data Schema: struct<year: int, production_area: int, country: string, iso: string, source: string ... 8 more fields>
18/02/28 10:55:29 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 10:55:29 INFO CodeGenerator: Code generated in 9.736458 ms
18/02/28 10:55:29 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 282.5 KB, free 360.7 MB)
18/02/28 10:55:29 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 24.1 KB, free 360.6 MB)
18/02/28 10:55:29 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:60157 (size: 24.1 KB, free: 365.8 MB)
18/02/28 10:55:29 INFO SparkContext: Created broadcast 52 from sql at <unknown>:0
18/02/28 10:55:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:55:29 INFO CodeGenerator: Code generated in 6.694079 ms
18/02/28 10:55:29 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 10:55:29 INFO DAGScheduler: Registering RDD 113 (sql at <unknown>:0)
18/02/28 10:55:29 INFO DAGScheduler: Got job 18 (sql at <unknown>:0) with 1 output partitions
18/02/28 10:55:29 INFO DAGScheduler: Final stage: ResultStage 36 (sql at <unknown>:0)
18/02/28 10:55:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
18/02/28 10:55:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 35)
18/02/28 10:55:29 INFO DAGScheduler: Submitting ShuffleMapStage 35 (MapPartitionsRDD[113] at sql at <unknown>:0), which has no missing parents
18/02/28 10:55:29 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 31.6 KB, free 360.6 MB)
18/02/28 10:55:29 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 13.9 KB, free 360.6 MB)
18/02/28 10:55:29 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:60157 (size: 13.9 KB, free: 365.8 MB)
18/02/28 10:55:29 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1006
18/02/28 10:55:29 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[113] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:55:29 INFO TaskSchedulerImpl: Adding task set 35.0 with 4 tasks
18/02/28 10:55:29 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 125, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 10:55:29 INFO TaskSetManager: Starting task 1.0 in stage 35.0 (TID 126, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 10:55:29 INFO TaskSetManager: Starting task 2.0 in stage 35.0 (TID 127, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 10:55:29 INFO TaskSetManager: Starting task 3.0 in stage 35.0 (TID 128, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 10:55:29 INFO Executor: Running task 1.0 in stage 35.0 (TID 126)
18/02/28 10:55:29 INFO Executor: Running task 2.0 in stage 35.0 (TID 127)
18/02/28 10:55:29 INFO Executor: Running task 0.0 in stage 35.0 (TID 125)
18/02/28 10:55:29 INFO Executor: Running task 3.0 in stage 35.0 (TID 128)
18/02/28 10:55:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 10:55:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 10:55:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 10:55:30 INFO ContextCleaner: Cleaned accumulator 1156
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 10:55:30 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:60157 in memory (size: 3.7 KB, free: 365.8 MB)
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 10:55:30 INFO MemoryStore: Block rdd_110_3 stored as values in memory (estimated size 18.1 KB, free 334.6 MB)
18/02/28 10:55:30 INFO BlockManagerInfo: Added rdd_110_3 in memory on 127.0.0.1:60157 (size: 18.1 KB, free: 365.8 MB)
18/02/28 10:55:30 INFO CodeGenerator: Code generated in 3.195062 ms
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 10:55:30 INFO CodeGenerator: Code generated in 25.010411 ms
18/02/28 10:55:30 INFO Executor: Finished task 3.0 in stage 35.0 (TID 128). 3086 bytes result sent to driver
18/02/28 10:55:30 INFO TaskSetManager: Finished task 3.0 in stage 35.0 (TID 128) in 991 ms on localhost (executor driver) (1/4)
18/02/28 10:55:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 10:55:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 10:55:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 10:55:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 10:55:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 10:55:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 10:55:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 10:55:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 10:55:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 10:55:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 10:55:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 10:55:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 10:55:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 10:55:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 10:55:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 10:55:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 10:55:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 10:55:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 10:55:31 INFO MemoryStore: Block rdd_110_2 stored as values in memory (estimated size 38.2 KB, free 332.6 MB)
18/02/28 10:55:31 INFO BlockManagerInfo: Added rdd_110_2 in memory on 127.0.0.1:60157 (size: 38.2 KB, free: 365.7 MB)
18/02/28 10:55:31 INFO Executor: Finished task 2.0 in stage 35.0 (TID 127). 3129 bytes result sent to driver
18/02/28 10:55:31 INFO TaskSetManager: Finished task 2.0 in stage 35.0 (TID 127) in 1582 ms on localhost (executor driver) (2/4)
18/02/28 10:55:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 10:55:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 10:55:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 10:55:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 10:55:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 10:55:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 10:55:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 10:55:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 10:55:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 10:55:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 10:55:31 INFO MemoryStore: Block rdd_110_1 stored as values in memory (estimated size 54.4 KB, free 340.5 MB)
18/02/28 10:55:31 INFO BlockManagerInfo: Added rdd_110_1 in memory on 127.0.0.1:60157 (size: 54.4 KB, free: 365.7 MB)
18/02/28 10:55:32 INFO Executor: Finished task 1.0 in stage 35.0 (TID 126). 3086 bytes result sent to driver
18/02/28 10:55:32 INFO TaskSetManager: Finished task 1.0 in stage 35.0 (TID 126) in 2047 ms on localhost (executor driver) (3/4)
18/02/28 10:55:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 10:55:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 10:55:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 10:55:32 INFO MemoryStore: Block rdd_110_0 stored as values in memory (estimated size 68.6 KB, free 360.4 MB)
18/02/28 10:55:32 INFO BlockManagerInfo: Added rdd_110_0 in memory on 127.0.0.1:60157 (size: 68.6 KB, free: 365.6 MB)
18/02/28 10:55:32 INFO Executor: Finished task 0.0 in stage 35.0 (TID 125). 3086 bytes result sent to driver
18/02/28 10:55:32 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 125) in 2333 ms on localhost (executor driver) (4/4)
18/02/28 10:55:32 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
18/02/28 10:55:32 INFO DAGScheduler: ShuffleMapStage 35 (sql at <unknown>:0) finished in 2.333 s
18/02/28 10:55:32 INFO DAGScheduler: looking for newly runnable stages
18/02/28 10:55:32 INFO DAGScheduler: running: Set()
18/02/28 10:55:32 INFO DAGScheduler: waiting: Set(ResultStage 36)
18/02/28 10:55:32 INFO DAGScheduler: failed: Set()
18/02/28 10:55:32 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[116] at sql at <unknown>:0), which has no missing parents
18/02/28 10:55:32 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 7.0 KB, free 360.4 MB)
18/02/28 10:55:32 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 3.7 KB, free 360.4 MB)
18/02/28 10:55:32 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:60157 (size: 3.7 KB, free: 365.6 MB)
18/02/28 10:55:32 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1006
18/02/28 10:55:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[116] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 10:55:32 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
18/02/28 10:55:32 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 129, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 10:55:32 INFO Executor: Running task 0.0 in stage 36.0 (TID 129)
18/02/28 10:55:32 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:55:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:55:32 INFO Executor: Finished task 0.0 in stage 36.0 (TID 129). 1452 bytes result sent to driver
18/02/28 10:55:32 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 129) in 3 ms on localhost (executor driver) (1/1)
18/02/28 10:55:32 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
18/02/28 10:55:32 INFO DAGScheduler: ResultStage 36 (sql at <unknown>:0) finished in 0.003 s
18/02/28 10:55:32 INFO DAGScheduler: Job 18 finished: sql at <unknown>:0, took 2.355889 s
18/02/28 10:55:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:55:32 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `training`
18/02/28 10:55:32 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:55:32 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:55:32 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:55:32 INFO DAGScheduler: Registering RDD 119 (collect at utils.scala:211)
18/02/28 10:55:32 INFO DAGScheduler: Got job 19 (collect at utils.scala:211) with 1 output partitions
18/02/28 10:55:32 INFO DAGScheduler: Final stage: ResultStage 38 (collect at utils.scala:211)
18/02/28 10:55:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 37)
18/02/28 10:55:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 37)
18/02/28 10:55:32 INFO DAGScheduler: Submitting ShuffleMapStage 37 (MapPartitionsRDD[119] at collect at utils.scala:211), which has no missing parents
18/02/28 10:55:32 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 31.6 KB, free 360.4 MB)
18/02/28 10:55:32 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 14.0 KB, free 360.4 MB)
18/02/28 10:55:32 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:60157 (size: 14.0 KB, free: 365.6 MB)
18/02/28 10:55:32 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1006
18/02/28 10:55:32 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[119] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:55:32 INFO TaskSchedulerImpl: Adding task set 37.0 with 4 tasks
18/02/28 10:55:32 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 130, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 10:55:32 INFO TaskSetManager: Starting task 1.0 in stage 37.0 (TID 131, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 10:55:32 INFO TaskSetManager: Starting task 2.0 in stage 37.0 (TID 132, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 10:55:32 INFO TaskSetManager: Starting task 3.0 in stage 37.0 (TID 133, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 10:55:32 INFO Executor: Running task 0.0 in stage 37.0 (TID 130)
18/02/28 10:55:32 INFO Executor: Running task 3.0 in stage 37.0 (TID 133)
18/02/28 10:55:32 INFO Executor: Running task 2.0 in stage 37.0 (TID 132)
18/02/28 10:55:32 INFO Executor: Running task 1.0 in stage 37.0 (TID 131)
18/02/28 10:55:32 INFO BlockManager: Found block rdd_110_3 locally
18/02/28 10:55:32 INFO BlockManager: Found block rdd_110_0 locally
18/02/28 10:55:32 INFO BlockManager: Found block rdd_110_1 locally
18/02/28 10:55:32 INFO BlockManager: Found block rdd_110_2 locally
18/02/28 10:55:32 INFO Executor: Finished task 0.0 in stage 37.0 (TID 130). 2319 bytes result sent to driver
18/02/28 10:55:32 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 130) in 17 ms on localhost (executor driver) (1/4)
18/02/28 10:55:32 INFO Executor: Finished task 1.0 in stage 37.0 (TID 131). 2319 bytes result sent to driver
18/02/28 10:55:32 INFO TaskSetManager: Finished task 1.0 in stage 37.0 (TID 131) in 17 ms on localhost (executor driver) (2/4)
18/02/28 10:55:32 INFO Executor: Finished task 3.0 in stage 37.0 (TID 133). 2276 bytes result sent to driver
18/02/28 10:55:32 INFO TaskSetManager: Finished task 3.0 in stage 37.0 (TID 133) in 18 ms on localhost (executor driver) (3/4)
18/02/28 10:55:32 INFO Executor: Finished task 2.0 in stage 37.0 (TID 132). 2276 bytes result sent to driver
18/02/28 10:55:32 INFO TaskSetManager: Finished task 2.0 in stage 37.0 (TID 132) in 19 ms on localhost (executor driver) (4/4)
18/02/28 10:55:32 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
18/02/28 10:55:32 INFO DAGScheduler: ShuffleMapStage 37 (collect at utils.scala:211) finished in 0.020 s
18/02/28 10:55:32 INFO DAGScheduler: looking for newly runnable stages
18/02/28 10:55:32 INFO DAGScheduler: running: Set()
18/02/28 10:55:32 INFO DAGScheduler: waiting: Set(ResultStage 38)
18/02/28 10:55:32 INFO DAGScheduler: failed: Set()
18/02/28 10:55:32 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[122] at collect at utils.scala:211), which has no missing parents
18/02/28 10:55:32 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 7.0 KB, free 360.4 MB)
18/02/28 10:55:32 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 3.7 KB, free 360.4 MB)
18/02/28 10:55:32 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:60157 (size: 3.7 KB, free: 365.6 MB)
18/02/28 10:55:32 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1006
18/02/28 10:55:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[122] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 10:55:32 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
18/02/28 10:55:32 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 134, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 10:55:32 INFO Executor: Running task 0.0 in stage 38.0 (TID 134)
18/02/28 10:55:32 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:55:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:55:32 INFO Executor: Finished task 0.0 in stage 38.0 (TID 134). 1495 bytes result sent to driver
18/02/28 10:55:32 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 134) in 3 ms on localhost (executor driver) (1/1)
18/02/28 10:55:32 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
18/02/28 10:55:32 INFO DAGScheduler: ResultStage 38 (collect at utils.scala:211) finished in 0.003 s
18/02/28 10:55:32 INFO DAGScheduler: Job 19 finished: collect at utils.scala:211, took 0.033444 s
18/02/28 10:56:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:56:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao`
18/02/28 10:56:18 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e05a52310b
18/02/28 10:56:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:56:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e05a52310b` AS `zzz13`
WHERE (0 = 1)
18/02/28 10:56:18 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e022d148f6
18/02/28 10:56:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:56:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e022d148f6` AS `zzz14`
WHERE (0 = 1)
18/02/28 10:56:18 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e031403454
18/02/28 10:56:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:56:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e031403454` AS `zzz15`
WHERE (0 = 1)
18/02/28 10:56:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:56:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao`
18/02/28 10:56:27 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e025133a11
18/02/28 10:56:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:56:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e025133a11` AS `zzz16`
WHERE (0 = 1)
18/02/28 10:56:27 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e01d8c71a
18/02/28 10:56:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:56:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e01d8c71a` AS `zzz17`
WHERE (0 = 1)
18/02/28 10:56:27 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e0789f7392
18/02/28 10:56:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:56:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0789f7392` AS `zzz18`
WHERE (0 = 1)
18/02/28 10:56:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:56:31 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e025133a11`
18/02/28 10:56:31 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:56:31 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:56:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:56:31 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e025133a11`
18/02/28 10:56:31 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:56:31 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:56:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:56:31 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e025133a11`
18/02/28 10:56:31 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:56:31 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:56:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:56:31 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e025133a11`
18/02/28 10:56:31 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:56:31 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:56:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:56:31 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e025133a11`
18/02/28 10:56:31 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:56:31 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:56:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:56:31 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e025133a11`
LIMIT 1000
18/02/28 10:56:31 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:56:31 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:56:31 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:56:31 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 10:56:31 INFO FileSourceStrategy: Output Data Schema: struct<year: int, production_area: int, country: string, iso: string, source: string ... 8 more fields>
18/02/28 10:56:31 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 10:56:31 INFO CodeGenerator: Code generated in 13.514395 ms
18/02/28 10:56:31 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 282.5 KB, free 360.1 MB)
18/02/28 10:56:31 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 24.1 KB, free 360.1 MB)
18/02/28 10:56:31 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:60157 (size: 24.1 KB, free: 365.6 MB)
18/02/28 10:56:31 INFO SparkContext: Created broadcast 57 from collect at utils.scala:211
18/02/28 10:56:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:56:31 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:56:31 INFO DAGScheduler: Registering RDD 125 (collect at utils.scala:211)
18/02/28 10:56:31 INFO DAGScheduler: Got job 20 (collect at utils.scala:211) with 1 output partitions
18/02/28 10:56:31 INFO DAGScheduler: Final stage: ResultStage 40 (collect at utils.scala:211)
18/02/28 10:56:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 39)
18/02/28 10:56:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 39)
18/02/28 10:56:31 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[125] at collect at utils.scala:211), which has no missing parents
18/02/28 10:56:31 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 24.5 KB, free 360.0 MB)
18/02/28 10:56:31 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 12.1 KB, free 360.0 MB)
18/02/28 10:56:31 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:60157 (size: 12.1 KB, free: 365.6 MB)
18/02/28 10:56:31 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1006
18/02/28 10:56:31 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[125] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:56:31 INFO TaskSchedulerImpl: Adding task set 39.0 with 4 tasks
18/02/28 10:56:31 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 135, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 10:56:31 INFO TaskSetManager: Starting task 1.0 in stage 39.0 (TID 136, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 10:56:31 INFO TaskSetManager: Starting task 2.0 in stage 39.0 (TID 137, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 10:56:31 INFO TaskSetManager: Starting task 3.0 in stage 39.0 (TID 138, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 10:56:31 INFO Executor: Running task 0.0 in stage 39.0 (TID 135)
18/02/28 10:56:31 INFO Executor: Running task 1.0 in stage 39.0 (TID 136)
18/02/28 10:56:31 INFO Executor: Running task 2.0 in stage 39.0 (TID 137)
18/02/28 10:56:31 INFO Executor: Running task 3.0 in stage 39.0 (TID 138)
18/02/28 10:56:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 10:56:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 10:56:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 10:56:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 10:56:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 10:56:32 INFO ContextCleaner: Cleaned accumulator 1278
18/02/28 10:56:32 INFO ContextCleaner: Cleaned accumulator 1165
18/02/28 10:56:32 INFO ContextCleaner: Cleaned shuffle 17
18/02/28 10:56:32 INFO ContextCleaner: Cleaned accumulator 1167
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 10:56:32 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:60157 in memory (size: 3.7 KB, free: 365.6 MB)
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 10:56:32 INFO ContextCleaner: Cleaned accumulator 1163
18/02/28 10:56:32 INFO ContextCleaner: Cleaned accumulator 1166
18/02/28 10:56:32 INFO ContextCleaner: Cleaned accumulator 1158
18/02/28 10:56:32 INFO ContextCleaner: Cleaned accumulator 1159
18/02/28 10:56:32 INFO ContextCleaner: Cleaned accumulator 1160
18/02/28 10:56:32 INFO ContextCleaner: Cleaned accumulator 1164
18/02/28 10:56:32 INFO ContextCleaner: Cleaned accumulator 1157
18/02/28 10:56:32 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:60157 in memory (size: 3.7 KB, free: 365.6 MB)
18/02/28 10:56:32 INFO ContextCleaner: Cleaned accumulator 1168
18/02/28 10:56:32 INFO ContextCleaner: Cleaned accumulator 1161
18/02/28 10:56:32 INFO ContextCleaner: Cleaned accumulator 1217
18/02/28 10:56:32 INFO ContextCleaner: Cleaned accumulator 1162
18/02/28 10:56:32 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:60157 in memory (size: 13.9 KB, free: 365.6 MB)
18/02/28 10:56:32 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:60157 in memory (size: 14.0 KB, free: 365.6 MB)
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 10:56:32 INFO Executor: Finished task 3.0 in stage 39.0 (TID 138). 2395 bytes result sent to driver
18/02/28 10:56:32 INFO TaskSetManager: Finished task 3.0 in stage 39.0 (TID 138) in 715 ms on localhost (executor driver) (1/4)
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 10:56:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 10:56:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 10:56:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 10:56:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 10:56:33 INFO Executor: Finished task 2.0 in stage 39.0 (TID 137). 2395 bytes result sent to driver
18/02/28 10:56:33 INFO TaskSetManager: Finished task 2.0 in stage 39.0 (TID 137) in 1206 ms on localhost (executor driver) (2/4)
18/02/28 10:56:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 10:56:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 10:56:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 10:56:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 10:56:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 10:56:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 10:56:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 10:56:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 10:56:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 10:56:33 INFO Executor: Finished task 1.0 in stage 39.0 (TID 136). 2395 bytes result sent to driver
18/02/28 10:56:33 INFO TaskSetManager: Finished task 1.0 in stage 39.0 (TID 136) in 1499 ms on localhost (executor driver) (3/4)
18/02/28 10:56:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 10:56:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 10:56:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 10:56:33 INFO Executor: Finished task 0.0 in stage 39.0 (TID 135). 2395 bytes result sent to driver
18/02/28 10:56:33 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 135) in 1754 ms on localhost (executor driver) (4/4)
18/02/28 10:56:33 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
18/02/28 10:56:33 INFO DAGScheduler: ShuffleMapStage 39 (collect at utils.scala:211) finished in 1.754 s
18/02/28 10:56:33 INFO DAGScheduler: looking for newly runnable stages
18/02/28 10:56:33 INFO DAGScheduler: running: Set()
18/02/28 10:56:33 INFO DAGScheduler: waiting: Set(ResultStage 40)
18/02/28 10:56:33 INFO DAGScheduler: failed: Set()
18/02/28 10:56:33 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[128] at collect at utils.scala:211), which has no missing parents
18/02/28 10:56:33 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 6.9 KB, free 360.1 MB)
18/02/28 10:56:33 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 3.7 KB, free 360.1 MB)
18/02/28 10:56:33 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:60157 (size: 3.7 KB, free: 365.6 MB)
18/02/28 10:56:33 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1006
18/02/28 10:56:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[128] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 10:56:33 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
18/02/28 10:56:33 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 139, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 10:56:33 INFO Executor: Running task 0.0 in stage 40.0 (TID 139)
18/02/28 10:56:33 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:56:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:56:33 INFO Executor: Finished task 0.0 in stage 40.0 (TID 139). 1471 bytes result sent to driver
18/02/28 10:56:33 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 139) in 2 ms on localhost (executor driver) (1/1)
18/02/28 10:56:33 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
18/02/28 10:56:33 INFO DAGScheduler: ResultStage 40 (collect at utils.scala:211) finished in 0.003 s
18/02/28 10:56:33 INFO DAGScheduler: Job 20 finished: collect at utils.scala:211, took 1.769420 s
18/02/28 10:56:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:56:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e025133a11`
18/02/28 10:56:35 INFO SparkSqlParser: Parsing command: training
18/02/28 10:56:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:56:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training` AS `zzz19`
WHERE (0 = 1)
18/02/28 10:56:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:56:36 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 10:56:36 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:56:36 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:56:36 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:56:36 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:56:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 10:56:36 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 10:57:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:57:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 10:57:48 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:57:48 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 10:57:48 INFO FileSourceStrategy: Output Data Schema: struct<year: int, production_area: int, country: string, iso: string, source: string ... 8 more fields>
18/02/28 10:57:48 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 10:57:48 INFO CodeGenerator: Code generated in 10.007268 ms
18/02/28 10:57:48 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 282.5 KB, free 359.9 MB)
18/02/28 10:57:48 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 24.1 KB, free 359.8 MB)
18/02/28 10:57:48 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:60157 (size: 24.1 KB, free: 365.6 MB)
18/02/28 10:57:48 INFO SparkContext: Created broadcast 60 from rdd at StringIndexer.scala:111
18/02/28 10:57:48 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:57:48 INFO SparkContext: Starting job: countByValue at StringIndexer.scala:113
18/02/28 10:57:48 INFO DAGScheduler: Registering RDD 135 (countByValue at StringIndexer.scala:113)
18/02/28 10:57:48 INFO DAGScheduler: Got job 21 (countByValue at StringIndexer.scala:113) with 4 output partitions
18/02/28 10:57:48 INFO DAGScheduler: Final stage: ResultStage 42 (countByValue at StringIndexer.scala:113)
18/02/28 10:57:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
18/02/28 10:57:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 41)
18/02/28 10:57:48 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[135] at countByValue at StringIndexer.scala:113), which has no missing parents
18/02/28 10:57:48 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 24.4 KB, free 359.8 MB)
18/02/28 10:57:48 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 12.0 KB, free 359.8 MB)
18/02/28 10:57:48 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:60157 (size: 12.0 KB, free: 365.6 MB)
18/02/28 10:57:48 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1006
18/02/28 10:57:48 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[135] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:57:48 INFO TaskSchedulerImpl: Adding task set 41.0 with 4 tasks
18/02/28 10:57:48 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 140, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 10:57:48 INFO TaskSetManager: Starting task 1.0 in stage 41.0 (TID 141, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 10:57:48 INFO TaskSetManager: Starting task 2.0 in stage 41.0 (TID 142, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 10:57:48 INFO TaskSetManager: Starting task 3.0 in stage 41.0 (TID 143, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 10:57:48 INFO Executor: Running task 0.0 in stage 41.0 (TID 140)
18/02/28 10:57:48 INFO Executor: Running task 3.0 in stage 41.0 (TID 143)
18/02/28 10:57:48 INFO Executor: Running task 2.0 in stage 41.0 (TID 142)
18/02/28 10:57:48 INFO Executor: Running task 1.0 in stage 41.0 (TID 141)
18/02/28 10:57:49 INFO CodeGenerator: Code generated in 6.299854 ms
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 10:57:49 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:60157 in memory (size: 12.1 KB, free: 365.6 MB)
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 10:57:49 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:60157 in memory (size: 3.7 KB, free: 365.6 MB)
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 10:57:49 INFO Executor: Finished task 3.0 in stage 41.0 (TID 143). 2026 bytes result sent to driver
18/02/28 10:57:49 INFO TaskSetManager: Finished task 3.0 in stage 41.0 (TID 143) in 709 ms on localhost (executor driver) (1/4)
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 10:57:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 10:57:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 10:57:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 10:57:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 10:57:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 10:57:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 10:57:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 10:57:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 10:57:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 10:57:50 INFO Executor: Finished task 2.0 in stage 41.0 (TID 142). 2026 bytes result sent to driver
18/02/28 10:57:50 INFO TaskSetManager: Finished task 2.0 in stage 41.0 (TID 142) in 1242 ms on localhost (executor driver) (2/4)
18/02/28 10:57:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 10:57:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 10:57:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 10:57:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 10:57:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 10:57:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 10:57:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 10:57:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 10:57:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 10:57:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 10:57:50 INFO Executor: Finished task 1.0 in stage 41.0 (TID 141). 2026 bytes result sent to driver
18/02/28 10:57:50 INFO TaskSetManager: Finished task 1.0 in stage 41.0 (TID 141) in 1621 ms on localhost (executor driver) (3/4)
18/02/28 10:57:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 10:57:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 10:57:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 10:57:50 INFO Executor: Finished task 0.0 in stage 41.0 (TID 140). 2026 bytes result sent to driver
18/02/28 10:57:50 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 140) in 1881 ms on localhost (executor driver) (4/4)
18/02/28 10:57:50 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
18/02/28 10:57:50 INFO DAGScheduler: ShuffleMapStage 41 (countByValue at StringIndexer.scala:113) finished in 1.881 s
18/02/28 10:57:50 INFO DAGScheduler: looking for newly runnable stages
18/02/28 10:57:50 INFO DAGScheduler: running: Set()
18/02/28 10:57:50 INFO DAGScheduler: waiting: Set(ResultStage 42)
18/02/28 10:57:50 INFO DAGScheduler: failed: Set()
18/02/28 10:57:50 INFO DAGScheduler: Submitting ResultStage 42 (ShuffledRDD[136] at countByValue at StringIndexer.scala:113), which has no missing parents
18/02/28 10:57:50 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 3.2 KB, free 359.8 MB)
18/02/28 10:57:50 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 1963.0 B, free 359.8 MB)
18/02/28 10:57:50 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:60157 (size: 1963.0 B, free: 365.6 MB)
18/02/28 10:57:50 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1006
18/02/28 10:57:50 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 42 (ShuffledRDD[136] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:57:50 INFO TaskSchedulerImpl: Adding task set 42.0 with 4 tasks
18/02/28 10:57:50 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 144, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 10:57:50 INFO TaskSetManager: Starting task 1.0 in stage 42.0 (TID 145, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 10:57:50 INFO TaskSetManager: Starting task 2.0 in stage 42.0 (TID 146, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 10:57:50 INFO TaskSetManager: Starting task 3.0 in stage 42.0 (TID 147, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 10:57:50 INFO Executor: Running task 0.0 in stage 42.0 (TID 144)
18/02/28 10:57:50 INFO Executor: Running task 1.0 in stage 42.0 (TID 145)
18/02/28 10:57:50 INFO Executor: Running task 2.0 in stage 42.0 (TID 146)
18/02/28 10:57:50 INFO Executor: Running task 3.0 in stage 42.0 (TID 147)
18/02/28 10:57:50 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 10:57:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 10:57:50 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 10:57:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
18/02/28 10:57:50 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 10:57:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 10:57:50 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 10:57:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
18/02/28 10:57:50 INFO Executor: Finished task 1.0 in stage 42.0 (TID 145). 1005 bytes result sent to driver
18/02/28 10:57:50 INFO Executor: Finished task 2.0 in stage 42.0 (TID 146). 962 bytes result sent to driver
18/02/28 10:57:50 INFO Executor: Finished task 3.0 in stage 42.0 (TID 147). 1048 bytes result sent to driver
18/02/28 10:57:50 INFO Executor: Finished task 0.0 in stage 42.0 (TID 144). 1005 bytes result sent to driver
18/02/28 10:57:50 INFO TaskSetManager: Finished task 2.0 in stage 42.0 (TID 146) in 29 ms on localhost (executor driver) (1/4)
18/02/28 10:57:50 INFO TaskSetManager: Finished task 1.0 in stage 42.0 (TID 145) in 29 ms on localhost (executor driver) (2/4)
18/02/28 10:57:50 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 144) in 32 ms on localhost (executor driver) (3/4)
18/02/28 10:57:50 INFO TaskSetManager: Finished task 3.0 in stage 42.0 (TID 147) in 30 ms on localhost (executor driver) (4/4)
18/02/28 10:57:50 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
18/02/28 10:57:50 INFO DAGScheduler: ResultStage 42 (countByValue at StringIndexer.scala:113) finished in 0.033 s
18/02/28 10:57:50 INFO DAGScheduler: Job 21 finished: countByValue at StringIndexer.scala:113, took 2.032689 s
18/02/28 10:57:51 INFO ContextCleaner: Cleaned accumulator 1348
18/02/28 10:57:51 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 127.0.0.1:60157 in memory (size: 12.0 KB, free: 365.6 MB)
18/02/28 10:57:51 INFO ContextCleaner: Cleaned accumulator 1349
18/02/28 10:57:51 INFO ContextCleaner: Cleaned accumulator 1347
18/02/28 10:57:51 INFO ContextCleaner: Cleaned accumulator 1346
18/02/28 10:57:51 INFO ContextCleaner: Cleaned accumulator 1350
18/02/28 10:57:51 INFO ContextCleaner: Cleaned accumulator 1353
18/02/28 10:57:51 INFO ContextCleaner: Cleaned accumulator 1354
18/02/28 10:57:51 INFO ContextCleaner: Cleaned accumulator 1351
18/02/28 10:57:51 INFO ContextCleaner: Cleaned accumulator 1355
18/02/28 10:57:51 INFO ContextCleaner: Cleaned accumulator 1352
18/02/28 10:57:51 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 127.0.0.1:60157 in memory (size: 1963.0 B, free: 365.6 MB)
18/02/28 10:57:51 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:60157 in memory (size: 24.1 KB, free: 365.6 MB)
18/02/28 10:57:51 INFO ContextCleaner: Cleaned shuffle 20
18/02/28 10:58:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:58:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 10:58:01 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:58:01 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 10:58:01 INFO FileSourceStrategy: Output Data Schema: struct<year: int, production_area: int, country: string, iso: string, source: string ... 8 more fields>
18/02/28 10:58:01 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 10:58:01 INFO CodeGenerator: Code generated in 20.215174 ms
18/02/28 10:58:01 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 282.5 KB, free 359.9 MB)
18/02/28 10:58:01 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 24.1 KB, free 359.9 MB)
18/02/28 10:58:01 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:60157 (size: 24.1 KB, free: 365.6 MB)
18/02/28 10:58:01 INFO SparkContext: Created broadcast 63 from first at LinearRegression.scala:198
18/02/28 10:58:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:58:01 INFO SparkContext: Starting job: first at LinearRegression.scala:198
18/02/28 10:58:01 INFO DAGScheduler: Got job 22 (first at LinearRegression.scala:198) with 1 output partitions
18/02/28 10:58:01 INFO DAGScheduler: Final stage: ResultStage 43 (first at LinearRegression.scala:198)
18/02/28 10:58:01 INFO DAGScheduler: Parents of final stage: List()
18/02/28 10:58:01 INFO DAGScheduler: Missing parents: List()
18/02/28 10:58:01 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[139] at first at LinearRegression.scala:198), which has no missing parents
18/02/28 10:58:01 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 29.3 KB, free 359.9 MB)
18/02/28 10:58:01 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 13.4 KB, free 359.8 MB)
18/02/28 10:58:01 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:60157 (size: 13.4 KB, free: 365.6 MB)
18/02/28 10:58:01 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1006
18/02/28 10:58:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[139] at first at LinearRegression.scala:198) (first 15 tasks are for partitions Vector(0))
18/02/28 10:58:01 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
18/02/28 10:58:01 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 148, localhost, executor driver, partition 0, PROCESS_LOCAL, 6775 bytes)
18/02/28 10:58:01 INFO Executor: Running task 0.0 in stage 43.0 (TID 148)
18/02/28 10:58:01 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 10:58:01 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 10:58:01 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 10:58:01 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 10:58:01 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 10:58:01 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 10:58:01 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 10:58:01 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 10:58:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 10:58:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 10:58:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 10:58:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 10:58:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 10:58:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 10:58:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 10:58:02 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 10:58:02 ERROR Executor: Exception in task 0.0 in stage 43.0 (TID 148)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<year_double_r_formula_30e0559ccb5:double>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:395)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:234)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:228)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more
18/02/28 10:58:02 WARN TaskSetManager: Lost task 0.0 in stage 43.0 (TID 148, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<year_double_r_formula_30e0559ccb5:double>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:395)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:234)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:228)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more

18/02/28 10:58:02 ERROR TaskSetManager: Task 0 in stage 43.0 failed 1 times; aborting job
18/02/28 10:58:02 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
18/02/28 10:58:02 INFO TaskSchedulerImpl: Cancelling stage 43
18/02/28 10:58:02 INFO DAGScheduler: ResultStage 43 (first at LinearRegression.scala:198) failed in 1.414 s due to Job aborted due to stage failure: Task 0 in stage 43.0 failed 1 times, most recent failure: Lost task 0.0 in stage 43.0 (TID 148, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<year_double_r_formula_30e0559ccb5:double>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:395)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:234)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:228)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more

Driver stacktrace:
18/02/28 10:58:02 INFO DAGScheduler: Job 22 failed: first at LinearRegression.scala:198, took 1.419292 s
18/02/28 10:58:21 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:58:21 INFO SparkSqlParser: Parsing command: CACHE TABLE `training`
18/02/28 10:58:21 INFO SparkSqlParser: Parsing command: `training`
18/02/28 10:58:21 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 10:58:21 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 10:58:21 INFO FileSourceStrategy: Output Data Schema: struct<year: int, production_area: int, country: string, iso: string, source: string ... 8 more fields>
18/02/28 10:58:21 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 10:58:21 INFO CodeGenerator: Code generated in 11.886363 ms
18/02/28 10:58:21 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 282.5 KB, free 359.6 MB)
18/02/28 10:58:21 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 24.1 KB, free 359.5 MB)
18/02/28 10:58:21 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:60157 (size: 24.1 KB, free: 365.5 MB)
18/02/28 10:58:21 INFO SparkContext: Created broadcast 65 from sql at <unknown>:0
18/02/28 10:58:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 10:58:21 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 10:58:21 INFO DAGScheduler: Registering RDD 145 (sql at <unknown>:0)
18/02/28 10:58:21 INFO DAGScheduler: Got job 23 (sql at <unknown>:0) with 1 output partitions
18/02/28 10:58:21 INFO DAGScheduler: Final stage: ResultStage 45 (sql at <unknown>:0)
18/02/28 10:58:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)
18/02/28 10:58:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 44)
18/02/28 10:58:21 INFO DAGScheduler: Submitting ShuffleMapStage 44 (MapPartitionsRDD[145] at sql at <unknown>:0), which has no missing parents
18/02/28 10:58:21 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 31.6 KB, free 359.5 MB)
18/02/28 10:58:21 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 13.9 KB, free 359.5 MB)
18/02/28 10:58:21 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:60157 (size: 13.9 KB, free: 365.5 MB)
18/02/28 10:58:21 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1006
18/02/28 10:58:21 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[145] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:58:21 INFO TaskSchedulerImpl: Adding task set 44.0 with 4 tasks
18/02/28 10:58:21 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 149, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 10:58:21 INFO TaskSetManager: Starting task 1.0 in stage 44.0 (TID 150, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 10:58:21 INFO TaskSetManager: Starting task 2.0 in stage 44.0 (TID 151, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 10:58:21 INFO TaskSetManager: Starting task 3.0 in stage 44.0 (TID 152, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 10:58:21 INFO Executor: Running task 0.0 in stage 44.0 (TID 149)
18/02/28 10:58:21 INFO Executor: Running task 1.0 in stage 44.0 (TID 150)
18/02/28 10:58:21 INFO Executor: Running task 2.0 in stage 44.0 (TID 151)
18/02/28 10:58:21 INFO Executor: Running task 3.0 in stage 44.0 (TID 152)
18/02/28 10:58:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 10:58:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 10:58:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 10:58:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 10:58:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 10:58:21 INFO ContextCleaner: Cleaned accumulator 1404
18/02/28 10:58:21 INFO ContextCleaner: Cleaned accumulator 1406
18/02/28 10:58:21 INFO ContextCleaner: Cleaned accumulator 1411
18/02/28 10:58:21 INFO ContextCleaner: Cleaned accumulator 1447
18/02/28 10:58:21 INFO ContextCleaner: Cleaned accumulator 1408
18/02/28 10:58:21 INFO ContextCleaner: Cleaned accumulator 1409
18/02/28 10:58:21 INFO ContextCleaner: Cleaned accumulator 1407
18/02/28 10:58:21 INFO ContextCleaner: Cleaned accumulator 1405
18/02/28 10:58:21 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 127.0.0.1:60157 in memory (size: 24.1 KB, free: 365.6 MB)
18/02/28 10:58:21 INFO ContextCleaner: Cleaned accumulator 1412
18/02/28 10:58:21 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:60157 in memory (size: 13.4 KB, free: 365.6 MB)
18/02/28 10:58:21 INFO ContextCleaner: Cleaned accumulator 1410
18/02/28 10:58:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 10:58:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 10:58:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 10:58:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 10:58:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 10:58:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 10:58:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 10:58:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 10:58:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 10:58:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 10:58:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 10:58:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 10:58:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 10:58:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 10:58:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 10:58:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 10:58:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 10:58:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 10:58:22 INFO MemoryStore: Block rdd_142_3 stored as values in memory (estimated size 166.5 KB, free 343.7 MB)
18/02/28 10:58:22 INFO BlockManagerInfo: Added rdd_142_3 in memory on 127.0.0.1:60157 (size: 166.5 KB, free: 365.4 MB)
18/02/28 10:58:22 INFO Executor: Finished task 3.0 in stage 44.0 (TID 152). 3086 bytes result sent to driver
18/02/28 10:58:22 INFO TaskSetManager: Finished task 3.0 in stage 44.0 (TID 152) in 730 ms on localhost (executor driver) (1/4)
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 10:58:22 INFO MemoryStore: Block rdd_142_2 stored as values in memory (estimated size 360.2 KB, free 327.3 MB)
18/02/28 10:58:22 INFO BlockManagerInfo: Added rdd_142_2 in memory on 127.0.0.1:60157 (size: 360.2 KB, free: 365.0 MB)
18/02/28 10:58:22 INFO Executor: Finished task 2.0 in stage 44.0 (TID 151). 3086 bytes result sent to driver
18/02/28 10:58:22 INFO TaskSetManager: Finished task 2.0 in stage 44.0 (TID 151) in 1378 ms on localhost (executor driver) (2/4)
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 10:58:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 10:58:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 10:58:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 10:58:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 10:58:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 10:58:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 10:58:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 10:58:23 INFO MemoryStore: Block rdd_142_1 stored as values in memory (estimated size 536.7 KB, free 338.8 MB)
18/02/28 10:58:23 INFO BlockManagerInfo: Added rdd_142_1 in memory on 127.0.0.1:60157 (size: 536.7 KB, free: 364.5 MB)
18/02/28 10:58:23 INFO Executor: Finished task 1.0 in stage 44.0 (TID 150). 3086 bytes result sent to driver
18/02/28 10:58:23 INFO TaskSetManager: Finished task 1.0 in stage 44.0 (TID 150) in 1883 ms on localhost (executor driver) (3/4)
18/02/28 10:58:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 10:58:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 10:58:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 10:58:23 INFO MemoryStore: Block rdd_142_0 stored as values in memory (estimated size 687.8 KB, free 358.1 MB)
18/02/28 10:58:23 INFO BlockManagerInfo: Added rdd_142_0 in memory on 127.0.0.1:60157 (size: 687.8 KB, free: 363.9 MB)
18/02/28 10:58:23 INFO Executor: Finished task 0.0 in stage 44.0 (TID 149). 3086 bytes result sent to driver
18/02/28 10:58:23 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 149) in 2205 ms on localhost (executor driver) (4/4)
18/02/28 10:58:23 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
18/02/28 10:58:23 INFO DAGScheduler: ShuffleMapStage 44 (sql at <unknown>:0) finished in 2.205 s
18/02/28 10:58:23 INFO DAGScheduler: looking for newly runnable stages
18/02/28 10:58:23 INFO DAGScheduler: running: Set()
18/02/28 10:58:23 INFO DAGScheduler: waiting: Set(ResultStage 45)
18/02/28 10:58:23 INFO DAGScheduler: failed: Set()
18/02/28 10:58:23 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[148] at sql at <unknown>:0), which has no missing parents
18/02/28 10:58:23 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 7.0 KB, free 358.1 MB)
18/02/28 10:58:23 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 3.7 KB, free 358.1 MB)
18/02/28 10:58:23 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:60157 (size: 3.7 KB, free: 363.8 MB)
18/02/28 10:58:23 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1006
18/02/28 10:58:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[148] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 10:58:23 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
18/02/28 10:58:23 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 153, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 10:58:23 INFO Executor: Running task 0.0 in stage 45.0 (TID 153)
18/02/28 10:58:23 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:58:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:58:23 INFO Executor: Finished task 0.0 in stage 45.0 (TID 153). 1452 bytes result sent to driver
18/02/28 10:58:23 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 153) in 2 ms on localhost (executor driver) (1/1)
18/02/28 10:58:23 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
18/02/28 10:58:23 INFO DAGScheduler: ResultStage 45 (sql at <unknown>:0) finished in 0.004 s
18/02/28 10:58:23 INFO DAGScheduler: Job 23 finished: sql at <unknown>:0, took 2.218298 s
18/02/28 10:58:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:58:23 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `training`
18/02/28 10:58:23 INFO HiveMetaStore: 0: get_database: default
18/02/28 10:58:23 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 10:58:23 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 10:58:23 INFO DAGScheduler: Registering RDD 151 (collect at utils.scala:211)
18/02/28 10:58:23 INFO DAGScheduler: Got job 24 (collect at utils.scala:211) with 1 output partitions
18/02/28 10:58:23 INFO DAGScheduler: Final stage: ResultStage 47 (collect at utils.scala:211)
18/02/28 10:58:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 46)
18/02/28 10:58:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 46)
18/02/28 10:58:23 INFO DAGScheduler: Submitting ShuffleMapStage 46 (MapPartitionsRDD[151] at collect at utils.scala:211), which has no missing parents
18/02/28 10:58:23 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 31.6 KB, free 358.1 MB)
18/02/28 10:58:23 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 13.9 KB, free 358.1 MB)
18/02/28 10:58:23 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:60157 (size: 13.9 KB, free: 363.8 MB)
18/02/28 10:58:23 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1006
18/02/28 10:58:23 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[151] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 10:58:23 INFO TaskSchedulerImpl: Adding task set 46.0 with 4 tasks
18/02/28 10:58:23 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 154, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 10:58:23 INFO TaskSetManager: Starting task 1.0 in stage 46.0 (TID 155, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 10:58:23 INFO TaskSetManager: Starting task 2.0 in stage 46.0 (TID 156, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 10:58:23 INFO TaskSetManager: Starting task 3.0 in stage 46.0 (TID 157, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 10:58:23 INFO Executor: Running task 0.0 in stage 46.0 (TID 154)
18/02/28 10:58:23 INFO Executor: Running task 1.0 in stage 46.0 (TID 155)
18/02/28 10:58:23 INFO BlockManager: Found block rdd_142_1 locally
18/02/28 10:58:23 INFO BlockManager: Found block rdd_142_0 locally
18/02/28 10:58:23 INFO Executor: Running task 2.0 in stage 46.0 (TID 156)
18/02/28 10:58:23 INFO Executor: Running task 3.0 in stage 46.0 (TID 157)
18/02/28 10:58:23 INFO BlockManager: Found block rdd_142_2 locally
18/02/28 10:58:23 INFO BlockManager: Found block rdd_142_3 locally
18/02/28 10:58:23 INFO Executor: Finished task 1.0 in stage 46.0 (TID 155). 2319 bytes result sent to driver
18/02/28 10:58:23 INFO TaskSetManager: Finished task 1.0 in stage 46.0 (TID 155) in 25 ms on localhost (executor driver) (1/4)
18/02/28 10:58:23 INFO Executor: Finished task 0.0 in stage 46.0 (TID 154). 2319 bytes result sent to driver
18/02/28 10:58:23 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 154) in 27 ms on localhost (executor driver) (2/4)
18/02/28 10:58:23 INFO Executor: Finished task 2.0 in stage 46.0 (TID 156). 2276 bytes result sent to driver
18/02/28 10:58:23 INFO TaskSetManager: Finished task 2.0 in stage 46.0 (TID 156) in 28 ms on localhost (executor driver) (3/4)
18/02/28 10:58:23 INFO Executor: Finished task 3.0 in stage 46.0 (TID 157). 2319 bytes result sent to driver
18/02/28 10:58:23 INFO TaskSetManager: Finished task 3.0 in stage 46.0 (TID 157) in 29 ms on localhost (executor driver) (4/4)
18/02/28 10:58:23 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
18/02/28 10:58:23 INFO DAGScheduler: ShuffleMapStage 46 (collect at utils.scala:211) finished in 0.031 s
18/02/28 10:58:23 INFO DAGScheduler: looking for newly runnable stages
18/02/28 10:58:23 INFO DAGScheduler: running: Set()
18/02/28 10:58:23 INFO DAGScheduler: waiting: Set(ResultStage 47)
18/02/28 10:58:23 INFO DAGScheduler: failed: Set()
18/02/28 10:58:23 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[154] at collect at utils.scala:211), which has no missing parents
18/02/28 10:58:23 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 7.0 KB, free 358.1 MB)
18/02/28 10:58:23 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 3.7 KB, free 358.1 MB)
18/02/28 10:58:23 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:60157 (size: 3.7 KB, free: 363.8 MB)
18/02/28 10:58:23 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1006
18/02/28 10:58:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[154] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 10:58:23 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
18/02/28 10:58:23 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 158, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 10:58:23 INFO Executor: Running task 0.0 in stage 47.0 (TID 158)
18/02/28 10:58:23 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 10:58:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 10:58:23 INFO Executor: Finished task 0.0 in stage 47.0 (TID 158). 1495 bytes result sent to driver
18/02/28 10:58:23 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 158) in 3 ms on localhost (executor driver) (1/1)
18/02/28 10:58:23 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
18/02/28 10:58:23 INFO DAGScheduler: ResultStage 47 (collect at utils.scala:211) finished in 0.003 s
18/02/28 10:58:23 INFO DAGScheduler: Job 24 finished: collect at utils.scala:211, took 0.041921 s
18/02/28 10:58:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 10:58:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 10:58:26 INFO CodeGenerator: Code generated in 13.219255 ms
18/02/28 10:58:26 INFO SparkContext: Starting job: first at LinearRegression.scala:198
18/02/28 10:58:26 INFO DAGScheduler: Got job 25 (first at LinearRegression.scala:198) with 1 output partitions
18/02/28 10:58:26 INFO DAGScheduler: Final stage: ResultStage 48 (first at LinearRegression.scala:198)
18/02/28 10:58:26 INFO DAGScheduler: Parents of final stage: List()
18/02/28 10:58:26 INFO DAGScheduler: Missing parents: List()
18/02/28 10:58:26 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[157] at first at LinearRegression.scala:198), which has no missing parents
18/02/28 10:58:26 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 37.9 KB, free 358.0 MB)
18/02/28 10:58:26 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 16.6 KB, free 358.0 MB)
18/02/28 10:58:26 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:60157 (size: 16.6 KB, free: 363.8 MB)
18/02/28 10:58:26 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1006
18/02/28 10:58:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[157] at first at LinearRegression.scala:198) (first 15 tasks are for partitions Vector(0))
18/02/28 10:58:26 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks
18/02/28 10:58:26 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 159, localhost, executor driver, partition 0, PROCESS_LOCAL, 6775 bytes)
18/02/28 10:58:26 INFO Executor: Running task 0.0 in stage 48.0 (TID 159)
18/02/28 10:58:26 INFO BlockManager: Found block rdd_142_0 locally
18/02/28 10:58:26 INFO CodeGenerator: Code generated in 24.424714 ms
18/02/28 10:58:26 ERROR Executor: Exception in task 0.0 in stage 48.0 (TID 159)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<year_double_r_formula_30e07b00600b:double>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:395)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:234)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:228)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more
18/02/28 10:58:26 WARN TaskSetManager: Lost task 0.0 in stage 48.0 (TID 159, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<year_double_r_formula_30e07b00600b:double>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:395)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:234)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:228)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more

18/02/28 10:58:26 ERROR TaskSetManager: Task 0 in stage 48.0 failed 1 times; aborting job
18/02/28 10:58:26 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
18/02/28 10:58:26 INFO TaskSchedulerImpl: Cancelling stage 48
18/02/28 10:58:26 INFO DAGScheduler: ResultStage 48 (first at LinearRegression.scala:198) failed in 0.073 s due to Job aborted due to stage failure: Task 0 in stage 48.0 failed 1 times, most recent failure: Lost task 0.0 in stage 48.0 (TID 159, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<year_double_r_formula_30e07b00600b:double>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:395)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:234)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:228)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more

Driver stacktrace:
18/02/28 10:58:26 INFO DAGScheduler: Job 25 failed: first at LinearRegression.scala:198, took 0.080099 s
18/02/28 11:11:22 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:60157 in memory (size: 12.1 KB, free: 363.8 MB)
18/02/28 11:11:22 INFO ContextCleaner: Cleaned accumulator 1453
18/02/28 11:11:22 INFO ContextCleaner: Cleaned accumulator 1569
18/02/28 11:11:22 INFO ContextCleaner: Cleaned accumulator 1454
18/02/28 11:11:22 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 127.0.0.1:60157 in memory (size: 3.7 KB, free: 363.8 MB)
18/02/28 11:11:22 INFO ContextCleaner: Cleaned accumulator 1455
18/02/28 11:11:22 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 127.0.0.1:60157 in memory (size: 13.9 KB, free: 363.8 MB)
18/02/28 11:11:22 INFO ContextCleaner: Cleaned accumulator 1508
18/02/28 11:11:22 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 127.0.0.1:60157 in memory (size: 16.6 KB, free: 363.9 MB)
18/02/28 11:11:22 INFO ContextCleaner: Cleaned accumulator 1456
18/02/28 11:11:22 INFO ContextCleaner: Cleaned accumulator 1448
18/02/28 11:11:22 INFO ContextCleaner: Cleaned accumulator 1459
18/02/28 11:11:22 INFO ContextCleaner: Cleaned shuffle 21
18/02/28 11:11:22 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 127.0.0.1:60157 in memory (size: 13.9 KB, free: 363.9 MB)
18/02/28 11:11:22 INFO ContextCleaner: Cleaned accumulator 1449
18/02/28 11:11:22 INFO ContextCleaner: Cleaned accumulator 1458
18/02/28 11:11:22 INFO ContextCleaner: Cleaned accumulator 1457
18/02/28 11:11:22 INFO ContextCleaner: Cleaned accumulator 1451
18/02/28 11:11:22 INFO ContextCleaner: Cleaned accumulator 1450
18/02/28 11:11:22 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 127.0.0.1:60157 in memory (size: 3.7 KB, free: 363.9 MB)
18/02/28 11:11:22 INFO ContextCleaner: Cleaned accumulator 1452
18/02/28 11:11:22 INFO ContextCleaner: Cleaned accumulator 1570
18/02/28 11:11:22 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:60157 in memory (size: 13.9 KB, free: 363.9 MB)
18/02/28 11:11:22 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:60157 in memory (size: 15.9 KB, free: 363.9 MB)
18/02/28 11:11:22 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:60157 in memory (size: 36.1 KB, free: 363.9 MB)
18/02/28 11:11:22 INFO ContextCleaner: Cleaned accumulator 819
18/02/28 12:09:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:09:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 12:09:40 INFO SparkContext: Starting job: first at LinearRegression.scala:198
18/02/28 12:09:40 INFO DAGScheduler: Got job 26 (first at LinearRegression.scala:198) with 1 output partitions
18/02/28 12:09:40 INFO DAGScheduler: Final stage: ResultStage 49 (first at LinearRegression.scala:198)
18/02/28 12:09:40 INFO DAGScheduler: Parents of final stage: List()
18/02/28 12:09:40 INFO DAGScheduler: Missing parents: List()
18/02/28 12:09:40 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[160] at first at LinearRegression.scala:198), which has no missing parents
18/02/28 12:09:40 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 37.9 KB, free 358.4 MB)
18/02/28 12:09:40 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 16.6 KB, free 358.4 MB)
18/02/28 12:09:40 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 127.0.0.1:60157 (size: 16.6 KB, free: 363.9 MB)
18/02/28 12:09:40 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1006
18/02/28 12:09:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[160] at first at LinearRegression.scala:198) (first 15 tasks are for partitions Vector(0))
18/02/28 12:09:40 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
18/02/28 12:09:40 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 160, localhost, executor driver, partition 0, PROCESS_LOCAL, 6775 bytes)
18/02/28 12:09:40 INFO Executor: Running task 0.0 in stage 49.0 (TID 160)
18/02/28 12:09:40 INFO BlockManager: Found block rdd_142_0 locally
18/02/28 12:09:40 ERROR Executor: Exception in task 0.0 in stage 49.0 (TID 160)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<year_double_r_formula_30e03eeefff:double>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:395)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:234)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:228)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more
18/02/28 12:09:40 WARN TaskSetManager: Lost task 0.0 in stage 49.0 (TID 160, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<year_double_r_formula_30e03eeefff:double>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:395)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:234)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:228)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more

18/02/28 12:09:40 ERROR TaskSetManager: Task 0 in stage 49.0 failed 1 times; aborting job
18/02/28 12:09:40 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
18/02/28 12:09:40 INFO TaskSchedulerImpl: Cancelling stage 49
18/02/28 12:09:40 INFO DAGScheduler: ResultStage 49 (first at LinearRegression.scala:198) failed in 0.031 s due to Job aborted due to stage failure: Task 0 in stage 49.0 failed 1 times, most recent failure: Lost task 0.0 in stage 49.0 (TID 160, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<year_double_r_formula_30e03eeefff:double>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:395)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:234)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:228)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more

Driver stacktrace:
18/02/28 12:09:40 INFO DAGScheduler: Job 26 failed: first at LinearRegression.scala:198, took 0.092551 s
18/02/28 12:10:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:10:13 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao`
18/02/28 12:10:13 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e02156e82
18/02/28 12:10:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:10:13 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e02156e82` AS `zzz20`
WHERE (0 = 1)
18/02/28 12:10:13 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e0535e39ad
18/02/28 12:10:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:10:13 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0535e39ad` AS `zzz21`
WHERE (0 = 1)
18/02/28 12:10:13 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e0729f1e9d
18/02/28 12:10:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:10:13 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0729f1e9d` AS `zzz22`
WHERE (0 = 1)
18/02/28 12:10:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:10:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 12:10:19 INFO SparkContext: Starting job: first at LinearRegression.scala:198
18/02/28 12:10:19 INFO DAGScheduler: Got job 27 (first at LinearRegression.scala:198) with 1 output partitions
18/02/28 12:10:19 INFO DAGScheduler: Final stage: ResultStage 50 (first at LinearRegression.scala:198)
18/02/28 12:10:19 INFO DAGScheduler: Parents of final stage: List()
18/02/28 12:10:19 INFO DAGScheduler: Missing parents: List()
18/02/28 12:10:19 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[163] at first at LinearRegression.scala:198), which has no missing parents
18/02/28 12:10:19 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 37.9 KB, free 358.3 MB)
18/02/28 12:10:19 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 16.6 KB, free 358.3 MB)
18/02/28 12:10:19 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 127.0.0.1:60157 (size: 16.6 KB, free: 363.9 MB)
18/02/28 12:10:19 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1006
18/02/28 12:10:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[163] at first at LinearRegression.scala:198) (first 15 tasks are for partitions Vector(0))
18/02/28 12:10:19 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
18/02/28 12:10:19 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 161, localhost, executor driver, partition 0, PROCESS_LOCAL, 6775 bytes)
18/02/28 12:10:19 INFO Executor: Running task 0.0 in stage 50.0 (TID 161)
18/02/28 12:10:19 INFO BlockManager: Found block rdd_142_0 locally
18/02/28 12:10:19 ERROR Executor: Exception in task 0.0 in stage 50.0 (TID 161)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<year_double_r_formula_30e0641144e2:double>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:395)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:234)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:228)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more
18/02/28 12:10:19 WARN TaskSetManager: Lost task 0.0 in stage 50.0 (TID 161, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<year_double_r_formula_30e0641144e2:double>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:395)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:234)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:228)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more

18/02/28 12:10:19 ERROR TaskSetManager: Task 0 in stage 50.0 failed 1 times; aborting job
18/02/28 12:10:19 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
18/02/28 12:10:19 INFO TaskSchedulerImpl: Cancelling stage 50
18/02/28 12:10:19 INFO DAGScheduler: ResultStage 50 (first at LinearRegression.scala:198) failed in 0.013 s due to Job aborted due to stage failure: Task 0 in stage 50.0 failed 1 times, most recent failure: Lost task 0.0 in stage 50.0 (TID 161, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<year_double_r_formula_30e0641144e2:double>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:395)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:234)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:228)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more

Driver stacktrace:
18/02/28 12:10:19 INFO DAGScheduler: Job 27 failed: first at LinearRegression.scala:198, took 0.019284 s
18/02/28 12:11:22 INFO ContextCleaner: Cleaned accumulator 1621
18/02/28 12:11:22 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 127.0.0.1:60157 in memory (size: 16.6 KB, free: 363.9 MB)
18/02/28 12:11:22 INFO ContextCleaner: Cleaned accumulator 1622
18/02/28 12:11:22 INFO ContextCleaner: Cleaned accumulator 1595
18/02/28 12:11:22 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 127.0.0.1:60157 in memory (size: 16.6 KB, free: 363.9 MB)
18/02/28 12:11:22 INFO ContextCleaner: Cleaned accumulator 1596
18/02/28 12:12:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:12:31 INFO SparkSqlParser: Parsing command: CACHE TABLE `training`
18/02/28 12:12:31 INFO SparkSqlParser: Parsing command: `training`
18/02/28 12:12:31 WARN CacheManager: Asked to cache already cached data.
18/02/28 12:12:31 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 12:12:31 INFO DAGScheduler: Registering RDD 166 (sql at <unknown>:0)
18/02/28 12:12:31 INFO DAGScheduler: Got job 28 (sql at <unknown>:0) with 1 output partitions
18/02/28 12:12:31 INFO DAGScheduler: Final stage: ResultStage 52 (sql at <unknown>:0)
18/02/28 12:12:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 51)
18/02/28 12:12:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 51)
18/02/28 12:12:31 INFO DAGScheduler: Submitting ShuffleMapStage 51 (MapPartitionsRDD[166] at sql at <unknown>:0), which has no missing parents
18/02/28 12:12:31 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 31.6 KB, free 358.4 MB)
18/02/28 12:12:31 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 13.9 KB, free 358.4 MB)
18/02/28 12:12:31 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 127.0.0.1:60157 (size: 13.9 KB, free: 363.9 MB)
18/02/28 12:12:31 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1006
18/02/28 12:12:31 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 51 (MapPartitionsRDD[166] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 12:12:31 INFO TaskSchedulerImpl: Adding task set 51.0 with 4 tasks
18/02/28 12:12:31 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 162, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 12:12:31 INFO TaskSetManager: Starting task 1.0 in stage 51.0 (TID 163, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 12:12:31 INFO TaskSetManager: Starting task 2.0 in stage 51.0 (TID 164, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 12:12:31 INFO TaskSetManager: Starting task 3.0 in stage 51.0 (TID 165, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 12:12:31 INFO Executor: Running task 0.0 in stage 51.0 (TID 162)
18/02/28 12:12:31 INFO Executor: Running task 1.0 in stage 51.0 (TID 163)
18/02/28 12:12:31 INFO Executor: Running task 3.0 in stage 51.0 (TID 165)
18/02/28 12:12:31 INFO Executor: Running task 2.0 in stage 51.0 (TID 164)
18/02/28 12:12:31 INFO BlockManager: Found block rdd_142_0 locally
18/02/28 12:12:31 INFO BlockManager: Found block rdd_142_3 locally
18/02/28 12:12:31 INFO BlockManager: Found block rdd_142_2 locally
18/02/28 12:12:31 INFO BlockManager: Found block rdd_142_1 locally
18/02/28 12:12:31 INFO Executor: Finished task 2.0 in stage 51.0 (TID 164). 2276 bytes result sent to driver
18/02/28 12:12:31 INFO TaskSetManager: Finished task 2.0 in stage 51.0 (TID 164) in 18 ms on localhost (executor driver) (1/4)
18/02/28 12:12:31 INFO Executor: Finished task 3.0 in stage 51.0 (TID 165). 2319 bytes result sent to driver
18/02/28 12:12:31 INFO TaskSetManager: Finished task 3.0 in stage 51.0 (TID 165) in 20 ms on localhost (executor driver) (2/4)
18/02/28 12:12:31 INFO Executor: Finished task 1.0 in stage 51.0 (TID 163). 2276 bytes result sent to driver
18/02/28 12:12:31 INFO TaskSetManager: Finished task 1.0 in stage 51.0 (TID 163) in 21 ms on localhost (executor driver) (3/4)
18/02/28 12:12:31 INFO Executor: Finished task 0.0 in stage 51.0 (TID 162). 2276 bytes result sent to driver
18/02/28 12:12:31 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 162) in 27 ms on localhost (executor driver) (4/4)
18/02/28 12:12:31 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
18/02/28 12:12:31 INFO DAGScheduler: ShuffleMapStage 51 (sql at <unknown>:0) finished in 0.028 s
18/02/28 12:12:31 INFO DAGScheduler: looking for newly runnable stages
18/02/28 12:12:31 INFO DAGScheduler: running: Set()
18/02/28 12:12:31 INFO DAGScheduler: waiting: Set(ResultStage 52)
18/02/28 12:12:31 INFO DAGScheduler: failed: Set()
18/02/28 12:12:31 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[169] at sql at <unknown>:0), which has no missing parents
18/02/28 12:12:31 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 7.0 KB, free 358.4 MB)
18/02/28 12:12:31 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 3.7 KB, free 358.4 MB)
18/02/28 12:12:31 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 127.0.0.1:60157 (size: 3.7 KB, free: 363.9 MB)
18/02/28 12:12:31 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1006
18/02/28 12:12:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[169] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 12:12:31 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
18/02/28 12:12:31 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 166, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 12:12:31 INFO Executor: Running task 0.0 in stage 52.0 (TID 166)
18/02/28 12:12:31 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:12:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 12:12:31 INFO Executor: Finished task 0.0 in stage 52.0 (TID 166). 1495 bytes result sent to driver
18/02/28 12:12:31 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 166) in 4 ms on localhost (executor driver) (1/1)
18/02/28 12:12:31 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
18/02/28 12:12:31 INFO DAGScheduler: ResultStage 52 (sql at <unknown>:0) finished in 0.005 s
18/02/28 12:12:31 INFO DAGScheduler: Job 28 finished: sql at <unknown>:0, took 0.084441 s
18/02/28 12:12:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:12:31 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `training`
18/02/28 12:12:31 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:12:31 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:12:31 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 12:12:31 INFO DAGScheduler: Registering RDD 172 (collect at utils.scala:211)
18/02/28 12:12:31 INFO DAGScheduler: Got job 29 (collect at utils.scala:211) with 1 output partitions
18/02/28 12:12:31 INFO DAGScheduler: Final stage: ResultStage 54 (collect at utils.scala:211)
18/02/28 12:12:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 53)
18/02/28 12:12:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 53)
18/02/28 12:12:31 INFO DAGScheduler: Submitting ShuffleMapStage 53 (MapPartitionsRDD[172] at collect at utils.scala:211), which has no missing parents
18/02/28 12:12:31 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 31.6 KB, free 358.3 MB)
18/02/28 12:12:31 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 14.0 KB, free 358.3 MB)
18/02/28 12:12:31 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 127.0.0.1:60157 (size: 14.0 KB, free: 363.9 MB)
18/02/28 12:12:31 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1006
18/02/28 12:12:31 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 53 (MapPartitionsRDD[172] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 12:12:31 INFO TaskSchedulerImpl: Adding task set 53.0 with 4 tasks
18/02/28 12:12:31 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 167, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 12:12:31 INFO TaskSetManager: Starting task 1.0 in stage 53.0 (TID 168, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 12:12:31 INFO TaskSetManager: Starting task 2.0 in stage 53.0 (TID 169, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 12:12:31 INFO TaskSetManager: Starting task 3.0 in stage 53.0 (TID 170, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 12:12:31 INFO Executor: Running task 2.0 in stage 53.0 (TID 169)
18/02/28 12:12:31 INFO Executor: Running task 0.0 in stage 53.0 (TID 167)
18/02/28 12:12:31 INFO Executor: Running task 3.0 in stage 53.0 (TID 170)
18/02/28 12:12:31 INFO Executor: Running task 1.0 in stage 53.0 (TID 168)
18/02/28 12:12:31 INFO BlockManager: Found block rdd_142_1 locally
18/02/28 12:12:31 INFO BlockManager: Found block rdd_142_2 locally
18/02/28 12:12:31 INFO BlockManager: Found block rdd_142_0 locally
18/02/28 12:12:31 INFO BlockManager: Found block rdd_142_3 locally
18/02/28 12:12:31 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file C:\Users\JC\AppData\Local\Temp\blockmgr-63cb5e29-4480-4914-8723-855010b4870c\28\temp_shuffle_b659d68f-890b-4803-96f8-fcd8e401072d
java.io.FileNotFoundException: C:\Users\JC\AppData\Local\Temp\blockmgr-63cb5e29-4480-4914-8723-855010b4870c\28\temp_shuffle_b659d68f-890b-4803-96f8-fcd8e401072d (The system cannot find the path specified)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at org.apache.spark.storage.DiskBlockObjectWriter$$anonfun$revertPartialWritesAndClose$2.apply$mcV$sp(DiskBlockObjectWriter.scala:215)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1346)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:212)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:237)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:102)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
18/02/28 12:12:31 ERROR BypassMergeSortShuffleWriter: Error while deleting file C:\Users\JC\AppData\Local\Temp\blockmgr-63cb5e29-4480-4914-8723-855010b4870c\28\temp_shuffle_b659d68f-890b-4803-96f8-fcd8e401072d
18/02/28 12:12:31 ERROR Executor: Exception in task 3.0 in stage 53.0 (TID 170)
java.io.FileNotFoundException: C:\Users\JC\AppData\Local\Temp\blockmgr-63cb5e29-4480-4914-8723-855010b4870c\28\temp_shuffle_b659d68f-890b-4803-96f8-fcd8e401072d (The system cannot find the path specified)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:102)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:115)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:235)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
18/02/28 12:12:31 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file C:\Users\JC\AppData\Local\Temp\blockmgr-63cb5e29-4480-4914-8723-855010b4870c\1e\temp_shuffle_e0ef5b0e-7a4d-4d72-94f1-579a5bcdf0c5
java.io.FileNotFoundException: C:\Users\JC\AppData\Local\Temp\blockmgr-63cb5e29-4480-4914-8723-855010b4870c\1e\temp_shuffle_e0ef5b0e-7a4d-4d72-94f1-579a5bcdf0c5 (The system cannot find the path specified)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at org.apache.spark.storage.DiskBlockObjectWriter$$anonfun$revertPartialWritesAndClose$2.apply$mcV$sp(DiskBlockObjectWriter.scala:215)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1346)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:212)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:237)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:102)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
18/02/28 12:12:31 ERROR BypassMergeSortShuffleWriter: Error while deleting file C:\Users\JC\AppData\Local\Temp\blockmgr-63cb5e29-4480-4914-8723-855010b4870c\1e\temp_shuffle_e0ef5b0e-7a4d-4d72-94f1-579a5bcdf0c5
18/02/28 12:12:31 ERROR Executor: Exception in task 2.0 in stage 53.0 (TID 169)
java.io.FileNotFoundException: C:\Users\JC\AppData\Local\Temp\blockmgr-63cb5e29-4480-4914-8723-855010b4870c\1e\temp_shuffle_e0ef5b0e-7a4d-4d72-94f1-579a5bcdf0c5 (The system cannot find the path specified)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:102)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:115)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:235)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
18/02/28 12:12:31 WARN TaskSetManager: Lost task 2.0 in stage 53.0 (TID 169, localhost, executor driver): java.io.FileNotFoundException: C:\Users\JC\AppData\Local\Temp\blockmgr-63cb5e29-4480-4914-8723-855010b4870c\1e\temp_shuffle_e0ef5b0e-7a4d-4d72-94f1-579a5bcdf0c5 (The system cannot find the path specified)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:102)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:115)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:235)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

18/02/28 12:12:31 ERROR TaskSetManager: Task 2 in stage 53.0 failed 1 times; aborting job
18/02/28 12:12:31 WARN TaskSetManager: Lost task 3.0 in stage 53.0 (TID 170, localhost, executor driver): java.io.FileNotFoundException: C:\Users\JC\AppData\Local\Temp\blockmgr-63cb5e29-4480-4914-8723-855010b4870c\28\temp_shuffle_b659d68f-890b-4803-96f8-fcd8e401072d (The system cannot find the path specified)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:102)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:115)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:235)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

18/02/28 12:12:31 INFO TaskSchedulerImpl: Cancelling stage 53
18/02/28 12:12:31 INFO Executor: Finished task 1.0 in stage 53.0 (TID 168). 2276 bytes result sent to driver
18/02/28 12:12:31 INFO TaskSchedulerImpl: Stage 53 was cancelled
18/02/28 12:12:31 INFO DAGScheduler: ShuffleMapStage 53 (collect at utils.scala:211) failed in 0.028 s due to Job aborted due to stage failure: Task 2 in stage 53.0 failed 1 times, most recent failure: Lost task 2.0 in stage 53.0 (TID 169, localhost, executor driver): java.io.FileNotFoundException: C:\Users\JC\AppData\Local\Temp\blockmgr-63cb5e29-4480-4914-8723-855010b4870c\1e\temp_shuffle_e0ef5b0e-7a4d-4d72-94f1-579a5bcdf0c5 (The system cannot find the path specified)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:102)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:115)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:235)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

Driver stacktrace:
18/02/28 12:12:31 INFO Executor: Executor is trying to kill task 1.0 in stage 53.0 (TID 168), reason: stage cancelled
18/02/28 12:12:31 INFO Executor: Executor is trying to kill task 0.0 in stage 53.0 (TID 167), reason: stage cancelled
18/02/28 12:12:31 INFO DAGScheduler: Job 29 failed: collect at utils.scala:211, took 0.032789 s
18/02/28 12:12:31 INFO TaskSetManager: Finished task 1.0 in stage 53.0 (TID 168) in 29 ms on localhost (executor driver) (1/4)
18/02/28 12:12:31 INFO Executor: Executor killed task 0.0 in stage 53.0 (TID 167), reason: stage cancelled
18/02/28 12:12:31 WARN TaskSetManager: Lost task 0.0 in stage 53.0 (TID 167, localhost, executor driver): TaskKilled (stage cancelled)
18/02/28 12:12:31 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
18/02/28 12:13:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:13:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao`
18/02/28 12:13:04 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e075595b62
18/02/28 12:13:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:13:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e075595b62` AS `zzz23`
WHERE (0 = 1)
18/02/28 12:13:04 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e045e166be
18/02/28 12:13:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:13:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e045e166be` AS `zzz24`
WHERE (0 = 1)
18/02/28 12:13:04 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e05ee77af7
18/02/28 12:13:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:13:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e05ee77af7` AS `zzz25`
WHERE (0 = 1)
18/02/28 12:13:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:13:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e075595b62`
18/02/28 12:13:08 INFO SparkSqlParser: Parsing command: training
18/02/28 12:13:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:13:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training` AS `zzz26`
WHERE (0 = 1)
18/02/28 12:13:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:13:08 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:13:08 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:13:08 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:13:08 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:13:08 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:13:08 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:13:08 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:13:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:13:13 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 12:13:13 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 12:13:13 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 12:13:13 INFO FileSourceStrategy: Output Data Schema: struct<year: int, production_area: int, country: string, iso: string, source: string ... 8 more fields>
18/02/28 12:13:13 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 12:13:13 INFO CodeGenerator: Code generated in 26.502333 ms
18/02/28 12:13:13 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 282.5 KB, free 358.1 MB)
18/02/28 12:13:13 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 24.1 KB, free 358.0 MB)
18/02/28 12:13:13 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 127.0.0.1:60157 (size: 24.1 KB, free: 363.9 MB)
18/02/28 12:13:13 INFO SparkContext: Created broadcast 76 from first at LinearRegression.scala:198
18/02/28 12:13:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 12:13:13 INFO SparkContext: Starting job: first at LinearRegression.scala:198
18/02/28 12:13:13 INFO DAGScheduler: Got job 30 (first at LinearRegression.scala:198) with 1 output partitions
18/02/28 12:13:13 INFO DAGScheduler: Final stage: ResultStage 55 (first at LinearRegression.scala:198)
18/02/28 12:13:13 INFO DAGScheduler: Parents of final stage: List()
18/02/28 12:13:13 INFO DAGScheduler: Missing parents: List()
18/02/28 12:13:13 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[178] at first at LinearRegression.scala:198), which has no missing parents
18/02/28 12:13:13 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 29.3 KB, free 358.0 MB)
18/02/28 12:13:13 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 13.4 KB, free 358.0 MB)
18/02/28 12:13:13 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 127.0.0.1:60157 (size: 13.4 KB, free: 363.9 MB)
18/02/28 12:13:13 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1006
18/02/28 12:13:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[178] at first at LinearRegression.scala:198) (first 15 tasks are for partitions Vector(0))
18/02/28 12:13:13 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks
18/02/28 12:13:13 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 171, localhost, executor driver, partition 0, PROCESS_LOCAL, 6775 bytes)
18/02/28 12:13:13 INFO Executor: Running task 0.0 in stage 55.0 (TID 171)
18/02/28 12:13:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 12:13:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 12:13:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 12:13:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 12:13:13 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 127.0.0.1:60157 in memory (size: 13.9 KB, free: 363.9 MB)
18/02/28 12:13:13 INFO ContextCleaner: Cleaned accumulator 1648
18/02/28 12:13:13 INFO ContextCleaner: Cleaned accumulator 1652
18/02/28 12:13:13 INFO ContextCleaner: Cleaned accumulator 1653
18/02/28 12:13:13 INFO ContextCleaner: Cleaned accumulator 1649
18/02/28 12:13:13 INFO ContextCleaner: Cleaned accumulator 1708
18/02/28 12:13:13 INFO ContextCleaner: Cleaned accumulator 1659
18/02/28 12:13:13 INFO ContextCleaner: Cleaned accumulator 1654
18/02/28 12:13:13 INFO ContextCleaner: Cleaned accumulator 1657
18/02/28 12:13:13 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 127.0.0.1:60157 in memory (size: 3.7 KB, free: 363.9 MB)
18/02/28 12:13:13 INFO ContextCleaner: Cleaned accumulator 1647
18/02/28 12:13:13 INFO ContextCleaner: Cleaned accumulator 1650
18/02/28 12:13:13 INFO ContextCleaner: Cleaned accumulator 1651
18/02/28 12:13:13 INFO ContextCleaner: Cleaned accumulator 1656
18/02/28 12:13:13 INFO ContextCleaner: Cleaned shuffle 23
18/02/28 12:13:13 INFO ContextCleaner: Cleaned accumulator 1658
18/02/28 12:13:13 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 127.0.0.1:60157 in memory (size: 14.0 KB, free: 363.9 MB)
18/02/28 12:13:13 INFO ContextCleaner: Cleaned accumulator 1655
18/02/28 12:13:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 12:13:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 12:13:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 12:13:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 12:13:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 12:13:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 12:13:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 12:13:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 12:13:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 12:13:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 12:13:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 12:13:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 12:13:14 ERROR Executor: Exception in task 0.0 in stage 55.0 (TID 171)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<year_double_r_formula_30e045245db0:double>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:395)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:234)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:228)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more
18/02/28 12:13:14 WARN TaskSetManager: Lost task 0.0 in stage 55.0 (TID 171, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<year_double_r_formula_30e045245db0:double>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:395)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:234)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:228)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more

18/02/28 12:13:14 ERROR TaskSetManager: Task 0 in stage 55.0 failed 1 times; aborting job
18/02/28 12:13:14 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
18/02/28 12:13:14 INFO TaskSchedulerImpl: Cancelling stage 55
18/02/28 12:13:14 INFO DAGScheduler: ResultStage 55 (first at LinearRegression.scala:198) failed in 1.436 s due to Job aborted due to stage failure: Task 0 in stage 55.0 failed 1 times, most recent failure: Lost task 0.0 in stage 55.0 (TID 171, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<year_double_r_formula_30e045245db0:double>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:395)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:234)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:228)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more

Driver stacktrace:
18/02/28 12:13:14 INFO DAGScheduler: Job 30 failed: first at LinearRegression.scala:198, took 1.439574 s
18/02/28 12:14:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:14:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 12:14:49 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 12:14:49 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 12:14:49 INFO FileSourceStrategy: Output Data Schema: struct<year: int, production_area: int, country: string, iso: string, source: string ... 8 more fields>
18/02/28 12:14:49 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 12:14:49 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 282.5 KB, free 357.8 MB)
18/02/28 12:14:49 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 24.1 KB, free 357.8 MB)
18/02/28 12:14:49 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 127.0.0.1:60157 (size: 24.1 KB, free: 363.9 MB)
18/02/28 12:14:49 INFO SparkContext: Created broadcast 78 from first at LinearRegression.scala:198
18/02/28 12:14:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 12:14:49 INFO SparkContext: Starting job: first at LinearRegression.scala:198
18/02/28 12:14:49 INFO DAGScheduler: Got job 31 (first at LinearRegression.scala:198) with 1 output partitions
18/02/28 12:14:49 INFO DAGScheduler: Final stage: ResultStage 56 (first at LinearRegression.scala:198)
18/02/28 12:14:49 INFO DAGScheduler: Parents of final stage: List()
18/02/28 12:14:49 INFO DAGScheduler: Missing parents: List()
18/02/28 12:14:49 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[181] at first at LinearRegression.scala:198), which has no missing parents
18/02/28 12:14:49 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 29.3 KB, free 357.8 MB)
18/02/28 12:14:49 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 13.4 KB, free 357.7 MB)
18/02/28 12:14:49 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 127.0.0.1:60157 (size: 13.4 KB, free: 363.9 MB)
18/02/28 12:14:49 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1006
18/02/28 12:14:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[181] at first at LinearRegression.scala:198) (first 15 tasks are for partitions Vector(0))
18/02/28 12:14:49 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
18/02/28 12:14:49 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 172, localhost, executor driver, partition 0, PROCESS_LOCAL, 6775 bytes)
18/02/28 12:14:49 INFO Executor: Running task 0.0 in stage 56.0 (TID 172)
18/02/28 12:14:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 12:14:49 INFO ContextCleaner: Cleaned accumulator 1749
18/02/28 12:14:49 INFO ContextCleaner: Cleaned accumulator 1752
18/02/28 12:14:49 INFO ContextCleaner: Cleaned accumulator 1745
18/02/28 12:14:49 INFO ContextCleaner: Cleaned accumulator 1751
18/02/28 12:14:49 INFO ContextCleaner: Cleaned accumulator 1747
18/02/28 12:14:49 INFO ContextCleaner: Cleaned accumulator 1748
18/02/28 12:14:49 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 127.0.0.1:60157 in memory (size: 13.4 KB, free: 363.9 MB)
18/02/28 12:14:49 INFO ContextCleaner: Cleaned accumulator 1746
18/02/28 12:14:49 INFO ContextCleaner: Cleaned accumulator 1753
18/02/28 12:14:49 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 127.0.0.1:60157 in memory (size: 24.1 KB, free: 363.9 MB)
18/02/28 12:14:49 INFO ContextCleaner: Cleaned accumulator 1750
18/02/28 12:14:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 12:14:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 12:14:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 12:14:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 12:14:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 12:14:49 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 12:14:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 12:14:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 12:14:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 12:14:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 12:14:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 12:14:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 12:14:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 12:14:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 12:14:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 12:14:50 ERROR Executor: Exception in task 0.0 in stage 56.0 (TID 172)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<year_double_r_formula_30e05ece2e1e:double>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:395)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:234)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:228)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more
18/02/28 12:14:50 WARN TaskSetManager: Lost task 0.0 in stage 56.0 (TID 172, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<year_double_r_formula_30e05ece2e1e:double>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:395)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:234)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:228)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more

18/02/28 12:14:50 ERROR TaskSetManager: Task 0 in stage 56.0 failed 1 times; aborting job
18/02/28 12:14:50 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
18/02/28 12:14:50 INFO TaskSchedulerImpl: Cancelling stage 56
18/02/28 12:14:50 INFO DAGScheduler: ResultStage 56 (first at LinearRegression.scala:198) failed in 1.362 s due to Job aborted due to stage failure: Task 0 in stage 56.0 failed 1 times, most recent failure: Lost task 0.0 in stage 56.0 (TID 172, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<year_double_r_formula_30e05ece2e1e:double>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:395)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:234)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:228)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more

Driver stacktrace:
18/02/28 12:14:50 INFO DAGScheduler: Job 31 failed: first at LinearRegression.scala:198, took 1.366825 s
18/02/28 12:15:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:15:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao`
18/02/28 12:15:29 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e059fd7490
18/02/28 12:15:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:15:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e059fd7490` AS `zzz27`
WHERE (0 = 1)
18/02/28 12:15:29 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e012d7f64
18/02/28 12:15:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:15:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e012d7f64` AS `zzz28`
WHERE (0 = 1)
18/02/28 12:15:29 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e06edd5f77
18/02/28 12:15:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:15:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e06edd5f77` AS `zzz29`
WHERE (0 = 1)
18/02/28 12:15:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:15:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e059fd7490`
18/02/28 12:15:33 INFO SparkSqlParser: Parsing command: training
18/02/28 12:15:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:15:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training` AS `zzz30`
WHERE (0 = 1)
18/02/28 12:15:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:15:33 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:15:33 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:15:33 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:15:33 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:15:33 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:15:33 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:15:33 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:16:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:16:10 INFO SparkSqlParser: Parsing command: CACHE TABLE `training`
18/02/28 12:16:10 INFO SparkSqlParser: Parsing command: `training`
18/02/28 12:16:10 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 12:16:10 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 12:16:10 INFO FileSourceStrategy: Output Data Schema: struct<year: int, production_area: int, country: string, iso: string, source: string ... 8 more fields>
18/02/28 12:16:10 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 12:16:10 INFO CodeGenerator: Code generated in 9.16416 ms
18/02/28 12:16:10 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 282.5 KB, free 357.8 MB)
18/02/28 12:16:10 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 24.1 KB, free 357.8 MB)
18/02/28 12:16:10 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 127.0.0.1:60157 (size: 24.1 KB, free: 363.9 MB)
18/02/28 12:16:10 INFO SparkContext: Created broadcast 80 from sql at <unknown>:0
18/02/28 12:16:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 12:16:10 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 12:16:10 INFO DAGScheduler: Registering RDD 187 (sql at <unknown>:0)
18/02/28 12:16:10 INFO DAGScheduler: Got job 32 (sql at <unknown>:0) with 1 output partitions
18/02/28 12:16:10 INFO DAGScheduler: Final stage: ResultStage 58 (sql at <unknown>:0)
18/02/28 12:16:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 57)
18/02/28 12:16:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 57)
18/02/28 12:16:10 INFO DAGScheduler: Submitting ShuffleMapStage 57 (MapPartitionsRDD[187] at sql at <unknown>:0), which has no missing parents
18/02/28 12:16:10 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 31.6 KB, free 357.8 MB)
18/02/28 12:16:10 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 13.9 KB, free 357.7 MB)
18/02/28 12:16:10 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 127.0.0.1:60157 (size: 13.9 KB, free: 363.9 MB)
18/02/28 12:16:10 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1006
18/02/28 12:16:10 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 57 (MapPartitionsRDD[187] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 12:16:10 INFO TaskSchedulerImpl: Adding task set 57.0 with 4 tasks
18/02/28 12:16:10 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 173, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 12:16:10 INFO TaskSetManager: Starting task 1.0 in stage 57.0 (TID 174, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 12:16:10 INFO TaskSetManager: Starting task 2.0 in stage 57.0 (TID 175, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 12:16:10 INFO TaskSetManager: Starting task 3.0 in stage 57.0 (TID 176, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 12:16:10 INFO Executor: Running task 1.0 in stage 57.0 (TID 174)
18/02/28 12:16:10 INFO Executor: Running task 0.0 in stage 57.0 (TID 173)
18/02/28 12:16:10 INFO Executor: Running task 2.0 in stage 57.0 (TID 175)
18/02/28 12:16:10 INFO Executor: Running task 3.0 in stage 57.0 (TID 176)
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 12:16:10 INFO ContextCleaner: Cleaned accumulator 1784
18/02/28 12:16:10 INFO ContextCleaner: Cleaned accumulator 1780
18/02/28 12:16:10 INFO ContextCleaner: Cleaned accumulator 1779
18/02/28 12:16:10 INFO ContextCleaner: Cleaned accumulator 1781
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 12:16:10 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 127.0.0.1:60157 in memory (size: 24.1 KB, free: 363.9 MB)
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 12:16:10 INFO ContextCleaner: Cleaned accumulator 1778
18/02/28 12:16:10 INFO ContextCleaner: Cleaned accumulator 1785
18/02/28 12:16:10 INFO ContextCleaner: Cleaned accumulator 1783
18/02/28 12:16:10 INFO ContextCleaner: Cleaned accumulator 1821
18/02/28 12:16:10 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 127.0.0.1:60157 in memory (size: 13.4 KB, free: 363.9 MB)
18/02/28 12:16:10 INFO ContextCleaner: Cleaned accumulator 1782
18/02/28 12:16:10 INFO ContextCleaner: Cleaned accumulator 1786
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 12:16:10 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 12:16:11 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 12:16:11 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 12:16:11 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 12:16:11 INFO MemoryStore: Block rdd_184_3 stored as values in memory (estimated size 163.4 KB, free 340.9 MB)
18/02/28 12:16:11 INFO BlockManagerInfo: Added rdd_184_3 in memory on 127.0.0.1:60157 (size: 163.4 KB, free: 363.7 MB)
18/02/28 12:16:11 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file C:\Users\JC\AppData\Local\Temp\blockmgr-63cb5e29-4480-4914-8723-855010b4870c\21\temp_shuffle_a071c4ce-e803-41e4-900e-35edec72cac3
java.io.FileNotFoundException: C:\Users\JC\AppData\Local\Temp\blockmgr-63cb5e29-4480-4914-8723-855010b4870c\21\temp_shuffle_a071c4ce-e803-41e4-900e-35edec72cac3 (The system cannot find the path specified)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at org.apache.spark.storage.DiskBlockObjectWriter$$anonfun$revertPartialWritesAndClose$2.apply$mcV$sp(DiskBlockObjectWriter.scala:215)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1346)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:212)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:237)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:102)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
18/02/28 12:16:11 ERROR BypassMergeSortShuffleWriter: Error while deleting file C:\Users\JC\AppData\Local\Temp\blockmgr-63cb5e29-4480-4914-8723-855010b4870c\21\temp_shuffle_a071c4ce-e803-41e4-900e-35edec72cac3
18/02/28 12:16:11 ERROR Executor: Exception in task 3.0 in stage 57.0 (TID 176)
java.io.FileNotFoundException: C:\Users\JC\AppData\Local\Temp\blockmgr-63cb5e29-4480-4914-8723-855010b4870c\21\temp_shuffle_a071c4ce-e803-41e4-900e-35edec72cac3 (The system cannot find the path specified)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:102)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:115)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:235)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
18/02/28 12:16:11 WARN TaskSetManager: Lost task 3.0 in stage 57.0 (TID 176, localhost, executor driver): java.io.FileNotFoundException: C:\Users\JC\AppData\Local\Temp\blockmgr-63cb5e29-4480-4914-8723-855010b4870c\21\temp_shuffle_a071c4ce-e803-41e4-900e-35edec72cac3 (The system cannot find the path specified)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:102)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:115)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:235)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

18/02/28 12:16:11 ERROR TaskSetManager: Task 3 in stage 57.0 failed 1 times; aborting job
18/02/28 12:16:11 INFO TaskSchedulerImpl: Cancelling stage 57
18/02/28 12:16:11 INFO TaskSchedulerImpl: Stage 57 was cancelled
18/02/28 12:16:11 INFO DAGScheduler: ShuffleMapStage 57 (sql at <unknown>:0) failed in 0.816 s due to Job aborted due to stage failure: Task 3 in stage 57.0 failed 1 times, most recent failure: Lost task 3.0 in stage 57.0 (TID 176, localhost, executor driver): java.io.FileNotFoundException: C:\Users\JC\AppData\Local\Temp\blockmgr-63cb5e29-4480-4914-8723-855010b4870c\21\temp_shuffle_a071c4ce-e803-41e4-900e-35edec72cac3 (The system cannot find the path specified)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:102)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:115)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:235)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

Driver stacktrace:
18/02/28 12:16:11 INFO DAGScheduler: Job 32 failed: sql at <unknown>:0, took 0.821411 s
18/02/28 12:16:11 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 12:16:11 INFO Executor: Executor is trying to kill task 0.0 in stage 57.0 (TID 173), reason: stage cancelled
18/02/28 12:16:11 INFO Executor: Executor is trying to kill task 1.0 in stage 57.0 (TID 174), reason: stage cancelled
18/02/28 12:16:11 INFO Executor: Executor is trying to kill task 2.0 in stage 57.0 (TID 175), reason: stage cancelled
18/02/28 12:16:11 WARN BlockManager: Putting block rdd_184_1 failed due to an exception
18/02/28 12:16:11 WARN BlockManager: Putting block rdd_184_2 failed due to an exception
18/02/28 12:16:11 WARN BlockManager: Putting block rdd_184_0 failed due to an exception
18/02/28 12:16:11 WARN BlockManager: Block rdd_184_0 could not be removed as it was not found on disk or in memory
18/02/28 12:16:11 WARN BlockManager: Block rdd_184_1 could not be removed as it was not found on disk or in memory
18/02/28 12:16:11 WARN BlockManager: Block rdd_184_2 could not be removed as it was not found on disk or in memory
18/02/28 12:16:11 INFO Executor: Executor killed task 2.0 in stage 57.0 (TID 175), reason: stage cancelled
18/02/28 12:16:11 INFO Executor: Executor killed task 0.0 in stage 57.0 (TID 173), reason: stage cancelled
18/02/28 12:16:11 INFO Executor: Executor killed task 1.0 in stage 57.0 (TID 174), reason: stage cancelled
18/02/28 12:16:11 WARN TaskSetManager: Lost task 2.0 in stage 57.0 (TID 175, localhost, executor driver): TaskKilled (stage cancelled)
18/02/28 12:16:11 WARN TaskSetManager: Lost task 0.0 in stage 57.0 (TID 173, localhost, executor driver): TaskKilled (stage cancelled)
18/02/28 12:16:11 WARN TaskSetManager: Lost task 1.0 in stage 57.0 (TID 174, localhost, executor driver): TaskKilled (stage cancelled)
18/02/28 12:16:11 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
18/02/28 12:16:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:16:20 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
LIMIT 6
18/02/28 12:16:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:16:20 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
LIMIT 6
18/02/28 12:16:20 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 12:16:20 INFO DAGScheduler: Got job 33 (collect at utils.scala:211) with 1 output partitions
18/02/28 12:16:20 INFO DAGScheduler: Final stage: ResultStage 59 (collect at utils.scala:211)
18/02/28 12:16:20 INFO DAGScheduler: Parents of final stage: List()
18/02/28 12:16:20 INFO DAGScheduler: Missing parents: List()
18/02/28 12:16:20 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[192] at collect at utils.scala:211), which has no missing parents
18/02/28 12:16:20 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 27.8 KB, free 357.9 MB)
18/02/28 12:16:20 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 12.6 KB, free 357.9 MB)
18/02/28 12:16:20 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 127.0.0.1:60157 (size: 12.6 KB, free: 363.7 MB)
18/02/28 12:16:20 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1006
18/02/28 12:16:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[192] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 12:16:20 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
18/02/28 12:16:20 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 177, localhost, executor driver, partition 0, PROCESS_LOCAL, 6775 bytes)
18/02/28 12:16:20 INFO Executor: Running task 0.0 in stage 59.0 (TID 177)
18/02/28 12:16:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 12:16:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 12:16:20 INFO ContextCleaner: Cleaned accumulator 1824
18/02/28 12:16:20 INFO ContextCleaner: Cleaned accumulator 1825
18/02/28 12:16:20 INFO ContextCleaner: Cleaned accumulator 1823
18/02/28 12:16:20 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 127.0.0.1:60157 in memory (size: 13.9 KB, free: 363.7 MB)
18/02/28 12:16:20 INFO ContextCleaner: Cleaned accumulator 1826
18/02/28 12:16:20 INFO ContextCleaner: Cleaned accumulator 1829
18/02/28 12:16:20 INFO ContextCleaner: Cleaned accumulator 1830
18/02/28 12:16:20 INFO ContextCleaner: Cleaned accumulator 1831
18/02/28 12:16:20 INFO ContextCleaner: Cleaned accumulator 1833
18/02/28 12:16:20 INFO ContextCleaner: Cleaned accumulator 1832
18/02/28 12:16:20 INFO ContextCleaner: Cleaned accumulator 1822
18/02/28 12:16:20 INFO ContextCleaner: Cleaned accumulator 1828
18/02/28 12:16:20 INFO ContextCleaner: Cleaned shuffle 25
18/02/28 12:16:20 INFO ContextCleaner: Cleaned accumulator 1827
18/02/28 12:16:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 12:16:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 12:16:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 12:16:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 12:16:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 12:16:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 12:16:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 12:16:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 12:16:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 12:16:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 12:16:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 12:16:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 12:16:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 12:16:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 12:16:22 INFO MemoryStore: Block rdd_184_0 stored as values in memory (estimated size 696.8 KB, free 357.2 MB)
18/02/28 12:16:22 INFO BlockManagerInfo: Added rdd_184_0 in memory on 127.0.0.1:60157 (size: 696.8 KB, free: 363.1 MB)
18/02/28 12:16:22 INFO CodeGenerator: Code generated in 15.48376 ms
18/02/28 12:16:22 INFO Executor: 1 block locks were not released by TID = 177:
[rdd_184_0]
18/02/28 12:16:22 INFO Executor: Finished task 0.0 in stage 59.0 (TID 177). 2610 bytes result sent to driver
18/02/28 12:16:22 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 177) in 1833 ms on localhost (executor driver) (1/1)
18/02/28 12:16:22 INFO DAGScheduler: ResultStage 59 (collect at utils.scala:211) finished in 1.834 s
18/02/28 12:16:22 INFO DAGScheduler: Job 33 finished: collect at utils.scala:211, took 1.839801 s
18/02/28 12:16:22 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
18/02/28 12:16:22 INFO CodeGenerator: Code generated in 7.970552 ms
18/02/28 12:16:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:16:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao`
LIMIT 6
18/02/28 12:16:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:16:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao`
LIMIT 6
18/02/28 12:16:37 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 12:16:37 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 12:16:37 INFO FileSourceStrategy: Output Data Schema: struct<year: int, production_area: int, country: string, iso: string, source: string ... 8 more fields>
18/02/28 12:16:37 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 12:16:37 INFO CodeGenerator: Code generated in 4.900317 ms
18/02/28 12:16:37 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 282.5 KB, free 357.0 MB)
18/02/28 12:16:37 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 24.1 KB, free 356.9 MB)
18/02/28 12:16:37 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 127.0.0.1:60157 (size: 24.1 KB, free: 363.0 MB)
18/02/28 12:16:37 INFO SparkContext: Created broadcast 83 from collect at utils.scala:211
18/02/28 12:16:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 12:16:37 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 12:16:37 INFO DAGScheduler: Got job 34 (collect at utils.scala:211) with 1 output partitions
18/02/28 12:16:37 INFO DAGScheduler: Final stage: ResultStage 60 (collect at utils.scala:211)
18/02/28 12:16:37 INFO DAGScheduler: Parents of final stage: List()
18/02/28 12:16:37 INFO DAGScheduler: Missing parents: List()
18/02/28 12:16:37 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[195] at collect at utils.scala:211), which has no missing parents
18/02/28 12:16:37 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 11.6 KB, free 356.9 MB)
18/02/28 12:16:37 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 6.8 KB, free 356.9 MB)
18/02/28 12:16:37 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 127.0.0.1:60157 (size: 6.8 KB, free: 363.0 MB)
18/02/28 12:16:37 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1006
18/02/28 12:16:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[195] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 12:16:37 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks
18/02/28 12:16:37 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 178, localhost, executor driver, partition 0, PROCESS_LOCAL, 6775 bytes)
18/02/28 12:16:37 INFO Executor: Running task 0.0 in stage 60.0 (TID 178)
18/02/28 12:16:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 12:16:37 INFO Executor: Finished task 0.0 in stage 60.0 (TID 178). 1111 bytes result sent to driver
18/02/28 12:16:37 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 178) in 5 ms on localhost (executor driver) (1/1)
18/02/28 12:16:37 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
18/02/28 12:16:37 INFO DAGScheduler: ResultStage 60 (collect at utils.scala:211) finished in 0.005 s
18/02/28 12:16:37 INFO DAGScheduler: Job 34 finished: collect at utils.scala:211, took 0.009249 s
18/02/28 12:17:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:17:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e059fd7490`
18/02/28 12:17:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:17:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e059fd7490`
LIMIT 10
18/02/28 12:17:14 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 12:17:14 INFO DAGScheduler: Got job 35 (collect at utils.scala:211) with 1 output partitions
18/02/28 12:17:14 INFO DAGScheduler: Final stage: ResultStage 61 (collect at utils.scala:211)
18/02/28 12:17:14 INFO DAGScheduler: Parents of final stage: List()
18/02/28 12:17:14 INFO DAGScheduler: Missing parents: List()
18/02/28 12:17:14 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[197] at collect at utils.scala:211), which has no missing parents
18/02/28 12:17:14 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 27.8 KB, free 356.9 MB)
18/02/28 12:17:14 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 12.6 KB, free 356.9 MB)
18/02/28 12:17:14 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 127.0.0.1:60157 (size: 12.6 KB, free: 363.0 MB)
18/02/28 12:17:14 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1006
18/02/28 12:17:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[197] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 12:17:14 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks
18/02/28 12:17:14 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 179, localhost, executor driver, partition 0, PROCESS_LOCAL, 6775 bytes)
18/02/28 12:17:14 INFO Executor: Running task 0.0 in stage 61.0 (TID 179)
18/02/28 12:17:14 INFO BlockManager: Found block rdd_184_0 locally
18/02/28 12:17:14 INFO Executor: 1 block locks were not released by TID = 179:
[rdd_184_0]
18/02/28 12:17:14 INFO Executor: Finished task 0.0 in stage 61.0 (TID 179). 1845 bytes result sent to driver
18/02/28 12:17:14 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 179) in 8 ms on localhost (executor driver) (1/1)
18/02/28 12:17:14 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
18/02/28 12:17:14 INFO DAGScheduler: ResultStage 61 (collect at utils.scala:211) finished in 0.008 s
18/02/28 12:17:14 INFO DAGScheduler: Job 35 finished: collect at utils.scala:211, took 0.012331 s
18/02/28 12:18:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:18:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao`
LIMIT 6
18/02/28 12:18:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:18:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao`
LIMIT 6
18/02/28 12:18:42 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 12:18:42 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 12:18:42 INFO FileSourceStrategy: Output Data Schema: struct<year: int, production_area: int, country: string, iso: string, source: string ... 8 more fields>
18/02/28 12:18:42 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 12:18:42 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 282.5 KB, free 356.6 MB)
18/02/28 12:18:42 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 24.1 KB, free 356.6 MB)
18/02/28 12:18:42 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 127.0.0.1:60157 (size: 24.1 KB, free: 363.0 MB)
18/02/28 12:18:42 INFO SparkContext: Created broadcast 86 from collect at utils.scala:211
18/02/28 12:18:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 12:18:42 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 12:18:42 INFO DAGScheduler: Got job 36 (collect at utils.scala:211) with 1 output partitions
18/02/28 12:18:42 INFO DAGScheduler: Final stage: ResultStage 62 (collect at utils.scala:211)
18/02/28 12:18:42 INFO DAGScheduler: Parents of final stage: List()
18/02/28 12:18:42 INFO DAGScheduler: Missing parents: List()
18/02/28 12:18:42 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[200] at collect at utils.scala:211), which has no missing parents
18/02/28 12:18:42 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 11.6 KB, free 356.6 MB)
18/02/28 12:18:42 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 6.8 KB, free 356.6 MB)
18/02/28 12:18:42 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 127.0.0.1:60157 (size: 6.8 KB, free: 363.0 MB)
18/02/28 12:18:42 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1006
18/02/28 12:18:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[200] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 12:18:42 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks
18/02/28 12:18:42 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 180, localhost, executor driver, partition 0, PROCESS_LOCAL, 6775 bytes)
18/02/28 12:18:42 INFO Executor: Running task 0.0 in stage 62.0 (TID 180)
18/02/28 12:18:42 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 12:18:42 INFO Executor: Finished task 0.0 in stage 62.0 (TID 180). 1197 bytes result sent to driver
18/02/28 12:18:42 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 180) in 6 ms on localhost (executor driver) (1/1)
18/02/28 12:18:42 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
18/02/28 12:18:42 INFO DAGScheduler: ResultStage 62 (collect at utils.scala:211) finished in 0.006 s
18/02/28 12:18:42 INFO DAGScheduler: Job 36 finished: collect at utils.scala:211, took 0.010329 s
18/02/28 12:18:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:18:50 INFO SparkSqlParser: Parsing command: SELECT * FROM spark_fao LIMIT 1000
18/02/28 12:18:50 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 12:18:50 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 12:18:50 INFO FileSourceStrategy: Output Data Schema: struct<year: int, production_area: int, country: string, iso: string, source: string ... 8 more fields>
18/02/28 12:18:50 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 12:18:50 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 282.5 KB, free 356.3 MB)
18/02/28 12:18:50 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 24.1 KB, free 356.3 MB)
18/02/28 12:18:50 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 127.0.0.1:60157 (size: 24.1 KB, free: 363.0 MB)
18/02/28 12:18:50 INFO SparkContext: Created broadcast 88 from collect at utils.scala:211
18/02/28 12:18:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 12:18:50 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 12:18:50 INFO DAGScheduler: Got job 37 (collect at utils.scala:211) with 1 output partitions
18/02/28 12:18:50 INFO DAGScheduler: Final stage: ResultStage 63 (collect at utils.scala:211)
18/02/28 12:18:50 INFO DAGScheduler: Parents of final stage: List()
18/02/28 12:18:50 INFO DAGScheduler: Missing parents: List()
18/02/28 12:18:50 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[203] at collect at utils.scala:211), which has no missing parents
18/02/28 12:18:50 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 11.6 KB, free 356.3 MB)
18/02/28 12:18:50 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 6.8 KB, free 356.3 MB)
18/02/28 12:18:50 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 127.0.0.1:60157 (size: 6.8 KB, free: 363.0 MB)
18/02/28 12:18:50 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1006
18/02/28 12:18:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[203] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 12:18:50 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks
18/02/28 12:18:50 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 181, localhost, executor driver, partition 0, PROCESS_LOCAL, 6775 bytes)
18/02/28 12:18:50 INFO Executor: Running task 0.0 in stage 63.0 (TID 181)
18/02/28 12:18:50 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 12:18:50 INFO Executor: Finished task 0.0 in stage 63.0 (TID 181). 1607 bytes result sent to driver
18/02/28 12:18:50 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 181) in 11 ms on localhost (executor driver) (1/1)
18/02/28 12:18:50 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
18/02/28 12:18:50 INFO DAGScheduler: ResultStage 63 (collect at utils.scala:211) finished in 0.011 s
18/02/28 12:18:50 INFO DAGScheduler: Job 37 finished: collect at utils.scala:211, took 0.014312 s
18/02/28 12:19:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:19:24 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:19:24 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:19:24 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:19:24 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:19:24 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:19:25 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:19:25 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:19:25 INFO CodeGenerator: Code generated in 4.414058 ms
18/02/28 12:19:25 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 12:19:25 INFO DAGScheduler: Got job 38 (collect at utils.scala:58) with 4 output partitions
18/02/28 12:19:25 INFO DAGScheduler: Final stage: ResultStage 64 (collect at utils.scala:58)
18/02/28 12:19:25 INFO DAGScheduler: Parents of final stage: List()
18/02/28 12:19:25 INFO DAGScheduler: Missing parents: List()
18/02/28 12:19:25 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[208] at map at utils.scala:55), which has no missing parents
18/02/28 12:19:25 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 8.4 KB, free 356.2 MB)
18/02/28 12:19:25 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 4.0 KB, free 356.2 MB)
18/02/28 12:19:25 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 127.0.0.1:60157 (size: 4.0 KB, free: 363.0 MB)
18/02/28 12:19:25 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1006
18/02/28 12:19:25 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 64 (MapPartitionsRDD[208] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 12:19:25 INFO TaskSchedulerImpl: Adding task set 64.0 with 4 tasks
18/02/28 12:19:25 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 182, localhost, executor driver, partition 0, PROCESS_LOCAL, 5255 bytes)
18/02/28 12:19:25 INFO TaskSetManager: Starting task 1.0 in stage 64.0 (TID 183, localhost, executor driver, partition 1, PROCESS_LOCAL, 5295 bytes)
18/02/28 12:19:25 INFO TaskSetManager: Starting task 2.0 in stage 64.0 (TID 184, localhost, executor driver, partition 2, PROCESS_LOCAL, 5295 bytes)
18/02/28 12:19:25 INFO TaskSetManager: Starting task 3.0 in stage 64.0 (TID 185, localhost, executor driver, partition 3, PROCESS_LOCAL, 5271 bytes)
18/02/28 12:19:25 INFO Executor: Running task 0.0 in stage 64.0 (TID 182)
18/02/28 12:19:25 INFO Executor: Running task 1.0 in stage 64.0 (TID 183)
18/02/28 12:19:25 INFO Executor: Running task 3.0 in stage 64.0 (TID 185)
18/02/28 12:19:25 INFO Executor: Finished task 3.0 in stage 64.0 (TID 185). 1007 bytes result sent to driver
18/02/28 12:19:25 INFO Executor: Running task 2.0 in stage 64.0 (TID 184)
18/02/28 12:19:25 INFO Executor: Finished task 2.0 in stage 64.0 (TID 184). 1024 bytes result sent to driver
18/02/28 12:19:25 INFO Executor: Finished task 0.0 in stage 64.0 (TID 182). 1048 bytes result sent to driver
18/02/28 12:19:25 INFO TaskSetManager: Finished task 3.0 in stage 64.0 (TID 185) in 23 ms on localhost (executor driver) (1/4)
18/02/28 12:19:25 INFO TaskSetManager: Finished task 2.0 in stage 64.0 (TID 184) in 23 ms on localhost (executor driver) (2/4)
18/02/28 12:19:25 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 182) in 26 ms on localhost (executor driver) (3/4)
18/02/28 12:19:25 INFO Executor: Finished task 1.0 in stage 64.0 (TID 183). 1110 bytes result sent to driver
18/02/28 12:19:25 INFO TaskSetManager: Finished task 1.0 in stage 64.0 (TID 183) in 26 ms on localhost (executor driver) (4/4)
18/02/28 12:19:25 INFO DAGScheduler: ResultStage 64 (collect at utils.scala:58) finished in 0.028 s
18/02/28 12:19:25 INFO DAGScheduler: Job 38 finished: collect at utils.scala:58, took 0.032041 s
18/02/28 12:19:25 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
18/02/28 12:19:25 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 127.0.0.1:60157 in memory (size: 6.8 KB, free: 363.0 MB)
18/02/28 12:19:25 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 127.0.0.1:60157 in memory (size: 6.8 KB, free: 363.0 MB)
18/02/28 12:19:25 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 127.0.0.1:60157 in memory (size: 6.8 KB, free: 363.0 MB)
18/02/28 12:19:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:19:25 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 127.0.0.1:60157 in memory (size: 12.6 KB, free: 363.0 MB)
18/02/28 12:19:25 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 127.0.0.1:60157 in memory (size: 12.6 KB, free: 363.0 MB)
18/02/28 12:19:25 INFO MapPartitionsRDD: Removing RDD 110 from persistence list
18/02/28 12:19:25 INFO BlockManager: Removing RDD 110
18/02/28 12:19:25 INFO MapPartitionsRDD: Removing RDD 142 from persistence list
18/02/28 12:19:25 INFO BlockManager: Removing RDD 142
18/02/28 12:19:25 INFO MapPartitionsRDD: Removing RDD 184 from persistence list
18/02/28 12:19:25 INFO BlockManager: Removing RDD 184
18/02/28 12:19:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:19:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:19:25 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:19:25 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:19:25 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:19:25 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:19:25 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:19:25 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:19:25 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:19:25 INFO SparkSqlParser: Parsing command: spark_fao
18/02/28 12:19:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:19:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao` AS `zzz31`
WHERE (0 = 1)
18/02/28 12:19:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:19:25 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:19:25 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:19:25 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:19:25 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:19:25 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:19:25 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:19:25 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:19:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:19:32 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_fao`
18/02/28 12:19:32 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:19:32 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:19:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:19:32 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_fao`
18/02/28 12:19:32 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:19:32 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:19:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:19:32 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_fao`
18/02/28 12:19:32 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:19:32 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:19:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:19:32 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_fao`
18/02/28 12:19:32 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:19:32 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:19:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:19:32 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_fao`
18/02/28 12:19:32 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:19:32 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:19:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:19:32 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_fao`
LIMIT 1000
18/02/28 12:19:32 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:19:32 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:19:32 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 12:19:32 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 12:19:32 INFO FileSourceStrategy: Output Data Schema: struct<>
18/02/28 12:19:32 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 12:19:32 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 282.5 KB, free 358.8 MB)
18/02/28 12:19:32 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 24.1 KB, free 358.8 MB)
18/02/28 12:19:32 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 127.0.0.1:60157 (size: 24.1 KB, free: 365.7 MB)
18/02/28 12:19:32 INFO SparkContext: Created broadcast 91 from collect at utils.scala:211
18/02/28 12:19:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 12:19:32 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 12:19:32 INFO DAGScheduler: Registering RDD 211 (collect at utils.scala:211)
18/02/28 12:19:32 INFO DAGScheduler: Got job 39 (collect at utils.scala:211) with 1 output partitions
18/02/28 12:19:32 INFO DAGScheduler: Final stage: ResultStage 66 (collect at utils.scala:211)
18/02/28 12:19:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 65)
18/02/28 12:19:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 65)
18/02/28 12:19:32 INFO DAGScheduler: Submitting ShuffleMapStage 65 (MapPartitionsRDD[211] at collect at utils.scala:211), which has no missing parents
18/02/28 12:19:32 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 13.9 KB, free 358.8 MB)
18/02/28 12:19:32 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 7.8 KB, free 358.8 MB)
18/02/28 12:19:32 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 127.0.0.1:60157 (size: 7.8 KB, free: 365.7 MB)
18/02/28 12:19:32 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1006
18/02/28 12:19:32 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 65 (MapPartitionsRDD[211] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 12:19:32 INFO TaskSchedulerImpl: Adding task set 65.0 with 4 tasks
18/02/28 12:19:32 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 186, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 12:19:32 INFO TaskSetManager: Starting task 1.0 in stage 65.0 (TID 187, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 12:19:32 INFO TaskSetManager: Starting task 2.0 in stage 65.0 (TID 188, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 12:19:32 INFO TaskSetManager: Starting task 3.0 in stage 65.0 (TID 189, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 12:19:32 INFO Executor: Running task 0.0 in stage 65.0 (TID 186)
18/02/28 12:19:32 INFO Executor: Running task 1.0 in stage 65.0 (TID 187)
18/02/28 12:19:32 INFO Executor: Running task 2.0 in stage 65.0 (TID 188)
18/02/28 12:19:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 12:19:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 12:19:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 12:19:32 INFO Executor: Running task 3.0 in stage 65.0 (TID 189)
18/02/28 12:19:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 12:19:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 12:19:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 12:19:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 12:19:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 12:19:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 12:19:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 12:19:33 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 127.0.0.1:60157 in memory (size: 4.0 KB, free: 365.7 MB)
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 12:19:33 INFO ContextCleaner: Cleaned accumulator 2020
18/02/28 12:19:33 INFO ContextCleaner: Cleaned accumulator 1995
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 12:19:33 ERROR Executor: Exception in task 3.0 in stage 65.0 (TID 189)
java.io.FileNotFoundException: C:\Users\JC\AppData\Local\Temp\blockmgr-63cb5e29-4480-4914-8723-855010b4870c\2d\shuffle_26_3_0.index.9c27700a-08e9-47e4-a8b6-62bbefb67f18 (The system cannot find the path specified)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.writeIndexFileAndCommit(IndexShuffleBlockResolver.scala:144)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:164)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
18/02/28 12:19:33 WARN TaskSetManager: Lost task 3.0 in stage 65.0 (TID 189, localhost, executor driver): java.io.FileNotFoundException: C:\Users\JC\AppData\Local\Temp\blockmgr-63cb5e29-4480-4914-8723-855010b4870c\2d\shuffle_26_3_0.index.9c27700a-08e9-47e4-a8b6-62bbefb67f18 (The system cannot find the path specified)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.writeIndexFileAndCommit(IndexShuffleBlockResolver.scala:144)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:164)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

18/02/28 12:19:33 ERROR TaskSetManager: Task 3 in stage 65.0 failed 1 times; aborting job
18/02/28 12:19:33 INFO TaskSchedulerImpl: Cancelling stage 65
18/02/28 12:19:33 INFO TaskSchedulerImpl: Stage 65 was cancelled
18/02/28 12:19:33 INFO DAGScheduler: ShuffleMapStage 65 (collect at utils.scala:211) failed in 0.289 s due to Job aborted due to stage failure: Task 3 in stage 65.0 failed 1 times, most recent failure: Lost task 3.0 in stage 65.0 (TID 189, localhost, executor driver): java.io.FileNotFoundException: C:\Users\JC\AppData\Local\Temp\blockmgr-63cb5e29-4480-4914-8723-855010b4870c\2d\shuffle_26_3_0.index.9c27700a-08e9-47e4-a8b6-62bbefb67f18 (The system cannot find the path specified)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.writeIndexFileAndCommit(IndexShuffleBlockResolver.scala:144)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:164)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

Driver stacktrace:
18/02/28 12:19:33 INFO DAGScheduler: Job 39 failed: collect at utils.scala:211, took 0.292042 s
18/02/28 12:19:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 12:19:33 INFO Executor: Executor is trying to kill task 0.0 in stage 65.0 (TID 186), reason: stage cancelled
18/02/28 12:19:33 INFO Executor: Executor is trying to kill task 1.0 in stage 65.0 (TID 187), reason: stage cancelled
18/02/28 12:19:33 INFO Executor: Executor is trying to kill task 2.0 in stage 65.0 (TID 188), reason: stage cancelled
18/02/28 12:19:33 INFO Executor: Executor killed task 2.0 in stage 65.0 (TID 188), reason: stage cancelled
18/02/28 12:19:33 INFO Executor: Executor killed task 0.0 in stage 65.0 (TID 186), reason: stage cancelled
18/02/28 12:19:33 INFO Executor: Executor killed task 1.0 in stage 65.0 (TID 187), reason: stage cancelled
18/02/28 12:19:33 WARN TaskSetManager: Lost task 2.0 in stage 65.0 (TID 188, localhost, executor driver): TaskKilled (stage cancelled)
18/02/28 12:19:33 WARN TaskSetManager: Lost task 0.0 in stage 65.0 (TID 186, localhost, executor driver): TaskKilled (stage cancelled)
18/02/28 12:19:33 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
18/02/28 12:19:33 WARN TaskSetManager: Lost task 1.0 in stage 65.0 (TID 187, localhost, executor driver): TaskKilled (stage cancelled)
18/02/28 12:19:33 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
18/02/28 12:19:48 INFO SparkContext: Invoking stop() from shutdown hook
18/02/28 12:19:48 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
18/02/28 12:19:48 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/02/28 12:19:48 INFO MemoryStore: MemoryStore cleared
18/02/28 12:19:48 INFO BlockManager: BlockManager stopped
18/02/28 12:19:48 INFO BlockManagerMaster: BlockManagerMaster stopped
18/02/28 12:19:48 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/02/28 12:19:48 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-f860167a-2762-4d40-a3be-220f7f163c30\userFiles-61ac4d8e-8acc-485c-a2d7-c9dc9bddb597
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-f860167a-2762-4d40-a3be-220f7f163c30\userFiles-61ac4d8e-8acc-485c-a2d7-c9dc9bddb597
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1937)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1936)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 12:19:48 INFO SparkContext: Successfully stopped SparkContext
18/02/28 12:19:48 INFO ShutdownHookManager: Shutdown hook called
18/02/28 12:19:48 INFO ShutdownHookManager: Deleting directory C:\Users\JC\AppData\Local\Temp\spark-f860167a-2762-4d40-a3be-220f7f163c30
18/02/28 12:19:48 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-f860167a-2762-4d40-a3be-220f7f163c30
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-f860167a-2762-4d40-a3be-220f7f163c30
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 12:19:48 INFO ShutdownHookManager: Deleting directory C:\Users\JC\AppData\Local\Temp\spark-f860167a-2762-4d40-a3be-220f7f163c30\userFiles-61ac4d8e-8acc-485c-a2d7-c9dc9bddb597
18/02/28 12:19:48 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-f860167a-2762-4d40-a3be-220f7f163c30\userFiles-61ac4d8e-8acc-485c-a2d7-c9dc9bddb597
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-f860167a-2762-4d40-a3be-220f7f163c30\userFiles-61ac4d8e-8acc-485c-a2d7-c9dc9bddb597
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 12:19:59 INFO SparkContext: Running Spark version 2.2.0
18/02/28 12:20:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/02/28 12:20:00 INFO SparkContext: Submitted application: sparklyr
18/02/28 12:20:00 INFO SecurityManager: Changing view acls to: JC
18/02/28 12:20:00 INFO SecurityManager: Changing modify acls to: JC
18/02/28 12:20:00 INFO SecurityManager: Changing view acls groups to: 
18/02/28 12:20:00 INFO SecurityManager: Changing modify acls groups to: 
18/02/28 12:20:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(JC); groups with view permissions: Set(); users  with modify permissions: Set(JC); groups with modify permissions: Set()
18/02/28 12:20:00 INFO Utils: Successfully started service 'sparkDriver' on port 60517.
18/02/28 12:20:00 INFO SparkEnv: Registering MapOutputTracker
18/02/28 12:20:00 INFO SparkEnv: Registering BlockManagerMaster
18/02/28 12:20:00 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/02/28 12:20:00 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/02/28 12:20:00 INFO DiskBlockManager: Created local directory at C:\Users\JC\AppData\Local\Temp\blockmgr-96705a85-1596-4687-9493-975dc6c15972
18/02/28 12:20:00 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/02/28 12:20:00 INFO SparkEnv: Registering OutputCommitCoordinator
18/02/28 12:20:00 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/02/28 12:20:00 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
18/02/28 12:20:00 INFO SparkContext: Added JAR file:/C:/Users/JC/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:60517/jars/sparklyr-2.2-2.11.jar with timestamp 1519849200814
18/02/28 12:20:00 INFO Executor: Starting executor ID driver on host localhost
18/02/28 12:20:00 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60538.
18/02/28 12:20:00 INFO NettyBlockTransferService: Server created on 127.0.0.1:60538
18/02/28 12:20:00 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/02/28 12:20:00 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 60538, None)
18/02/28 12:20:00 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:60538 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 60538, None)
18/02/28 12:20:00 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 60538, None)
18/02/28 12:20:00 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 60538, None)
18/02/28 12:20:01 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/02/28 12:20:01 INFO SharedState: loading hive config file: file:/C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
18/02/28 12:20:01 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:\Users\JC\AppData\Local\spark\spark-2.2.0-bin-hadoop2.7\tmp\hive') to the value of spark.sql.warehouse.dir ('C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive').
18/02/28 12:20:01 INFO SharedState: Warehouse path is 'C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive'.
18/02/28 12:20:02 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
18/02/28 12:20:03 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
18/02/28 12:20:03 INFO ObjectStore: ObjectStore, initialize called
18/02/28 12:20:03 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
18/02/28 12:20:03 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
18/02/28 12:20:04 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
18/02/28 12:20:05 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 12:20:05 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 12:20:05 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 12:20:05 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 12:20:06 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
18/02/28 12:20:06 INFO ObjectStore: Initialized ObjectStore
18/02/28 12:20:06 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
18/02/28 12:20:06 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
18/02/28 12:20:06 INFO HiveMetaStore: Added admin role in metastore
18/02/28 12:20:06 INFO HiveMetaStore: Added public role in metastore
18/02/28 12:20:06 INFO HiveMetaStore: No user is added in admin role, since config is empty
18/02/28 12:20:06 INFO HiveMetaStore: 0: get_all_databases
18/02/28 12:20:06 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_all_databases	
18/02/28 12:20:06 INFO HiveMetaStore: 0: get_functions: db=default pat=*
18/02/28 12:20:06 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
18/02/28 12:20:06 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 12:20:06 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/Temp/d4295b21-3693-464f-8210-9d224fef1d34_resources
18/02/28 12:20:06 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/d4295b21-3693-464f-8210-9d224fef1d34
18/02/28 12:20:06 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/d4295b21-3693-464f-8210-9d224fef1d34
18/02/28 12:20:06 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/d4295b21-3693-464f-8210-9d224fef1d34/_tmp_space.db
18/02/28 12:20:06 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive
18/02/28 12:20:06 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:20:06 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:20:06 INFO HiveMetaStore: 0: get_database: global_temp
18/02/28 12:20:06 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: global_temp	
18/02/28 12:20:06 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
18/02/28 12:20:07 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/Temp/3d5b1e33-d648-45ba-8ce7-e72d857c4bda_resources
18/02/28 12:20:07 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/3d5b1e33-d648-45ba-8ce7-e72d857c4bda
18/02/28 12:20:07 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/3d5b1e33-d648-45ba-8ce7-e72d857c4bda
18/02/28 12:20:07 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/3d5b1e33-d648-45ba-8ce7-e72d857c4bda/_tmp_space.db
18/02/28 12:20:07 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive
18/02/28 12:20:07 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
18/02/28 12:20:07 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:20:08 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:20:08 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:20:08 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:20:08 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:20:08 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:20:08 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:20:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:20:18 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:20:18 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:20:18 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:20:18 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:20:18 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:20:18 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:20:18 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:20:18 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 12:20:18 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
18/02/28 12:20:18 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
18/02/28 12:20:18 INFO DAGScheduler: Parents of final stage: List()
18/02/28 12:20:18 INFO DAGScheduler: Missing parents: List()
18/02/28 12:20:18 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55), which has no missing parents
18/02/28 12:20:18 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
18/02/28 12:20:18 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
18/02/28 12:20:18 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:60538 (size: 3.4 KB, free: 366.3 MB)
18/02/28 12:20:18 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
18/02/28 12:20:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0))
18/02/28 12:20:18 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/02/28 12:20:18 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 12:20:18 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/02/28 12:20:18 INFO Executor: Fetching spark://127.0.0.1:60517/jars/sparklyr-2.2-2.11.jar with timestamp 1519849200814
18/02/28 12:20:18 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:60517 after 21 ms (0 ms spent in bootstraps)
18/02/28 12:20:18 INFO Utils: Fetching spark://127.0.0.1:60517/jars/sparklyr-2.2-2.11.jar to C:\Users\JC\AppData\Local\Temp\spark-eee94776-518e-4420-8b75-1d645ec05192\userFiles-8cec39bc-0a30-46f9-8235-ee9808956e63\fetchFileTemp8416609559415481628.tmp
18/02/28 12:20:18 INFO Executor: Adding file:/C:/Users/JC/AppData/Local/Temp/spark-eee94776-518e-4420-8b75-1d645ec05192/userFiles-8cec39bc-0a30-46f9-8235-ee9808956e63/sparklyr-2.2-2.11.jar to class loader
18/02/28 12:20:19 INFO CodeGenerator: Code generated in 259.660028 ms
18/02/28 12:20:19 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1056 bytes result sent to driver
18/02/28 12:20:19 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 645 ms on localhost (executor driver) (1/1)
18/02/28 12:20:19 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.667 s
18/02/28 12:20:19 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/02/28 12:20:19 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.812983 s
18/02/28 12:20:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:20:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:20:19 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:20:19 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:20:19 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:20:19 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:20:19 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:20:19 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:20:19 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:20:19 INFO SparkSqlParser: Parsing command: spark_fao
18/02/28 12:20:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:20:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao` AS `zzz32`
WHERE (0 = 1)
18/02/28 12:20:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:20:19 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:20:19 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:20:19 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:20:19 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:20:19 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:20:19 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:20:19 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:20:19 INFO CodeGenerator: Code generated in 10.540777 ms
18/02/28 12:20:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:20:32 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:20:32 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:20:32 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:20:32 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:20:32 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:20:32 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:20:32 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:20:32 INFO CodeGenerator: Code generated in 8.975863 ms
18/02/28 12:20:32 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 12:20:32 INFO DAGScheduler: Got job 1 (collect at utils.scala:58) with 1 output partitions
18/02/28 12:20:32 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:58)
18/02/28 12:20:32 INFO DAGScheduler: Parents of final stage: List()
18/02/28 12:20:32 INFO DAGScheduler: Missing parents: List()
18/02/28 12:20:32 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at map at utils.scala:55), which has no missing parents
18/02/28 12:20:32 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.3 KB, free 366.3 MB)
18/02/28 12:20:32 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.5 KB, free 366.3 MB)
18/02/28 12:20:32 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:60538 (size: 3.5 KB, free: 366.3 MB)
18/02/28 12:20:32 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
18/02/28 12:20:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0))
18/02/28 12:20:32 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
18/02/28 12:20:32 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5019 bytes)
18/02/28 12:20:32 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
18/02/28 12:20:32 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 896 bytes result sent to driver
18/02/28 12:20:32 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 7 ms on localhost (executor driver) (1/1)
18/02/28 12:20:32 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/02/28 12:20:32 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:58) finished in 0.007 s
18/02/28 12:20:32 INFO DAGScheduler: Job 1 finished: collect at utils.scala:58, took 0.016716 s
18/02/28 12:20:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:20:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:20:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:20:32 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:20:32 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:20:32 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:20:32 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:20:32 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:20:32 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:20:32 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:20:32 INFO SparkSqlParser: Parsing command: spark_fao
18/02/28 12:20:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:20:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao` AS `zzz33`
WHERE (0 = 1)
18/02/28 12:20:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:20:32 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:20:32 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:20:32 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:20:32 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:20:32 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:20:32 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:20:32 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:20:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:20:38 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:20:38 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:20:38 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:20:38 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:20:38 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:20:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:20:38 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:20:38 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 12:20:38 INFO DAGScheduler: Got job 2 (collect at utils.scala:58) with 1 output partitions
18/02/28 12:20:38 INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:58)
18/02/28 12:20:38 INFO DAGScheduler: Parents of final stage: List()
18/02/28 12:20:38 INFO DAGScheduler: Missing parents: List()
18/02/28 12:20:38 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at map at utils.scala:55), which has no missing parents
18/02/28 12:20:38 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 6.3 KB, free 366.3 MB)
18/02/28 12:20:38 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.5 KB, free 366.3 MB)
18/02/28 12:20:38 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:60538 (size: 3.5 KB, free: 366.3 MB)
18/02/28 12:20:38 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
18/02/28 12:20:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0))
18/02/28 12:20:38 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
18/02/28 12:20:38 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5019 bytes)
18/02/28 12:20:38 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
18/02/28 12:20:38 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 939 bytes result sent to driver
18/02/28 12:20:38 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 9 ms on localhost (executor driver) (1/1)
18/02/28 12:20:38 INFO DAGScheduler: ResultStage 2 (collect at utils.scala:58) finished in 0.011 s
18/02/28 12:20:38 INFO DAGScheduler: Job 2 finished: collect at utils.scala:58, took 0.019337 s
18/02/28 12:20:38 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/02/28 12:20:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:20:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:20:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:20:38 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:20:38 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:20:38 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:20:38 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:20:38 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:20:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:20:38 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:20:38 INFO SparkSqlParser: Parsing command: spark_fao
18/02/28 12:20:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:20:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao` AS `zzz34`
WHERE (0 = 1)
18/02/28 12:20:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:20:39 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:20:39 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:20:39 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:20:39 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:20:39 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:20:39 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:20:39 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:20:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:20:52 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_fao`
18/02/28 12:20:52 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:20:52 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:20:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:20:52 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_fao`
18/02/28 12:20:52 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:20:52 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:20:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:20:52 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_fao`
18/02/28 12:20:52 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:20:52 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:20:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:20:52 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_fao`
18/02/28 12:20:52 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:20:52 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:20:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:20:52 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_fao`
18/02/28 12:20:52 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:20:52 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:20:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:20:52 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_fao`
LIMIT 1000
18/02/28 12:20:52 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:20:52 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:20:52 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 12:20:52 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 12:20:52 INFO FileSourceStrategy: Output Data Schema: struct<>
18/02/28 12:20:52 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 12:20:52 INFO CodeGenerator: Code generated in 19.402392 ms
18/02/28 12:20:52 INFO CodeGenerator: Code generated in 11.196997 ms
18/02/28 12:20:52 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 282.5 KB, free 366.0 MB)
18/02/28 12:20:52 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 24.1 KB, free 366.0 MB)
18/02/28 12:20:52 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:60538 (size: 24.1 KB, free: 366.3 MB)
18/02/28 12:20:52 INFO SparkContext: Created broadcast 3 from collect at utils.scala:211
18/02/28 12:20:52 INFO ContextCleaner: Cleaned accumulator 99
18/02/28 12:20:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 12:20:52 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 12:20:52 INFO DAGScheduler: Registering RDD 17 (collect at utils.scala:211)
18/02/28 12:20:52 INFO DAGScheduler: Got job 3 (collect at utils.scala:211) with 1 output partitions
18/02/28 12:20:52 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:211)
18/02/28 12:20:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
18/02/28 12:20:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
18/02/28 12:20:52 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[17] at collect at utils.scala:211), which has no missing parents
18/02/28 12:20:52 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:60538 in memory (size: 3.5 KB, free: 366.3 MB)
18/02/28 12:20:52 INFO ContextCleaner: Cleaned accumulator 74
18/02/28 12:20:52 INFO ContextCleaner: Cleaned accumulator 49
18/02/28 12:20:52 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.9 KB, free 366.0 MB)
18/02/28 12:20:52 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.8 KB, free 366.0 MB)
18/02/28 12:20:52 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:60538 (size: 7.8 KB, free: 366.3 MB)
18/02/28 12:20:52 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
18/02/28 12:20:52 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[17] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 12:20:52 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks
18/02/28 12:20:52 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 12:20:52 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 4, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 12:20:52 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:60538 in memory (size: 3.5 KB, free: 366.3 MB)
18/02/28 12:20:52 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 5, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 12:20:52 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 6, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 12:20:52 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
18/02/28 12:20:52 INFO Executor: Running task 2.0 in stage 3.0 (TID 5)
18/02/28 12:20:52 INFO ContextCleaner: Cleaned accumulator 0
18/02/28 12:20:52 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:60538 in memory (size: 3.4 KB, free: 366.3 MB)
18/02/28 12:20:52 INFO Executor: Running task 3.0 in stage 3.0 (TID 6)
18/02/28 12:20:52 INFO Executor: Running task 1.0 in stage 3.0 (TID 4)
18/02/28 12:20:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 12:20:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 12:20:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 12:20:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 12:20:52 INFO CodeGenerator: Code generated in 8.145803 ms
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 12:20:53 INFO Executor: Finished task 3.0 in stage 3.0 (TID 6). 1628 bytes result sent to driver
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 12:20:53 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 6) in 995 ms on localhost (executor driver) (1/4)
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 12:20:53 INFO Executor: Finished task 2.0 in stage 3.0 (TID 5). 1628 bytes result sent to driver
18/02/28 12:20:53 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 5) in 1108 ms on localhost (executor driver) (2/4)
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 12:20:53 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 12:20:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 12:20:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 12:20:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 12:20:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 12:20:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 12:20:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 12:20:54 INFO Executor: Finished task 1.0 in stage 3.0 (TID 4). 1585 bytes result sent to driver
18/02/28 12:20:54 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 4) in 1255 ms on localhost (executor driver) (3/4)
18/02/28 12:20:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 12:20:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 12:20:54 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1628 bytes result sent to driver
18/02/28 12:20:54 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 1333 ms on localhost (executor driver) (4/4)
18/02/28 12:20:54 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:211) finished in 1.334 s
18/02/28 12:20:54 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/02/28 12:20:54 INFO DAGScheduler: looking for newly runnable stages
18/02/28 12:20:54 INFO DAGScheduler: running: Set()
18/02/28 12:20:54 INFO DAGScheduler: waiting: Set(ResultStage 4)
18/02/28 12:20:54 INFO DAGScheduler: failed: Set()
18/02/28 12:20:54 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[20] at collect at utils.scala:211), which has no missing parents
18/02/28 12:20:54 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 6.9 KB, free 366.0 MB)
18/02/28 12:20:54 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.0 MB)
18/02/28 12:20:54 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:60538 (size: 3.7 KB, free: 366.3 MB)
18/02/28 12:20:54 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
18/02/28 12:20:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 12:20:54 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
18/02/28 12:20:54 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 7, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 12:20:54 INFO Executor: Running task 0.0 in stage 4.0 (TID 7)
18/02/28 12:20:54 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:20:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
18/02/28 12:20:54 INFO Executor: Finished task 0.0 in stage 4.0 (TID 7). 1514 bytes result sent to driver
18/02/28 12:20:54 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 7) in 40 ms on localhost (executor driver) (1/1)
18/02/28 12:20:54 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:211) finished in 0.041 s
18/02/28 12:20:54 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/02/28 12:20:54 INFO DAGScheduler: Job 3 finished: collect at utils.scala:211, took 1.452232 s
18/02/28 12:20:54 INFO CodeGenerator: Code generated in 7.682464 ms
18/02/28 12:20:58 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:20:58 INFO SparkSqlParser: Parsing command: SELECT `year`, SUM(`quantity`) / 1000000.0 AS `sum(quantity)/1e+06`
FROM `spark_fao`
GROUP BY `year`
18/02/28 12:20:58 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:20:58 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:20:58 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 12:20:58 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 12:20:58 INFO FileSourceStrategy: Output Data Schema: struct<year: string, quantity: string>
18/02/28 12:20:58 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 12:20:58 INFO CodeGenerator: Code generated in 32.9993 ms
18/02/28 12:20:59 INFO CodeGenerator: Code generated in 52.674617 ms
18/02/28 12:20:59 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 282.5 KB, free 365.7 MB)
18/02/28 12:20:59 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.7 MB)
18/02/28 12:20:59 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:60538 (size: 24.1 KB, free: 366.2 MB)
18/02/28 12:20:59 INFO SparkContext: Created broadcast 6 from collect at utils.scala:211
18/02/28 12:20:59 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 12:20:59 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 12:20:59 INFO DAGScheduler: Registering RDD 23 (collect at utils.scala:211)
18/02/28 12:20:59 INFO DAGScheduler: Got job 4 (collect at utils.scala:211) with 4 output partitions
18/02/28 12:20:59 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:211)
18/02/28 12:20:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
18/02/28 12:20:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
18/02/28 12:20:59 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[23] at collect at utils.scala:211), which has no missing parents
18/02/28 12:20:59 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 28.9 KB, free 365.6 MB)
18/02/28 12:20:59 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 14.2 KB, free 365.6 MB)
18/02/28 12:20:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:60538 (size: 14.2 KB, free: 366.2 MB)
18/02/28 12:20:59 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
18/02/28 12:20:59 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[23] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 12:20:59 INFO TaskSchedulerImpl: Adding task set 5.0 with 4 tasks
18/02/28 12:20:59 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 12:20:59 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 9, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 12:20:59 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 10, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 12:20:59 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 11, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 12:20:59 INFO Executor: Running task 1.0 in stage 5.0 (TID 9)
18/02/28 12:20:59 INFO Executor: Running task 0.0 in stage 5.0 (TID 8)
18/02/28 12:20:59 INFO Executor: Running task 2.0 in stage 5.0 (TID 10)
18/02/28 12:20:59 INFO Executor: Running task 3.0 in stage 5.0 (TID 11)
18/02/28 12:20:59 INFO CodeGenerator: Code generated in 8.882419 ms
18/02/28 12:20:59 INFO CodeGenerator: Code generated in 9.084821 ms
18/02/28 12:20:59 INFO CodeGenerator: Code generated in 10.503047 ms
18/02/28 12:20:59 INFO CodeGenerator: Code generated in 16.216851 ms
18/02/28 12:20:59 INFO CodeGenerator: Code generated in 8.789681 ms
18/02/28 12:20:59 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 12:20:59 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 12:20:59 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 12:20:59 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 12:20:59 INFO CodeGenerator: Code generated in 30.78557 ms
18/02/28 12:20:59 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 12:20:59 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 12:20:59 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 12:20:59 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 12:20:59 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 12:20:59 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 12:20:59 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 12:20:59 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 12:20:59 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 12:20:59 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 12:20:59 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 12:20:59 INFO ContextCleaner: Cleaned accumulator 163
18/02/28 12:20:59 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:60538 in memory (size: 7.8 KB, free: 366.2 MB)
18/02/28 12:20:59 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:60538 in memory (size: 3.7 KB, free: 366.2 MB)
18/02/28 12:20:59 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 12:20:59 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 12:20:59 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 12:21:00 INFO Executor: Finished task 3.0 in stage 5.0 (TID 11). 2103 bytes result sent to driver
18/02/28 12:21:00 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 11) in 1204 ms on localhost (executor driver) (1/4)
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 12:21:00 INFO Executor: Finished task 2.0 in stage 5.0 (TID 10). 2060 bytes result sent to driver
18/02/28 12:21:00 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 10) in 1397 ms on localhost (executor driver) (2/4)
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 12:21:00 INFO Executor: Finished task 1.0 in stage 5.0 (TID 9). 2060 bytes result sent to driver
18/02/28 12:21:00 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 9) in 1549 ms on localhost (executor driver) (3/4)
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 12:21:00 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 12:21:00 INFO Executor: Finished task 0.0 in stage 5.0 (TID 8). 2060 bytes result sent to driver
18/02/28 12:21:00 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 8) in 1649 ms on localhost (executor driver) (4/4)
18/02/28 12:21:00 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:211) finished in 1.651 s
18/02/28 12:21:00 INFO DAGScheduler: looking for newly runnable stages
18/02/28 12:21:00 INFO DAGScheduler: running: Set()
18/02/28 12:21:00 INFO DAGScheduler: waiting: Set(ResultStage 6)
18/02/28 12:21:00 INFO DAGScheduler: failed: Set()
18/02/28 12:21:00 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[26] at collect at utils.scala:211), which has no missing parents
18/02/28 12:21:00 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 26.6 KB, free 365.6 MB)
18/02/28 12:21:00 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 13.1 KB, free 365.6 MB)
18/02/28 12:21:00 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/02/28 12:21:00 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:60538 (size: 13.1 KB, free: 366.2 MB)
18/02/28 12:21:00 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
18/02/28 12:21:00 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 12:21:00 INFO TaskSchedulerImpl: Adding task set 6.0 with 4 tasks
18/02/28 12:21:00 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 12, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 12:21:00 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 13, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 12:21:00 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 14, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 12:21:00 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 15, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 12:21:00 INFO Executor: Running task 0.0 in stage 6.0 (TID 12)
18/02/28 12:21:00 INFO Executor: Running task 1.0 in stage 6.0 (TID 13)
18/02/28 12:21:00 INFO Executor: Running task 2.0 in stage 6.0 (TID 14)
18/02/28 12:21:00 INFO Executor: Running task 3.0 in stage 6.0 (TID 15)
18/02/28 12:21:00 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:21:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 12:21:00 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:21:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 12:21:00 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:21:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
18/02/28 12:21:00 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:21:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 12:21:00 INFO Executor: Finished task 1.0 in stage 6.0 (TID 13). 61024 bytes result sent to driver
18/02/28 12:21:00 INFO Executor: Finished task 3.0 in stage 6.0 (TID 15). 70174 bytes result sent to driver
18/02/28 12:21:00 INFO Executor: Finished task 2.0 in stage 6.0 (TID 14). 57443 bytes result sent to driver
18/02/28 12:21:00 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 13) in 41 ms on localhost (executor driver) (1/4)
18/02/28 12:21:00 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 15) in 42 ms on localhost (executor driver) (2/4)
18/02/28 12:21:00 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 14) in 43 ms on localhost (executor driver) (3/4)
18/02/28 12:21:00 INFO Executor: Finished task 0.0 in stage 6.0 (TID 12). 54422 bytes result sent to driver
18/02/28 12:21:00 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 12) in 45 ms on localhost (executor driver) (4/4)
18/02/28 12:21:00 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:211) finished in 0.046 s
18/02/28 12:21:00 INFO DAGScheduler: Job 4 finished: collect at utils.scala:211, took 1.714870 s
18/02/28 12:21:00 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
18/02/28 12:21:00 INFO CodeGenerator: Code generated in 7.295996 ms
18/02/28 12:22:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:22:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao`
LIMIT 6
18/02/28 12:22:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:22:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao`
LIMIT 6
18/02/28 12:22:57 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 12:22:57 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 12:22:57 INFO FileSourceStrategy: Output Data Schema: struct<year: string, production_area: string, country: string, iso: string, source: string ... 8 more fields>
18/02/28 12:22:57 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 12:22:57 INFO CodeGenerator: Code generated in 5.714156 ms
18/02/28 12:22:57 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 282.5 KB, free 365.3 MB)
18/02/28 12:22:57 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.3 MB)
18/02/28 12:22:57 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:60538 (size: 24.1 KB, free: 366.2 MB)
18/02/28 12:22:57 INFO SparkContext: Created broadcast 9 from collect at utils.scala:211
18/02/28 12:22:57 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 12:22:57 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 12:22:57 INFO DAGScheduler: Got job 5 (collect at utils.scala:211) with 1 output partitions
18/02/28 12:22:57 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:211)
18/02/28 12:22:57 INFO DAGScheduler: Parents of final stage: List()
18/02/28 12:22:57 INFO DAGScheduler: Missing parents: List()
18/02/28 12:22:57 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[29] at collect at utils.scala:211), which has no missing parents
18/02/28 12:22:57 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 11.6 KB, free 365.3 MB)
18/02/28 12:22:57 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 6.8 KB, free 365.3 MB)
18/02/28 12:22:57 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:60538 (size: 6.8 KB, free: 366.2 MB)
18/02/28 12:22:57 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
18/02/28 12:22:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[29] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 12:22:57 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
18/02/28 12:22:57 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 6775 bytes)
18/02/28 12:22:57 INFO Executor: Running task 0.0 in stage 7.0 (TID 16)
18/02/28 12:22:57 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 12:22:57 INFO CodeGenerator: Code generated in 8.889119 ms
18/02/28 12:22:57 INFO Executor: Finished task 0.0 in stage 7.0 (TID 16). 1766 bytes result sent to driver
18/02/28 12:22:57 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 16) in 24 ms on localhost (executor driver) (1/1)
18/02/28 12:22:57 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
18/02/28 12:22:57 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:211) finished in 0.024 s
18/02/28 12:22:57 INFO DAGScheduler: Job 5 finished: collect at utils.scala:211, took 0.031351 s
18/02/28 12:22:57 INFO CodeGenerator: Code generated in 12.187497 ms
18/02/28 12:23:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:23:31 INFO SparkSqlParser: Parsing command: SELECT `year`, SUM(`quantity`) / 1000000.0 AS `sum(quantity)/1e+06`
FROM `spark_fao`
GROUP BY `year`
18/02/28 12:23:31 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:23:31 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:23:31 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 12:23:31 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 12:23:31 INFO FileSourceStrategy: Output Data Schema: struct<year: string, quantity: string>
18/02/28 12:23:31 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 12:23:31 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 282.5 KB, free 365.0 MB)
18/02/28 12:23:31 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.0 MB)
18/02/28 12:23:31 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:60538 (size: 24.1 KB, free: 366.2 MB)
18/02/28 12:23:31 INFO SparkContext: Created broadcast 11 from collect at utils.scala:211
18/02/28 12:23:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 12:23:31 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 12:23:31 INFO DAGScheduler: Registering RDD 32 (collect at utils.scala:211)
18/02/28 12:23:31 INFO DAGScheduler: Got job 6 (collect at utils.scala:211) with 4 output partitions
18/02/28 12:23:31 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:211)
18/02/28 12:23:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
18/02/28 12:23:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
18/02/28 12:23:31 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[32] at collect at utils.scala:211), which has no missing parents
18/02/28 12:23:31 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 28.9 KB, free 365.0 MB)
18/02/28 12:23:31 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.2 KB, free 365.0 MB)
18/02/28 12:23:31 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:60538 (size: 14.2 KB, free: 366.2 MB)
18/02/28 12:23:31 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
18/02/28 12:23:31 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[32] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 12:23:31 INFO TaskSchedulerImpl: Adding task set 8.0 with 4 tasks
18/02/28 12:23:31 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 12:23:31 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 18, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 12:23:31 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 19, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 12:23:31 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 20, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 12:23:31 INFO Executor: Running task 0.0 in stage 8.0 (TID 17)
18/02/28 12:23:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 12:23:31 INFO ContextCleaner: Cleaned accumulator 256
18/02/28 12:23:31 INFO Executor: Running task 1.0 in stage 8.0 (TID 18)
18/02/28 12:23:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 12:23:32 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:60538 in memory (size: 14.2 KB, free: 366.2 MB)
18/02/28 12:23:32 INFO Executor: Running task 3.0 in stage 8.0 (TID 20)
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 12:23:32 INFO Executor: Running task 2.0 in stage 8.0 (TID 19)
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 12:23:32 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:60538 in memory (size: 13.1 KB, free: 366.2 MB)
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 12:23:32 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:60538 in memory (size: 6.8 KB, free: 366.2 MB)
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 12:23:32 INFO Executor: Finished task 3.0 in stage 8.0 (TID 20). 2103 bytes result sent to driver
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 12:23:32 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 20) in 854 ms on localhost (executor driver) (1/4)
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 12:23:32 INFO Executor: Finished task 2.0 in stage 8.0 (TID 19). 2060 bytes result sent to driver
18/02/28 12:23:32 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 19) in 971 ms on localhost (executor driver) (2/4)
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 12:23:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 12:23:33 INFO Executor: Finished task 1.0 in stage 8.0 (TID 18). 2103 bytes result sent to driver
18/02/28 12:23:33 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 18) in 1081 ms on localhost (executor driver) (3/4)
18/02/28 12:23:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 12:23:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 12:23:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 12:23:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 12:23:33 INFO Executor: Finished task 0.0 in stage 8.0 (TID 17). 2060 bytes result sent to driver
18/02/28 12:23:33 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 17) in 1229 ms on localhost (executor driver) (4/4)
18/02/28 12:23:33 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
18/02/28 12:23:33 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:211) finished in 1.230 s
18/02/28 12:23:33 INFO DAGScheduler: looking for newly runnable stages
18/02/28 12:23:33 INFO DAGScheduler: running: Set()
18/02/28 12:23:33 INFO DAGScheduler: waiting: Set(ResultStage 9)
18/02/28 12:23:33 INFO DAGScheduler: failed: Set()
18/02/28 12:23:33 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[35] at collect at utils.scala:211), which has no missing parents
18/02/28 12:23:33 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 26.6 KB, free 365.0 MB)
18/02/28 12:23:33 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 13.1 KB, free 365.0 MB)
18/02/28 12:23:33 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:60538 (size: 13.1 KB, free: 366.2 MB)
18/02/28 12:23:33 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
18/02/28 12:23:33 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 9 (MapPartitionsRDD[35] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 12:23:33 INFO TaskSchedulerImpl: Adding task set 9.0 with 4 tasks
18/02/28 12:23:33 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 21, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 12:23:33 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 22, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 12:23:33 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 23, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 12:23:33 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 24, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 12:23:33 INFO Executor: Running task 0.0 in stage 9.0 (TID 21)
18/02/28 12:23:33 INFO Executor: Running task 1.0 in stage 9.0 (TID 22)
18/02/28 12:23:33 INFO Executor: Running task 2.0 in stage 9.0 (TID 23)
18/02/28 12:23:33 INFO Executor: Running task 3.0 in stage 9.0 (TID 24)
18/02/28 12:23:33 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:23:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 12:23:33 INFO Executor: Finished task 0.0 in stage 9.0 (TID 21). 54422 bytes result sent to driver
18/02/28 12:23:33 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 21) in 17 ms on localhost (executor driver) (1/4)
18/02/28 12:23:33 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:23:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 12:23:33 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:23:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 12:23:33 INFO Executor: Finished task 3.0 in stage 9.0 (TID 24). 70174 bytes result sent to driver
18/02/28 12:23:33 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:23:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 12:23:33 INFO Executor: Finished task 1.0 in stage 9.0 (TID 22). 60895 bytes result sent to driver
18/02/28 12:23:33 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 24) in 46 ms on localhost (executor driver) (2/4)
18/02/28 12:23:33 INFO Executor: Finished task 2.0 in stage 9.0 (TID 23). 57443 bytes result sent to driver
18/02/28 12:23:33 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 22) in 49 ms on localhost (executor driver) (3/4)
18/02/28 12:23:33 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 23) in 50 ms on localhost (executor driver) (4/4)
18/02/28 12:23:33 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:211) finished in 0.051 s
18/02/28 12:23:33 INFO DAGScheduler: Job 6 finished: collect at utils.scala:211, took 1.297818 s
18/02/28 12:23:33 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
18/02/28 12:26:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:26:40 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:26:40 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:26:40 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:26:40 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:26:40 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:26:40 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:26:40 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:26:40 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 12:26:40 INFO DAGScheduler: Got job 7 (collect at utils.scala:58) with 1 output partitions
18/02/28 12:26:40 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:58)
18/02/28 12:26:40 INFO DAGScheduler: Parents of final stage: List()
18/02/28 12:26:40 INFO DAGScheduler: Missing parents: List()
18/02/28 12:26:40 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[40] at map at utils.scala:55), which has no missing parents
18/02/28 12:26:40 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 6.3 KB, free 365.0 MB)
18/02/28 12:26:40 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.5 KB, free 365.0 MB)
18/02/28 12:26:40 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:60538 (size: 3.5 KB, free: 366.2 MB)
18/02/28 12:26:40 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
18/02/28 12:26:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[40] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0))
18/02/28 12:26:40 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
18/02/28 12:26:40 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 5019 bytes)
18/02/28 12:26:40 INFO Executor: Running task 0.0 in stage 10.0 (TID 25)
18/02/28 12:26:40 INFO Executor: Finished task 0.0 in stage 10.0 (TID 25). 896 bytes result sent to driver
18/02/28 12:26:40 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 25) in 8 ms on localhost (executor driver) (1/1)
18/02/28 12:26:40 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:58) finished in 0.009 s
18/02/28 12:26:40 INFO DAGScheduler: Job 7 finished: collect at utils.scala:58, took 0.016360 s
18/02/28 12:26:40 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
18/02/28 12:26:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:26:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:26:40 INFO InMemoryFileIndex: Listing leaf files and directories in parallel under: file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds
18/02/28 12:26:40 INFO SparkContext: Starting job: csv at <unknown>:0
18/02/28 12:26:40 INFO DAGScheduler: Got job 8 (csv at <unknown>:0) with 67 output partitions
18/02/28 12:26:40 INFO DAGScheduler: Final stage: ResultStage 11 (csv at <unknown>:0)
18/02/28 12:26:40 INFO DAGScheduler: Parents of final stage: List()
18/02/28 12:26:40 INFO DAGScheduler: Missing parents: List()
18/02/28 12:26:40 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[43] at csv at <unknown>:0), which has no missing parents
18/02/28 12:26:40 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 71.3 KB, free 364.9 MB)
18/02/28 12:26:40 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 25.4 KB, free 364.9 MB)
18/02/28 12:26:40 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:60538 (size: 25.4 KB, free: 366.2 MB)
18/02/28 12:26:40 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
18/02/28 12:26:40 INFO DAGScheduler: Submitting 67 missing tasks from ResultStage 11 (MapPartitionsRDD[43] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
18/02/28 12:26:40 INFO TaskSchedulerImpl: Adding task set 11.0 with 67 tasks
18/02/28 12:26:40 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 27, localhost, executor driver, partition 1, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 28, localhost, executor driver, partition 2, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 29, localhost, executor driver, partition 3, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO Executor: Running task 0.0 in stage 11.0 (TID 26)
18/02/28 12:26:40 INFO Executor: Finished task 0.0 in stage 11.0 (TID 26). 1810 bytes result sent to driver
18/02/28 12:26:40 INFO TaskSetManager: Starting task 4.0 in stage 11.0 (TID 30, localhost, executor driver, partition 4, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO Executor: Running task 4.0 in stage 11.0 (TID 30)
18/02/28 12:26:40 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 26) in 45 ms on localhost (executor driver) (1/67)
18/02/28 12:26:40 INFO Executor: Running task 3.0 in stage 11.0 (TID 29)
18/02/28 12:26:40 INFO Executor: Running task 1.0 in stage 11.0 (TID 27)
18/02/28 12:26:40 INFO Executor: Finished task 1.0 in stage 11.0 (TID 27). 1681 bytes result sent to driver
18/02/28 12:26:40 INFO Executor: Running task 2.0 in stage 11.0 (TID 28)
18/02/28 12:26:40 INFO Executor: Finished task 3.0 in stage 11.0 (TID 29). 1724 bytes result sent to driver
18/02/28 12:26:40 INFO Executor: Finished task 2.0 in stage 11.0 (TID 28). 1724 bytes result sent to driver
18/02/28 12:26:40 INFO TaskSetManager: Starting task 5.0 in stage 11.0 (TID 31, localhost, executor driver, partition 5, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO TaskSetManager: Starting task 6.0 in stage 11.0 (TID 32, localhost, executor driver, partition 6, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO TaskSetManager: Starting task 7.0 in stage 11.0 (TID 33, localhost, executor driver, partition 7, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO Executor: Running task 5.0 in stage 11.0 (TID 31)
18/02/28 12:26:40 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 27) in 83 ms on localhost (executor driver) (2/67)
18/02/28 12:26:40 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 29) in 86 ms on localhost (executor driver) (3/67)
18/02/28 12:26:40 INFO Executor: Running task 7.0 in stage 11.0 (TID 33)
18/02/28 12:26:40 INFO Executor: Finished task 7.0 in stage 11.0 (TID 33). 1724 bytes result sent to driver
18/02/28 12:26:40 INFO Executor: Running task 6.0 in stage 11.0 (TID 32)
18/02/28 12:26:40 INFO Executor: Finished task 6.0 in stage 11.0 (TID 32). 1681 bytes result sent to driver
18/02/28 12:26:40 INFO TaskSetManager: Starting task 8.0 in stage 11.0 (TID 34, localhost, executor driver, partition 8, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO TaskSetManager: Starting task 9.0 in stage 11.0 (TID 35, localhost, executor driver, partition 9, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO Executor: Finished task 5.0 in stage 11.0 (TID 31). 1681 bytes result sent to driver
18/02/28 12:26:40 INFO TaskSetManager: Starting task 10.0 in stage 11.0 (TID 36, localhost, executor driver, partition 10, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO TaskSetManager: Finished task 7.0 in stage 11.0 (TID 33) in 41 ms on localhost (executor driver) (4/67)
18/02/28 12:26:40 INFO TaskSetManager: Finished task 6.0 in stage 11.0 (TID 32) in 42 ms on localhost (executor driver) (5/67)
18/02/28 12:26:40 INFO TaskSetManager: Finished task 5.0 in stage 11.0 (TID 31) in 44 ms on localhost (executor driver) (6/67)
18/02/28 12:26:40 INFO Executor: Running task 8.0 in stage 11.0 (TID 34)
18/02/28 12:26:40 INFO Executor: Running task 9.0 in stage 11.0 (TID 35)
18/02/28 12:26:40 INFO Executor: Finished task 8.0 in stage 11.0 (TID 34). 1681 bytes result sent to driver
18/02/28 12:26:40 INFO Executor: Finished task 9.0 in stage 11.0 (TID 35). 1724 bytes result sent to driver
18/02/28 12:26:40 INFO TaskSetManager: Starting task 11.0 in stage 11.0 (TID 37, localhost, executor driver, partition 11, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO TaskSetManager: Starting task 12.0 in stage 11.0 (TID 38, localhost, executor driver, partition 12, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO Executor: Running task 10.0 in stage 11.0 (TID 36)
18/02/28 12:26:40 INFO TaskSetManager: Finished task 8.0 in stage 11.0 (TID 34) in 34 ms on localhost (executor driver) (7/67)
18/02/28 12:26:40 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 28) in 144 ms on localhost (executor driver) (8/67)
18/02/28 12:26:40 INFO TaskSetManager: Finished task 9.0 in stage 11.0 (TID 35) in 35 ms on localhost (executor driver) (9/67)
18/02/28 12:26:40 INFO Executor: Finished task 4.0 in stage 11.0 (TID 30). 1724 bytes result sent to driver
18/02/28 12:26:40 INFO Executor: Running task 11.0 in stage 11.0 (TID 37)
18/02/28 12:26:40 INFO TaskSetManager: Starting task 13.0 in stage 11.0 (TID 39, localhost, executor driver, partition 13, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO TaskSetManager: Finished task 4.0 in stage 11.0 (TID 30) in 110 ms on localhost (executor driver) (10/67)
18/02/28 12:26:40 INFO Executor: Running task 13.0 in stage 11.0 (TID 39)
18/02/28 12:26:40 INFO Executor: Finished task 10.0 in stage 11.0 (TID 36). 1724 bytes result sent to driver
18/02/28 12:26:40 INFO TaskSetManager: Starting task 14.0 in stage 11.0 (TID 40, localhost, executor driver, partition 14, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO TaskSetManager: Finished task 10.0 in stage 11.0 (TID 36) in 40 ms on localhost (executor driver) (11/67)
18/02/28 12:26:40 INFO Executor: Running task 12.0 in stage 11.0 (TID 38)
18/02/28 12:26:40 INFO Executor: Running task 14.0 in stage 11.0 (TID 40)
18/02/28 12:26:40 INFO Executor: Finished task 13.0 in stage 11.0 (TID 39). 1681 bytes result sent to driver
18/02/28 12:26:40 INFO Executor: Finished task 11.0 in stage 11.0 (TID 37). 1681 bytes result sent to driver
18/02/28 12:26:40 INFO TaskSetManager: Starting task 15.0 in stage 11.0 (TID 41, localhost, executor driver, partition 15, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO TaskSetManager: Starting task 16.0 in stage 11.0 (TID 42, localhost, executor driver, partition 16, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO Executor: Finished task 12.0 in stage 11.0 (TID 38). 1767 bytes result sent to driver
18/02/28 12:26:40 INFO TaskSetManager: Finished task 13.0 in stage 11.0 (TID 39) in 23 ms on localhost (executor driver) (12/67)
18/02/28 12:26:40 INFO TaskSetManager: Finished task 11.0 in stage 11.0 (TID 37) in 35 ms on localhost (executor driver) (13/67)
18/02/28 12:26:40 INFO Executor: Running task 16.0 in stage 11.0 (TID 42)
18/02/28 12:26:40 INFO TaskSetManager: Starting task 17.0 in stage 11.0 (TID 43, localhost, executor driver, partition 17, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO TaskSetManager: Finished task 12.0 in stage 11.0 (TID 38) in 37 ms on localhost (executor driver) (14/67)
18/02/28 12:26:40 INFO Executor: Running task 15.0 in stage 11.0 (TID 41)
18/02/28 12:26:40 INFO Executor: Finished task 16.0 in stage 11.0 (TID 42). 1681 bytes result sent to driver
18/02/28 12:26:40 INFO Executor: Running task 17.0 in stage 11.0 (TID 43)
18/02/28 12:26:40 INFO Executor: Finished task 15.0 in stage 11.0 (TID 41). 1681 bytes result sent to driver
18/02/28 12:26:40 INFO TaskSetManager: Starting task 18.0 in stage 11.0 (TID 44, localhost, executor driver, partition 18, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO TaskSetManager: Starting task 19.0 in stage 11.0 (TID 45, localhost, executor driver, partition 19, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO Executor: Finished task 17.0 in stage 11.0 (TID 43). 1681 bytes result sent to driver
18/02/28 12:26:40 INFO Executor: Finished task 14.0 in stage 11.0 (TID 40). 1681 bytes result sent to driver
18/02/28 12:26:40 INFO Executor: Running task 18.0 in stage 11.0 (TID 44)
18/02/28 12:26:40 INFO Executor: Running task 19.0 in stage 11.0 (TID 45)
18/02/28 12:26:40 INFO TaskSetManager: Starting task 20.0 in stage 11.0 (TID 46, localhost, executor driver, partition 20, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO TaskSetManager: Starting task 21.0 in stage 11.0 (TID 47, localhost, executor driver, partition 21, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO TaskSetManager: Finished task 17.0 in stage 11.0 (TID 43) in 21 ms on localhost (executor driver) (15/67)
18/02/28 12:26:40 INFO TaskSetManager: Finished task 15.0 in stage 11.0 (TID 41) in 30 ms on localhost (executor driver) (16/67)
18/02/28 12:26:40 INFO Executor: Running task 21.0 in stage 11.0 (TID 47)
18/02/28 12:26:40 INFO Executor: Running task 20.0 in stage 11.0 (TID 46)
18/02/28 12:26:40 INFO Executor: Finished task 18.0 in stage 11.0 (TID 44). 1724 bytes result sent to driver
18/02/28 12:26:40 INFO TaskSetManager: Finished task 16.0 in stage 11.0 (TID 42) in 36 ms on localhost (executor driver) (17/67)
18/02/28 12:26:40 INFO Executor: Finished task 20.0 in stage 11.0 (TID 46). 1724 bytes result sent to driver
18/02/28 12:26:40 INFO TaskSetManager: Starting task 22.0 in stage 11.0 (TID 48, localhost, executor driver, partition 22, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO TaskSetManager: Starting task 23.0 in stage 11.0 (TID 49, localhost, executor driver, partition 23, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO Executor: Finished task 21.0 in stage 11.0 (TID 47). 1681 bytes result sent to driver
18/02/28 12:26:40 INFO TaskSetManager: Finished task 14.0 in stage 11.0 (TID 40) in 70 ms on localhost (executor driver) (18/67)
18/02/28 12:26:40 INFO TaskSetManager: Finished task 18.0 in stage 11.0 (TID 44) in 39 ms on localhost (executor driver) (19/67)
18/02/28 12:26:40 INFO Executor: Running task 23.0 in stage 11.0 (TID 49)
18/02/28 12:26:40 INFO TaskSetManager: Starting task 24.0 in stage 11.0 (TID 50, localhost, executor driver, partition 24, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO Executor: Running task 22.0 in stage 11.0 (TID 48)
18/02/28 12:26:40 INFO Executor: Running task 24.0 in stage 11.0 (TID 50)
18/02/28 12:26:40 INFO Executor: Finished task 23.0 in stage 11.0 (TID 49). 1724 bytes result sent to driver
18/02/28 12:26:40 INFO TaskSetManager: Finished task 21.0 in stage 11.0 (TID 47) in 39 ms on localhost (executor driver) (20/67)
18/02/28 12:26:40 INFO TaskSetManager: Finished task 20.0 in stage 11.0 (TID 46) in 41 ms on localhost (executor driver) (21/67)
18/02/28 12:26:40 INFO Executor: Finished task 19.0 in stage 11.0 (TID 45). 1724 bytes result sent to driver
18/02/28 12:26:40 INFO TaskSetManager: Starting task 25.0 in stage 11.0 (TID 51, localhost, executor driver, partition 25, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO TaskSetManager: Starting task 26.0 in stage 11.0 (TID 52, localhost, executor driver, partition 26, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO Executor: Running task 25.0 in stage 11.0 (TID 51)
18/02/28 12:26:40 INFO Executor: Finished task 24.0 in stage 11.0 (TID 50). 1681 bytes result sent to driver
18/02/28 12:26:40 INFO Executor: Running task 26.0 in stage 11.0 (TID 52)
18/02/28 12:26:40 INFO TaskSetManager: Finished task 23.0 in stage 11.0 (TID 49) in 22 ms on localhost (executor driver) (22/67)
18/02/28 12:26:40 INFO Executor: Finished task 22.0 in stage 11.0 (TID 48). 1724 bytes result sent to driver
18/02/28 12:26:40 INFO TaskSetManager: Starting task 27.0 in stage 11.0 (TID 53, localhost, executor driver, partition 27, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO TaskSetManager: Starting task 28.0 in stage 11.0 (TID 54, localhost, executor driver, partition 28, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO Executor: Finished task 25.0 in stage 11.0 (TID 51). 1724 bytes result sent to driver
18/02/28 12:26:40 INFO TaskSetManager: Finished task 19.0 in stage 11.0 (TID 45) in 70 ms on localhost (executor driver) (23/67)
18/02/28 12:26:40 INFO TaskSetManager: Finished task 24.0 in stage 11.0 (TID 50) in 32 ms on localhost (executor driver) (24/67)
18/02/28 12:26:40 INFO Executor: Running task 28.0 in stage 11.0 (TID 54)
18/02/28 12:26:40 INFO Executor: Running task 27.0 in stage 11.0 (TID 53)
18/02/28 12:26:40 INFO Executor: Finished task 28.0 in stage 11.0 (TID 54). 1681 bytes result sent to driver
18/02/28 12:26:40 INFO Executor: Finished task 27.0 in stage 11.0 (TID 53). 1724 bytes result sent to driver
18/02/28 12:26:40 INFO TaskSetManager: Finished task 22.0 in stage 11.0 (TID 48) in 43 ms on localhost (executor driver) (25/67)
18/02/28 12:26:40 INFO TaskSetManager: Starting task 29.0 in stage 11.0 (TID 55, localhost, executor driver, partition 29, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO TaskSetManager: Starting task 30.0 in stage 11.0 (TID 56, localhost, executor driver, partition 30, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO TaskSetManager: Starting task 31.0 in stage 11.0 (TID 57, localhost, executor driver, partition 31, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO TaskSetManager: Finished task 25.0 in stage 11.0 (TID 51) in 36 ms on localhost (executor driver) (26/67)
18/02/28 12:26:40 INFO Executor: Finished task 26.0 in stage 11.0 (TID 52). 1724 bytes result sent to driver
18/02/28 12:26:40 INFO TaskSetManager: Finished task 28.0 in stage 11.0 (TID 54) in 21 ms on localhost (executor driver) (27/67)
18/02/28 12:26:40 INFO TaskSetManager: Finished task 27.0 in stage 11.0 (TID 53) in 23 ms on localhost (executor driver) (28/67)
18/02/28 12:26:40 INFO Executor: Running task 29.0 in stage 11.0 (TID 55)
18/02/28 12:26:40 INFO TaskSetManager: Starting task 32.0 in stage 11.0 (TID 58, localhost, executor driver, partition 32, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO TaskSetManager: Finished task 26.0 in stage 11.0 (TID 52) in 43 ms on localhost (executor driver) (29/67)
18/02/28 12:26:40 INFO Executor: Running task 30.0 in stage 11.0 (TID 56)
18/02/28 12:26:40 INFO Executor: Running task 31.0 in stage 11.0 (TID 57)
18/02/28 12:26:40 INFO Executor: Finished task 31.0 in stage 11.0 (TID 57). 1681 bytes result sent to driver
18/02/28 12:26:40 INFO TaskSetManager: Starting task 33.0 in stage 11.0 (TID 59, localhost, executor driver, partition 33, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO Executor: Running task 32.0 in stage 11.0 (TID 58)
18/02/28 12:26:40 INFO Executor: Finished task 32.0 in stage 11.0 (TID 58). 1724 bytes result sent to driver
18/02/28 12:26:40 INFO Executor: Finished task 29.0 in stage 11.0 (TID 55). 1681 bytes result sent to driver
18/02/28 12:26:40 INFO TaskSetManager: Finished task 31.0 in stage 11.0 (TID 57) in 36 ms on localhost (executor driver) (30/67)
18/02/28 12:26:40 INFO Executor: Running task 33.0 in stage 11.0 (TID 59)
18/02/28 12:26:40 INFO Executor: Finished task 33.0 in stage 11.0 (TID 59). 1681 bytes result sent to driver
18/02/28 12:26:40 INFO TaskSetManager: Starting task 34.0 in stage 11.0 (TID 60, localhost, executor driver, partition 34, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO TaskSetManager: Starting task 35.0 in stage 11.0 (TID 61, localhost, executor driver, partition 35, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO TaskSetManager: Starting task 36.0 in stage 11.0 (TID 62, localhost, executor driver, partition 36, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO TaskSetManager: Finished task 29.0 in stage 11.0 (TID 55) in 47 ms on localhost (executor driver) (31/67)
18/02/28 12:26:40 INFO TaskSetManager: Finished task 33.0 in stage 11.0 (TID 59) in 22 ms on localhost (executor driver) (32/67)
18/02/28 12:26:40 INFO TaskSetManager: Finished task 32.0 in stage 11.0 (TID 58) in 34 ms on localhost (executor driver) (33/67)
18/02/28 12:26:40 INFO Executor: Running task 34.0 in stage 11.0 (TID 60)
18/02/28 12:26:40 INFO Executor: Running task 35.0 in stage 11.0 (TID 61)
18/02/28 12:26:40 INFO Executor: Finished task 34.0 in stage 11.0 (TID 60). 1681 bytes result sent to driver
18/02/28 12:26:40 INFO Executor: Running task 36.0 in stage 11.0 (TID 62)
18/02/28 12:26:40 INFO Executor: Finished task 35.0 in stage 11.0 (TID 61). 1681 bytes result sent to driver
18/02/28 12:26:40 INFO TaskSetManager: Starting task 37.0 in stage 11.0 (TID 63, localhost, executor driver, partition 37, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO TaskSetManager: Starting task 38.0 in stage 11.0 (TID 64, localhost, executor driver, partition 38, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO TaskSetManager: Finished task 34.0 in stage 11.0 (TID 60) in 24 ms on localhost (executor driver) (34/67)
18/02/28 12:26:40 INFO TaskSetManager: Finished task 35.0 in stage 11.0 (TID 61) in 18 ms on localhost (executor driver) (35/67)
18/02/28 12:26:40 INFO Executor: Finished task 36.0 in stage 11.0 (TID 62). 1724 bytes result sent to driver
18/02/28 12:26:40 INFO Executor: Running task 37.0 in stage 11.0 (TID 63)
18/02/28 12:26:40 INFO Executor: Running task 38.0 in stage 11.0 (TID 64)
18/02/28 12:26:40 INFO Executor: Finished task 37.0 in stage 11.0 (TID 63). 1681 bytes result sent to driver
18/02/28 12:26:40 INFO TaskSetManager: Starting task 39.0 in stage 11.0 (TID 65, localhost, executor driver, partition 39, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO Executor: Running task 39.0 in stage 11.0 (TID 65)
18/02/28 12:26:40 INFO TaskSetManager: Starting task 40.0 in stage 11.0 (TID 66, localhost, executor driver, partition 40, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO Executor: Finished task 30.0 in stage 11.0 (TID 56). 1767 bytes result sent to driver
18/02/28 12:26:40 INFO Executor: Finished task 38.0 in stage 11.0 (TID 64). 1724 bytes result sent to driver
18/02/28 12:26:40 INFO Executor: Running task 40.0 in stage 11.0 (TID 66)
18/02/28 12:26:40 INFO TaskSetManager: Finished task 36.0 in stage 11.0 (TID 62) in 69 ms on localhost (executor driver) (36/67)
18/02/28 12:26:40 INFO TaskSetManager: Starting task 41.0 in stage 11.0 (TID 67, localhost, executor driver, partition 41, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO TaskSetManager: Starting task 42.0 in stage 11.0 (TID 68, localhost, executor driver, partition 42, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:40 INFO TaskSetManager: Finished task 30.0 in stage 11.0 (TID 56) in 117 ms on localhost (executor driver) (37/67)
18/02/28 12:26:40 INFO Executor: Running task 41.0 in stage 11.0 (TID 67)
18/02/28 12:26:40 INFO Executor: Finished task 40.0 in stage 11.0 (TID 66). 1681 bytes result sent to driver
18/02/28 12:26:40 INFO Executor: Running task 42.0 in stage 11.0 (TID 68)
18/02/28 12:26:41 INFO Executor: Finished task 41.0 in stage 11.0 (TID 67). 1681 bytes result sent to driver
18/02/28 12:26:41 INFO Executor: Finished task 42.0 in stage 11.0 (TID 68). 1724 bytes result sent to driver
18/02/28 12:26:41 INFO TaskSetManager: Finished task 38.0 in stage 11.0 (TID 64) in 62 ms on localhost (executor driver) (38/67)
18/02/28 12:26:41 INFO TaskSetManager: Finished task 37.0 in stage 11.0 (TID 63) in 71 ms on localhost (executor driver) (39/67)
18/02/28 12:26:41 INFO TaskSetManager: Starting task 43.0 in stage 11.0 (TID 69, localhost, executor driver, partition 43, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:41 INFO TaskSetManager: Starting task 44.0 in stage 11.0 (TID 70, localhost, executor driver, partition 44, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:41 INFO TaskSetManager: Starting task 45.0 in stage 11.0 (TID 71, localhost, executor driver, partition 45, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:41 INFO Executor: Running task 43.0 in stage 11.0 (TID 69)
18/02/28 12:26:41 INFO Executor: Running task 44.0 in stage 11.0 (TID 70)
18/02/28 12:26:41 INFO Executor: Finished task 44.0 in stage 11.0 (TID 70). 1681 bytes result sent to driver
18/02/28 12:26:41 INFO Executor: Finished task 43.0 in stage 11.0 (TID 69). 1681 bytes result sent to driver
18/02/28 12:26:41 INFO Executor: Running task 45.0 in stage 11.0 (TID 71)
18/02/28 12:26:41 INFO TaskSetManager: Starting task 46.0 in stage 11.0 (TID 72, localhost, executor driver, partition 46, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:41 INFO TaskSetManager: Starting task 47.0 in stage 11.0 (TID 73, localhost, executor driver, partition 47, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:41 INFO TaskSetManager: Finished task 42.0 in stage 11.0 (TID 68) in 20 ms on localhost (executor driver) (40/67)
18/02/28 12:26:41 INFO TaskSetManager: Finished task 44.0 in stage 11.0 (TID 70) in 9 ms on localhost (executor driver) (41/67)
18/02/28 12:26:41 INFO TaskSetManager: Finished task 43.0 in stage 11.0 (TID 69) in 10 ms on localhost (executor driver) (42/67)
18/02/28 12:26:41 INFO TaskSetManager: Finished task 40.0 in stage 11.0 (TID 66) in 67 ms on localhost (executor driver) (43/67)
18/02/28 12:26:41 INFO Executor: Running task 46.0 in stage 11.0 (TID 72)
18/02/28 12:26:41 INFO Executor: Running task 47.0 in stage 11.0 (TID 73)
18/02/28 12:26:41 INFO Executor: Finished task 45.0 in stage 11.0 (TID 71). 1724 bytes result sent to driver
18/02/28 12:26:41 INFO TaskSetManager: Finished task 41.0 in stage 11.0 (TID 67) in 29 ms on localhost (executor driver) (44/67)
18/02/28 12:26:41 INFO Executor: Finished task 47.0 in stage 11.0 (TID 73). 1681 bytes result sent to driver
18/02/28 12:26:41 INFO TaskSetManager: Starting task 48.0 in stage 11.0 (TID 74, localhost, executor driver, partition 48, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:41 INFO TaskSetManager: Starting task 49.0 in stage 11.0 (TID 75, localhost, executor driver, partition 49, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:41 INFO TaskSetManager: Finished task 45.0 in stage 11.0 (TID 71) in 20 ms on localhost (executor driver) (45/67)
18/02/28 12:26:41 INFO TaskSetManager: Finished task 47.0 in stage 11.0 (TID 73) in 12 ms on localhost (executor driver) (46/67)
18/02/28 12:26:41 INFO Executor: Finished task 46.0 in stage 11.0 (TID 72). 1681 bytes result sent to driver
18/02/28 12:26:41 INFO Executor: Running task 48.0 in stage 11.0 (TID 74)
18/02/28 12:26:41 INFO Executor: Running task 49.0 in stage 11.0 (TID 75)
18/02/28 12:26:41 INFO Executor: Finished task 49.0 in stage 11.0 (TID 75). 1724 bytes result sent to driver
18/02/28 12:26:41 INFO TaskSetManager: Starting task 50.0 in stage 11.0 (TID 76, localhost, executor driver, partition 50, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:41 INFO TaskSetManager: Starting task 51.0 in stage 11.0 (TID 77, localhost, executor driver, partition 51, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:41 INFO TaskSetManager: Finished task 46.0 in stage 11.0 (TID 72) in 25 ms on localhost (executor driver) (47/67)
18/02/28 12:26:41 INFO TaskSetManager: Finished task 49.0 in stage 11.0 (TID 75) in 14 ms on localhost (executor driver) (48/67)
18/02/28 12:26:41 INFO Executor: Running task 50.0 in stage 11.0 (TID 76)
18/02/28 12:26:41 INFO Executor: Finished task 48.0 in stage 11.0 (TID 74). 1724 bytes result sent to driver
18/02/28 12:26:41 INFO Executor: Running task 51.0 in stage 11.0 (TID 77)
18/02/28 12:26:41 INFO Executor: Finished task 50.0 in stage 11.0 (TID 76). 1724 bytes result sent to driver
18/02/28 12:26:41 INFO Executor: Finished task 51.0 in stage 11.0 (TID 77). 1681 bytes result sent to driver
18/02/28 12:26:41 INFO TaskSetManager: Starting task 52.0 in stage 11.0 (TID 78, localhost, executor driver, partition 52, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:41 INFO TaskSetManager: Starting task 53.0 in stage 11.0 (TID 79, localhost, executor driver, partition 53, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:41 INFO TaskSetManager: Starting task 54.0 in stage 11.0 (TID 80, localhost, executor driver, partition 54, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:41 INFO TaskSetManager: Finished task 48.0 in stage 11.0 (TID 74) in 32 ms on localhost (executor driver) (49/67)
18/02/28 12:26:41 INFO TaskSetManager: Finished task 50.0 in stage 11.0 (TID 76) in 21 ms on localhost (executor driver) (50/67)
18/02/28 12:26:41 INFO TaskSetManager: Finished task 51.0 in stage 11.0 (TID 77) in 22 ms on localhost (executor driver) (51/67)
18/02/28 12:26:41 INFO Executor: Running task 52.0 in stage 11.0 (TID 78)
18/02/28 12:26:41 INFO Executor: Running task 53.0 in stage 11.0 (TID 79)
18/02/28 12:26:41 INFO Executor: Running task 54.0 in stage 11.0 (TID 80)
18/02/28 12:26:41 INFO Executor: Finished task 39.0 in stage 11.0 (TID 65). 1810 bytes result sent to driver
18/02/28 12:26:41 INFO TaskSetManager: Starting task 55.0 in stage 11.0 (TID 81, localhost, executor driver, partition 55, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:41 INFO Executor: Running task 55.0 in stage 11.0 (TID 81)
18/02/28 12:26:41 INFO TaskSetManager: Finished task 39.0 in stage 11.0 (TID 65) in 136 ms on localhost (executor driver) (52/67)
18/02/28 12:26:41 INFO Executor: Finished task 55.0 in stage 11.0 (TID 81). 1724 bytes result sent to driver
18/02/28 12:26:41 INFO Executor: Finished task 52.0 in stage 11.0 (TID 78). 1724 bytes result sent to driver
18/02/28 12:26:41 INFO TaskSetManager: Starting task 56.0 in stage 11.0 (TID 82, localhost, executor driver, partition 56, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:41 INFO TaskSetManager: Starting task 57.0 in stage 11.0 (TID 83, localhost, executor driver, partition 57, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:41 INFO Executor: Running task 56.0 in stage 11.0 (TID 82)
18/02/28 12:26:41 INFO TaskSetManager: Finished task 52.0 in stage 11.0 (TID 78) in 30 ms on localhost (executor driver) (53/67)
18/02/28 12:26:41 INFO TaskSetManager: Finished task 55.0 in stage 11.0 (TID 81) in 11 ms on localhost (executor driver) (54/67)
18/02/28 12:26:41 INFO Executor: Running task 57.0 in stage 11.0 (TID 83)
18/02/28 12:26:41 INFO Executor: Finished task 56.0 in stage 11.0 (TID 82). 1681 bytes result sent to driver
18/02/28 12:26:41 INFO TaskSetManager: Starting task 58.0 in stage 11.0 (TID 84, localhost, executor driver, partition 58, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:41 INFO TaskSetManager: Finished task 56.0 in stage 11.0 (TID 82) in 10 ms on localhost (executor driver) (55/67)
18/02/28 12:26:41 INFO Executor: Finished task 57.0 in stage 11.0 (TID 83). 1724 bytes result sent to driver
18/02/28 12:26:41 INFO Executor: Running task 58.0 in stage 11.0 (TID 84)
18/02/28 12:26:41 INFO TaskSetManager: Starting task 59.0 in stage 11.0 (TID 85, localhost, executor driver, partition 59, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:41 INFO TaskSetManager: Finished task 57.0 in stage 11.0 (TID 83) in 14 ms on localhost (executor driver) (56/67)
18/02/28 12:26:41 INFO Executor: Running task 59.0 in stage 11.0 (TID 85)
18/02/28 12:26:41 INFO Executor: Finished task 53.0 in stage 11.0 (TID 79). 1724 bytes result sent to driver
18/02/28 12:26:41 INFO TaskSetManager: Starting task 60.0 in stage 11.0 (TID 86, localhost, executor driver, partition 60, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:41 INFO TaskSetManager: Finished task 53.0 in stage 11.0 (TID 79) in 46 ms on localhost (executor driver) (57/67)
18/02/28 12:26:41 INFO Executor: Finished task 58.0 in stage 11.0 (TID 84). 1681 bytes result sent to driver
18/02/28 12:26:41 INFO Executor: Finished task 59.0 in stage 11.0 (TID 85). 1681 bytes result sent to driver
18/02/28 12:26:41 INFO TaskSetManager: Starting task 61.0 in stage 11.0 (TID 87, localhost, executor driver, partition 61, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:41 INFO TaskSetManager: Starting task 62.0 in stage 11.0 (TID 88, localhost, executor driver, partition 62, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:41 INFO TaskSetManager: Finished task 58.0 in stage 11.0 (TID 84) in 16 ms on localhost (executor driver) (58/67)
18/02/28 12:26:41 INFO TaskSetManager: Finished task 59.0 in stage 11.0 (TID 85) in 13 ms on localhost (executor driver) (59/67)
18/02/28 12:26:41 INFO Executor: Running task 61.0 in stage 11.0 (TID 87)
18/02/28 12:26:41 INFO Executor: Running task 62.0 in stage 11.0 (TID 88)
18/02/28 12:26:41 INFO Executor: Finished task 61.0 in stage 11.0 (TID 87). 1681 bytes result sent to driver
18/02/28 12:26:41 INFO TaskSetManager: Starting task 63.0 in stage 11.0 (TID 89, localhost, executor driver, partition 63, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:41 INFO TaskSetManager: Finished task 61.0 in stage 11.0 (TID 87) in 16 ms on localhost (executor driver) (60/67)
18/02/28 12:26:41 INFO Executor: Running task 63.0 in stage 11.0 (TID 89)
18/02/28 12:26:41 INFO Executor: Finished task 62.0 in stage 11.0 (TID 88). 1638 bytes result sent to driver
18/02/28 12:26:41 INFO TaskSetManager: Starting task 64.0 in stage 11.0 (TID 90, localhost, executor driver, partition 64, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:41 INFO TaskSetManager: Finished task 62.0 in stage 11.0 (TID 88) in 18 ms on localhost (executor driver) (61/67)
18/02/28 12:26:41 INFO Executor: Running task 64.0 in stage 11.0 (TID 90)
18/02/28 12:26:41 INFO Executor: Finished task 64.0 in stage 11.0 (TID 90). 1681 bytes result sent to driver
18/02/28 12:26:41 INFO TaskSetManager: Starting task 65.0 in stage 11.0 (TID 91, localhost, executor driver, partition 65, PROCESS_LOCAL, 4896 bytes)
18/02/28 12:26:41 INFO Executor: Running task 65.0 in stage 11.0 (TID 91)
18/02/28 12:26:41 INFO TaskSetManager: Finished task 64.0 in stage 11.0 (TID 90) in 25 ms on localhost (executor driver) (62/67)
18/02/28 12:26:41 INFO Executor: Finished task 65.0 in stage 11.0 (TID 91). 1681 bytes result sent to driver
18/02/28 12:26:41 INFO TaskSetManager: Starting task 66.0 in stage 11.0 (TID 92, localhost, executor driver, partition 66, PROCESS_LOCAL, 4902 bytes)
18/02/28 12:26:41 INFO TaskSetManager: Finished task 65.0 in stage 11.0 (TID 91) in 8 ms on localhost (executor driver) (63/67)
18/02/28 12:26:41 INFO Executor: Running task 66.0 in stage 11.0 (TID 92)
18/02/28 12:26:41 INFO Executor: Finished task 66.0 in stage 11.0 (TID 92). 1693 bytes result sent to driver
18/02/28 12:26:41 INFO TaskSetManager: Finished task 66.0 in stage 11.0 (TID 92) in 9 ms on localhost (executor driver) (64/67)
18/02/28 12:26:41 INFO Executor: Finished task 54.0 in stage 11.0 (TID 80). 1681 bytes result sent to driver
18/02/28 12:26:41 INFO TaskSetManager: Finished task 54.0 in stage 11.0 (TID 80) in 107 ms on localhost (executor driver) (65/67)
18/02/28 12:26:41 INFO Executor: Finished task 63.0 in stage 11.0 (TID 89). 1681 bytes result sent to driver
18/02/28 12:26:41 INFO TaskSetManager: Finished task 63.0 in stage 11.0 (TID 89) in 50 ms on localhost (executor driver) (66/67)
18/02/28 12:26:41 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:60538 in memory (size: 13.1 KB, free: 366.2 MB)
18/02/28 12:26:41 INFO Executor: Running task 60.0 in stage 11.0 (TID 86)
18/02/28 12:26:41 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:60538 in memory (size: 3.5 KB, free: 366.2 MB)
18/02/28 12:26:41 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:60538 in memory (size: 14.2 KB, free: 366.2 MB)
18/02/28 12:26:41 INFO ContextCleaner: Cleaned accumulator 320
18/02/28 12:26:41 INFO Executor: Finished task 60.0 in stage 11.0 (TID 86). 1724 bytes result sent to driver
18/02/28 12:26:41 INFO TaskSetManager: Finished task 60.0 in stage 11.0 (TID 86) in 104 ms on localhost (executor driver) (67/67)
18/02/28 12:26:41 INFO DAGScheduler: ResultStage 11 (csv at <unknown>:0) finished in 0.598 s
18/02/28 12:26:41 INFO DAGScheduler: Job 8 finished: csv at <unknown>:0, took 0.620547 s
18/02/28 12:26:41 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
18/02/28 12:26:41 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 12:26:41 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#264)) > 0)
18/02/28 12:26:41 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
18/02/28 12:26:41 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 12:26:41 INFO CodeGenerator: Code generated in 10.620468 ms
18/02/28 12:26:41 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 281.3 KB, free 364.7 MB)
18/02/28 12:26:41 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 23.9 KB, free 364.7 MB)
18/02/28 12:26:41 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:60538 (size: 23.9 KB, free: 366.2 MB)
18/02/28 12:26:41 INFO SparkContext: Created broadcast 16 from csv at <unknown>:0
18/02/28 12:26:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 12:26:41 INFO SparkContext: Starting job: csv at <unknown>:0
18/02/28 12:26:41 INFO DAGScheduler: Got job 9 (csv at <unknown>:0) with 1 output partitions
18/02/28 12:26:41 INFO DAGScheduler: Final stage: ResultStage 12 (csv at <unknown>:0)
18/02/28 12:26:41 INFO DAGScheduler: Parents of final stage: List()
18/02/28 12:26:41 INFO DAGScheduler: Missing parents: List()
18/02/28 12:26:41 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[46] at csv at <unknown>:0), which has no missing parents
18/02/28 12:26:41 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 8.2 KB, free 364.7 MB)
18/02/28 12:26:41 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 4.3 KB, free 364.7 MB)
18/02/28 12:26:41 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:60538 (size: 4.3 KB, free: 366.2 MB)
18/02/28 12:26:41 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
18/02/28 12:26:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[46] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 12:26:41 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
18/02/28 12:26:41 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 93, localhost, executor driver, partition 0, PROCESS_LOCAL, 6743 bytes)
18/02/28 12:26:41 INFO Executor: Running task 0.0 in stage 12.0 (TID 93)
18/02/28 12:26:41 INFO FileScanRDD: Reading File path: file:/C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 12:26:41 INFO Executor: Finished task 0.0 in stage 12.0 (TID 93). 1309 bytes result sent to driver
18/02/28 12:26:41 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 93) in 9 ms on localhost (executor driver) (1/1)
18/02/28 12:26:41 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
18/02/28 12:26:41 INFO DAGScheduler: ResultStage 12 (csv at <unknown>:0) finished in 0.010 s
18/02/28 12:26:41 INFO DAGScheduler: Job 9 finished: csv at <unknown>:0, took 0.018621 s
18/02/28 12:26:41 INFO CodeGenerator: Code generated in 6.44619 ms
18/02/28 12:26:41 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 12:26:41 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 12:26:41 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
18/02/28 12:26:41 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 12:26:41 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 281.3 KB, free 364.4 MB)
18/02/28 12:26:41 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 23.9 KB, free 364.4 MB)
18/02/28 12:26:41 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:60538 (size: 23.9 KB, free: 366.1 MB)
18/02/28 12:26:41 INFO SparkContext: Created broadcast 18 from csv at <unknown>:0
18/02/28 12:26:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 12:26:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:26:41 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:26:41 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:26:41 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:26:41 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:26:41 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:26:41 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:26:41 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:26:41 INFO SparkSqlParser: Parsing command: spark_fao
18/02/28 12:26:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:26:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao` AS `zzz35`
WHERE (0 = 1)
18/02/28 12:26:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:26:42 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:26:42 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:26:42 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:26:42 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:26:42 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:26:42 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:26:42 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:26:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:26:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao`
LIMIT 6
18/02/28 12:26:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:26:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao`
LIMIT 6
18/02/28 12:26:51 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 12:26:51 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 12:26:51 INFO FileSourceStrategy: Output Data Schema: struct<year: string, production_area: string, country: string, iso: string, source: string ... 8 more fields>
18/02/28 12:26:51 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 12:26:51 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 282.5 KB, free 364.1 MB)
18/02/28 12:26:51 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.1 MB)
18/02/28 12:26:51 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:60538 (size: 24.1 KB, free: 366.1 MB)
18/02/28 12:26:51 INFO SparkContext: Created broadcast 19 from collect at utils.scala:211
18/02/28 12:26:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 12:26:51 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 12:26:51 INFO DAGScheduler: Got job 10 (collect at utils.scala:211) with 1 output partitions
18/02/28 12:26:51 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:211)
18/02/28 12:26:51 INFO DAGScheduler: Parents of final stage: List()
18/02/28 12:26:51 INFO DAGScheduler: Missing parents: List()
18/02/28 12:26:51 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[54] at collect at utils.scala:211), which has no missing parents
18/02/28 12:26:51 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 11.6 KB, free 364.1 MB)
18/02/28 12:26:51 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 6.8 KB, free 364.1 MB)
18/02/28 12:26:51 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:60538 (size: 6.8 KB, free: 366.1 MB)
18/02/28 12:26:51 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
18/02/28 12:26:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[54] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 12:26:51 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
18/02/28 12:26:51 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 94, localhost, executor driver, partition 0, PROCESS_LOCAL, 6775 bytes)
18/02/28 12:26:51 INFO Executor: Running task 0.0 in stage 13.0 (TID 94)
18/02/28 12:26:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 12:26:51 INFO Executor: Finished task 0.0 in stage 13.0 (TID 94). 1723 bytes result sent to driver
18/02/28 12:26:51 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 94) in 6 ms on localhost (executor driver) (1/1)
18/02/28 12:26:51 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
18/02/28 12:26:51 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:211) finished in 0.006 s
18/02/28 12:26:51 INFO DAGScheduler: Job 10 finished: collect at utils.scala:211, took 0.012757 s
18/02/28 12:27:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:27:27 INFO SparkSqlParser: Parsing command: SELECT `year`, SUM(`quantity`) / 1000000.0 AS `sum(quantity)/1e+06`
FROM `spark_fao`
GROUP BY `year`
18/02/28 12:27:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:27:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:27:27 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 12:27:27 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 12:27:27 INFO FileSourceStrategy: Output Data Schema: struct<year: string, quantity: string>
18/02/28 12:27:27 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 12:27:27 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 282.5 KB, free 363.8 MB)
18/02/28 12:27:27 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 24.1 KB, free 363.8 MB)
18/02/28 12:27:27 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:60538 (size: 24.1 KB, free: 366.1 MB)
18/02/28 12:27:27 INFO SparkContext: Created broadcast 21 from collect at utils.scala:211
18/02/28 12:27:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 12:27:27 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 12:27:27 INFO DAGScheduler: Registering RDD 57 (collect at utils.scala:211)
18/02/28 12:27:27 INFO DAGScheduler: Got job 11 (collect at utils.scala:211) with 4 output partitions
18/02/28 12:27:27 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:211)
18/02/28 12:27:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
18/02/28 12:27:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)
18/02/28 12:27:27 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[57] at collect at utils.scala:211), which has no missing parents
18/02/28 12:27:27 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 28.8 KB, free 363.8 MB)
18/02/28 12:27:27 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 14.1 KB, free 363.7 MB)
18/02/28 12:27:27 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:60538 (size: 14.1 KB, free: 366.1 MB)
18/02/28 12:27:27 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
18/02/28 12:27:27 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[57] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 12:27:27 INFO TaskSchedulerImpl: Adding task set 14.0 with 4 tasks
18/02/28 12:27:27 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 95, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 12:27:27 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 96, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 12:27:27 INFO TaskSetManager: Starting task 2.0 in stage 14.0 (TID 97, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 12:27:27 INFO TaskSetManager: Starting task 3.0 in stage 14.0 (TID 98, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 12:27:27 INFO Executor: Running task 0.0 in stage 14.0 (TID 95)
18/02/28 12:27:27 INFO Executor: Running task 1.0 in stage 14.0 (TID 96)
18/02/28 12:27:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 12:27:27 INFO Executor: Running task 2.0 in stage 14.0 (TID 97)
18/02/28 12:27:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 12:27:27 INFO Executor: Running task 3.0 in stage 14.0 (TID 98)
18/02/28 12:27:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 12:27:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 12:27:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 12:27:27 INFO ContextCleaner: Cleaned accumulator 369
18/02/28 12:27:27 INFO ContextCleaner: Cleaned accumulator 399
18/02/28 12:27:27 INFO ContextCleaner: Cleaned accumulator 371
18/02/28 12:27:27 INFO ContextCleaner: Cleaned accumulator 401
18/02/28 12:27:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 12:27:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 12:27:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 12:27:27 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:60538 in memory (size: 6.8 KB, free: 366.1 MB)
18/02/28 12:27:27 INFO ContextCleaner: Cleaned accumulator 374
18/02/28 12:27:27 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:60538 in memory (size: 23.9 KB, free: 366.1 MB)
18/02/28 12:27:27 INFO ContextCleaner: Cleaned accumulator 433
18/02/28 12:27:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 12:27:27 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:60538 in memory (size: 25.4 KB, free: 366.1 MB)
18/02/28 12:27:27 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:60538 in memory (size: 23.9 KB, free: 366.1 MB)
18/02/28 12:27:27 INFO ContextCleaner: Cleaned accumulator 402
18/02/28 12:27:27 INFO ContextCleaner: Cleaned accumulator 403
18/02/28 12:27:27 INFO ContextCleaner: Cleaned accumulator 400
18/02/28 12:27:27 INFO ContextCleaner: Cleaned accumulator 370
18/02/28 12:27:27 INFO ContextCleaner: Cleaned accumulator 372
18/02/28 12:27:27 INFO ContextCleaner: Cleaned accumulator 373
18/02/28 12:27:27 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:60538 in memory (size: 4.3 KB, free: 366.1 MB)
18/02/28 12:27:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 12:27:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 12:27:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 12:27:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 12:27:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 12:27:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 12:27:28 INFO Executor: Finished task 3.0 in stage 14.0 (TID 98). 2060 bytes result sent to driver
18/02/28 12:27:28 INFO TaskSetManager: Finished task 3.0 in stage 14.0 (TID 98) in 626 ms on localhost (executor driver) (1/4)
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 12:27:28 INFO Executor: Finished task 2.0 in stage 14.0 (TID 97). 2103 bytes result sent to driver
18/02/28 12:27:28 INFO TaskSetManager: Finished task 2.0 in stage 14.0 (TID 97) in 733 ms on localhost (executor driver) (2/4)
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 12:27:28 INFO Executor: Finished task 1.0 in stage 14.0 (TID 96). 2060 bytes result sent to driver
18/02/28 12:27:28 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 96) in 835 ms on localhost (executor driver) (3/4)
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 12:27:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 12:27:28 INFO Executor: Finished task 0.0 in stage 14.0 (TID 95). 2060 bytes result sent to driver
18/02/28 12:27:28 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 95) in 978 ms on localhost (executor driver) (4/4)
18/02/28 12:27:28 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
18/02/28 12:27:28 INFO DAGScheduler: ShuffleMapStage 14 (collect at utils.scala:211) finished in 0.978 s
18/02/28 12:27:28 INFO DAGScheduler: looking for newly runnable stages
18/02/28 12:27:28 INFO DAGScheduler: running: Set()
18/02/28 12:27:28 INFO DAGScheduler: waiting: Set(ResultStage 15)
18/02/28 12:27:28 INFO DAGScheduler: failed: Set()
18/02/28 12:27:28 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[60] at collect at utils.scala:211), which has no missing parents
18/02/28 12:27:28 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 26.5 KB, free 364.4 MB)
18/02/28 12:27:28 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 13.1 KB, free 364.4 MB)
18/02/28 12:27:28 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:60538 (size: 13.1 KB, free: 366.1 MB)
18/02/28 12:27:28 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
18/02/28 12:27:28 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 15 (MapPartitionsRDD[60] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 12:27:28 INFO TaskSchedulerImpl: Adding task set 15.0 with 4 tasks
18/02/28 12:27:28 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 99, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 12:27:28 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 100, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 12:27:28 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 101, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 12:27:28 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 102, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 12:27:28 INFO Executor: Running task 0.0 in stage 15.0 (TID 99)
18/02/28 12:27:28 INFO Executor: Running task 1.0 in stage 15.0 (TID 100)
18/02/28 12:27:28 INFO Executor: Running task 2.0 in stage 15.0 (TID 101)
18/02/28 12:27:28 INFO Executor: Running task 3.0 in stage 15.0 (TID 102)
18/02/28 12:27:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:27:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 12:27:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:27:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 12:27:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:27:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 12:27:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:27:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 12:27:28 INFO Executor: Finished task 1.0 in stage 15.0 (TID 100). 60895 bytes result sent to driver
18/02/28 12:27:28 INFO Executor: Finished task 0.0 in stage 15.0 (TID 99). 54465 bytes result sent to driver
18/02/28 12:27:28 INFO Executor: Finished task 2.0 in stage 15.0 (TID 101). 57443 bytes result sent to driver
18/02/28 12:27:28 INFO Executor: Finished task 3.0 in stage 15.0 (TID 102). 70174 bytes result sent to driver
18/02/28 12:27:28 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 100) in 26 ms on localhost (executor driver) (1/4)
18/02/28 12:27:28 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 99) in 27 ms on localhost (executor driver) (2/4)
18/02/28 12:27:28 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 101) in 26 ms on localhost (executor driver) (3/4)
18/02/28 12:27:28 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 102) in 27 ms on localhost (executor driver) (4/4)
18/02/28 12:27:28 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:211) finished in 0.028 s
18/02/28 12:27:28 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
18/02/28 12:27:28 INFO DAGScheduler: Job 11 finished: collect at utils.scala:211, took 1.020108 s
18/02/28 12:29:11 INFO SparkContext: Invoking stop() from shutdown hook
18/02/28 12:29:11 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
18/02/28 12:29:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/02/28 12:29:11 INFO MemoryStore: MemoryStore cleared
18/02/28 12:29:11 INFO BlockManager: BlockManager stopped
18/02/28 12:29:11 INFO BlockManagerMaster: BlockManagerMaster stopped
18/02/28 12:29:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/02/28 12:29:11 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-eee94776-518e-4420-8b75-1d645ec05192\userFiles-8cec39bc-0a30-46f9-8235-ee9808956e63
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-eee94776-518e-4420-8b75-1d645ec05192\userFiles-8cec39bc-0a30-46f9-8235-ee9808956e63
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1937)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1936)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 12:29:11 INFO SparkContext: Successfully stopped SparkContext
18/02/28 12:29:11 INFO ShutdownHookManager: Shutdown hook called
18/02/28 12:29:11 INFO ShutdownHookManager: Deleting directory C:\Users\JC\AppData\Local\Temp\spark-eee94776-518e-4420-8b75-1d645ec05192\userFiles-8cec39bc-0a30-46f9-8235-ee9808956e63
18/02/28 12:29:11 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-eee94776-518e-4420-8b75-1d645ec05192\userFiles-8cec39bc-0a30-46f9-8235-ee9808956e63
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-eee94776-518e-4420-8b75-1d645ec05192\userFiles-8cec39bc-0a30-46f9-8235-ee9808956e63
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 12:29:11 INFO ShutdownHookManager: Deleting directory C:\Users\JC\AppData\Local\Temp\spark-eee94776-518e-4420-8b75-1d645ec05192
18/02/28 12:29:11 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-eee94776-518e-4420-8b75-1d645ec05192
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-eee94776-518e-4420-8b75-1d645ec05192
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 12:29:14 INFO SparkContext: Running Spark version 2.2.0
18/02/28 12:29:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/02/28 12:29:14 INFO SparkContext: Submitted application: sparklyr
18/02/28 12:29:14 INFO SecurityManager: Changing view acls to: JC
18/02/28 12:29:14 INFO SecurityManager: Changing modify acls to: JC
18/02/28 12:29:14 INFO SecurityManager: Changing view acls groups to: 
18/02/28 12:29:14 INFO SecurityManager: Changing modify acls groups to: 
18/02/28 12:29:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(JC); groups with view permissions: Set(); users  with modify permissions: Set(JC); groups with modify permissions: Set()
18/02/28 12:29:14 INFO Utils: Successfully started service 'sparkDriver' on port 60604.
18/02/28 12:29:14 INFO SparkEnv: Registering MapOutputTracker
18/02/28 12:29:14 INFO SparkEnv: Registering BlockManagerMaster
18/02/28 12:29:14 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/02/28 12:29:14 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/02/28 12:29:14 INFO DiskBlockManager: Created local directory at C:\Users\JC\AppData\Local\Temp\blockmgr-9fd2a59d-9f4a-460e-a001-110f84833023
18/02/28 12:29:14 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/02/28 12:29:14 INFO SparkEnv: Registering OutputCommitCoordinator
18/02/28 12:29:14 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/02/28 12:29:14 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
18/02/28 12:29:14 INFO SparkContext: Added JAR file:/C:/Users/JC/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:60604/jars/sparklyr-2.2-2.11.jar with timestamp 1519849754967
18/02/28 12:29:15 INFO Executor: Starting executor ID driver on host localhost
18/02/28 12:29:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60625.
18/02/28 12:29:15 INFO NettyBlockTransferService: Server created on 127.0.0.1:60625
18/02/28 12:29:15 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/02/28 12:29:15 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 60625, None)
18/02/28 12:29:15 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:60625 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 60625, None)
18/02/28 12:29:15 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 60625, None)
18/02/28 12:29:15 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 60625, None)
18/02/28 12:29:15 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/02/28 12:29:15 INFO SharedState: loading hive config file: file:/C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
18/02/28 12:29:15 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:\Users\JC\AppData\Local\spark\spark-2.2.0-bin-hadoop2.7\tmp\hive') to the value of spark.sql.warehouse.dir ('C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive').
18/02/28 12:29:15 INFO SharedState: Warehouse path is 'C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive'.
18/02/28 12:29:16 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
18/02/28 12:29:16 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
18/02/28 12:29:16 INFO ObjectStore: ObjectStore, initialize called
18/02/28 12:29:17 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
18/02/28 12:29:17 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
18/02/28 12:29:18 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
18/02/28 12:29:19 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 12:29:19 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 12:29:19 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 12:29:19 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 12:29:19 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
18/02/28 12:29:19 INFO ObjectStore: Initialized ObjectStore
18/02/28 12:29:20 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
18/02/28 12:29:20 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
18/02/28 12:29:20 INFO HiveMetaStore: Added admin role in metastore
18/02/28 12:29:20 INFO HiveMetaStore: Added public role in metastore
18/02/28 12:29:20 INFO HiveMetaStore: No user is added in admin role, since config is empty
18/02/28 12:29:20 INFO HiveMetaStore: 0: get_all_databases
18/02/28 12:29:20 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_all_databases	
18/02/28 12:29:20 INFO HiveMetaStore: 0: get_functions: db=default pat=*
18/02/28 12:29:20 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
18/02/28 12:29:20 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 12:29:20 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/Temp/fcc3c68f-43ab-4bce-9419-6dd9598a1007_resources
18/02/28 12:29:20 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/fcc3c68f-43ab-4bce-9419-6dd9598a1007
18/02/28 12:29:20 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/fcc3c68f-43ab-4bce-9419-6dd9598a1007
18/02/28 12:29:20 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/fcc3c68f-43ab-4bce-9419-6dd9598a1007/_tmp_space.db
18/02/28 12:29:20 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive
18/02/28 12:29:20 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:29:20 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:29:20 INFO HiveMetaStore: 0: get_database: global_temp
18/02/28 12:29:20 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: global_temp	
18/02/28 12:29:20 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
18/02/28 12:29:20 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/Temp/339443f9-e8a1-4c51-863a-c8d254653824_resources
18/02/28 12:29:20 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/339443f9-e8a1-4c51-863a-c8d254653824
18/02/28 12:29:21 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/339443f9-e8a1-4c51-863a-c8d254653824
18/02/28 12:29:21 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/339443f9-e8a1-4c51-863a-c8d254653824/_tmp_space.db
18/02/28 12:29:21 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive
18/02/28 12:29:21 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
18/02/28 12:29:21 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:29:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:29:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:29:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:29:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:29:22 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:29:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:29:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:29:56 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:29:56 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:29:56 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:29:56 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:29:56 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:29:56 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:29:56 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:29:56 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 12:29:56 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
18/02/28 12:29:56 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
18/02/28 12:29:56 INFO DAGScheduler: Parents of final stage: List()
18/02/28 12:29:56 INFO DAGScheduler: Missing parents: List()
18/02/28 12:29:56 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55), which has no missing parents
18/02/28 12:29:56 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
18/02/28 12:29:56 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
18/02/28 12:29:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:60625 (size: 3.4 KB, free: 366.3 MB)
18/02/28 12:29:56 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
18/02/28 12:29:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0))
18/02/28 12:29:57 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/02/28 12:29:57 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 12:29:57 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/02/28 12:29:57 INFO Executor: Fetching spark://127.0.0.1:60604/jars/sparklyr-2.2-2.11.jar with timestamp 1519849754967
18/02/28 12:29:57 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:60604 after 15 ms (0 ms spent in bootstraps)
18/02/28 12:29:57 INFO Utils: Fetching spark://127.0.0.1:60604/jars/sparklyr-2.2-2.11.jar to C:\Users\JC\AppData\Local\Temp\spark-e23e35e4-6bea-4bfd-a148-726cc37bfedf\userFiles-070a0c4c-3197-44f0-beb4-5430bd9103c9\fetchFileTemp4071585227390127331.tmp
18/02/28 12:29:57 INFO Executor: Adding file:/C:/Users/JC/AppData/Local/Temp/spark-e23e35e4-6bea-4bfd-a148-726cc37bfedf/userFiles-070a0c4c-3197-44f0-beb4-5430bd9103c9/sparklyr-2.2-2.11.jar to class loader
18/02/28 12:29:57 INFO CodeGenerator: Code generated in 237.128161 ms
18/02/28 12:29:57 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
18/02/28 12:29:57 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 640 ms on localhost (executor driver) (1/1)
18/02/28 12:29:57 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/02/28 12:29:57 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.661 s
18/02/28 12:29:57 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.813848 s
18/02/28 12:29:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:29:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:29:57 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:29:57 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:29:57 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:29:57 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:29:57 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:29:57 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:29:57 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:29:57 INFO SparkSqlParser: Parsing command: spark_fao
18/02/28 12:29:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:29:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao` AS `zzz36`
WHERE (0 = 1)
18/02/28 12:29:58 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:29:58 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:29:58 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:29:58 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:29:58 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:29:58 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:29:58 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:29:58 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:29:58 INFO CodeGenerator: Code generated in 12.739343 ms
18/02/28 12:30:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:30:26 INFO SparkSqlParser: Parsing command: SELECT `year`, SUM(`quantity`) / 1000000.0 AS `sum(quantity)/1e+06`
FROM `spark_fao`
GROUP BY `year`
18/02/28 12:30:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:30:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:30:26 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 12:30:26 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 12:30:26 INFO FileSourceStrategy: Output Data Schema: struct<year: int, quantity: int>
18/02/28 12:30:26 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 12:30:26 INFO CodeGenerator: Code generated in 46.004516 ms
18/02/28 12:30:26 INFO CodeGenerator: Code generated in 95.16319 ms
18/02/28 12:30:26 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 282.5 KB, free 366.0 MB)
18/02/28 12:30:26 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 24.1 KB, free 366.0 MB)
18/02/28 12:30:26 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:60625 (size: 24.1 KB, free: 366.3 MB)
18/02/28 12:30:26 INFO SparkContext: Created broadcast 1 from collect at utils.scala:211
18/02/28 12:30:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 12:30:27 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:60625 in memory (size: 3.4 KB, free: 366.3 MB)
18/02/28 12:30:27 INFO ContextCleaner: Cleaned accumulator 49
18/02/28 12:30:27 INFO ContextCleaner: Cleaned accumulator 0
18/02/28 12:30:27 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 12:30:27 INFO DAGScheduler: Registering RDD 7 (collect at utils.scala:211)
18/02/28 12:30:27 INFO DAGScheduler: Got job 1 (collect at utils.scala:211) with 4 output partitions
18/02/28 12:30:27 INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:211)
18/02/28 12:30:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
18/02/28 12:30:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
18/02/28 12:30:27 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at collect at utils.scala:211), which has no missing parents
18/02/28 12:30:27 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 28.3 KB, free 366.0 MB)
18/02/28 12:30:27 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 13.9 KB, free 366.0 MB)
18/02/28 12:30:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:60625 (size: 13.9 KB, free: 366.3 MB)
18/02/28 12:30:27 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
18/02/28 12:30:27 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 12:30:27 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks
18/02/28 12:30:27 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 12:30:27 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 12:30:27 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 12:30:27 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 12:30:27 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
18/02/28 12:30:27 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
18/02/28 12:30:27 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
18/02/28 12:30:27 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
18/02/28 12:30:27 INFO CodeGenerator: Code generated in 10.244579 ms
18/02/28 12:30:27 INFO CodeGenerator: Code generated in 8.609494 ms
18/02/28 12:30:27 INFO CodeGenerator: Code generated in 8.291081 ms
18/02/28 12:30:27 INFO CodeGenerator: Code generated in 19.402039 ms
18/02/28 12:30:27 INFO CodeGenerator: Code generated in 9.75691 ms
18/02/28 12:30:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 12:30:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 12:30:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 12:30:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 12:30:27 INFO CodeGenerator: Code generated in 14.830361 ms
18/02/28 12:30:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 12:30:28 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 2103 bytes result sent to driver
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 12:30:28 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 1356 ms on localhost (executor driver) (1/4)
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 12:30:28 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 2060 bytes result sent to driver
18/02/28 12:30:28 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1503 ms on localhost (executor driver) (2/4)
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 12:30:28 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 2060 bytes result sent to driver
18/02/28 12:30:28 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1608 ms on localhost (executor driver) (3/4)
18/02/28 12:30:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 12:30:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 12:30:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 12:30:29 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2060 bytes result sent to driver
18/02/28 12:30:29 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1690 ms on localhost (executor driver) (4/4)
18/02/28 12:30:29 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/02/28 12:30:29 INFO DAGScheduler: ShuffleMapStage 1 (collect at utils.scala:211) finished in 1.691 s
18/02/28 12:30:29 INFO DAGScheduler: looking for newly runnable stages
18/02/28 12:30:29 INFO DAGScheduler: running: Set()
18/02/28 12:30:29 INFO DAGScheduler: waiting: Set(ResultStage 2)
18/02/28 12:30:29 INFO DAGScheduler: failed: Set()
18/02/28 12:30:29 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[10] at collect at utils.scala:211), which has no missing parents
18/02/28 12:30:29 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 28.7 KB, free 365.9 MB)
18/02/28 12:30:29 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 14.2 KB, free 365.9 MB)
18/02/28 12:30:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:60625 (size: 14.2 KB, free: 366.2 MB)
18/02/28 12:30:29 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
18/02/28 12:30:29 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 12:30:29 INFO TaskSchedulerImpl: Adding task set 2.0 with 4 tasks
18/02/28 12:30:29 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 12:30:29 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 6, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 12:30:29 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 7, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 12:30:29 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 8, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 12:30:29 INFO Executor: Running task 1.0 in stage 2.0 (TID 6)
18/02/28 12:30:29 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
18/02/28 12:30:29 INFO Executor: Running task 2.0 in stage 2.0 (TID 7)
18/02/28 12:30:29 INFO Executor: Running task 3.0 in stage 2.0 (TID 8)
18/02/28 12:30:29 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:30:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
18/02/28 12:30:29 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:30:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
18/02/28 12:30:29 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:30:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
18/02/28 12:30:29 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:30:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
18/02/28 12:30:29 INFO Executor: Finished task 3.0 in stage 2.0 (TID 8). 2779 bytes result sent to driver
18/02/28 12:30:29 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 2716 bytes result sent to driver
18/02/28 12:30:29 INFO Executor: Finished task 1.0 in stage 2.0 (TID 6). 2828 bytes result sent to driver
18/02/28 12:30:29 INFO Executor: Finished task 2.0 in stage 2.0 (TID 7). 2709 bytes result sent to driver
18/02/28 12:30:29 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 76 ms on localhost (executor driver) (1/4)
18/02/28 12:30:29 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 6) in 76 ms on localhost (executor driver) (2/4)
18/02/28 12:30:29 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 7) in 77 ms on localhost (executor driver) (3/4)
18/02/28 12:30:29 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 8) in 77 ms on localhost (executor driver) (4/4)
18/02/28 12:30:29 INFO DAGScheduler: ResultStage 2 (collect at utils.scala:211) finished in 0.080 s
18/02/28 12:30:29 INFO DAGScheduler: Job 1 finished: collect at utils.scala:211, took 1.820280 s
18/02/28 12:30:29 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/02/28 12:30:29 INFO CodeGenerator: Code generated in 7.97972 ms
18/02/28 12:30:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:30:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao`
18/02/28 12:30:51 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e0760e1781
18/02/28 12:30:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:30:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0760e1781` AS `zzz37`
WHERE (0 = 1)
18/02/28 12:30:51 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e039ad152c
18/02/28 12:30:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:30:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e039ad152c` AS `zzz38`
WHERE (0 = 1)
18/02/28 12:30:51 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e025127007
18/02/28 12:30:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:30:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e025127007` AS `zzz39`
WHERE (0 = 1)
18/02/28 12:30:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:30:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao`
LIMIT 6
18/02/28 12:30:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:30:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao`
LIMIT 6
18/02/28 12:30:56 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 12:30:56 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 12:30:56 INFO FileSourceStrategy: Output Data Schema: struct<year: int, production_area: int, country: string, iso: string, source: string ... 8 more fields>
18/02/28 12:30:56 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 12:30:56 INFO CodeGenerator: Code generated in 5.848856 ms
18/02/28 12:30:56 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 282.5 KB, free 365.6 MB)
18/02/28 12:30:56 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.6 MB)
18/02/28 12:30:56 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:60625 (size: 24.1 KB, free: 366.2 MB)
18/02/28 12:30:56 INFO SparkContext: Created broadcast 4 from collect at utils.scala:211
18/02/28 12:30:56 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 12:30:56 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 12:30:56 INFO DAGScheduler: Got job 2 (collect at utils.scala:211) with 1 output partitions
18/02/28 12:30:56 INFO DAGScheduler: Final stage: ResultStage 3 (collect at utils.scala:211)
18/02/28 12:30:56 INFO DAGScheduler: Parents of final stage: List()
18/02/28 12:30:56 INFO DAGScheduler: Missing parents: List()
18/02/28 12:30:56 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[13] at collect at utils.scala:211), which has no missing parents
18/02/28 12:30:56 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 11.7 KB, free 365.6 MB)
18/02/28 12:30:56 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.9 KB, free 365.6 MB)
18/02/28 12:30:56 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:60625 (size: 6.9 KB, free: 366.2 MB)
18/02/28 12:30:56 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
18/02/28 12:30:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 12:30:56 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
18/02/28 12:30:56 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 6775 bytes)
18/02/28 12:30:56 INFO Executor: Running task 0.0 in stage 3.0 (TID 9)
18/02/28 12:30:56 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 12:30:56 INFO CodeGenerator: Code generated in 9.457538 ms
18/02/28 12:30:56 INFO Executor: Finished task 0.0 in stage 3.0 (TID 9). 1154 bytes result sent to driver
18/02/28 12:30:56 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 9) in 28 ms on localhost (executor driver) (1/1)
18/02/28 12:30:56 INFO DAGScheduler: ResultStage 3 (collect at utils.scala:211) finished in 0.029 s
18/02/28 12:30:56 INFO DAGScheduler: Job 2 finished: collect at utils.scala:211, took 0.036888 s
18/02/28 12:30:56 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/02/28 12:30:56 INFO CodeGenerator: Code generated in 10.385625 ms
18/02/28 12:31:38 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:60625 in memory (size: 14.2 KB, free: 366.2 MB)
18/02/28 12:31:38 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:60625 in memory (size: 6.9 KB, free: 366.2 MB)
18/02/28 12:34:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:34:52 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao`
18/02/28 12:34:52 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e0565853be
18/02/28 12:34:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:34:52 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0565853be` AS `zzz40`
WHERE (0 = 1)
18/02/28 12:34:52 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e0792e716e
18/02/28 12:34:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:34:53 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0792e716e` AS `zzz41`
WHERE (0 = 1)
18/02/28 12:34:53 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e0474b51d8
18/02/28 12:34:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:34:53 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0474b51d8` AS `zzz42`
WHERE (0 = 1)
18/02/28 12:35:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:35:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0565853be`
18/02/28 12:35:57 INFO SparkSqlParser: Parsing command: training
18/02/28 12:35:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:35:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training` AS `zzz43`
WHERE (0 = 1)
18/02/28 12:35:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:35:57 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:35:57 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:35:57 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:35:57 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:35:57 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:35:57 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:35:57 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:36:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:36:28 INFO SparkSqlParser: Parsing command: CACHE TABLE `training`
18/02/28 12:36:28 INFO SparkSqlParser: Parsing command: `training`
18/02/28 12:36:28 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 12:36:28 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 12:36:28 INFO FileSourceStrategy: Output Data Schema: struct<year: int, production_area: int, country: string, iso: string, source: string ... 8 more fields>
18/02/28 12:36:28 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 12:36:28 INFO CodeGenerator: Code generated in 18.752167 ms
18/02/28 12:36:28 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 282.5 KB, free 365.4 MB)
18/02/28 12:36:28 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.4 MB)
18/02/28 12:36:28 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:60625 (size: 24.1 KB, free: 366.2 MB)
18/02/28 12:36:28 INFO SparkContext: Created broadcast 6 from sql at <unknown>:0
18/02/28 12:36:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 12:36:28 INFO CodeGenerator: Code generated in 7.858421 ms
18/02/28 12:36:28 INFO CodeGenerator: Code generated in 7.972315 ms
18/02/28 12:36:28 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 12:36:28 INFO DAGScheduler: Registering RDD 19 (sql at <unknown>:0)
18/02/28 12:36:28 INFO DAGScheduler: Got job 3 (sql at <unknown>:0) with 1 output partitions
18/02/28 12:36:28 INFO DAGScheduler: Final stage: ResultStage 5 (sql at <unknown>:0)
18/02/28 12:36:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
18/02/28 12:36:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
18/02/28 12:36:28 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[19] at sql at <unknown>:0), which has no missing parents
18/02/28 12:36:28 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 31.7 KB, free 365.3 MB)
18/02/28 12:36:28 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 14.0 KB, free 365.3 MB)
18/02/28 12:36:28 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:60625 (size: 14.0 KB, free: 366.2 MB)
18/02/28 12:36:28 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
18/02/28 12:36:28 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[19] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 12:36:28 INFO TaskSchedulerImpl: Adding task set 4.0 with 4 tasks
18/02/28 12:36:28 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 12:36:28 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 11, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 12:36:28 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 12, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 12:36:28 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 13, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 12:36:28 INFO Executor: Running task 0.0 in stage 4.0 (TID 10)
18/02/28 12:36:28 INFO Executor: Running task 2.0 in stage 4.0 (TID 12)
18/02/28 12:36:28 INFO Executor: Running task 3.0 in stage 4.0 (TID 13)
18/02/28 12:36:28 INFO Executor: Running task 1.0 in stage 4.0 (TID 11)
18/02/28 12:36:28 INFO CodeGenerator: Code generated in 19.251471 ms
18/02/28 12:36:28 INFO CodeGenerator: Code generated in 6.475104 ms
18/02/28 12:36:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 12:36:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 12:36:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 12:36:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 12:36:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 12:36:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 12:36:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 12:36:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 12:36:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 12:36:28 INFO ContextCleaner: Cleaned accumulator 152
18/02/28 12:36:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 12:36:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 12:36:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 12:36:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 12:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 12:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 12:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 12:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 12:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 12:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 12:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 12:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 12:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 12:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 12:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 12:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 12:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 12:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 12:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 12:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 12:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 12:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 12:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 12:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 12:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 12:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 12:36:29 INFO MemoryStore: Block rdd_16_3 stored as values in memory (estimated size 165.0 KB, free 335.2 MB)
18/02/28 12:36:29 INFO BlockManagerInfo: Added rdd_16_3 in memory on 127.0.0.1:60625 (size: 165.0 KB, free: 366.0 MB)
18/02/28 12:36:29 INFO CodeGenerator: Code generated in 7.624988 ms
18/02/28 12:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 12:36:29 INFO CodeGenerator: Code generated in 24.606312 ms
18/02/28 12:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 12:36:29 INFO Executor: Finished task 3.0 in stage 4.0 (TID 13). 3086 bytes result sent to driver
18/02/28 12:36:29 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 13) in 1479 ms on localhost (executor driver) (1/4)
18/02/28 12:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 12:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 12:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 12:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 12:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 12:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 12:36:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 12:36:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 12:36:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 12:36:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 12:36:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 12:36:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 12:36:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 12:36:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 12:36:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 12:36:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 12:36:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 12:36:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 12:36:30 INFO MemoryStore: Block rdd_16_2 stored as values in memory (estimated size 366.9 KB, free 332.8 MB)
18/02/28 12:36:30 INFO BlockManagerInfo: Added rdd_16_2 in memory on 127.0.0.1:60625 (size: 366.9 KB, free: 365.7 MB)
18/02/28 12:36:30 INFO Executor: Finished task 2.0 in stage 4.0 (TID 12). 3086 bytes result sent to driver
18/02/28 12:36:30 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 12) in 2190 ms on localhost (executor driver) (2/4)
18/02/28 12:36:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 12:36:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 12:36:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 12:36:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 12:36:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 12:36:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 12:36:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 12:36:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 12:36:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 12:36:30 INFO MemoryStore: Block rdd_16_1 stored as values in memory (estimated size 532.3 KB, free 344.3 MB)
18/02/28 12:36:30 INFO BlockManagerInfo: Added rdd_16_1 in memory on 127.0.0.1:60625 (size: 532.3 KB, free: 365.2 MB)
18/02/28 12:36:30 INFO Executor: Finished task 1.0 in stage 4.0 (TID 11). 3086 bytes result sent to driver
18/02/28 12:36:30 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 11) in 2650 ms on localhost (executor driver) (3/4)
18/02/28 12:36:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 12:36:30 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 12:36:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 12:36:31 INFO MemoryStore: Block rdd_16_0 stored as values in memory (estimated size 698.0 KB, free 363.6 MB)
18/02/28 12:36:31 INFO BlockManagerInfo: Added rdd_16_0 in memory on 127.0.0.1:60625 (size: 698.0 KB, free: 364.5 MB)
18/02/28 12:36:31 INFO Executor: Finished task 0.0 in stage 4.0 (TID 10). 3129 bytes result sent to driver
18/02/28 12:36:31 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 10) in 3026 ms on localhost (executor driver) (4/4)
18/02/28 12:36:31 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/02/28 12:36:31 INFO DAGScheduler: ShuffleMapStage 4 (sql at <unknown>:0) finished in 3.027 s
18/02/28 12:36:31 INFO DAGScheduler: looking for newly runnable stages
18/02/28 12:36:31 INFO DAGScheduler: running: Set()
18/02/28 12:36:31 INFO DAGScheduler: waiting: Set(ResultStage 5)
18/02/28 12:36:31 INFO DAGScheduler: failed: Set()
18/02/28 12:36:31 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[22] at sql at <unknown>:0), which has no missing parents
18/02/28 12:36:31 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.0 KB, free 363.6 MB)
18/02/28 12:36:31 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.7 KB, free 363.6 MB)
18/02/28 12:36:31 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:60625 (size: 3.7 KB, free: 364.5 MB)
18/02/28 12:36:31 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
18/02/28 12:36:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[22] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 12:36:31 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
18/02/28 12:36:31 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 14, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 12:36:31 INFO Executor: Running task 0.0 in stage 5.0 (TID 14)
18/02/28 12:36:31 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:36:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 12:36:31 INFO Executor: Finished task 0.0 in stage 5.0 (TID 14). 1538 bytes result sent to driver
18/02/28 12:36:31 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 14) in 16 ms on localhost (executor driver) (1/1)
18/02/28 12:36:31 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/02/28 12:36:31 INFO DAGScheduler: ResultStage 5 (sql at <unknown>:0) finished in 0.016 s
18/02/28 12:36:31 INFO DAGScheduler: Job 3 finished: sql at <unknown>:0, took 3.074275 s
18/02/28 12:36:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:36:31 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `training`
18/02/28 12:36:31 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:36:31 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:36:31 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 12:36:31 INFO DAGScheduler: Registering RDD 25 (collect at utils.scala:211)
18/02/28 12:36:31 INFO DAGScheduler: Got job 4 (collect at utils.scala:211) with 1 output partitions
18/02/28 12:36:31 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:211)
18/02/28 12:36:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
18/02/28 12:36:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
18/02/28 12:36:31 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[25] at collect at utils.scala:211), which has no missing parents
18/02/28 12:36:31 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 31.7 KB, free 363.6 MB)
18/02/28 12:36:31 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 14.0 KB, free 363.5 MB)
18/02/28 12:36:31 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:60625 (size: 14.0 KB, free: 364.5 MB)
18/02/28 12:36:31 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
18/02/28 12:36:31 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[25] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 12:36:31 INFO TaskSchedulerImpl: Adding task set 6.0 with 4 tasks
18/02/28 12:36:31 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 12:36:31 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 16, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 12:36:31 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 17, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 12:36:31 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 18, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 12:36:31 INFO Executor: Running task 1.0 in stage 6.0 (TID 16)
18/02/28 12:36:31 INFO BlockManager: Found block rdd_16_1 locally
18/02/28 12:36:31 INFO Executor: Running task 2.0 in stage 6.0 (TID 17)
18/02/28 12:36:31 INFO BlockManager: Found block rdd_16_2 locally
18/02/28 12:36:31 INFO Executor: Running task 3.0 in stage 6.0 (TID 18)
18/02/28 12:36:31 INFO Executor: Running task 0.0 in stage 6.0 (TID 15)
18/02/28 12:36:31 INFO BlockManager: Found block rdd_16_0 locally
18/02/28 12:36:31 INFO BlockManager: Found block rdd_16_3 locally
18/02/28 12:36:31 INFO Executor: Finished task 3.0 in stage 6.0 (TID 18). 2319 bytes result sent to driver
18/02/28 12:36:31 INFO Executor: Finished task 1.0 in stage 6.0 (TID 16). 2276 bytes result sent to driver
18/02/28 12:36:31 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 18) in 37 ms on localhost (executor driver) (1/4)
18/02/28 12:36:31 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 16) in 39 ms on localhost (executor driver) (2/4)
18/02/28 12:36:31 INFO Executor: Finished task 0.0 in stage 6.0 (TID 15). 2276 bytes result sent to driver
18/02/28 12:36:31 INFO Executor: Finished task 2.0 in stage 6.0 (TID 17). 2319 bytes result sent to driver
18/02/28 12:36:31 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 15) in 46 ms on localhost (executor driver) (3/4)
18/02/28 12:36:31 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 17) in 45 ms on localhost (executor driver) (4/4)
18/02/28 12:36:31 INFO DAGScheduler: ShuffleMapStage 6 (collect at utils.scala:211) finished in 0.050 s
18/02/28 12:36:31 INFO DAGScheduler: looking for newly runnable stages
18/02/28 12:36:31 INFO DAGScheduler: running: Set()
18/02/28 12:36:31 INFO DAGScheduler: waiting: Set(ResultStage 7)
18/02/28 12:36:31 INFO DAGScheduler: failed: Set()
18/02/28 12:36:31 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[28] at collect at utils.scala:211), which has no missing parents
18/02/28 12:36:31 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.0 KB, free 363.5 MB)
18/02/28 12:36:31 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.7 KB, free 363.5 MB)
18/02/28 12:36:31 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
18/02/28 12:36:31 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:60625 (size: 3.7 KB, free: 364.5 MB)
18/02/28 12:36:31 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
18/02/28 12:36:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[28] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 12:36:31 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
18/02/28 12:36:31 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 19, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 12:36:31 INFO Executor: Running task 0.0 in stage 7.0 (TID 19)
18/02/28 12:36:31 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:36:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 12:36:31 INFO Executor: Finished task 0.0 in stage 7.0 (TID 19). 1495 bytes result sent to driver
18/02/28 12:36:31 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 19) in 5 ms on localhost (executor driver) (1/1)
18/02/28 12:36:31 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
18/02/28 12:36:31 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:211) finished in 0.006 s
18/02/28 12:36:31 INFO DAGScheduler: Job 4 finished: collect at utils.scala:211, took 0.073301 s
18/02/28 12:36:31 INFO CodeGenerator: Code generated in 4.686983 ms
18/02/28 12:36:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:36:57 INFO SparkSqlParser: Parsing command: SELECT * FROM training LIMIT 5
18/02/28 12:36:57 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 12:36:57 INFO DAGScheduler: Got job 5 (collect at utils.scala:211) with 1 output partitions
18/02/28 12:36:57 INFO DAGScheduler: Final stage: ResultStage 8 (collect at utils.scala:211)
18/02/28 12:36:57 INFO DAGScheduler: Parents of final stage: List()
18/02/28 12:36:57 INFO DAGScheduler: Missing parents: List()
18/02/28 12:36:57 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[30] at collect at utils.scala:211), which has no missing parents
18/02/28 12:36:57 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 27.8 KB, free 363.5 MB)
18/02/28 12:36:57 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 12.7 KB, free 363.5 MB)
18/02/28 12:36:57 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:60625 (size: 12.7 KB, free: 364.4 MB)
18/02/28 12:36:57 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
18/02/28 12:36:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[30] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 12:36:57 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
18/02/28 12:36:57 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 6775 bytes)
18/02/28 12:36:57 INFO Executor: Running task 0.0 in stage 8.0 (TID 20)
18/02/28 12:36:57 INFO BlockManager: Found block rdd_16_0 locally
18/02/28 12:36:57 INFO CodeGenerator: Code generated in 15.083893 ms
18/02/28 12:36:57 INFO Executor: 1 block locks were not released by TID = 20:
[rdd_16_0]
18/02/28 12:36:57 INFO Executor: Finished task 0.0 in stage 8.0 (TID 20). 1843 bytes result sent to driver
18/02/28 12:36:57 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 20) in 42 ms on localhost (executor driver) (1/1)
18/02/28 12:36:57 INFO DAGScheduler: ResultStage 8 (collect at utils.scala:211) finished in 0.044 s
18/02/28 12:36:57 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
18/02/28 12:36:57 INFO DAGScheduler: Job 5 finished: collect at utils.scala:211, took 0.050766 s
18/02/28 12:40:40 INFO SparkContext: Invoking stop() from shutdown hook
18/02/28 12:40:40 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
18/02/28 12:40:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/02/28 12:40:40 INFO MemoryStore: MemoryStore cleared
18/02/28 12:40:40 INFO BlockManager: BlockManager stopped
18/02/28 12:40:40 INFO BlockManagerMaster: BlockManagerMaster stopped
18/02/28 12:40:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/02/28 12:40:40 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-e23e35e4-6bea-4bfd-a148-726cc37bfedf\userFiles-070a0c4c-3197-44f0-beb4-5430bd9103c9
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-e23e35e4-6bea-4bfd-a148-726cc37bfedf\userFiles-070a0c4c-3197-44f0-beb4-5430bd9103c9
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1937)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1936)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 12:40:40 INFO SparkContext: Successfully stopped SparkContext
18/02/28 12:40:40 INFO ShutdownHookManager: Shutdown hook called
18/02/28 12:40:40 INFO ShutdownHookManager: Deleting directory C:\Users\JC\AppData\Local\Temp\spark-e23e35e4-6bea-4bfd-a148-726cc37bfedf
18/02/28 12:40:40 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-e23e35e4-6bea-4bfd-a148-726cc37bfedf
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-e23e35e4-6bea-4bfd-a148-726cc37bfedf
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 12:40:40 INFO ShutdownHookManager: Deleting directory C:\Users\JC\AppData\Local\Temp\spark-e23e35e4-6bea-4bfd-a148-726cc37bfedf\userFiles-070a0c4c-3197-44f0-beb4-5430bd9103c9
18/02/28 12:40:40 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-e23e35e4-6bea-4bfd-a148-726cc37bfedf\userFiles-070a0c4c-3197-44f0-beb4-5430bd9103c9
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-e23e35e4-6bea-4bfd-a148-726cc37bfedf\userFiles-070a0c4c-3197-44f0-beb4-5430bd9103c9
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 12:40:50 INFO SparkContext: Running Spark version 2.2.0
18/02/28 12:40:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/02/28 12:40:50 INFO SparkContext: Submitted application: sparklyr
18/02/28 12:40:50 INFO SecurityManager: Changing view acls to: JC
18/02/28 12:40:50 INFO SecurityManager: Changing modify acls to: JC
18/02/28 12:40:50 INFO SecurityManager: Changing view acls groups to: 
18/02/28 12:40:50 INFO SecurityManager: Changing modify acls groups to: 
18/02/28 12:40:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(JC); groups with view permissions: Set(); users  with modify permissions: Set(JC); groups with modify permissions: Set()
18/02/28 12:40:50 INFO Utils: Successfully started service 'sparkDriver' on port 60698.
18/02/28 12:40:50 INFO SparkEnv: Registering MapOutputTracker
18/02/28 12:40:50 INFO SparkEnv: Registering BlockManagerMaster
18/02/28 12:40:50 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/02/28 12:40:50 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/02/28 12:40:50 INFO DiskBlockManager: Created local directory at C:\Users\JC\AppData\Local\Temp\blockmgr-8cf0163f-cad2-45a0-9f98-6498f6d037c2
18/02/28 12:40:50 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/02/28 12:40:51 INFO SparkEnv: Registering OutputCommitCoordinator
18/02/28 12:40:51 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/02/28 12:40:51 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
18/02/28 12:40:51 INFO SparkContext: Added JAR file:/C:/Users/JC/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:60698/jars/sparklyr-2.2-2.11.jar with timestamp 1519850451307
18/02/28 12:40:51 INFO Executor: Starting executor ID driver on host localhost
18/02/28 12:40:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60719.
18/02/28 12:40:51 INFO NettyBlockTransferService: Server created on 127.0.0.1:60719
18/02/28 12:40:51 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/02/28 12:40:51 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 60719, None)
18/02/28 12:40:51 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:60719 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 60719, None)
18/02/28 12:40:51 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 60719, None)
18/02/28 12:40:51 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 60719, None)
18/02/28 12:40:51 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/02/28 12:40:51 INFO SharedState: loading hive config file: file:/C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
18/02/28 12:40:51 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:\Users\JC\AppData\Local\spark\spark-2.2.0-bin-hadoop2.7\tmp\hive') to the value of spark.sql.warehouse.dir ('C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive').
18/02/28 12:40:51 INFO SharedState: Warehouse path is 'C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive'.
18/02/28 12:40:52 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
18/02/28 12:40:53 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
18/02/28 12:40:53 INFO ObjectStore: ObjectStore, initialize called
18/02/28 12:40:53 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
18/02/28 12:40:53 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
18/02/28 12:40:54 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
18/02/28 12:40:55 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 12:40:55 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 12:40:56 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 12:40:56 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 12:40:56 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
18/02/28 12:40:56 INFO ObjectStore: Initialized ObjectStore
18/02/28 12:40:56 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
18/02/28 12:40:56 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
18/02/28 12:40:56 INFO HiveMetaStore: Added admin role in metastore
18/02/28 12:40:56 INFO HiveMetaStore: Added public role in metastore
18/02/28 12:40:56 INFO HiveMetaStore: No user is added in admin role, since config is empty
18/02/28 12:40:56 INFO HiveMetaStore: 0: get_all_databases
18/02/28 12:40:56 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_all_databases	
18/02/28 12:40:56 INFO HiveMetaStore: 0: get_functions: db=default pat=*
18/02/28 12:40:56 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
18/02/28 12:40:56 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 12:40:56 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/Temp/a7b80329-b6ba-4601-aa80-6b55c1e832f9_resources
18/02/28 12:40:56 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/a7b80329-b6ba-4601-aa80-6b55c1e832f9
18/02/28 12:40:56 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/a7b80329-b6ba-4601-aa80-6b55c1e832f9
18/02/28 12:40:56 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/a7b80329-b6ba-4601-aa80-6b55c1e832f9/_tmp_space.db
18/02/28 12:40:56 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive
18/02/28 12:40:57 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:40:57 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:40:57 INFO HiveMetaStore: 0: get_database: global_temp
18/02/28 12:40:57 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: global_temp	
18/02/28 12:40:57 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
18/02/28 12:40:57 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/Temp/b69fc6d4-a8f2-4fbb-92e0-35b4c5e2abe8_resources
18/02/28 12:40:57 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/b69fc6d4-a8f2-4fbb-92e0-35b4c5e2abe8
18/02/28 12:40:57 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/b69fc6d4-a8f2-4fbb-92e0-35b4c5e2abe8
18/02/28 12:40:57 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/b69fc6d4-a8f2-4fbb-92e0-35b4c5e2abe8/_tmp_space.db
18/02/28 12:40:57 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive
18/02/28 12:40:57 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
18/02/28 12:40:57 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:40:58 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:40:58 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:40:58 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:40:58 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:40:58 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:40:58 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:42:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:42:27 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:42:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:42:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:42:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:42:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:42:27 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:42:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:42:27 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 12:42:27 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
18/02/28 12:42:27 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
18/02/28 12:42:27 INFO DAGScheduler: Parents of final stage: List()
18/02/28 12:42:27 INFO DAGScheduler: Missing parents: List()
18/02/28 12:42:27 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55), which has no missing parents
18/02/28 12:42:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
18/02/28 12:42:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
18/02/28 12:42:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:60719 (size: 3.4 KB, free: 366.3 MB)
18/02/28 12:42:27 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
18/02/28 12:42:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0))
18/02/28 12:42:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/02/28 12:42:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 12:42:27 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/02/28 12:42:27 INFO Executor: Fetching spark://127.0.0.1:60698/jars/sparklyr-2.2-2.11.jar with timestamp 1519850451307
18/02/28 12:42:27 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:60698 after 15 ms (0 ms spent in bootstraps)
18/02/28 12:42:27 INFO Utils: Fetching spark://127.0.0.1:60698/jars/sparklyr-2.2-2.11.jar to C:\Users\JC\AppData\Local\Temp\spark-b5512e24-c225-4023-8d08-2c09b0769771\userFiles-0e41f5fe-5b2c-4214-9dad-0fd94427b36f\fetchFileTemp3562262961673174931.tmp
18/02/28 12:42:28 INFO Executor: Adding file:/C:/Users/JC/AppData/Local/Temp/spark-b5512e24-c225-4023-8d08-2c09b0769771/userFiles-0e41f5fe-5b2c-4214-9dad-0fd94427b36f/sparklyr-2.2-2.11.jar to class loader
18/02/28 12:42:28 INFO CodeGenerator: Code generated in 251.530093 ms
18/02/28 12:42:28 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
18/02/28 12:42:28 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 651 ms on localhost (executor driver) (1/1)
18/02/28 12:42:28 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/02/28 12:42:28 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.668 s
18/02/28 12:42:28 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.814397 s
18/02/28 12:42:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:42:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:42:28 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:42:28 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:42:28 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:42:28 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:42:28 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:42:28 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:42:28 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:42:28 INFO SparkSqlParser: Parsing command: spark_fao
18/02/28 12:42:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:42:28 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao` AS `zzz44`
WHERE (0 = 1)
18/02/28 12:42:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:42:28 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:42:28 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:42:28 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:42:28 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:42:28 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:42:28 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:42:28 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:42:28 INFO CodeGenerator: Code generated in 13.271442 ms
18/02/28 12:44:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:44:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao`
18/02/28 12:44:22 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e04cb85d98
18/02/28 12:44:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:44:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e04cb85d98` AS `zzz45`
WHERE (0 = 1)
18/02/28 12:44:22 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e0301e31bf
18/02/28 12:44:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:44:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0301e31bf` AS `zzz46`
WHERE (0 = 1)
18/02/28 12:44:22 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e0a01e96
18/02/28 12:44:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:44:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0a01e96` AS `zzz47`
WHERE (0 = 1)
18/02/28 12:44:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:44:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e04cb85d98`
18/02/28 12:44:30 INFO SparkSqlParser: Parsing command: training
18/02/28 12:44:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:44:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training` AS `zzz48`
WHERE (0 = 1)
18/02/28 12:44:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:44:30 INFO SparkSqlParser: Parsing command: CACHE TABLE `training`
18/02/28 12:44:30 INFO SparkSqlParser: Parsing command: `training`
18/02/28 12:44:30 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 12:44:30 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 12:44:30 INFO FileSourceStrategy: Output Data Schema: struct<year: int, production_area: int, country: string, iso: string, source: string ... 8 more fields>
18/02/28 12:44:30 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 12:44:30 INFO CodeGenerator: Code generated in 30.856094 ms
18/02/28 12:44:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 282.5 KB, free 366.0 MB)
18/02/28 12:44:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 24.1 KB, free 366.0 MB)
18/02/28 12:44:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:60719 (size: 24.1 KB, free: 366.3 MB)
18/02/28 12:44:30 INFO SparkContext: Created broadcast 1 from sql at <unknown>:0
18/02/28 12:44:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 12:44:31 INFO ContextCleaner: Cleaned accumulator 0
18/02/28 12:44:31 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:60719 in memory (size: 3.4 KB, free: 366.3 MB)
18/02/28 12:44:31 INFO CodeGenerator: Code generated in 11.997438 ms
18/02/28 12:44:31 INFO CodeGenerator: Code generated in 8.14545 ms
18/02/28 12:44:31 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 12:44:31 INFO DAGScheduler: Registering RDD 10 (sql at <unknown>:0)
18/02/28 12:44:31 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
18/02/28 12:44:31 INFO DAGScheduler: Final stage: ResultStage 2 (sql at <unknown>:0)
18/02/28 12:44:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
18/02/28 12:44:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
18/02/28 12:44:31 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[10] at sql at <unknown>:0), which has no missing parents
18/02/28 12:44:31 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 31.7 KB, free 366.0 MB)
18/02/28 12:44:31 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.0 KB, free 366.0 MB)
18/02/28 12:44:31 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:60719 (size: 14.0 KB, free: 366.3 MB)
18/02/28 12:44:31 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
18/02/28 12:44:31 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[10] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 12:44:31 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks
18/02/28 12:44:31 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 12:44:31 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 12:44:31 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 12:44:31 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 12:44:31 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
18/02/28 12:44:31 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
18/02/28 12:44:31 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
18/02/28 12:44:31 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
18/02/28 12:44:31 INFO CodeGenerator: Code generated in 36.991627 ms
18/02/28 12:44:31 INFO CodeGenerator: Code generated in 9.89443 ms
18/02/28 12:44:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 12:44:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 12:44:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 12:44:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 12:44:31 INFO CodeGenerator: Code generated in 26.456845 ms
18/02/28 12:44:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 12:44:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 12:44:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 12:44:32 INFO ContextCleaner: Cleaned accumulator 59
18/02/28 12:44:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 12:44:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 12:44:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 12:44:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 12:44:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 12:44:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 12:44:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 12:44:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 12:44:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 12:44:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 12:44:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 12:44:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 12:44:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 12:44:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 12:44:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 12:44:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 12:44:32 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 12:44:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 12:44:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 12:44:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 12:44:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 12:44:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 12:44:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 12:44:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 12:44:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 12:44:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 12:44:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 12:44:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 12:44:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 12:44:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 12:44:33 INFO MemoryStore: Block rdd_7_3 stored as values in memory (estimated size 164.3 KB, free 335.8 MB)
18/02/28 12:44:33 INFO BlockManagerInfo: Added rdd_7_3 in memory on 127.0.0.1:60719 (size: 164.3 KB, free: 366.1 MB)
18/02/28 12:44:33 INFO CodeGenerator: Code generated in 5.19581 ms
18/02/28 12:44:33 INFO CodeGenerator: Code generated in 34.195024 ms
18/02/28 12:44:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 12:44:33 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 3172 bytes result sent to driver
18/02/28 12:44:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 12:44:33 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 2131 ms on localhost (executor driver) (1/4)
18/02/28 12:44:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 12:44:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 12:44:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 12:44:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 12:44:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 12:44:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 12:44:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 12:44:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 12:44:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 12:44:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 12:44:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 12:44:33 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 12:44:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 12:44:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 12:44:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 12:44:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 12:44:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 12:44:34 INFO MemoryStore: Block rdd_7_2 stored as values in memory (estimated size 362.3 KB, free 333.4 MB)
18/02/28 12:44:34 INFO BlockManagerInfo: Added rdd_7_2 in memory on 127.0.0.1:60719 (size: 362.3 KB, free: 365.7 MB)
18/02/28 12:44:34 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 3086 bytes result sent to driver
18/02/28 12:44:34 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 2730 ms on localhost (executor driver) (2/4)
18/02/28 12:44:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 12:44:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 12:44:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 12:44:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 12:44:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 12:44:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 12:44:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 12:44:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 12:44:34 INFO MemoryStore: Block rdd_7_1 stored as values in memory (estimated size 533.4 KB, free 348.9 MB)
18/02/28 12:44:34 INFO BlockManagerInfo: Added rdd_7_1 in memory on 127.0.0.1:60719 (size: 533.4 KB, free: 365.2 MB)
18/02/28 12:44:34 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 3086 bytes result sent to driver
18/02/28 12:44:34 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 3116 ms on localhost (executor driver) (3/4)
18/02/28 12:44:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 12:44:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 12:44:34 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 12:44:34 INFO MemoryStore: Block rdd_7_0 stored as values in memory (estimated size 692.7 KB, free 364.2 MB)
18/02/28 12:44:34 INFO BlockManagerInfo: Added rdd_7_0 in memory on 127.0.0.1:60719 (size: 692.7 KB, free: 364.6 MB)
18/02/28 12:44:34 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 3086 bytes result sent to driver
18/02/28 12:44:34 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 3445 ms on localhost (executor driver) (4/4)
18/02/28 12:44:34 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/02/28 12:44:34 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 3.445 s
18/02/28 12:44:34 INFO DAGScheduler: looking for newly runnable stages
18/02/28 12:44:34 INFO DAGScheduler: running: Set()
18/02/28 12:44:34 INFO DAGScheduler: waiting: Set(ResultStage 2)
18/02/28 12:44:34 INFO DAGScheduler: failed: Set()
18/02/28 12:44:34 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[13] at sql at <unknown>:0), which has no missing parents
18/02/28 12:44:34 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.0 KB, free 364.2 MB)
18/02/28 12:44:34 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.2 MB)
18/02/28 12:44:34 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:60719 (size: 3.7 KB, free: 364.5 MB)
18/02/28 12:44:34 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
18/02/28 12:44:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[13] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 12:44:34 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
18/02/28 12:44:34 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 12:44:34 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
18/02/28 12:44:34 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:44:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
18/02/28 12:44:34 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1538 bytes result sent to driver
18/02/28 12:44:34 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 31 ms on localhost (executor driver) (1/1)
18/02/28 12:44:34 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/02/28 12:44:34 INFO DAGScheduler: ResultStage 2 (sql at <unknown>:0) finished in 0.031 s
18/02/28 12:44:34 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 3.527146 s
18/02/28 12:44:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:44:34 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `training`
18/02/28 12:44:34 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:44:34 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:44:35 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 12:44:35 INFO DAGScheduler: Registering RDD 16 (collect at utils.scala:211)
18/02/28 12:44:35 INFO DAGScheduler: Got job 2 (collect at utils.scala:211) with 1 output partitions
18/02/28 12:44:35 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:211)
18/02/28 12:44:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
18/02/28 12:44:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
18/02/28 12:44:35 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[16] at collect at utils.scala:211), which has no missing parents
18/02/28 12:44:35 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 31.7 KB, free 364.2 MB)
18/02/28 12:44:35 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.0 KB, free 364.2 MB)
18/02/28 12:44:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:60719 (size: 14.0 KB, free: 364.5 MB)
18/02/28 12:44:35 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
18/02/28 12:44:35 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[16] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 12:44:35 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks
18/02/28 12:44:35 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 12:44:35 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 12:44:35 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 8, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 12:44:35 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 9, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 12:44:35 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)
18/02/28 12:44:35 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)
18/02/28 12:44:35 INFO Executor: Running task 2.0 in stage 3.0 (TID 8)
18/02/28 12:44:35 INFO Executor: Running task 3.0 in stage 3.0 (TID 9)
18/02/28 12:44:35 INFO BlockManager: Found block rdd_7_0 locally
18/02/28 12:44:35 INFO BlockManager: Found block rdd_7_3 locally
18/02/28 12:44:35 INFO BlockManager: Found block rdd_7_1 locally
18/02/28 12:44:35 INFO BlockManager: Found block rdd_7_2 locally
18/02/28 12:44:35 INFO Executor: Finished task 2.0 in stage 3.0 (TID 8). 2276 bytes result sent to driver
18/02/28 12:44:35 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 8) in 37 ms on localhost (executor driver) (1/4)
18/02/28 12:44:35 INFO Executor: Finished task 3.0 in stage 3.0 (TID 9). 2319 bytes result sent to driver
18/02/28 12:44:35 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 9) in 54 ms on localhost (executor driver) (2/4)
18/02/28 12:44:35 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 2319 bytes result sent to driver
18/02/28 12:44:35 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 68 ms on localhost (executor driver) (3/4)
18/02/28 12:44:35 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 2276 bytes result sent to driver
18/02/28 12:44:35 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 76 ms on localhost (executor driver) (4/4)
18/02/28 12:44:35 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/02/28 12:44:35 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:211) finished in 0.076 s
18/02/28 12:44:35 INFO DAGScheduler: looking for newly runnable stages
18/02/28 12:44:35 INFO DAGScheduler: running: Set()
18/02/28 12:44:35 INFO DAGScheduler: waiting: Set(ResultStage 4)
18/02/28 12:44:35 INFO DAGScheduler: failed: Set()
18/02/28 12:44:35 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[19] at collect at utils.scala:211), which has no missing parents
18/02/28 12:44:35 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 364.2 MB)
18/02/28 12:44:35 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.2 MB)
18/02/28 12:44:35 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:60719 (size: 3.7 KB, free: 364.5 MB)
18/02/28 12:44:35 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
18/02/28 12:44:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 12:44:35 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
18/02/28 12:44:35 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 10, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 12:44:35 INFO Executor: Running task 0.0 in stage 4.0 (TID 10)
18/02/28 12:44:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:44:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 12:44:35 INFO Executor: Finished task 0.0 in stage 4.0 (TID 10). 1452 bytes result sent to driver
18/02/28 12:44:35 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 10) in 10 ms on localhost (executor driver) (1/1)
18/02/28 12:44:35 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/02/28 12:44:35 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:211) finished in 0.010 s
18/02/28 12:44:35 INFO DAGScheduler: Job 2 finished: collect at utils.scala:211, took 0.110414 s
18/02/28 12:44:35 INFO CodeGenerator: Code generated in 6.476515 ms
18/02/28 12:44:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:44:35 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:44:35 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:44:35 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:44:35 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:44:35 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:44:35 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:44:35 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:44:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:44:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 12:44:42 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:60719 in memory (size: 3.7 KB, free: 364.5 MB)
18/02/28 12:44:42 INFO ContextCleaner: Cleaned accumulator 120
18/02/28 12:44:42 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:60719 in memory (size: 3.7 KB, free: 364.5 MB)
18/02/28 12:44:42 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:60719 in memory (size: 14.0 KB, free: 364.6 MB)
18/02/28 12:44:42 INFO CodeGenerator: Code generated in 28.111324 ms
18/02/28 12:44:42 INFO SparkContext: Starting job: first at LinearRegression.scala:198
18/02/28 12:44:42 INFO DAGScheduler: Got job 3 (first at LinearRegression.scala:198) with 1 output partitions
18/02/28 12:44:42 INFO DAGScheduler: Final stage: ResultStage 5 (first at LinearRegression.scala:198)
18/02/28 12:44:42 INFO DAGScheduler: Parents of final stage: List()
18/02/28 12:44:42 INFO DAGScheduler: Missing parents: List()
18/02/28 12:44:42 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[22] at first at LinearRegression.scala:198), which has no missing parents
18/02/28 12:44:42 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 37.9 KB, free 364.2 MB)
18/02/28 12:44:42 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 16.6 KB, free 364.2 MB)
18/02/28 12:44:42 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:60719 (size: 16.6 KB, free: 364.5 MB)
18/02/28 12:44:42 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
18/02/28 12:44:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[22] at first at LinearRegression.scala:198) (first 15 tasks are for partitions Vector(0))
18/02/28 12:44:42 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
18/02/28 12:44:42 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 6775 bytes)
18/02/28 12:44:42 INFO Executor: Running task 0.0 in stage 5.0 (TID 11)
18/02/28 12:44:42 INFO BlockManager: Found block rdd_7_0 locally
18/02/28 12:44:42 INFO CodeGenerator: Code generated in 19.068112 ms
18/02/28 12:44:42 ERROR Executor: Exception in task 0.0 in stage 5.0 (TID 11)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<year_double_r_formula_30e075ed188c:double>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:395)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:234)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:228)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more
18/02/28 12:44:43 WARN TaskSetManager: Lost task 0.0 in stage 5.0 (TID 11, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<year_double_r_formula_30e075ed188c:double>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:395)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:234)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:228)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more

18/02/28 12:44:43 ERROR TaskSetManager: Task 0 in stage 5.0 failed 1 times; aborting job
18/02/28 12:44:43 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/02/28 12:44:43 INFO TaskSchedulerImpl: Cancelling stage 5
18/02/28 12:44:43 INFO DAGScheduler: ResultStage 5 (first at LinearRegression.scala:198) failed in 0.102 s due to Job aborted due to stage failure: Task 0 in stage 5.0 failed 1 times, most recent failure: Lost task 0.0 in stage 5.0 (TID 11, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<year_double_r_formula_30e075ed188c:double>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:395)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:234)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:228)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more

Driver stacktrace:
18/02/28 12:44:43 INFO DAGScheduler: Job 3 failed: first at LinearRegression.scala:198, took 0.116549 s
18/02/28 12:47:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:47:36 INFO SparkSqlParser: Parsing command: SELECT * FROM training LIMIT 1000
18/02/28 12:47:36 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 12:47:36 INFO DAGScheduler: Got job 4 (collect at utils.scala:211) with 1 output partitions
18/02/28 12:47:36 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:211)
18/02/28 12:47:36 INFO DAGScheduler: Parents of final stage: List()
18/02/28 12:47:36 INFO DAGScheduler: Missing parents: List()
18/02/28 12:47:36 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[24] at collect at utils.scala:211), which has no missing parents
18/02/28 12:47:36 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 27.8 KB, free 364.2 MB)
18/02/28 12:47:36 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 12.7 KB, free 364.2 MB)
18/02/28 12:47:36 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:60719 (size: 12.7 KB, free: 364.5 MB)
18/02/28 12:47:36 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
18/02/28 12:47:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[24] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 12:47:36 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
18/02/28 12:47:36 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 6775 bytes)
18/02/28 12:47:36 INFO Executor: Running task 0.0 in stage 6.0 (TID 12)
18/02/28 12:47:36 INFO BlockManager: Found block rdd_7_0 locally
18/02/28 12:47:36 INFO CodeGenerator: Code generated in 36.781116 ms
18/02/28 12:47:36 INFO Executor: 1 block locks were not released by TID = 12:
[rdd_7_0]
18/02/28 12:47:36 INFO Executor: Finished task 0.0 in stage 6.0 (TID 12). 2296 bytes result sent to driver
18/02/28 12:47:36 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 12) in 65 ms on localhost (executor driver) (1/1)
18/02/28 12:47:36 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:211) finished in 0.067 s
18/02/28 12:47:36 INFO DAGScheduler: Job 4 finished: collect at utils.scala:211, took 0.083200 s
18/02/28 12:47:36 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
18/02/28 12:47:36 INFO CodeGenerator: Code generated in 11.966054 ms
18/02/28 12:49:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:49:13 INFO SparkSqlParser: Parsing command: SELECT `year`, `quantity`
FROM `spark_fao`
18/02/28 12:49:14 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e0220d5afa
18/02/28 12:49:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:49:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0220d5afa` AS `zzz49`
WHERE (0 = 1)
18/02/28 12:49:14 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e059d0a4e
18/02/28 12:49:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:49:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e059d0a4e` AS `zzz50`
WHERE (0 = 1)
18/02/28 12:49:14 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e03825066
18/02/28 12:49:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:49:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e03825066` AS `zzz51`
WHERE (0 = 1)
18/02/28 12:49:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:49:16 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e0220d5afa`
18/02/28 12:49:16 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:49:16 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:49:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:49:16 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e0220d5afa`
18/02/28 12:49:16 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:49:16 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:49:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:49:16 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e0220d5afa`
18/02/28 12:49:16 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:49:16 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:49:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:49:16 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e0220d5afa`
18/02/28 12:49:16 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:49:16 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:49:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:49:16 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e0220d5afa`
18/02/28 12:49:16 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:49:16 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:49:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:49:16 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e0220d5afa`
LIMIT 1000
18/02/28 12:49:16 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:49:16 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:49:16 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 12:49:16 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 12:49:16 INFO FileSourceStrategy: Output Data Schema: struct<year: int, quantity: int>
18/02/28 12:49:16 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 12:49:16 INFO CodeGenerator: Code generated in 16.982734 ms
18/02/28 12:49:16 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 282.5 KB, free 363.9 MB)
18/02/28 12:49:16 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 24.1 KB, free 363.9 MB)
18/02/28 12:49:16 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:60719 (size: 24.1 KB, free: 364.5 MB)
18/02/28 12:49:16 INFO SparkContext: Created broadcast 8 from collect at utils.scala:211
18/02/28 12:49:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 12:49:16 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 12:49:16 INFO DAGScheduler: Registering RDD 27 (collect at utils.scala:211)
18/02/28 12:49:16 INFO DAGScheduler: Got job 5 (collect at utils.scala:211) with 1 output partitions
18/02/28 12:49:16 INFO DAGScheduler: Final stage: ResultStage 8 (collect at utils.scala:211)
18/02/28 12:49:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
18/02/28 12:49:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
18/02/28 12:49:16 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[27] at collect at utils.scala:211), which has no missing parents
18/02/28 12:49:16 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 23.9 KB, free 363.8 MB)
18/02/28 12:49:16 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 12.0 KB, free 363.8 MB)
18/02/28 12:49:16 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:60719 (size: 12.0 KB, free: 364.5 MB)
18/02/28 12:49:16 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
18/02/28 12:49:16 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[27] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 12:49:16 INFO TaskSchedulerImpl: Adding task set 7.0 with 4 tasks
18/02/28 12:49:16 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 12:49:16 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 14, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 12:49:16 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 15, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 12:49:16 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 16, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 12:49:16 INFO Executor: Running task 3.0 in stage 7.0 (TID 16)
18/02/28 12:49:16 INFO Executor: Running task 1.0 in stage 7.0 (TID 14)
18/02/28 12:49:16 INFO Executor: Running task 2.0 in stage 7.0 (TID 15)
18/02/28 12:49:16 INFO Executor: Running task 0.0 in stage 7.0 (TID 13)
18/02/28 12:49:16 INFO CodeGenerator: Code generated in 12.006958 ms
18/02/28 12:49:16 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 12:49:16 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 12:49:16 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 12:49:16 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 12:49:16 INFO CodeGenerator: Code generated in 13.808831 ms
18/02/28 12:49:16 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 12:49:17 INFO Executor: Finished task 3.0 in stage 7.0 (TID 16). 2395 bytes result sent to driver
18/02/28 12:49:17 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 16) in 890 ms on localhost (executor driver) (1/4)
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 12:49:17 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:60719 in memory (size: 12.7 KB, free: 364.5 MB)
18/02/28 12:49:17 INFO ContextCleaner: Cleaned accumulator 182
18/02/28 12:49:17 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:60719 in memory (size: 16.6 KB, free: 364.5 MB)
18/02/28 12:49:17 INFO ContextCleaner: Cleaned accumulator 181
18/02/28 12:49:17 INFO ContextCleaner: Cleaned accumulator 232
18/02/28 12:49:17 INFO Executor: Finished task 2.0 in stage 7.0 (TID 15). 2438 bytes result sent to driver
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 12:49:17 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 15) in 993 ms on localhost (executor driver) (2/4)
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 12:49:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 12:49:17 INFO Executor: Finished task 1.0 in stage 7.0 (TID 14). 2438 bytes result sent to driver
18/02/28 12:49:17 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 14) in 1162 ms on localhost (executor driver) (3/4)
18/02/28 12:49:18 INFO Executor: Finished task 0.0 in stage 7.0 (TID 13). 2395 bytes result sent to driver
18/02/28 12:49:18 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 13) in 1240 ms on localhost (executor driver) (4/4)
18/02/28 12:49:18 INFO DAGScheduler: ShuffleMapStage 7 (collect at utils.scala:211) finished in 1.241 s
18/02/28 12:49:18 INFO DAGScheduler: looking for newly runnable stages
18/02/28 12:49:18 INFO DAGScheduler: running: Set()
18/02/28 12:49:18 INFO DAGScheduler: waiting: Set(ResultStage 8)
18/02/28 12:49:18 INFO DAGScheduler: failed: Set()
18/02/28 12:49:18 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[30] at collect at utils.scala:211), which has no missing parents
18/02/28 12:49:18 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 6.9 KB, free 363.9 MB)
18/02/28 12:49:18 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.7 KB, free 363.9 MB)
18/02/28 12:49:18 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
18/02/28 12:49:18 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:60719 (size: 3.7 KB, free: 364.5 MB)
18/02/28 12:49:18 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
18/02/28 12:49:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[30] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 12:49:18 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
18/02/28 12:49:18 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 17, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 12:49:18 INFO Executor: Running task 0.0 in stage 8.0 (TID 17)
18/02/28 12:49:18 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:49:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 12:49:18 INFO Executor: Finished task 0.0 in stage 8.0 (TID 17). 1428 bytes result sent to driver
18/02/28 12:49:18 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 17) in 5 ms on localhost (executor driver) (1/1)
18/02/28 12:49:18 INFO DAGScheduler: ResultStage 8 (collect at utils.scala:211) finished in 0.005 s
18/02/28 12:49:18 INFO DAGScheduler: Job 5 finished: collect at utils.scala:211, took 1.270564 s
18/02/28 12:49:18 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
18/02/28 12:49:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:49:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0220d5afa`
18/02/28 12:49:19 INFO SparkSqlParser: Parsing command: training
18/02/28 12:49:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:49:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training` AS `zzz52`
WHERE (0 = 1)
18/02/28 12:49:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:49:19 INFO SparkSqlParser: Parsing command: CACHE TABLE `training`
18/02/28 12:49:19 INFO SparkSqlParser: Parsing command: `training`
18/02/28 12:49:19 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 12:49:19 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 12:49:19 INFO FileSourceStrategy: Output Data Schema: struct<year: int, quantity: int>
18/02/28 12:49:19 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 12:49:19 INFO CodeGenerator: Code generated in 14.68191 ms
18/02/28 12:49:19 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 282.5 KB, free 363.6 MB)
18/02/28 12:49:19 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 24.1 KB, free 363.6 MB)
18/02/28 12:49:19 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:60719 (size: 24.1 KB, free: 364.5 MB)
18/02/28 12:49:19 INFO SparkContext: Created broadcast 11 from sql at <unknown>:0
18/02/28 12:49:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 12:49:19 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 12:49:19 INFO DAGScheduler: Registering RDD 36 (sql at <unknown>:0)
18/02/28 12:49:19 INFO DAGScheduler: Got job 6 (sql at <unknown>:0) with 1 output partitions
18/02/28 12:49:19 INFO DAGScheduler: Final stage: ResultStage 10 (sql at <unknown>:0)
18/02/28 12:49:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
18/02/28 12:49:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
18/02/28 12:49:19 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[36] at sql at <unknown>:0), which has no missing parents
18/02/28 12:49:19 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 25.6 KB, free 363.6 MB)
18/02/28 12:49:19 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 12.4 KB, free 363.6 MB)
18/02/28 12:49:19 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:60719 (size: 12.4 KB, free: 364.5 MB)
18/02/28 12:49:19 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
18/02/28 12:49:19 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[36] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 12:49:19 INFO TaskSchedulerImpl: Adding task set 9.0 with 4 tasks
18/02/28 12:49:19 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 12:49:19 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 19, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 12:49:19 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 20, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 12:49:19 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 21, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 12:49:19 INFO Executor: Running task 0.0 in stage 9.0 (TID 18)
18/02/28 12:49:19 INFO Executor: Running task 1.0 in stage 9.0 (TID 19)
18/02/28 12:49:19 INFO Executor: Running task 2.0 in stage 9.0 (TID 20)
18/02/28 12:49:19 INFO Executor: Running task 3.0 in stage 9.0 (TID 21)
18/02/28 12:49:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 12:49:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 12:49:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 12:49:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 12:49:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 12:49:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 12:49:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 12:49:20 INFO ContextCleaner: Cleaned accumulator 310
18/02/28 12:49:20 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:60719 in memory (size: 12.0 KB, free: 364.5 MB)
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 12:49:20 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:60719 in memory (size: 3.7 KB, free: 364.5 MB)
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 12:49:20 INFO MemoryStore: Block rdd_33_3 stored as values in memory (estimated size 9.1 KB, free 339.6 MB)
18/02/28 12:49:20 INFO BlockManagerInfo: Added rdd_33_3 in memory on 127.0.0.1:60719 (size: 9.1 KB, free: 364.5 MB)
18/02/28 12:49:20 INFO MemoryStore: Block rdd_33_2 stored as values in memory (estimated size 14.7 KB, free 347.6 MB)
18/02/28 12:49:20 INFO BlockManagerInfo: Added rdd_33_2 in memory on 127.0.0.1:60719 (size: 14.7 KB, free: 364.5 MB)
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 12:49:20 INFO Executor: Finished task 3.0 in stage 9.0 (TID 21). 3086 bytes result sent to driver
18/02/28 12:49:20 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 21) in 612 ms on localhost (executor driver) (1/4)
18/02/28 12:49:20 INFO Executor: Finished task 2.0 in stage 9.0 (TID 20). 3086 bytes result sent to driver
18/02/28 12:49:20 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 20) in 616 ms on localhost (executor driver) (2/4)
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 12:49:20 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 12:49:20 INFO MemoryStore: Block rdd_33_1 stored as values in memory (estimated size 21.0 KB, free 347.6 MB)
18/02/28 12:49:20 INFO BlockManagerInfo: Added rdd_33_1 in memory on 127.0.0.1:60719 (size: 21.0 KB, free: 364.4 MB)
18/02/28 12:49:20 INFO Executor: Finished task 1.0 in stage 9.0 (TID 19). 3086 bytes result sent to driver
18/02/28 12:49:20 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 19) in 773 ms on localhost (executor driver) (3/4)
18/02/28 12:49:20 INFO MemoryStore: Block rdd_33_0 stored as values in memory (estimated size 24.3 KB, free 363.5 MB)
18/02/28 12:49:20 INFO BlockManagerInfo: Added rdd_33_0 in memory on 127.0.0.1:60719 (size: 24.3 KB, free: 364.4 MB)
18/02/28 12:49:20 INFO Executor: Finished task 0.0 in stage 9.0 (TID 18). 3086 bytes result sent to driver
18/02/28 12:49:20 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 18) in 840 ms on localhost (executor driver) (4/4)
18/02/28 12:49:20 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
18/02/28 12:49:20 INFO DAGScheduler: ShuffleMapStage 9 (sql at <unknown>:0) finished in 0.841 s
18/02/28 12:49:20 INFO DAGScheduler: looking for newly runnable stages
18/02/28 12:49:20 INFO DAGScheduler: running: Set()
18/02/28 12:49:20 INFO DAGScheduler: waiting: Set(ResultStage 10)
18/02/28 12:49:20 INFO DAGScheduler: failed: Set()
18/02/28 12:49:20 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[39] at sql at <unknown>:0), which has no missing parents
18/02/28 12:49:20 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 7.0 KB, free 363.5 MB)
18/02/28 12:49:20 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.7 KB, free 363.5 MB)
18/02/28 12:49:20 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:60719 (size: 3.7 KB, free: 364.4 MB)
18/02/28 12:49:20 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
18/02/28 12:49:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[39] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 12:49:20 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
18/02/28 12:49:20 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 12:49:20 INFO Executor: Running task 0.0 in stage 10.0 (TID 22)
18/02/28 12:49:20 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:49:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 12:49:20 INFO Executor: Finished task 0.0 in stage 10.0 (TID 22). 1495 bytes result sent to driver
18/02/28 12:49:20 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 7 ms on localhost (executor driver) (1/1)
18/02/28 12:49:20 INFO DAGScheduler: ResultStage 10 (sql at <unknown>:0) finished in 0.008 s
18/02/28 12:49:20 INFO DAGScheduler: Job 6 finished: sql at <unknown>:0, took 0.869013 s
18/02/28 12:49:20 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
18/02/28 12:49:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:49:20 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `training`
18/02/28 12:49:20 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:49:20 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:49:20 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 12:49:20 INFO DAGScheduler: Registering RDD 42 (collect at utils.scala:211)
18/02/28 12:49:20 INFO DAGScheduler: Got job 7 (collect at utils.scala:211) with 1 output partitions
18/02/28 12:49:20 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:211)
18/02/28 12:49:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
18/02/28 12:49:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
18/02/28 12:49:20 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[42] at collect at utils.scala:211), which has no missing parents
18/02/28 12:49:20 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 25.6 KB, free 363.5 MB)
18/02/28 12:49:20 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 12.5 KB, free 363.5 MB)
18/02/28 12:49:20 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:60719 (size: 12.5 KB, free: 364.4 MB)
18/02/28 12:49:20 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
18/02/28 12:49:20 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[42] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 12:49:20 INFO TaskSchedulerImpl: Adding task set 11.0 with 4 tasks
18/02/28 12:49:20 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 12:49:20 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 24, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 12:49:20 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 25, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 12:49:20 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 26, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 12:49:20 INFO Executor: Running task 0.0 in stage 11.0 (TID 23)
18/02/28 12:49:20 INFO Executor: Running task 1.0 in stage 11.0 (TID 24)
18/02/28 12:49:20 INFO BlockManager: Found block rdd_33_1 locally
18/02/28 12:49:20 INFO BlockManager: Found block rdd_33_0 locally
18/02/28 12:49:20 INFO Executor: Running task 2.0 in stage 11.0 (TID 25)
18/02/28 12:49:20 INFO Executor: Running task 3.0 in stage 11.0 (TID 26)
18/02/28 12:49:20 INFO BlockManager: Found block rdd_33_2 locally
18/02/28 12:49:20 INFO BlockManager: Found block rdd_33_3 locally
18/02/28 12:49:20 INFO Executor: Finished task 1.0 in stage 11.0 (TID 24). 2276 bytes result sent to driver
18/02/28 12:49:20 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 24) in 43 ms on localhost (executor driver) (1/4)
18/02/28 12:49:20 INFO Executor: Finished task 0.0 in stage 11.0 (TID 23). 2319 bytes result sent to driver
18/02/28 12:49:20 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 23) in 47 ms on localhost (executor driver) (2/4)
18/02/28 12:49:20 INFO Executor: Finished task 2.0 in stage 11.0 (TID 25). 2276 bytes result sent to driver
18/02/28 12:49:20 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 25) in 52 ms on localhost (executor driver) (3/4)
18/02/28 12:49:20 INFO Executor: Finished task 3.0 in stage 11.0 (TID 26). 2362 bytes result sent to driver
18/02/28 12:49:20 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 26) in 54 ms on localhost (executor driver) (4/4)
18/02/28 12:49:20 INFO DAGScheduler: ShuffleMapStage 11 (collect at utils.scala:211) finished in 0.056 s
18/02/28 12:49:20 INFO DAGScheduler: looking for newly runnable stages
18/02/28 12:49:20 INFO DAGScheduler: running: Set()
18/02/28 12:49:20 INFO DAGScheduler: waiting: Set(ResultStage 12)
18/02/28 12:49:20 INFO DAGScheduler: failed: Set()
18/02/28 12:49:20 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[45] at collect at utils.scala:211), which has no missing parents
18/02/28 12:49:20 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.0 KB, free 363.5 MB)
18/02/28 12:49:20 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
18/02/28 12:49:20 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 363.5 MB)
18/02/28 12:49:20 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:60719 (size: 3.7 KB, free: 364.4 MB)
18/02/28 12:49:20 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
18/02/28 12:49:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[45] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 12:49:20 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
18/02/28 12:49:20 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 27, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 12:49:20 INFO Executor: Running task 0.0 in stage 12.0 (TID 27)
18/02/28 12:49:20 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:49:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 12:49:20 INFO Executor: Finished task 0.0 in stage 12.0 (TID 27). 1538 bytes result sent to driver
18/02/28 12:49:20 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 27) in 6 ms on localhost (executor driver) (1/1)
18/02/28 12:49:20 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:211) finished in 0.007 s
18/02/28 12:49:20 INFO DAGScheduler: Job 7 finished: collect at utils.scala:211, took 0.076882 s
18/02/28 12:49:20 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
18/02/28 12:49:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:49:20 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:49:20 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:49:20 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:49:20 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:49:20 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:49:20 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:49:20 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:49:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:49:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 12:49:23 INFO SparkContext: Starting job: first at LinearRegression.scala:198
18/02/28 12:49:23 INFO DAGScheduler: Got job 8 (first at LinearRegression.scala:198) with 1 output partitions
18/02/28 12:49:23 INFO DAGScheduler: Final stage: ResultStage 13 (first at LinearRegression.scala:198)
18/02/28 12:49:23 INFO DAGScheduler: Parents of final stage: List()
18/02/28 12:49:23 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:60719 in memory (size: 12.4 KB, free: 364.4 MB)
18/02/28 12:49:23 INFO DAGScheduler: Missing parents: List()
18/02/28 12:49:23 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[48] at first at LinearRegression.scala:198), which has no missing parents
18/02/28 12:49:23 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 31.9 KB, free 363.5 MB)
18/02/28 12:49:23 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 14.4 KB, free 363.5 MB)
18/02/28 12:49:23 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:60719 (size: 14.4 KB, free: 364.4 MB)
18/02/28 12:49:23 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
18/02/28 12:49:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[48] at first at LinearRegression.scala:198) (first 15 tasks are for partitions Vector(0))
18/02/28 12:49:23 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
18/02/28 12:49:23 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 6775 bytes)
18/02/28 12:49:23 INFO Executor: Running task 0.0 in stage 13.0 (TID 28)
18/02/28 12:49:23 INFO BlockManager: Found block rdd_33_0 locally
18/02/28 12:49:23 ERROR Executor: Exception in task 0.0 in stage 13.0 (TID 28)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<year_double_r_formula_30e033695c2f:double>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:395)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:234)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:228)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more
18/02/28 12:49:23 INFO ContextCleaner: Cleaned accumulator 314
18/02/28 12:49:23 INFO ContextCleaner: Cleaned accumulator 312
18/02/28 12:49:23 WARN TaskSetManager: Lost task 0.0 in stage 13.0 (TID 28, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<year_double_r_formula_30e033695c2f:double>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:395)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:234)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:228)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more

18/02/28 12:49:23 ERROR TaskSetManager: Task 0 in stage 13.0 failed 1 times; aborting job
18/02/28 12:49:23 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
18/02/28 12:49:23 INFO TaskSchedulerImpl: Cancelling stage 13
18/02/28 12:49:23 INFO DAGScheduler: ResultStage 13 (first at LinearRegression.scala:198) failed in 0.016 s due to Job aborted due to stage failure: Task 0 in stage 13.0 failed 1 times, most recent failure: Lost task 0.0 in stage 13.0 (TID 28, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<year_double_r_formula_30e033695c2f:double>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:395)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:234)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:228)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more

Driver stacktrace:
18/02/28 12:49:23 INFO DAGScheduler: Job 8 failed: first at LinearRegression.scala:198, took 0.026358 s
18/02/28 12:49:23 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:60719 in memory (size: 3.7 KB, free: 364.4 MB)
18/02/28 12:49:23 INFO ContextCleaner: Cleaned accumulator 313
18/02/28 12:49:23 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:60719 in memory (size: 12.5 KB, free: 364.4 MB)
18/02/28 12:49:23 INFO ContextCleaner: Cleaned accumulator 315
18/02/28 12:49:23 INFO ContextCleaner: Cleaned accumulator 316
18/02/28 12:49:23 INFO ContextCleaner: Cleaned accumulator 371
18/02/28 12:49:23 INFO ContextCleaner: Cleaned accumulator 317
18/02/28 12:49:23 INFO ContextCleaner: Cleaned shuffle 3
18/02/28 12:49:23 INFO ContextCleaner: Cleaned accumulator 319
18/02/28 12:49:23 INFO ContextCleaner: Cleaned accumulator 318
18/02/28 12:49:23 INFO ContextCleaner: Cleaned accumulator 321
18/02/28 12:49:23 INFO ContextCleaner: Cleaned accumulator 322
18/02/28 12:49:23 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:60719 in memory (size: 3.7 KB, free: 364.4 MB)
18/02/28 12:49:23 INFO ContextCleaner: Cleaned accumulator 320
18/02/28 12:49:23 INFO ContextCleaner: Cleaned accumulator 311
18/02/28 12:52:54 WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:92)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:726)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply$mcV$sp(Executor.scala:755)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:755)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:755)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.executor.Executor$$anon$2.run(Executor.scala:755)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:201)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 14 more
18/02/28 12:53:00 WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
18/02/28 12:57:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:57:24 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:57:24 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:57:24 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:57:24 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:57:24 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:57:24 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:57:24 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:57:24 INFO CodeGenerator: Code generated in 6.471577 ms
18/02/28 12:57:24 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 12:57:24 INFO DAGScheduler: Got job 9 (collect at utils.scala:58) with 4 output partitions
18/02/28 12:57:24 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:58)
18/02/28 12:57:24 INFO DAGScheduler: Parents of final stage: List()
18/02/28 12:57:24 INFO DAGScheduler: Missing parents: List()
18/02/28 12:57:24 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[53] at map at utils.scala:55), which has no missing parents
18/02/28 12:57:24 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 363.5 MB)
18/02/28 12:57:24 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KB, free 363.5 MB)
18/02/28 12:57:24 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:60719 (size: 3.7 KB, free: 364.4 MB)
18/02/28 12:57:24 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
18/02/28 12:57:24 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 14 (MapPartitionsRDD[53] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 12:57:24 INFO TaskSchedulerImpl: Adding task set 14.0 with 4 tasks
18/02/28 12:57:24 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 29, localhost, executor driver, partition 0, PROCESS_LOCAL, 5084 bytes)
18/02/28 12:57:24 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 30, localhost, executor driver, partition 1, PROCESS_LOCAL, 5092 bytes)
18/02/28 12:57:24 INFO TaskSetManager: Starting task 2.0 in stage 14.0 (TID 31, localhost, executor driver, partition 2, PROCESS_LOCAL, 5092 bytes)
18/02/28 12:57:24 INFO TaskSetManager: Starting task 3.0 in stage 14.0 (TID 32, localhost, executor driver, partition 3, PROCESS_LOCAL, 5068 bytes)
18/02/28 12:57:24 INFO Executor: Running task 0.0 in stage 14.0 (TID 29)
18/02/28 12:57:24 INFO Executor: Running task 1.0 in stage 14.0 (TID 30)
18/02/28 12:57:24 INFO Executor: Running task 3.0 in stage 14.0 (TID 32)
18/02/28 12:57:24 INFO Executor: Running task 2.0 in stage 14.0 (TID 31)
18/02/28 12:57:24 INFO Executor: Finished task 1.0 in stage 14.0 (TID 30). 896 bytes result sent to driver
18/02/28 12:57:24 INFO Executor: Finished task 2.0 in stage 14.0 (TID 31). 982 bytes result sent to driver
18/02/28 12:57:24 INFO Executor: Finished task 0.0 in stage 14.0 (TID 29). 967 bytes result sent to driver
18/02/28 12:57:24 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 30) in 8 ms on localhost (executor driver) (1/4)
18/02/28 12:57:24 INFO Executor: Finished task 3.0 in stage 14.0 (TID 32). 921 bytes result sent to driver
18/02/28 12:57:24 INFO TaskSetManager: Finished task 2.0 in stage 14.0 (TID 31) in 8 ms on localhost (executor driver) (2/4)
18/02/28 12:57:24 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 29) in 9 ms on localhost (executor driver) (3/4)
18/02/28 12:57:24 INFO TaskSetManager: Finished task 3.0 in stage 14.0 (TID 32) in 9 ms on localhost (executor driver) (4/4)
18/02/28 12:57:24 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
18/02/28 12:57:24 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:58) finished in 0.009 s
18/02/28 12:57:24 INFO DAGScheduler: Job 9 finished: collect at utils.scala:58, took 0.014893 s
18/02/28 12:57:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:57:24 INFO MapPartitionsRDD: Removing RDD 7 from persistence list
18/02/28 12:57:24 INFO BlockManager: Removing RDD 7
18/02/28 12:57:24 INFO MapPartitionsRDD: Removing RDD 33 from persistence list
18/02/28 12:57:24 INFO BlockManager: Removing RDD 33
18/02/28 12:57:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:57:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:57:24 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:57:24 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:57:24 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:57:24 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:57:24 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:57:24 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:57:24 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:57:24 INFO SparkSqlParser: Parsing command: spark_fao
18/02/28 12:57:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:57:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao` AS `zzz53`
WHERE (0 = 1)
18/02/28 12:57:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:57:24 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 12:57:24 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:57:24 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:57:24 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:57:24 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:57:24 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 12:57:24 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 12:58:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:58:18 INFO SparkSqlParser: Parsing command: SELECT `month`, SUM(`quantity`) AS `sum(quantity)`
FROM `spark_fao`
GROUP BY `month`
18/02/28 12:58:18 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:58:18 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:58:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:58:26 INFO SparkSqlParser: Parsing command: SELECT `month`, count(*) AS `n()`
FROM `spark_fao`
GROUP BY `month`
18/02/28 12:58:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:58:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:58:26 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 12:58:26 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 12:58:26 INFO FileSourceStrategy: Output Data Schema: struct<month: int>
18/02/28 12:58:26 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 12:58:27 INFO CodeGenerator: Code generated in 23.732528 ms
18/02/28 12:58:27 INFO CodeGenerator: Code generated in 32.187576 ms
18/02/28 12:58:27 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 282.5 KB, free 365.0 MB)
18/02/28 12:58:27 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.0 MB)
18/02/28 12:58:27 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:60719 (size: 24.1 KB, free: 366.2 MB)
18/02/28 12:58:27 INFO SparkContext: Created broadcast 18 from collect at utils.scala:211
18/02/28 12:58:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 12:58:27 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 12:58:27 INFO DAGScheduler: Registering RDD 56 (collect at utils.scala:211)
18/02/28 12:58:27 INFO DAGScheduler: Got job 10 (collect at utils.scala:211) with 4 output partitions
18/02/28 12:58:27 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:211)
18/02/28 12:58:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
18/02/28 12:58:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 15)
18/02/28 12:58:27 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[56] at collect at utils.scala:211), which has no missing parents
18/02/28 12:58:27 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 26.1 KB, free 365.0 MB)
18/02/28 12:58:27 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 13.1 KB, free 365.0 MB)
18/02/28 12:58:27 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:60719 (size: 13.1 KB, free: 366.2 MB)
18/02/28 12:58:27 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
18/02/28 12:58:27 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[56] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 12:58:27 INFO TaskSchedulerImpl: Adding task set 15.0 with 4 tasks
18/02/28 12:58:27 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 12:58:27 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 34, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 12:58:27 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 35, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 12:58:27 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 36, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 12:58:27 INFO Executor: Running task 2.0 in stage 15.0 (TID 35)
18/02/28 12:58:27 INFO Executor: Running task 0.0 in stage 15.0 (TID 33)
18/02/28 12:58:27 INFO Executor: Running task 1.0 in stage 15.0 (TID 34)
18/02/28 12:58:27 INFO Executor: Running task 3.0 in stage 15.0 (TID 36)
18/02/28 12:58:27 INFO CodeGenerator: Code generated in 9.281582 ms
18/02/28 12:58:27 INFO CodeGenerator: Code generated in 22.908462 ms
18/02/28 12:58:27 INFO CodeGenerator: Code generated in 10.759399 ms
18/02/28 12:58:27 INFO CodeGenerator: Code generated in 15.191089 ms
18/02/28 12:58:27 INFO CodeGenerator: Code generated in 15.624455 ms
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 12:58:27 INFO ContextCleaner: Cleaned accumulator 433
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 12:58:27 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:60719 in memory (size: 3.7 KB, free: 366.2 MB)
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 12:58:27 INFO ContextCleaner: Cleaned accumulator 458
18/02/28 12:58:27 INFO ContextCleaner: Cleaned accumulator 432
18/02/28 12:58:27 INFO ContextCleaner: Cleaned accumulator 483
18/02/28 12:58:27 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:60719 in memory (size: 14.4 KB, free: 366.2 MB)
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 12:58:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 12:58:28 INFO Executor: Finished task 3.0 in stage 15.0 (TID 36). 2060 bytes result sent to driver
18/02/28 12:58:28 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 36) in 914 ms on localhost (executor driver) (1/4)
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 12:58:28 INFO Executor: Finished task 2.0 in stage 15.0 (TID 35). 2060 bytes result sent to driver
18/02/28 12:58:28 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 35) in 1392 ms on localhost (executor driver) (2/4)
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 12:58:28 INFO Executor: Finished task 1.0 in stage 15.0 (TID 34). 2060 bytes result sent to driver
18/02/28 12:58:28 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 34) in 1723 ms on localhost (executor driver) (3/4)
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 12:58:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 12:58:29 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 12:58:29 INFO Executor: Finished task 0.0 in stage 15.0 (TID 33). 2060 bytes result sent to driver
18/02/28 12:58:29 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 33) in 1946 ms on localhost (executor driver) (4/4)
18/02/28 12:58:29 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
18/02/28 12:58:29 INFO DAGScheduler: ShuffleMapStage 15 (collect at utils.scala:211) finished in 1.946 s
18/02/28 12:58:29 INFO DAGScheduler: looking for newly runnable stages
18/02/28 12:58:29 INFO DAGScheduler: running: Set()
18/02/28 12:58:29 INFO DAGScheduler: waiting: Set(ResultStage 16)
18/02/28 12:58:29 INFO DAGScheduler: failed: Set()
18/02/28 12:58:29 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[59] at collect at utils.scala:211), which has no missing parents
18/02/28 12:58:29 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 24.7 KB, free 365.0 MB)
18/02/28 12:58:29 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 12.3 KB, free 365.0 MB)
18/02/28 12:58:29 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:60719 (size: 12.3 KB, free: 366.2 MB)
18/02/28 12:58:29 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
18/02/28 12:58:29 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 16 (MapPartitionsRDD[59] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 12:58:29 INFO TaskSchedulerImpl: Adding task set 16.0 with 4 tasks
18/02/28 12:58:29 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 37, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 12:58:29 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 38, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 12:58:29 INFO TaskSetManager: Starting task 2.0 in stage 16.0 (TID 39, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 12:58:29 INFO TaskSetManager: Starting task 3.0 in stage 16.0 (TID 40, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 12:58:29 INFO Executor: Running task 0.0 in stage 16.0 (TID 37)
18/02/28 12:58:29 INFO Executor: Running task 1.0 in stage 16.0 (TID 38)
18/02/28 12:58:29 INFO Executor: Running task 2.0 in stage 16.0 (TID 39)
18/02/28 12:58:29 INFO Executor: Running task 3.0 in stage 16.0 (TID 40)
18/02/28 12:58:29 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:58:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 12:58:29 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:58:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 12:58:29 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:58:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 12:58:29 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:58:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 12:58:29 INFO Executor: Finished task 2.0 in stage 16.0 (TID 39). 2603 bytes result sent to driver
18/02/28 12:58:29 INFO Executor: Finished task 3.0 in stage 16.0 (TID 40). 2611 bytes result sent to driver
18/02/28 12:58:29 INFO TaskSetManager: Finished task 2.0 in stage 16.0 (TID 39) in 15 ms on localhost (executor driver) (1/4)
18/02/28 12:58:29 INFO TaskSetManager: Finished task 3.0 in stage 16.0 (TID 40) in 15 ms on localhost (executor driver) (2/4)
18/02/28 12:58:29 INFO Executor: Finished task 1.0 in stage 16.0 (TID 38). 2597 bytes result sent to driver
18/02/28 12:58:29 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 38) in 17 ms on localhost (executor driver) (3/4)
18/02/28 12:58:29 INFO Executor: Finished task 0.0 in stage 16.0 (TID 37). 2494 bytes result sent to driver
18/02/28 12:58:29 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 37) in 20 ms on localhost (executor driver) (4/4)
18/02/28 12:58:29 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
18/02/28 12:58:29 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:211) finished in 0.021 s
18/02/28 12:58:29 INFO DAGScheduler: Job 10 finished: collect at utils.scala:211, took 1.982070 s
18/02/28 12:58:29 INFO CodeGenerator: Code generated in 6.304084 ms
18/02/28 12:58:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:58:38 INFO SparkSqlParser: Parsing command: SELECT `month`, count(*) AS `n()`
FROM `spark_fao`
GROUP BY `month`
18/02/28 12:58:38 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:58:38 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:58:38 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 12:58:38 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 12:58:38 INFO FileSourceStrategy: Output Data Schema: struct<month: int>
18/02/28 12:58:38 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 12:58:38 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 282.5 KB, free 364.7 MB)
18/02/28 12:58:38 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.7 MB)
18/02/28 12:58:38 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:60719 (size: 24.1 KB, free: 366.1 MB)
18/02/28 12:58:38 INFO SparkContext: Created broadcast 21 from collect at utils.scala:211
18/02/28 12:58:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 12:58:38 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 12:58:38 INFO DAGScheduler: Registering RDD 62 (collect at utils.scala:211)
18/02/28 12:58:38 INFO DAGScheduler: Got job 11 (collect at utils.scala:211) with 4 output partitions
18/02/28 12:58:38 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:211)
18/02/28 12:58:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
18/02/28 12:58:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
18/02/28 12:58:38 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[62] at collect at utils.scala:211), which has no missing parents
18/02/28 12:58:38 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 26.1 KB, free 364.7 MB)
18/02/28 12:58:38 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 13.1 KB, free 364.6 MB)
18/02/28 12:58:38 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:60719 (size: 13.1 KB, free: 366.1 MB)
18/02/28 12:58:38 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
18/02/28 12:58:38 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[62] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 12:58:38 INFO TaskSchedulerImpl: Adding task set 17.0 with 4 tasks
18/02/28 12:58:38 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 41, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 12:58:38 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 42, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 12:58:38 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 43, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 12:58:38 INFO TaskSetManager: Starting task 3.0 in stage 17.0 (TID 44, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 12:58:38 INFO Executor: Running task 2.0 in stage 17.0 (TID 43)
18/02/28 12:58:38 INFO Executor: Running task 3.0 in stage 17.0 (TID 44)
18/02/28 12:58:38 INFO Executor: Running task 0.0 in stage 17.0 (TID 41)
18/02/28 12:58:38 INFO Executor: Running task 1.0 in stage 17.0 (TID 42)
18/02/28 12:58:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 12:58:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 12:58:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 12:58:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 12:58:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 12:58:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 12:58:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 12:58:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 12:58:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 12:58:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 12:58:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 12:58:38 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:60719 in memory (size: 13.1 KB, free: 366.1 MB)
18/02/28 12:58:38 INFO ContextCleaner: Cleaned accumulator 547
18/02/28 12:58:38 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:60719 in memory (size: 12.3 KB, free: 366.2 MB)
18/02/28 12:58:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 12:58:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 12:58:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 12:58:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 12:58:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 12:58:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 12:58:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 12:58:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 12:58:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 12:58:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 12:58:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 12:58:39 INFO Executor: Finished task 3.0 in stage 17.0 (TID 44). 2060 bytes result sent to driver
18/02/28 12:58:39 INFO TaskSetManager: Finished task 3.0 in stage 17.0 (TID 44) in 830 ms on localhost (executor driver) (1/4)
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 12:58:39 INFO Executor: Finished task 2.0 in stage 17.0 (TID 43). 2060 bytes result sent to driver
18/02/28 12:58:39 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 43) in 1227 ms on localhost (executor driver) (2/4)
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 12:58:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 12:58:40 INFO Executor: Finished task 1.0 in stage 17.0 (TID 42). 2060 bytes result sent to driver
18/02/28 12:58:40 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 42) in 1571 ms on localhost (executor driver) (3/4)
18/02/28 12:58:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 12:58:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 12:58:40 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 12:58:40 INFO Executor: Finished task 0.0 in stage 17.0 (TID 41). 2060 bytes result sent to driver
18/02/28 12:58:40 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 41) in 1784 ms on localhost (executor driver) (4/4)
18/02/28 12:58:40 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
18/02/28 12:58:40 INFO DAGScheduler: ShuffleMapStage 17 (collect at utils.scala:211) finished in 1.785 s
18/02/28 12:58:40 INFO DAGScheduler: looking for newly runnable stages
18/02/28 12:58:40 INFO DAGScheduler: running: Set()
18/02/28 12:58:40 INFO DAGScheduler: waiting: Set(ResultStage 18)
18/02/28 12:58:40 INFO DAGScheduler: failed: Set()
18/02/28 12:58:40 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[65] at collect at utils.scala:211), which has no missing parents
18/02/28 12:58:40 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 24.7 KB, free 364.7 MB)
18/02/28 12:58:40 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 12.3 KB, free 364.7 MB)
18/02/28 12:58:40 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:60719 (size: 12.3 KB, free: 366.1 MB)
18/02/28 12:58:40 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
18/02/28 12:58:40 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 18 (MapPartitionsRDD[65] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 12:58:40 INFO TaskSchedulerImpl: Adding task set 18.0 with 4 tasks
18/02/28 12:58:40 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 45, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 12:58:40 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 46, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 12:58:40 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 47, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 12:58:40 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 48, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 12:58:40 INFO Executor: Running task 1.0 in stage 18.0 (TID 46)
18/02/28 12:58:40 INFO Executor: Running task 2.0 in stage 18.0 (TID 47)
18/02/28 12:58:40 INFO Executor: Running task 3.0 in stage 18.0 (TID 48)
18/02/28 12:58:40 INFO Executor: Running task 0.0 in stage 18.0 (TID 45)
18/02/28 12:58:40 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:58:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 12:58:40 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:58:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 12:58:40 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:58:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 12:58:40 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:58:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 12:58:40 INFO Executor: Finished task 0.0 in stage 18.0 (TID 45). 2494 bytes result sent to driver
18/02/28 12:58:40 INFO Executor: Finished task 1.0 in stage 18.0 (TID 46). 2554 bytes result sent to driver
18/02/28 12:58:40 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 45) in 13 ms on localhost (executor driver) (1/4)
18/02/28 12:58:40 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 46) in 14 ms on localhost (executor driver) (2/4)
18/02/28 12:58:40 INFO Executor: Finished task 2.0 in stage 18.0 (TID 47). 2646 bytes result sent to driver
18/02/28 12:58:40 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 47) in 20 ms on localhost (executor driver) (3/4)
18/02/28 12:58:40 INFO Executor: Finished task 3.0 in stage 18.0 (TID 48). 2654 bytes result sent to driver
18/02/28 12:58:40 INFO TaskSetManager: Finished task 3.0 in stage 18.0 (TID 48) in 23 ms on localhost (executor driver) (4/4)
18/02/28 12:58:40 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
18/02/28 12:58:40 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:211) finished in 0.024 s
18/02/28 12:58:40 INFO DAGScheduler: Job 11 finished: collect at utils.scala:211, took 1.818557 s
18/02/28 12:59:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:59:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao`
LIMIT 6
18/02/28 12:59:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:59:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao`
LIMIT 6
18/02/28 12:59:17 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 12:59:17 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 12:59:17 INFO FileSourceStrategy: Output Data Schema: struct<year: int, month: int, day: int, dep_time: int, sched_dep_time: int ... 17 more fields>
18/02/28 12:59:17 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 12:59:17 INFO CodeGenerator: Code generated in 5.184527 ms
18/02/28 12:59:17 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 282.5 KB, free 364.4 MB)
18/02/28 12:59:17 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.4 MB)
18/02/28 12:59:17 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:60719 (size: 24.1 KB, free: 366.1 MB)
18/02/28 12:59:17 INFO SparkContext: Created broadcast 24 from collect at utils.scala:211
18/02/28 12:59:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 12:59:17 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 12:59:17 INFO DAGScheduler: Got job 12 (collect at utils.scala:211) with 1 output partitions
18/02/28 12:59:17 INFO DAGScheduler: Final stage: ResultStage 19 (collect at utils.scala:211)
18/02/28 12:59:17 INFO DAGScheduler: Parents of final stage: List()
18/02/28 12:59:17 INFO DAGScheduler: Missing parents: List()
18/02/28 12:59:17 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[68] at collect at utils.scala:211), which has no missing parents
18/02/28 12:59:17 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 12.6 KB, free 364.4 MB)
18/02/28 12:59:17 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 7.1 KB, free 364.4 MB)
18/02/28 12:59:17 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:60719 (size: 7.1 KB, free: 366.1 MB)
18/02/28 12:59:17 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1006
18/02/28 12:59:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[68] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 12:59:17 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
18/02/28 12:59:17 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 6775 bytes)
18/02/28 12:59:17 INFO Executor: Running task 0.0 in stage 19.0 (TID 49)
18/02/28 12:59:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 12:59:17 INFO CodeGenerator: Code generated in 10.858837 ms
18/02/28 12:59:17 INFO Executor: Finished task 0.0 in stage 19.0 (TID 49). 1114 bytes result sent to driver
18/02/28 12:59:17 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 49) in 20 ms on localhost (executor driver) (1/1)
18/02/28 12:59:17 INFO DAGScheduler: ResultStage 19 (collect at utils.scala:211) finished in 0.022 s
18/02/28 12:59:17 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
18/02/28 12:59:17 INFO DAGScheduler: Job 12 finished: collect at utils.scala:211, took 0.028439 s
18/02/28 12:59:17 INFO CodeGenerator: Code generated in 9.666287 ms
18/02/28 12:59:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:59:51 INFO SparkSqlParser: Parsing command: SELECT `month`, count(*) AS `n`
FROM `spark_fao`
GROUP BY `month`
18/02/28 12:59:51 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:59:51 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:59:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 12:59:51 INFO SparkSqlParser: Parsing command: SELECT `month`, count(*) AS `n`
FROM `spark_fao`
GROUP BY `month`
LIMIT 10
18/02/28 12:59:51 INFO HiveMetaStore: 0: get_database: default
18/02/28 12:59:51 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 12:59:51 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 12:59:51 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 12:59:51 INFO FileSourceStrategy: Output Data Schema: struct<month: int>
18/02/28 12:59:51 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 12:59:51 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 282.5 KB, free 364.1 MB)
18/02/28 12:59:51 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.1 MB)
18/02/28 12:59:51 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:60719 (size: 24.1 KB, free: 366.1 MB)
18/02/28 12:59:51 INFO SparkContext: Created broadcast 26 from collect at utils.scala:211
18/02/28 12:59:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 12:59:51 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 12:59:51 INFO DAGScheduler: Registering RDD 71 (collect at utils.scala:211)
18/02/28 12:59:51 INFO DAGScheduler: Got job 13 (collect at utils.scala:211) with 1 output partitions
18/02/28 12:59:51 INFO DAGScheduler: Final stage: ResultStage 21 (collect at utils.scala:211)
18/02/28 12:59:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
18/02/28 12:59:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
18/02/28 12:59:51 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[71] at collect at utils.scala:211), which has no missing parents
18/02/28 12:59:51 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 26.1 KB, free 364.0 MB)
18/02/28 12:59:51 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 13.1 KB, free 364.0 MB)
18/02/28 12:59:51 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:60719 (size: 13.1 KB, free: 366.1 MB)
18/02/28 12:59:51 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
18/02/28 12:59:51 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[71] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 12:59:51 INFO TaskSchedulerImpl: Adding task set 20.0 with 4 tasks
18/02/28 12:59:51 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 12:59:51 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 51, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 12:59:51 INFO TaskSetManager: Starting task 2.0 in stage 20.0 (TID 52, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 12:59:51 INFO TaskSetManager: Starting task 3.0 in stage 20.0 (TID 53, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 12:59:51 INFO Executor: Running task 0.0 in stage 20.0 (TID 50)
18/02/28 12:59:51 INFO Executor: Running task 1.0 in stage 20.0 (TID 51)
18/02/28 12:59:51 INFO Executor: Running task 3.0 in stage 20.0 (TID 53)
18/02/28 12:59:51 INFO Executor: Running task 2.0 in stage 20.0 (TID 52)
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 12:59:51 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:60719 in memory (size: 13.1 KB, free: 366.1 MB)
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 12:59:51 INFO ContextCleaner: Cleaned accumulator 640
18/02/28 12:59:51 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:60719 in memory (size: 12.3 KB, free: 366.1 MB)
18/02/28 12:59:51 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:60719 in memory (size: 7.1 KB, free: 366.1 MB)
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 12:59:51 INFO Executor: Finished task 3.0 in stage 20.0 (TID 53). 2103 bytes result sent to driver
18/02/28 12:59:51 INFO TaskSetManager: Finished task 3.0 in stage 20.0 (TID 53) in 548 ms on localhost (executor driver) (1/4)
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 12:59:51 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 12:59:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 12:59:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 12:59:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 12:59:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 12:59:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 12:59:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 12:59:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 12:59:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 12:59:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 12:59:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 12:59:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 12:59:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 12:59:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 12:59:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 12:59:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 12:59:52 INFO Executor: Finished task 2.0 in stage 20.0 (TID 52). 2103 bytes result sent to driver
18/02/28 12:59:52 INFO TaskSetManager: Finished task 2.0 in stage 20.0 (TID 52) in 927 ms on localhost (executor driver) (2/4)
18/02/28 12:59:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 12:59:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 12:59:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 12:59:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 12:59:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 12:59:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 12:59:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 12:59:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 12:59:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 12:59:52 INFO Executor: Finished task 1.0 in stage 20.0 (TID 51). 2060 bytes result sent to driver
18/02/28 12:59:52 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 51) in 1182 ms on localhost (executor driver) (3/4)
18/02/28 12:59:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 12:59:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 12:59:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 12:59:52 INFO Executor: Finished task 0.0 in stage 20.0 (TID 50). 2060 bytes result sent to driver
18/02/28 12:59:52 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 50) in 1363 ms on localhost (executor driver) (4/4)
18/02/28 12:59:52 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
18/02/28 12:59:52 INFO DAGScheduler: ShuffleMapStage 20 (collect at utils.scala:211) finished in 1.364 s
18/02/28 12:59:52 INFO DAGScheduler: looking for newly runnable stages
18/02/28 12:59:52 INFO DAGScheduler: running: Set()
18/02/28 12:59:52 INFO DAGScheduler: waiting: Set(ResultStage 21)
18/02/28 12:59:52 INFO DAGScheduler: failed: Set()
18/02/28 12:59:52 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[74] at collect at utils.scala:211), which has no missing parents
18/02/28 12:59:52 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 24.5 KB, free 364.1 MB)
18/02/28 12:59:52 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 12.3 KB, free 364.1 MB)
18/02/28 12:59:52 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:60719 (size: 12.3 KB, free: 366.1 MB)
18/02/28 12:59:52 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
18/02/28 12:59:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[74] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 12:59:52 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
18/02/28 12:59:52 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 54, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 12:59:52 INFO Executor: Running task 0.0 in stage 21.0 (TID 54)
18/02/28 12:59:52 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:59:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 12:59:52 INFO Executor: Finished task 0.0 in stage 21.0 (TID 54). 2470 bytes result sent to driver
18/02/28 12:59:52 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 54) in 5 ms on localhost (executor driver) (1/1)
18/02/28 12:59:52 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
18/02/28 12:59:52 INFO DAGScheduler: ResultStage 21 (collect at utils.scala:211) finished in 0.005 s
18/02/28 12:59:52 INFO DAGScheduler: Job 13 finished: collect at utils.scala:211, took 1.376297 s
18/02/28 12:59:52 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 12:59:52 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 7 is 167 bytes
18/02/28 12:59:52 INFO DAGScheduler: Got job 14 (collect at utils.scala:211) with 3 output partitions
18/02/28 12:59:52 INFO DAGScheduler: Final stage: ResultStage 23 (collect at utils.scala:211)
18/02/28 12:59:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
18/02/28 12:59:52 INFO DAGScheduler: Missing parents: List()
18/02/28 12:59:52 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[74] at collect at utils.scala:211), which has no missing parents
18/02/28 12:59:52 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 24.5 KB, free 364.1 MB)
18/02/28 12:59:52 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 12.3 KB, free 364.0 MB)
18/02/28 12:59:52 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:60719 (size: 12.3 KB, free: 366.1 MB)
18/02/28 12:59:52 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
18/02/28 12:59:52 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 23 (MapPartitionsRDD[74] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(1, 2, 3))
18/02/28 12:59:52 INFO TaskSchedulerImpl: Adding task set 23.0 with 3 tasks
18/02/28 12:59:52 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 55, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 12:59:52 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 56, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 12:59:52 INFO TaskSetManager: Starting task 2.0 in stage 23.0 (TID 57, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 12:59:52 INFO Executor: Running task 2.0 in stage 23.0 (TID 57)
18/02/28 12:59:52 INFO Executor: Running task 0.0 in stage 23.0 (TID 55)
18/02/28 12:59:52 INFO Executor: Running task 1.0 in stage 23.0 (TID 56)
18/02/28 12:59:52 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:59:52 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:59:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 12:59:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 12:59:52 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 12:59:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 12:59:52 INFO Executor: Finished task 1.0 in stage 23.0 (TID 56). 2576 bytes result sent to driver
18/02/28 12:59:52 INFO Executor: Finished task 2.0 in stage 23.0 (TID 57). 2584 bytes result sent to driver
18/02/28 12:59:52 INFO Executor: Finished task 0.0 in stage 23.0 (TID 55). 2530 bytes result sent to driver
18/02/28 12:59:52 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 56) in 9 ms on localhost (executor driver) (1/3)
18/02/28 12:59:52 INFO TaskSetManager: Finished task 2.0 in stage 23.0 (TID 57) in 10 ms on localhost (executor driver) (2/3)
18/02/28 12:59:52 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 55) in 11 ms on localhost (executor driver) (3/3)
18/02/28 12:59:52 INFO DAGScheduler: ResultStage 23 (collect at utils.scala:211) finished in 0.011 s
18/02/28 12:59:52 INFO DAGScheduler: Job 14 finished: collect at utils.scala:211, took 0.019936 s
18/02/28 12:59:52 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
18/02/28 13:01:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:01:59 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 13:01:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:01:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:01:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:01:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:01:59 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 13:01:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 13:01:59 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 13:01:59 INFO DAGScheduler: Got job 15 (collect at utils.scala:58) with 4 output partitions
18/02/28 13:01:59 INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:58)
18/02/28 13:01:59 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:01:59 INFO DAGScheduler: Missing parents: List()
18/02/28 13:01:59 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[79] at map at utils.scala:55), which has no missing parents
18/02/28 13:01:59 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 7.0 KB, free 364.0 MB)
18/02/28 13:01:59 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.0 MB)
18/02/28 13:01:59 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:60719 (size: 3.7 KB, free: 366.1 MB)
18/02/28 13:01:59 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1006
18/02/28 13:01:59 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 24 (MapPartitionsRDD[79] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:01:59 INFO TaskSchedulerImpl: Adding task set 24.0 with 4 tasks
18/02/28 13:01:59 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 58, localhost, executor driver, partition 0, PROCESS_LOCAL, 5084 bytes)
18/02/28 13:01:59 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 59, localhost, executor driver, partition 1, PROCESS_LOCAL, 5092 bytes)
18/02/28 13:01:59 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 60, localhost, executor driver, partition 2, PROCESS_LOCAL, 5092 bytes)
18/02/28 13:01:59 INFO TaskSetManager: Starting task 3.0 in stage 24.0 (TID 61, localhost, executor driver, partition 3, PROCESS_LOCAL, 5068 bytes)
18/02/28 13:01:59 INFO Executor: Running task 1.0 in stage 24.0 (TID 59)
18/02/28 13:01:59 INFO Executor: Running task 0.0 in stage 24.0 (TID 58)
18/02/28 13:01:59 INFO Executor: Running task 2.0 in stage 24.0 (TID 60)
18/02/28 13:01:59 INFO Executor: Running task 3.0 in stage 24.0 (TID 61)
18/02/28 13:01:59 INFO Executor: Finished task 0.0 in stage 24.0 (TID 58). 924 bytes result sent to driver
18/02/28 13:01:59 INFO Executor: Finished task 1.0 in stage 24.0 (TID 59). 939 bytes result sent to driver
18/02/28 13:01:59 INFO Executor: Finished task 2.0 in stage 24.0 (TID 60). 939 bytes result sent to driver
18/02/28 13:01:59 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 58) in 4 ms on localhost (executor driver) (1/4)
18/02/28 13:01:59 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 60) in 5 ms on localhost (executor driver) (2/4)
18/02/28 13:01:59 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 59) in 5 ms on localhost (executor driver) (3/4)
18/02/28 13:01:59 INFO Executor: Finished task 3.0 in stage 24.0 (TID 61). 921 bytes result sent to driver
18/02/28 13:01:59 INFO TaskSetManager: Finished task 3.0 in stage 24.0 (TID 61) in 5 ms on localhost (executor driver) (4/4)
18/02/28 13:01:59 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
18/02/28 13:01:59 INFO DAGScheduler: ResultStage 24 (collect at utils.scala:58) finished in 0.005 s
18/02/28 13:01:59 INFO DAGScheduler: Job 15 finished: collect at utils.scala:58, took 0.010858 s
18/02/28 13:01:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:01:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:01:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:01:59 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 13:01:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:01:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:01:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:01:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:01:59 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 13:01:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 13:01:59 INFO SparkSqlParser: Parsing command: spark_fao
18/02/28 13:01:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:01:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_fao` AS `zzz54`
WHERE (0 = 1)
18/02/28 13:01:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:01:59 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 13:01:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:01:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:01:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:01:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:01:59 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 13:01:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 13:02:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:02:05 INFO SparkSqlParser: Parsing command: SELECT `month`, count(*) AS `n()`
FROM `spark_fao`
GROUP BY `month`
18/02/28 13:02:05 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:02:05 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:02:05 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 13:02:05 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 13:02:05 INFO FileSourceStrategy: Output Data Schema: struct<month: string>
18/02/28 13:02:05 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 13:02:05 INFO CodeGenerator: Code generated in 24.28261 ms
18/02/28 13:02:05 INFO CodeGenerator: Code generated in 25.166973 ms
18/02/28 13:02:05 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 282.5 KB, free 363.8 MB)
18/02/28 13:02:05 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 24.1 KB, free 363.7 MB)
18/02/28 13:02:05 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:60719 (size: 24.1 KB, free: 366.1 MB)
18/02/28 13:02:05 INFO SparkContext: Created broadcast 31 from collect at utils.scala:211
18/02/28 13:02:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 13:02:05 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:02:05 INFO DAGScheduler: Registering RDD 82 (collect at utils.scala:211)
18/02/28 13:02:05 INFO DAGScheduler: Got job 16 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:02:05 INFO DAGScheduler: Final stage: ResultStage 26 (collect at utils.scala:211)
18/02/28 13:02:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
18/02/28 13:02:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 25)
18/02/28 13:02:05 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[82] at collect at utils.scala:211), which has no missing parents
18/02/28 13:02:05 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 26.5 KB, free 363.7 MB)
18/02/28 13:02:05 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 13.3 KB, free 363.7 MB)
18/02/28 13:02:05 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:60719 (size: 13.3 KB, free: 366.0 MB)
18/02/28 13:02:05 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
18/02/28 13:02:05 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[82] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:02:05 INFO TaskSchedulerImpl: Adding task set 25.0 with 4 tasks
18/02/28 13:02:05 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 62, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 13:02:05 INFO TaskSetManager: Starting task 1.0 in stage 25.0 (TID 63, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 13:02:05 INFO TaskSetManager: Starting task 2.0 in stage 25.0 (TID 64, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 13:02:05 INFO TaskSetManager: Starting task 3.0 in stage 25.0 (TID 65, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 13:02:05 INFO Executor: Running task 0.0 in stage 25.0 (TID 62)
18/02/28 13:02:05 INFO Executor: Running task 1.0 in stage 25.0 (TID 63)
18/02/28 13:02:05 INFO Executor: Running task 3.0 in stage 25.0 (TID 65)
18/02/28 13:02:05 INFO Executor: Running task 2.0 in stage 25.0 (TID 64)
18/02/28 13:02:05 INFO CodeGenerator: Code generated in 14.315893 ms
18/02/28 13:02:05 INFO CodeGenerator: Code generated in 13.634285 ms
18/02/28 13:02:05 INFO CodeGenerator: Code generated in 7.117572 ms
18/02/28 13:02:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 13:02:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 13:02:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 13:02:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 13:02:05 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 13:02:06 INFO ContextCleaner: Cleaned accumulator 728
18/02/28 13:02:06 INFO ContextCleaner: Cleaned accumulator 753
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 13:02:06 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:60719 in memory (size: 12.3 KB, free: 366.1 MB)
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 13:02:06 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:60719 in memory (size: 13.1 KB, free: 366.1 MB)
18/02/28 13:02:06 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:60719 in memory (size: 3.7 KB, free: 366.1 MB)
18/02/28 13:02:06 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:60719 in memory (size: 12.3 KB, free: 366.1 MB)
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 13:02:06 INFO Executor: Finished task 3.0 in stage 25.0 (TID 65). 2060 bytes result sent to driver
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 13:02:06 INFO TaskSetManager: Finished task 3.0 in stage 25.0 (TID 65) in 1078 ms on localhost (executor driver) (1/4)
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 13:02:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 13:02:07 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 13:02:07 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 13:02:07 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 13:02:07 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 13:02:07 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 13:02:07 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 13:02:07 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 13:02:07 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 13:02:07 INFO Executor: Finished task 2.0 in stage 25.0 (TID 64). 2060 bytes result sent to driver
18/02/28 13:02:07 INFO TaskSetManager: Finished task 2.0 in stage 25.0 (TID 64) in 1497 ms on localhost (executor driver) (2/4)
18/02/28 13:02:07 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 13:02:07 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 13:02:07 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 13:02:07 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 13:02:07 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 13:02:07 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 13:02:07 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 13:02:07 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 13:02:07 INFO Executor: Finished task 1.0 in stage 25.0 (TID 63). 2060 bytes result sent to driver
18/02/28 13:02:07 INFO TaskSetManager: Finished task 1.0 in stage 25.0 (TID 63) in 1746 ms on localhost (executor driver) (3/4)
18/02/28 13:02:07 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 13:02:07 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 13:02:07 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 13:02:07 INFO Executor: Finished task 0.0 in stage 25.0 (TID 62). 2060 bytes result sent to driver
18/02/28 13:02:07 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 62) in 1951 ms on localhost (executor driver) (4/4)
18/02/28 13:02:07 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
18/02/28 13:02:07 INFO DAGScheduler: ShuffleMapStage 25 (collect at utils.scala:211) finished in 1.951 s
18/02/28 13:02:07 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:02:07 INFO DAGScheduler: running: Set()
18/02/28 13:02:07 INFO DAGScheduler: waiting: Set(ResultStage 26)
18/02/28 13:02:07 INFO DAGScheduler: failed: Set()
18/02/28 13:02:07 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[85] at collect at utils.scala:211), which has no missing parents
18/02/28 13:02:07 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 24.9 KB, free 363.8 MB)
18/02/28 13:02:07 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 12.5 KB, free 363.8 MB)
18/02/28 13:02:07 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:60719 (size: 12.5 KB, free: 366.1 MB)
18/02/28 13:02:07 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1006
18/02/28 13:02:07 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 26 (MapPartitionsRDD[85] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:02:07 INFO TaskSchedulerImpl: Adding task set 26.0 with 4 tasks
18/02/28 13:02:07 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 66, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:02:07 INFO TaskSetManager: Starting task 1.0 in stage 26.0 (TID 67, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 13:02:07 INFO TaskSetManager: Starting task 2.0 in stage 26.0 (TID 68, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 13:02:07 INFO TaskSetManager: Starting task 3.0 in stage 26.0 (TID 69, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 13:02:07 INFO Executor: Running task 1.0 in stage 26.0 (TID 67)
18/02/28 13:02:07 INFO Executor: Running task 0.0 in stage 26.0 (TID 66)
18/02/28 13:02:07 INFO Executor: Running task 2.0 in stage 26.0 (TID 68)
18/02/28 13:02:07 INFO Executor: Running task 3.0 in stage 26.0 (TID 69)
18/02/28 13:02:07 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:02:07 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:02:07 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:02:07 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:02:07 INFO Executor: Finished task 3.0 in stage 26.0 (TID 69). 19778 bytes result sent to driver
18/02/28 13:02:07 INFO Executor: Finished task 1.0 in stage 26.0 (TID 67). 21547 bytes result sent to driver
18/02/28 13:02:07 INFO TaskSetManager: Finished task 3.0 in stage 26.0 (TID 69) in 13 ms on localhost (executor driver) (1/4)
18/02/28 13:02:07 INFO TaskSetManager: Finished task 1.0 in stage 26.0 (TID 67) in 13 ms on localhost (executor driver) (2/4)
18/02/28 13:02:07 INFO Executor: Finished task 0.0 in stage 26.0 (TID 66). 23867 bytes result sent to driver
18/02/28 13:02:07 INFO Executor: Finished task 2.0 in stage 26.0 (TID 68). 23121 bytes result sent to driver
18/02/28 13:02:07 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 66) in 18 ms on localhost (executor driver) (3/4)
18/02/28 13:02:07 INFO TaskSetManager: Finished task 2.0 in stage 26.0 (TID 68) in 18 ms on localhost (executor driver) (4/4)
18/02/28 13:02:07 INFO DAGScheduler: ResultStage 26 (collect at utils.scala:211) finished in 0.019 s
18/02/28 13:02:07 INFO DAGScheduler: Job 16 finished: collect at utils.scala:211, took 1.979177 s
18/02/28 13:02:07 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
18/02/28 13:02:07 INFO CodeGenerator: Code generated in 5.485661 ms
18/02/28 13:02:14 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:60719 in memory (size: 13.3 KB, free: 366.1 MB)
18/02/28 13:02:14 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:60719 in memory (size: 12.5 KB, free: 366.1 MB)
18/02/28 13:03:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:03:19 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 13:03:19 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:03:19 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:03:19 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:03:19 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:03:19 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 13:03:19 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 13:03:20 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 13:03:20 INFO DAGScheduler: Got job 17 (collect at utils.scala:58) with 4 output partitions
18/02/28 13:03:20 INFO DAGScheduler: Final stage: ResultStage 27 (collect at utils.scala:58)
18/02/28 13:03:20 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:03:20 INFO DAGScheduler: Missing parents: List()
18/02/28 13:03:20 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[90] at map at utils.scala:55), which has no missing parents
18/02/28 13:03:20 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 7.0 KB, free 363.9 MB)
18/02/28 13:03:20 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 3.7 KB, free 363.8 MB)
18/02/28 13:03:20 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:60719 (size: 3.7 KB, free: 366.1 MB)
18/02/28 13:03:20 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1006
18/02/28 13:03:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 27 (MapPartitionsRDD[90] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:03:20 INFO TaskSchedulerImpl: Adding task set 27.0 with 4 tasks
18/02/28 13:03:20 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 70, localhost, executor driver, partition 0, PROCESS_LOCAL, 5084 bytes)
18/02/28 13:03:20 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 71, localhost, executor driver, partition 1, PROCESS_LOCAL, 5092 bytes)
18/02/28 13:03:20 INFO TaskSetManager: Starting task 2.0 in stage 27.0 (TID 72, localhost, executor driver, partition 2, PROCESS_LOCAL, 5092 bytes)
18/02/28 13:03:20 INFO TaskSetManager: Starting task 3.0 in stage 27.0 (TID 73, localhost, executor driver, partition 3, PROCESS_LOCAL, 5068 bytes)
18/02/28 13:03:20 INFO Executor: Running task 1.0 in stage 27.0 (TID 71)
18/02/28 13:03:20 INFO Executor: Running task 2.0 in stage 27.0 (TID 72)
18/02/28 13:03:20 INFO Executor: Running task 3.0 in stage 27.0 (TID 73)
18/02/28 13:03:20 INFO Executor: Running task 0.0 in stage 27.0 (TID 70)
18/02/28 13:03:20 INFO Executor: Finished task 1.0 in stage 27.0 (TID 71). 896 bytes result sent to driver
18/02/28 13:03:20 INFO Executor: Finished task 3.0 in stage 27.0 (TID 73). 878 bytes result sent to driver
18/02/28 13:03:20 INFO Executor: Finished task 0.0 in stage 27.0 (TID 70). 924 bytes result sent to driver
18/02/28 13:03:20 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 71) in 6 ms on localhost (executor driver) (1/4)
18/02/28 13:03:20 INFO TaskSetManager: Finished task 3.0 in stage 27.0 (TID 73) in 7 ms on localhost (executor driver) (2/4)
18/02/28 13:03:20 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 70) in 9 ms on localhost (executor driver) (3/4)
18/02/28 13:03:20 INFO Executor: Finished task 2.0 in stage 27.0 (TID 72). 982 bytes result sent to driver
18/02/28 13:03:20 INFO TaskSetManager: Finished task 2.0 in stage 27.0 (TID 72) in 8 ms on localhost (executor driver) (4/4)
18/02/28 13:03:20 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
18/02/28 13:03:20 INFO DAGScheduler: ResultStage 27 (collect at utils.scala:58) finished in 0.009 s
18/02/28 13:03:20 INFO DAGScheduler: Job 17 finished: collect at utils.scala:58, took 0.013422 s
18/02/28 13:03:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:03:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:03:20 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 13:03:20 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:03:20 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:03:20 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:03:20 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:03:20 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 13:03:20 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 13:03:20 INFO SparkSqlParser: Parsing command: spark_flights
18/02/28 13:03:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:03:20 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_flights` AS `zzz55`
WHERE (0 = 1)
18/02/28 13:03:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:03:20 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 13:03:20 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:03:20 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:03:20 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:03:20 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:03:20 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 13:03:20 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 13:03:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:03:25 INFO SparkSqlParser: Parsing command: SELECT `month`, count(*) AS `n()`
FROM `spark_flights`
GROUP BY `month`
18/02/28 13:03:25 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:03:25 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:03:25 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 13:03:25 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 13:03:25 INFO FileSourceStrategy: Output Data Schema: struct<month: string>
18/02/28 13:03:25 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 13:03:25 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 282.5 KB, free 363.6 MB)
18/02/28 13:03:25 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 24.1 KB, free 363.6 MB)
18/02/28 13:03:25 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:60719 (size: 24.1 KB, free: 366.1 MB)
18/02/28 13:03:25 INFO SparkContext: Created broadcast 35 from collect at utils.scala:211
18/02/28 13:03:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79989536 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 13:03:25 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:03:25 INFO DAGScheduler: Registering RDD 93 (collect at utils.scala:211)
18/02/28 13:03:25 INFO DAGScheduler: Got job 18 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:03:25 INFO DAGScheduler: Final stage: ResultStage 29 (collect at utils.scala:211)
18/02/28 13:03:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
18/02/28 13:03:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 28)
18/02/28 13:03:25 INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[93] at collect at utils.scala:211), which has no missing parents
18/02/28 13:03:25 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 26.5 KB, free 363.5 MB)
18/02/28 13:03:25 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 13.3 KB, free 363.5 MB)
18/02/28 13:03:25 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:60719 (size: 13.3 KB, free: 366.1 MB)
18/02/28 13:03:25 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1006
18/02/28 13:03:25 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[93] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:03:25 INFO TaskSchedulerImpl: Adding task set 28.0 with 4 tasks
18/02/28 13:03:25 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 74, localhost, executor driver, partition 0, PROCESS_LOCAL, 6764 bytes)
18/02/28 13:03:25 INFO TaskSetManager: Starting task 1.0 in stage 28.0 (TID 75, localhost, executor driver, partition 1, PROCESS_LOCAL, 6862 bytes)
18/02/28 13:03:25 INFO TaskSetManager: Starting task 2.0 in stage 28.0 (TID 76, localhost, executor driver, partition 2, PROCESS_LOCAL, 6960 bytes)
18/02/28 13:03:25 INFO TaskSetManager: Starting task 3.0 in stage 28.0 (TID 77, localhost, executor driver, partition 3, PROCESS_LOCAL, 6770 bytes)
18/02/28 13:03:25 INFO Executor: Running task 0.0 in stage 28.0 (TID 74)
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2014.csv, range: 0-1008742, partition values: [empty row]
18/02/28 13:03:25 INFO Executor: Running task 1.0 in stage 28.0 (TID 75)
18/02/28 13:03:25 INFO Executor: Running task 2.0 in stage 28.0 (TID 76)
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1982.csv, range: 0-578716, partition values: [empty row]
18/02/28 13:03:25 INFO Executor: Running task 3.0 in stage 28.0 (TID 77)
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/trip_spp_landings.rds, range: 0-308770, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1999.csv, range: 0-820037, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1964.csv, range: 0-299329, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1963.csv, range: 0-278166, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1981.csv, range: 0-564640, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1962.csv, range: 0-270927, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1998.csv, range: 0-789406, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1961.csv, range: 0-261296, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1980.csv, range: 0-560808, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2015.csv, range: 0-1003898, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1960.csv, range: 0-252594, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1959.csv, range: 0-245736, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1997.csv, range: 0-767018, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1979.csv, range: 0-553379, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1958.csv, range: 0-241453, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1957.csv, range: 0-231628, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1978.csv, range: 0-551738, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1956.csv, range: 0-224082, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1996.csv, range: 0-747021, partition values: [empty row]
18/02/28 13:03:25 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:60719 in memory (size: 3.7 KB, free: 366.1 MB)
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2013.csv, range: 0-998750, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1955.csv, range: 0-219621, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1954.csv, range: 0-216257, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1953.csv, range: 0-210280, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1977.csv, range: 0-532580, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1995.csv, range: 0-727289, partition values: [empty row]
18/02/28 13:03:25 INFO ContextCleaner: Cleaned accumulator 842
18/02/28 13:03:25 INFO ContextCleaner: Cleaned accumulator 817
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1952.csv, range: 0-204928, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1976.csv, range: 0-517531, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2012.csv, range: 0-995582, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1951.csv, range: 0-200822, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1950.csv, range: 0-196189, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1990.csv, range: 0-708582, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1975.csv, range: 0-500879, partition values: [empty row]
18/02/28 13:03:25 INFO Executor: Finished task 3.0 in stage 28.0 (TID 77). 2060 bytes result sent to driver
18/02/28 13:03:25 INFO TaskSetManager: Finished task 3.0 in stage 28.0 (TID 77) in 781 ms on localhost (executor driver) (1/4)
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2011.csv, range: 0-987311, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1974.csv, range: 0-473413, partition values: [empty row]
18/02/28 13:03:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1989.csv, range: 0-701662, partition values: [empty row]
18/02/28 13:03:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1973.csv, range: 0-419779, partition values: [empty row]
18/02/28 13:03:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1994.csv, range: 0-701135, partition values: [empty row]
18/02/28 13:03:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1972.csv, range: 0-411988, partition values: [empty row]
18/02/28 13:03:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2010.csv, range: 0-980519, partition values: [empty row]
18/02/28 13:03:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1971.csv, range: 0-396106, partition values: [empty row]
18/02/28 13:03:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1991.csv, range: 0-701003, partition values: [empty row]
18/02/28 13:03:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1970.csv, range: 0-382460, partition values: [empty row]
18/02/28 13:03:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2009.csv, range: 0-973865, partition values: [empty row]
18/02/28 13:03:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1969.csv, range: 0-339001, partition values: [empty row]
18/02/28 13:03:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1992.csv, range: 0-697207, partition values: [empty row]
18/02/28 13:03:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1968.csv, range: 0-335292, partition values: [empty row]
18/02/28 13:03:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1967.csv, range: 0-326295, partition values: [empty row]
18/02/28 13:03:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2007.csv, range: 0-964087, partition values: [empty row]
18/02/28 13:03:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1988.csv, range: 0-695001, partition values: [empty row]
18/02/28 13:03:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1966.csv, range: 0-316046, partition values: [empty row]
18/02/28 13:03:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1965.csv, range: 0-309752, partition values: [empty row]
18/02/28 13:03:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1993.csv, range: 0-691899, partition values: [empty row]
18/02/28 13:03:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2008.csv, range: 0-961808, partition values: [empty row]
18/02/28 13:03:26 INFO Executor: Finished task 2.0 in stage 28.0 (TID 76). 2060 bytes result sent to driver
18/02/28 13:03:26 INFO TaskSetManager: Finished task 2.0 in stage 28.0 (TID 76) in 1213 ms on localhost (executor driver) (2/4)
18/02/28 13:03:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1987.csv, range: 0-639471, partition values: [empty row]
18/02/28 13:03:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2006.csv, range: 0-956996, partition values: [empty row]
18/02/28 13:03:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1986.csv, range: 0-624636, partition values: [empty row]
18/02/28 13:03:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2005.csv, range: 0-945689, partition values: [empty row]
18/02/28 13:03:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1985.csv, range: 0-613388, partition values: [empty row]
18/02/28 13:03:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1984.csv, range: 0-603864, partition values: [empty row]
18/02/28 13:03:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2004.csv, range: 0-923075, partition values: [empty row]
18/02/28 13:03:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_1983.csv, range: 0-589377, partition values: [empty row]
18/02/28 13:03:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2003.csv, range: 0-895832, partition values: [empty row]
18/02/28 13:03:26 INFO Executor: Finished task 1.0 in stage 28.0 (TID 75). 2060 bytes result sent to driver
18/02/28 13:03:26 INFO TaskSetManager: Finished task 1.0 in stage 28.0 (TID 75) in 1491 ms on localhost (executor driver) (3/4)
18/02/28 13:03:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2002.csv, range: 0-879520, partition values: [empty row]
18/02/28 13:03:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2001.csv, range: 0-869513, partition values: [empty row]
18/02/28 13:03:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/FAO_ts_2000.csv, range: 0-844114, partition values: [empty row]
18/02/28 13:03:26 INFO Executor: Finished task 0.0 in stage 28.0 (TID 74). 2103 bytes result sent to driver
18/02/28 13:03:26 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 74) in 1702 ms on localhost (executor driver) (4/4)
18/02/28 13:03:26 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
18/02/28 13:03:26 INFO DAGScheduler: ShuffleMapStage 28 (collect at utils.scala:211) finished in 1.703 s
18/02/28 13:03:26 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:03:26 INFO DAGScheduler: running: Set()
18/02/28 13:03:26 INFO DAGScheduler: waiting: Set(ResultStage 29)
18/02/28 13:03:26 INFO DAGScheduler: failed: Set()
18/02/28 13:03:26 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[96] at collect at utils.scala:211), which has no missing parents
18/02/28 13:03:26 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 24.9 KB, free 363.5 MB)
18/02/28 13:03:26 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 12.4 KB, free 363.5 MB)
18/02/28 13:03:26 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:60719 (size: 12.4 KB, free: 366.0 MB)
18/02/28 13:03:26 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1006
18/02/28 13:03:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 29 (MapPartitionsRDD[96] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:03:26 INFO TaskSchedulerImpl: Adding task set 29.0 with 4 tasks
18/02/28 13:03:26 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 78, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:03:26 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 79, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 13:03:26 INFO TaskSetManager: Starting task 2.0 in stage 29.0 (TID 80, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 13:03:26 INFO TaskSetManager: Starting task 3.0 in stage 29.0 (TID 81, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 13:03:26 INFO Executor: Running task 2.0 in stage 29.0 (TID 80)
18/02/28 13:03:26 INFO Executor: Running task 1.0 in stage 29.0 (TID 79)
18/02/28 13:03:26 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:03:26 INFO Executor: Running task 0.0 in stage 29.0 (TID 78)
18/02/28 13:03:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:03:26 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:03:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:03:26 INFO Executor: Running task 3.0 in stage 29.0 (TID 81)
18/02/28 13:03:26 INFO Executor: Finished task 2.0 in stage 29.0 (TID 80). 23121 bytes result sent to driver
18/02/28 13:03:26 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:03:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
18/02/28 13:03:26 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:03:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:03:26 INFO TaskSetManager: Finished task 2.0 in stage 29.0 (TID 80) in 15 ms on localhost (executor driver) (1/4)
18/02/28 13:03:26 INFO Executor: Finished task 0.0 in stage 29.0 (TID 78). 23910 bytes result sent to driver
18/02/28 13:03:26 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 78) in 17 ms on localhost (executor driver) (2/4)
18/02/28 13:03:26 INFO Executor: Finished task 1.0 in stage 29.0 (TID 79). 21547 bytes result sent to driver
18/02/28 13:03:26 INFO Executor: Finished task 3.0 in stage 29.0 (TID 81). 19821 bytes result sent to driver
18/02/28 13:03:26 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 79) in 21 ms on localhost (executor driver) (3/4)
18/02/28 13:03:26 INFO TaskSetManager: Finished task 3.0 in stage 29.0 (TID 81) in 23 ms on localhost (executor driver) (4/4)
18/02/28 13:03:26 INFO DAGScheduler: ResultStage 29 (collect at utils.scala:211) finished in 0.023 s
18/02/28 13:03:26 INFO DAGScheduler: Job 18 finished: collect at utils.scala:211, took 1.737639 s
18/02/28 13:03:26 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
18/02/28 13:04:51 INFO SparkContext: Invoking stop() from shutdown hook
18/02/28 13:04:51 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
18/02/28 13:04:51 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/02/28 13:04:51 INFO MemoryStore: MemoryStore cleared
18/02/28 13:04:51 INFO BlockManager: BlockManager stopped
18/02/28 13:04:51 INFO BlockManagerMaster: BlockManagerMaster stopped
18/02/28 13:04:51 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/02/28 13:04:51 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-b5512e24-c225-4023-8d08-2c09b0769771\userFiles-0e41f5fe-5b2c-4214-9dad-0fd94427b36f
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-b5512e24-c225-4023-8d08-2c09b0769771\userFiles-0e41f5fe-5b2c-4214-9dad-0fd94427b36f
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1937)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1936)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 13:04:51 INFO SparkContext: Successfully stopped SparkContext
18/02/28 13:04:51 INFO ShutdownHookManager: Shutdown hook called
18/02/28 13:04:51 INFO ShutdownHookManager: Deleting directory C:\Users\JC\AppData\Local\Temp\spark-b5512e24-c225-4023-8d08-2c09b0769771
18/02/28 13:04:51 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-b5512e24-c225-4023-8d08-2c09b0769771
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-b5512e24-c225-4023-8d08-2c09b0769771
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 13:04:51 INFO ShutdownHookManager: Deleting directory C:\Users\JC\AppData\Local\Temp\spark-b5512e24-c225-4023-8d08-2c09b0769771\userFiles-0e41f5fe-5b2c-4214-9dad-0fd94427b36f
18/02/28 13:04:51 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-b5512e24-c225-4023-8d08-2c09b0769771\userFiles-0e41f5fe-5b2c-4214-9dad-0fd94427b36f
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-b5512e24-c225-4023-8d08-2c09b0769771\userFiles-0e41f5fe-5b2c-4214-9dad-0fd94427b36f
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 13:05:03 INFO SparkContext: Running Spark version 2.2.0
18/02/28 13:05:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/02/28 13:05:03 INFO SparkContext: Submitted application: sparklyr
18/02/28 13:05:03 INFO SecurityManager: Changing view acls to: JC
18/02/28 13:05:03 INFO SecurityManager: Changing modify acls to: JC
18/02/28 13:05:03 INFO SecurityManager: Changing view acls groups to: 
18/02/28 13:05:03 INFO SecurityManager: Changing modify acls groups to: 
18/02/28 13:05:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(JC); groups with view permissions: Set(); users  with modify permissions: Set(JC); groups with modify permissions: Set()
18/02/28 13:05:03 INFO Utils: Successfully started service 'sparkDriver' on port 60920.
18/02/28 13:05:03 INFO SparkEnv: Registering MapOutputTracker
18/02/28 13:05:03 INFO SparkEnv: Registering BlockManagerMaster
18/02/28 13:05:03 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/02/28 13:05:03 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/02/28 13:05:03 INFO DiskBlockManager: Created local directory at C:\Users\JC\AppData\Local\Temp\blockmgr-27b8c8c8-fb5c-460c-aa65-84df691dfd80
18/02/28 13:05:03 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/02/28 13:05:04 INFO SparkEnv: Registering OutputCommitCoordinator
18/02/28 13:05:04 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/02/28 13:05:04 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
18/02/28 13:05:04 INFO SparkContext: Added JAR file:/C:/Users/JC/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:60920/jars/sparklyr-2.2-2.11.jar with timestamp 1519851904296
18/02/28 13:05:04 INFO Executor: Starting executor ID driver on host localhost
18/02/28 13:05:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60941.
18/02/28 13:05:04 INFO NettyBlockTransferService: Server created on 127.0.0.1:60941
18/02/28 13:05:04 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/02/28 13:05:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 60941, None)
18/02/28 13:05:04 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:60941 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 60941, None)
18/02/28 13:05:04 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 60941, None)
18/02/28 13:05:04 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 60941, None)
18/02/28 13:05:04 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/02/28 13:05:04 INFO SharedState: loading hive config file: file:/C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
18/02/28 13:05:04 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:\Users\JC\AppData\Local\spark\spark-2.2.0-bin-hadoop2.7\tmp\hive') to the value of spark.sql.warehouse.dir ('C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive').
18/02/28 13:05:04 INFO SharedState: Warehouse path is 'C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive'.
18/02/28 13:05:05 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
18/02/28 13:05:06 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
18/02/28 13:05:06 INFO ObjectStore: ObjectStore, initialize called
18/02/28 13:05:06 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
18/02/28 13:05:06 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
18/02/28 13:05:07 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
18/02/28 13:05:08 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 13:05:08 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 13:05:08 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 13:05:08 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 13:05:09 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
18/02/28 13:05:09 INFO ObjectStore: Initialized ObjectStore
18/02/28 13:05:09 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
18/02/28 13:05:09 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
18/02/28 13:05:09 INFO HiveMetaStore: Added admin role in metastore
18/02/28 13:05:09 INFO HiveMetaStore: Added public role in metastore
18/02/28 13:05:09 INFO HiveMetaStore: No user is added in admin role, since config is empty
18/02/28 13:05:09 INFO HiveMetaStore: 0: get_all_databases
18/02/28 13:05:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_all_databases	
18/02/28 13:05:09 INFO HiveMetaStore: 0: get_functions: db=default pat=*
18/02/28 13:05:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
18/02/28 13:05:09 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 13:05:09 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/Temp/3e631631-bbe6-4432-8b88-14bf955f74b6_resources
18/02/28 13:05:09 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/3e631631-bbe6-4432-8b88-14bf955f74b6
18/02/28 13:05:09 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/3e631631-bbe6-4432-8b88-14bf955f74b6
18/02/28 13:05:09 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/3e631631-bbe6-4432-8b88-14bf955f74b6/_tmp_space.db
18/02/28 13:05:09 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive
18/02/28 13:05:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:05:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:05:09 INFO HiveMetaStore: 0: get_database: global_temp
18/02/28 13:05:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: global_temp	
18/02/28 13:05:09 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
18/02/28 13:05:10 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/Temp/62a8cd62-5195-4fc9-b956-0ac606c5dbc7_resources
18/02/28 13:05:10 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/62a8cd62-5195-4fc9-b956-0ac606c5dbc7
18/02/28 13:05:10 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/62a8cd62-5195-4fc9-b956-0ac606c5dbc7
18/02/28 13:05:10 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/62a8cd62-5195-4fc9-b956-0ac606c5dbc7/_tmp_space.db
18/02/28 13:05:10 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive
18/02/28 13:05:10 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
18/02/28 13:05:10 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 13:05:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:05:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:05:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:05:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:05:11 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 13:05:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 13:05:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:05:52 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 13:05:52 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:05:52 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:05:52 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:05:52 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:05:52 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 13:05:52 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 13:05:52 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 13:05:52 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
18/02/28 13:05:52 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
18/02/28 13:05:52 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:05:52 INFO DAGScheduler: Missing parents: List()
18/02/28 13:05:52 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55), which has no missing parents
18/02/28 13:05:52 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
18/02/28 13:05:52 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
18/02/28 13:05:52 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:60941 (size: 3.4 KB, free: 366.3 MB)
18/02/28 13:05:52 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
18/02/28 13:05:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0))
18/02/28 13:05:52 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/02/28 13:05:52 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 13:05:52 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/02/28 13:05:52 INFO Executor: Fetching spark://127.0.0.1:60920/jars/sparklyr-2.2-2.11.jar with timestamp 1519851904296
18/02/28 13:05:52 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:60920 after 17 ms (0 ms spent in bootstraps)
18/02/28 13:05:53 INFO Utils: Fetching spark://127.0.0.1:60920/jars/sparklyr-2.2-2.11.jar to C:\Users\JC\AppData\Local\Temp\spark-270041d1-4711-4c11-beb7-662a8c46d069\userFiles-acafcda6-52e6-4d03-8ea3-6b371ffbc1ad\fetchFileTemp4030372882504350474.tmp
18/02/28 13:05:53 INFO Executor: Adding file:/C:/Users/JC/AppData/Local/Temp/spark-270041d1-4711-4c11-beb7-662a8c46d069/userFiles-acafcda6-52e6-4d03-8ea3-6b371ffbc1ad/sparklyr-2.2-2.11.jar to class loader
18/02/28 13:05:53 INFO CodeGenerator: Code generated in 235.99203 ms
18/02/28 13:05:53 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
18/02/28 13:05:53 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 609 ms on localhost (executor driver) (1/1)
18/02/28 13:05:53 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/02/28 13:05:53 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.625 s
18/02/28 13:05:53 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.779712 s
18/02/28 13:05:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:05:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:05:53 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 13:05:53 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:05:53 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:05:53 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:05:53 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:05:53 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 13:05:53 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 13:05:53 INFO SparkSqlParser: Parsing command: spark_flights
18/02/28 13:05:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:05:53 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_flights` AS `zzz56`
WHERE (0 = 1)
18/02/28 13:05:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:05:54 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 13:05:54 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:05:54 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:05:54 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:05:54 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:05:54 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 13:05:54 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 13:05:54 INFO CodeGenerator: Code generated in 13.563056 ms
18/02/28 13:06:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:06:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_flights`
18/02/28 13:06:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:06:11 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_flights`
18/02/28 13:06:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:06:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:06:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:06:11 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_flights`
18/02/28 13:06:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:06:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:06:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:06:11 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_flights`
18/02/28 13:06:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:06:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:06:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:06:11 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_flights`
18/02/28 13:06:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:06:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:06:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:06:11 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_flights`
18/02/28 13:06:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:06:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:06:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:06:11 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_flights`
LIMIT 1000
18/02/28 13:06:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:06:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:06:11 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 13:06:11 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 13:06:11 INFO FileSourceStrategy: Output Data Schema: struct<>
18/02/28 13:06:11 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 13:06:11 INFO CodeGenerator: Code generated in 55.650351 ms
18/02/28 13:06:11 INFO CodeGenerator: Code generated in 11.130352 ms
18/02/28 13:06:11 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 282.5 KB, free 366.0 MB)
18/02/28 13:06:11 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 24.1 KB, free 366.0 MB)
18/02/28 13:06:11 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:60941 (size: 24.1 KB, free: 366.3 MB)
18/02/28 13:06:11 INFO SparkContext: Created broadcast 1 from collect at utils.scala:211
18/02/28 13:06:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21019222 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 13:06:12 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:06:12 INFO DAGScheduler: Registering RDD 7 (collect at utils.scala:211)
18/02/28 13:06:12 INFO DAGScheduler: Got job 1 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:06:12 INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:211)
18/02/28 13:06:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
18/02/28 13:06:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
18/02/28 13:06:12 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at collect at utils.scala:211), which has no missing parents
18/02/28 13:06:12 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:60941 in memory (size: 3.4 KB, free: 366.3 MB)
18/02/28 13:06:12 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 14.2 KB, free 366.0 MB)
18/02/28 13:06:12 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 8.0 KB, free 366.0 MB)
18/02/28 13:06:12 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:60941 (size: 8.0 KB, free: 366.3 MB)
18/02/28 13:06:12 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
18/02/28 13:06:12 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:06:12 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks
18/02/28 13:06:12 INFO ContextCleaner: Cleaned accumulator 49
18/02/28 13:06:12 INFO ContextCleaner: Cleaned accumulator 0
18/02/28 13:06:12 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:06:12 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:06:12 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:06:12 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:06:12 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
18/02/28 13:06:12 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
18/02/28 13:06:12 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
18/02/28 13:06:12 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
18/02/28 13:06:12 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_7.csv, range: 0-2938867, partition values: [empty row]
18/02/28 13:06:12 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_4.csv, range: 0-2830543, partition values: [empty row]
18/02/28 13:06:12 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_11.csv, range: 0-2757037, partition values: [empty row]
18/02/28 13:06:12 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_3.csv, range: 0-2881793, partition values: [empty row]
18/02/28 13:06:12 INFO CodeGenerator: Code generated in 9.527708 ms
18/02/28 13:06:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_8.csv, range: 0-2932019, partition values: [empty row]
18/02/28 13:06:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_1.csv, range: 0-2697256, partition values: [empty row]
18/02/28 13:06:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_5.csv, range: 0-2880181, partition values: [empty row]
18/02/28 13:06:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_6.csv, range: 0-2820227, partition values: [empty row]
18/02/28 13:06:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_10.csv, range: 0-2920629, partition values: [empty row]
18/02/28 13:06:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_2.csv, range: 0-2487144, partition values: [empty row]
18/02/28 13:06:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_9.csv, range: 0-2763076, partition values: [empty row]
18/02/28 13:06:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_12.csv, range: 0-2836468, partition values: [empty row]
18/02/28 13:06:13 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 1628 bytes result sent to driver
18/02/28 13:06:13 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1628 bytes result sent to driver
18/02/28 13:06:13 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1585 bytes result sent to driver
18/02/28 13:06:13 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1092 ms on localhost (executor driver) (1/4)
18/02/28 13:06:13 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1083 ms on localhost (executor driver) (2/4)
18/02/28 13:06:13 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 1081 ms on localhost (executor driver) (3/4)
18/02/28 13:06:13 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1585 bytes result sent to driver
18/02/28 13:06:13 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1113 ms on localhost (executor driver) (4/4)
18/02/28 13:06:13 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/02/28 13:06:13 INFO DAGScheduler: ShuffleMapStage 1 (collect at utils.scala:211) finished in 1.127 s
18/02/28 13:06:13 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:06:13 INFO DAGScheduler: running: Set()
18/02/28 13:06:13 INFO DAGScheduler: waiting: Set(ResultStage 2)
18/02/28 13:06:13 INFO DAGScheduler: failed: Set()
18/02/28 13:06:13 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[10] at collect at utils.scala:211), which has no missing parents
18/02/28 13:06:13 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.9 KB, free 366.0 MB)
18/02/28 13:06:13 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.0 MB)
18/02/28 13:06:13 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 366.3 MB)
18/02/28 13:06:13 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
18/02/28 13:06:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:06:13 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
18/02/28 13:06:13 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:06:13 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
18/02/28 13:06:13 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:06:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
18/02/28 13:06:13 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1557 bytes result sent to driver
18/02/28 13:06:13 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 34 ms on localhost (executor driver) (1/1)
18/02/28 13:06:13 INFO DAGScheduler: ResultStage 2 (collect at utils.scala:211) finished in 0.034 s
18/02/28 13:06:13 INFO DAGScheduler: Job 1 finished: collect at utils.scala:211, took 1.249083 s
18/02/28 13:06:13 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/02/28 13:06:13 INFO CodeGenerator: Code generated in 7.098178 ms
18/02/28 13:06:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:06:18 INFO SparkSqlParser: Parsing command: SELECT `month`, count(*) AS `n()`
FROM `spark_flights`
GROUP BY `month`
18/02/28 13:06:18 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:06:18 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:06:18 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 13:06:18 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 13:06:18 INFO FileSourceStrategy: Output Data Schema: struct<month: string>
18/02/28 13:06:18 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 13:06:18 INFO CodeGenerator: Code generated in 28.479456 ms
18/02/28 13:06:18 INFO CodeGenerator: Code generated in 40.303758 ms
18/02/28 13:06:18 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 282.5 KB, free 365.7 MB)
18/02/28 13:06:18 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.7 MB)
18/02/28 13:06:18 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:60941 (size: 24.1 KB, free: 366.2 MB)
18/02/28 13:06:18 INFO SparkContext: Created broadcast 4 from collect at utils.scala:211
18/02/28 13:06:18 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21019222 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 13:06:18 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:06:18 INFO DAGScheduler: Registering RDD 13 (collect at utils.scala:211)
18/02/28 13:06:18 INFO DAGScheduler: Got job 2 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:06:18 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:211)
18/02/28 13:06:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
18/02/28 13:06:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
18/02/28 13:06:18 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[13] at collect at utils.scala:211), which has no missing parents
18/02/28 13:06:18 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 26.6 KB, free 365.6 MB)
18/02/28 13:06:18 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 13.3 KB, free 365.6 MB)
18/02/28 13:06:18 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:60941 (size: 13.3 KB, free: 366.2 MB)
18/02/28 13:06:18 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
18/02/28 13:06:18 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[13] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:06:18 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks
18/02/28 13:06:18 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:06:18 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:06:18 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 8, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:06:18 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 9, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:06:18 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)
18/02/28 13:06:18 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)
18/02/28 13:06:18 INFO Executor: Running task 3.0 in stage 3.0 (TID 9)
18/02/28 13:06:18 INFO Executor: Running task 2.0 in stage 3.0 (TID 8)
18/02/28 13:06:18 INFO CodeGenerator: Code generated in 8.850684 ms
18/02/28 13:06:18 INFO CodeGenerator: Code generated in 17.08993 ms
18/02/28 13:06:18 INFO CodeGenerator: Code generated in 8.283676 ms
18/02/28 13:06:18 INFO CodeGenerator: Code generated in 14.952367 ms
18/02/28 13:06:18 INFO CodeGenerator: Code generated in 9.104215 ms
18/02/28 13:06:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_3.csv, range: 0-2881793, partition values: [empty row]
18/02/28 13:06:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_7.csv, range: 0-2938867, partition values: [empty row]
18/02/28 13:06:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_4.csv, range: 0-2830543, partition values: [empty row]
18/02/28 13:06:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_11.csv, range: 0-2757037, partition values: [empty row]
18/02/28 13:06:19 INFO ContextCleaner: Cleaned accumulator 113
18/02/28 13:06:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_1.csv, range: 0-2697256, partition values: [empty row]
18/02/28 13:06:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_5.csv, range: 0-2880181, partition values: [empty row]
18/02/28 13:06:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_8.csv, range: 0-2932019, partition values: [empty row]
18/02/28 13:06:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_6.csv, range: 0-2820227, partition values: [empty row]
18/02/28 13:06:19 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 366.2 MB)
18/02/28 13:06:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_12.csv, range: 0-2836468, partition values: [empty row]
18/02/28 13:06:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_9.csv, range: 0-2763076, partition values: [empty row]
18/02/28 13:06:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_2.csv, range: 0-2487144, partition values: [empty row]
18/02/28 13:06:19 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_10.csv, range: 0-2920629, partition values: [empty row]
18/02/28 13:06:19 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 2060 bytes result sent to driver
18/02/28 13:06:19 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 1199 ms on localhost (executor driver) (1/4)
18/02/28 13:06:19 INFO Executor: Finished task 2.0 in stage 3.0 (TID 8). 2060 bytes result sent to driver
18/02/28 13:06:19 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 8) in 1283 ms on localhost (executor driver) (2/4)
18/02/28 13:06:20 INFO Executor: Finished task 3.0 in stage 3.0 (TID 9). 2060 bytes result sent to driver
18/02/28 13:06:20 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 9) in 1332 ms on localhost (executor driver) (3/4)
18/02/28 13:06:20 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 2060 bytes result sent to driver
18/02/28 13:06:20 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 1351 ms on localhost (executor driver) (4/4)
18/02/28 13:06:20 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/02/28 13:06:20 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:211) finished in 1.353 s
18/02/28 13:06:20 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:06:20 INFO DAGScheduler: running: Set()
18/02/28 13:06:20 INFO DAGScheduler: waiting: Set(ResultStage 4)
18/02/28 13:06:20 INFO DAGScheduler: failed: Set()
18/02/28 13:06:20 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[16] at collect at utils.scala:211), which has no missing parents
18/02/28 13:06:20 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 25.0 KB, free 365.6 MB)
18/02/28 13:06:20 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 12.4 KB, free 365.6 MB)
18/02/28 13:06:20 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:60941 (size: 12.4 KB, free: 366.2 MB)
18/02/28 13:06:20 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
18/02/28 13:06:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 4 (MapPartitionsRDD[16] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:06:20 INFO TaskSchedulerImpl: Adding task set 4.0 with 4 tasks
18/02/28 13:06:20 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 10, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:06:20 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 11, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 13:06:20 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 12, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 13:06:20 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 13, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 13:06:20 INFO Executor: Running task 0.0 in stage 4.0 (TID 10)
18/02/28 13:06:20 INFO Executor: Running task 1.0 in stage 4.0 (TID 11)
18/02/28 13:06:20 INFO Executor: Running task 2.0 in stage 4.0 (TID 12)
18/02/28 13:06:20 INFO Executor: Running task 3.0 in stage 4.0 (TID 13)
18/02/28 13:06:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 13:06:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:06:20 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 13:06:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
18/02/28 13:06:20 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 13:06:20 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 4 blocks
18/02/28 13:06:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
18/02/28 13:06:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
18/02/28 13:06:20 INFO Executor: Finished task 0.0 in stage 4.0 (TID 10). 2518 bytes result sent to driver
18/02/28 13:06:20 INFO Executor: Finished task 2.0 in stage 4.0 (TID 12). 2612 bytes result sent to driver
18/02/28 13:06:20 INFO Executor: Finished task 3.0 in stage 4.0 (TID 13). 2594 bytes result sent to driver
18/02/28 13:06:20 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 10) in 41 ms on localhost (executor driver) (1/4)
18/02/28 13:06:20 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 12) in 40 ms on localhost (executor driver) (2/4)
18/02/28 13:06:20 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 13) in 41 ms on localhost (executor driver) (3/4)
18/02/28 13:06:20 INFO Executor: Finished task 1.0 in stage 4.0 (TID 11). 2535 bytes result sent to driver
18/02/28 13:06:20 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 11) in 44 ms on localhost (executor driver) (4/4)
18/02/28 13:06:20 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:211) finished in 0.047 s
18/02/28 13:06:20 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/02/28 13:06:20 INFO DAGScheduler: Job 2 finished: collect at utils.scala:211, took 1.418163 s
18/02/28 13:06:20 INFO CodeGenerator: Code generated in 7.294233 ms
18/02/28 13:06:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:06:52 INFO SparkSqlParser: Parsing command: SELECT `month`, count(*) AS `n()`
FROM `spark_flights`
GROUP BY `month`
18/02/28 13:06:52 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:06:52 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:06:52 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 13:06:52 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 13:06:52 INFO FileSourceStrategy: Output Data Schema: struct<month: string>
18/02/28 13:06:52 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 13:06:52 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 282.5 KB, free 365.3 MB)
18/02/28 13:06:52 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.3 MB)
18/02/28 13:06:52 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:60941 (size: 24.1 KB, free: 366.2 MB)
18/02/28 13:06:52 INFO SparkContext: Created broadcast 7 from collect at utils.scala:211
18/02/28 13:06:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21019222 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 13:06:52 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:06:52 INFO DAGScheduler: Registering RDD 19 (collect at utils.scala:211)
18/02/28 13:06:52 INFO DAGScheduler: Got job 3 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:06:52 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:211)
18/02/28 13:06:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
18/02/28 13:06:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
18/02/28 13:06:52 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[19] at collect at utils.scala:211), which has no missing parents
18/02/28 13:06:52 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 26.6 KB, free 365.3 MB)
18/02/28 13:06:52 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 13.3 KB, free 365.3 MB)
18/02/28 13:06:52 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:60941 (size: 13.3 KB, free: 366.2 MB)
18/02/28 13:06:52 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
18/02/28 13:06:52 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[19] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:06:52 INFO TaskSchedulerImpl: Adding task set 5.0 with 4 tasks
18/02/28 13:06:52 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:06:52 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 15, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:06:52 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 16, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:06:52 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 17, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:06:52 INFO Executor: Running task 0.0 in stage 5.0 (TID 14)
18/02/28 13:06:52 INFO Executor: Running task 1.0 in stage 5.0 (TID 15)
18/02/28 13:06:52 INFO Executor: Running task 2.0 in stage 5.0 (TID 16)
18/02/28 13:06:52 INFO Executor: Running task 3.0 in stage 5.0 (TID 17)
18/02/28 13:06:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_7.csv, range: 0-2938867, partition values: [empty row]
18/02/28 13:06:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_3.csv, range: 0-2881793, partition values: [empty row]
18/02/28 13:06:52 INFO ContextCleaner: Cleaned accumulator 177
18/02/28 13:06:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_4.csv, range: 0-2830543, partition values: [empty row]
18/02/28 13:06:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_11.csv, range: 0-2757037, partition values: [empty row]
18/02/28 13:06:52 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:60941 in memory (size: 12.4 KB, free: 366.2 MB)
18/02/28 13:06:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_8.csv, range: 0-2932019, partition values: [empty row]
18/02/28 13:06:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_5.csv, range: 0-2880181, partition values: [empty row]
18/02/28 13:06:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_1.csv, range: 0-2697256, partition values: [empty row]
18/02/28 13:06:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_6.csv, range: 0-2820227, partition values: [empty row]
18/02/28 13:06:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_12.csv, range: 0-2836468, partition values: [empty row]
18/02/28 13:06:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_10.csv, range: 0-2920629, partition values: [empty row]
18/02/28 13:06:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_9.csv, range: 0-2763076, partition values: [empty row]
18/02/28 13:06:52 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_2.csv, range: 0-2487144, partition values: [empty row]
18/02/28 13:06:52 INFO Executor: Finished task 1.0 in stage 5.0 (TID 15). 2060 bytes result sent to driver
18/02/28 13:06:52 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 15) in 458 ms on localhost (executor driver) (1/4)
18/02/28 13:06:52 INFO Executor: Finished task 0.0 in stage 5.0 (TID 14). 2060 bytes result sent to driver
18/02/28 13:06:52 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 14) in 471 ms on localhost (executor driver) (2/4)
18/02/28 13:06:52 INFO Executor: Finished task 2.0 in stage 5.0 (TID 16). 2060 bytes result sent to driver
18/02/28 13:06:52 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 16) in 478 ms on localhost (executor driver) (3/4)
18/02/28 13:06:52 INFO Executor: Finished task 3.0 in stage 5.0 (TID 17). 2103 bytes result sent to driver
18/02/28 13:06:52 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 17) in 495 ms on localhost (executor driver) (4/4)
18/02/28 13:06:52 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:211) finished in 0.497 s
18/02/28 13:06:52 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:06:52 INFO DAGScheduler: running: Set()
18/02/28 13:06:52 INFO DAGScheduler: waiting: Set(ResultStage 6)
18/02/28 13:06:52 INFO DAGScheduler: failed: Set()
18/02/28 13:06:52 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[22] at collect at utils.scala:211), which has no missing parents
18/02/28 13:06:52 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 25.0 KB, free 365.3 MB)
18/02/28 13:06:52 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 12.4 KB, free 365.3 MB)
18/02/28 13:06:52 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/02/28 13:06:52 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:60941 (size: 12.4 KB, free: 366.2 MB)
18/02/28 13:06:52 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
18/02/28 13:06:52 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 6 (MapPartitionsRDD[22] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:06:52 INFO TaskSchedulerImpl: Adding task set 6.0 with 4 tasks
18/02/28 13:06:52 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 18, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:06:52 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 19, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 13:06:52 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 20, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 13:06:52 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 21, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 13:06:52 INFO Executor: Running task 0.0 in stage 6.0 (TID 18)
18/02/28 13:06:52 INFO Executor: Running task 1.0 in stage 6.0 (TID 19)
18/02/28 13:06:52 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 13:06:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:06:52 INFO Executor: Finished task 0.0 in stage 6.0 (TID 18). 2518 bytes result sent to driver
18/02/28 13:06:52 INFO Executor: Running task 2.0 in stage 6.0 (TID 20)
18/02/28 13:06:52 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 13:06:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:06:52 INFO Executor: Running task 3.0 in stage 6.0 (TID 21)
18/02/28 13:06:52 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 18) in 20 ms on localhost (executor driver) (1/4)
18/02/28 13:06:52 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 4 blocks
18/02/28 13:06:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:06:52 INFO Executor: Finished task 1.0 in stage 6.0 (TID 19). 2492 bytes result sent to driver
18/02/28 13:06:52 INFO Executor: Finished task 2.0 in stage 6.0 (TID 20). 2526 bytes result sent to driver
18/02/28 13:06:52 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 19) in 32 ms on localhost (executor driver) (2/4)
18/02/28 13:06:52 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 13:06:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:06:52 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 20) in 36 ms on localhost (executor driver) (3/4)
18/02/28 13:06:52 INFO Executor: Finished task 3.0 in stage 6.0 (TID 21). 2551 bytes result sent to driver
18/02/28 13:06:52 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 21) in 40 ms on localhost (executor driver) (4/4)
18/02/28 13:06:52 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:211) finished in 0.041 s
18/02/28 13:06:52 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
18/02/28 13:06:52 INFO DAGScheduler: Job 3 finished: collect at utils.scala:211, took 0.557369 s
18/02/28 13:07:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:07:12 INFO SparkSqlParser: Parsing command: SELECT `month`, count(*) AS `n()`
FROM `spark_flights`
GROUP BY `month`
18/02/28 13:07:12 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:07:12 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:07:12 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 13:07:12 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 13:07:12 INFO FileSourceStrategy: Output Data Schema: struct<month: string>
18/02/28 13:07:12 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 13:07:12 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 282.5 KB, free 365.0 MB)
18/02/28 13:07:12 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.0 MB)
18/02/28 13:07:12 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:60941 (size: 24.1 KB, free: 366.2 MB)
18/02/28 13:07:12 INFO SparkContext: Created broadcast 10 from collect at utils.scala:211
18/02/28 13:07:12 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21019222 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 13:07:12 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:07:12 INFO DAGScheduler: Registering RDD 25 (collect at utils.scala:211)
18/02/28 13:07:12 INFO DAGScheduler: Got job 4 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:07:12 INFO DAGScheduler: Final stage: ResultStage 8 (collect at utils.scala:211)
18/02/28 13:07:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
18/02/28 13:07:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
18/02/28 13:07:12 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[25] at collect at utils.scala:211), which has no missing parents
18/02/28 13:07:12 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 26.6 KB, free 364.9 MB)
18/02/28 13:07:12 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 13.3 KB, free 364.9 MB)
18/02/28 13:07:12 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:60941 (size: 13.3 KB, free: 366.1 MB)
18/02/28 13:07:12 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
18/02/28 13:07:12 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[25] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:07:12 INFO TaskSchedulerImpl: Adding task set 7.0 with 4 tasks
18/02/28 13:07:12 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:07:12 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 23, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:07:12 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 24, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:07:12 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 25, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:07:12 INFO Executor: Running task 0.0 in stage 7.0 (TID 22)
18/02/28 13:07:12 INFO Executor: Running task 1.0 in stage 7.0 (TID 23)
18/02/28 13:07:12 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_3.csv, range: 0-2881793, partition values: [empty row]
18/02/28 13:07:12 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_7.csv, range: 0-2938867, partition values: [empty row]
18/02/28 13:07:12 INFO Executor: Running task 2.0 in stage 7.0 (TID 24)
18/02/28 13:07:12 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_4.csv, range: 0-2830543, partition values: [empty row]
18/02/28 13:07:12 INFO Executor: Running task 3.0 in stage 7.0 (TID 25)
18/02/28 13:07:12 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_11.csv, range: 0-2757037, partition values: [empty row]
18/02/28 13:07:12 INFO ContextCleaner: Cleaned accumulator 241
18/02/28 13:07:12 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_5.csv, range: 0-2880181, partition values: [empty row]
18/02/28 13:07:12 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_8.csv, range: 0-2932019, partition values: [empty row]
18/02/28 13:07:12 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:60941 in memory (size: 12.4 KB, free: 366.2 MB)
18/02/28 13:07:12 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_1.csv, range: 0-2697256, partition values: [empty row]
18/02/28 13:07:12 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_6.csv, range: 0-2820227, partition values: [empty row]
18/02/28 13:07:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_10.csv, range: 0-2920629, partition values: [empty row]
18/02/28 13:07:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_12.csv, range: 0-2836468, partition values: [empty row]
18/02/28 13:07:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_2.csv, range: 0-2487144, partition values: [empty row]
18/02/28 13:07:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_9.csv, range: 0-2763076, partition values: [empty row]
18/02/28 13:07:13 INFO Executor: Finished task 1.0 in stage 7.0 (TID 23). 2060 bytes result sent to driver
18/02/28 13:07:13 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 23) in 543 ms on localhost (executor driver) (1/4)
18/02/28 13:07:13 INFO Executor: Finished task 0.0 in stage 7.0 (TID 22). 2060 bytes result sent to driver
18/02/28 13:07:13 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 22) in 553 ms on localhost (executor driver) (2/4)
18/02/28 13:07:13 INFO Executor: Finished task 3.0 in stage 7.0 (TID 25). 2103 bytes result sent to driver
18/02/28 13:07:13 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 25) in 590 ms on localhost (executor driver) (3/4)
18/02/28 13:07:13 INFO Executor: Finished task 2.0 in stage 7.0 (TID 24). 2103 bytes result sent to driver
18/02/28 13:07:13 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 24) in 608 ms on localhost (executor driver) (4/4)
18/02/28 13:07:13 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
18/02/28 13:07:13 INFO DAGScheduler: ShuffleMapStage 7 (collect at utils.scala:211) finished in 0.609 s
18/02/28 13:07:13 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:07:13 INFO DAGScheduler: running: Set()
18/02/28 13:07:13 INFO DAGScheduler: waiting: Set(ResultStage 8)
18/02/28 13:07:13 INFO DAGScheduler: failed: Set()
18/02/28 13:07:13 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[28] at collect at utils.scala:211), which has no missing parents
18/02/28 13:07:13 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 25.0 KB, free 364.9 MB)
18/02/28 13:07:13 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 12.4 KB, free 364.9 MB)
18/02/28 13:07:13 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:60941 (size: 12.4 KB, free: 366.1 MB)
18/02/28 13:07:13 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
18/02/28 13:07:13 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 8 (MapPartitionsRDD[28] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:07:13 INFO TaskSchedulerImpl: Adding task set 8.0 with 4 tasks
18/02/28 13:07:13 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 26, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:07:13 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 27, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 13:07:13 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 28, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 13:07:13 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 29, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 13:07:13 INFO Executor: Running task 0.0 in stage 8.0 (TID 26)
18/02/28 13:07:13 INFO Executor: Running task 1.0 in stage 8.0 (TID 27)
18/02/28 13:07:13 INFO Executor: Running task 2.0 in stage 8.0 (TID 28)
18/02/28 13:07:13 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 13:07:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:07:13 INFO Executor: Finished task 0.0 in stage 8.0 (TID 26). 2518 bytes result sent to driver
18/02/28 13:07:13 INFO Executor: Running task 3.0 in stage 8.0 (TID 29)
18/02/28 13:07:13 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 13:07:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:07:13 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 4 blocks
18/02/28 13:07:13 INFO Executor: Finished task 3.0 in stage 8.0 (TID 29). 2551 bytes result sent to driver
18/02/28 13:07:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
18/02/28 13:07:13 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 26) in 20 ms on localhost (executor driver) (1/4)
18/02/28 13:07:13 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 29) in 20 ms on localhost (executor driver) (2/4)
18/02/28 13:07:13 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 13:07:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:07:13 INFO Executor: Finished task 1.0 in stage 8.0 (TID 27). 2535 bytes result sent to driver
18/02/28 13:07:13 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 27) in 24 ms on localhost (executor driver) (3/4)
18/02/28 13:07:13 INFO Executor: Finished task 2.0 in stage 8.0 (TID 28). 2569 bytes result sent to driver
18/02/28 13:07:13 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 28) in 29 ms on localhost (executor driver) (4/4)
18/02/28 13:07:13 INFO DAGScheduler: ResultStage 8 (collect at utils.scala:211) finished in 0.030 s
18/02/28 13:07:13 INFO DAGScheduler: Job 4 finished: collect at utils.scala:211, took 0.655346 s
18/02/28 13:07:13 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
18/02/28 13:08:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:08:08 INFO SparkSqlParser: Parsing command: SELECT `x`, `y`, count(*) AS `fillname`
FROM (SELECT `year`, `month`, `day`, `dep_time`, `sched_dep_time`, `dep_delay`, `arr_time`, `sched_arr_time`, `arr_delay`, `carrier`, `flight`, `tailnum`, `origin`, `dest`, `air_time`, `distance`, `hour`, `minute`, `time_hour`, (max(`deptime`) OVER () - min(`deptime`) OVER () / 100.0 * CASE WHEN (CAST(FLOOR((`deptime` - min(`deptime`) OVER ()) / max(`deptime`) OVER () - min(`deptime`) OVER () / 100.0) AS INT) = 100.0) THEN (CAST(FLOOR((`deptime` - min(`deptime`) OVER ()) / max(`deptime`) OVER () - min(`deptime`) OVER () / 100.0) AS INT) - 1.0) WHEN NOT(CAST(FLOOR((`deptime` - min(`deptime`) OVER ()) / max(`deptime`) OVER () - min(`deptime`) OVER () / 100.0) AS INT) = 100.0) THEN (CAST(FLOOR((`deptime` - min(`deptime`) OVER ()) / max(`deptime`) OVER () - min(`deptime`) OVER () / 100.0) AS INT)) END) + min(`deptime`) OVER () AS `x`, (max(`arrtime`) OVER () - min(`arrtime`) OVER () / 100.0 * CASE WHEN (CAST(FLOOR((`arrtime` - min(`arrtime`) OVER ()) / max(`arrtime`) OVER () - min(`arrtime`) OVER () / 100.0) AS INT) = 100.0) THEN (CAST(FLOOR((`arrtime` - min(`arrtime`) OVER ()) / max(`arrtime`) OVER () - min(`arrtime`) OVER () / 100.0) AS INT) - 1.0) WHEN NOT(CAST(FLOOR((`arrtime` - min(`arrtime`) OVER ()) / max(`arrtime`) OVER () - min(`arrtime`) OVER () / 100.0) AS INT) = 100.0) THEN (CAST(FLOOR((`arrtime` - min(`arrtime`) OVER ()) / max(`arrtime`) OVER () - min(`arrtime`) OVER () / 100.0) AS INT)) END) + min(`arrtime`) OVER () AS `y`
FROM `spark_flights`) `npatwxdkfx`
GROUP BY `x`, `y`
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:08:26 INFO SparkSqlParser: Parsing command: SELECT `x`, `y`, count(*) AS `fillname`
FROM (SELECT `year`, `month`, `day`, `dep_time`, `sched_dep_time`, `dep_delay`, `arr_time`, `sched_arr_time`, `arr_delay`, `carrier`, `flight`, `tailnum`, `origin`, `dest`, `air_time`, `distance`, `hour`, `minute`, `time_hour`, (max(`dep_time`) OVER () - min(`dep_time`) OVER () / 100.0 * CASE WHEN (CAST(FLOOR((`dep_time` - min(`dep_time`) OVER ()) / max(`dep_time`) OVER () - min(`dep_time`) OVER () / 100.0) AS INT) = 100.0) THEN (CAST(FLOOR((`dep_time` - min(`dep_time`) OVER ()) / max(`dep_time`) OVER () - min(`dep_time`) OVER () / 100.0) AS INT) - 1.0) WHEN NOT(CAST(FLOOR((`dep_time` - min(`dep_time`) OVER ()) / max(`dep_time`) OVER () - min(`dep_time`) OVER () / 100.0) AS INT) = 100.0) THEN (CAST(FLOOR((`dep_time` - min(`dep_time`) OVER ()) / max(`dep_time`) OVER () - min(`dep_time`) OVER () / 100.0) AS INT)) END) + min(`dep_time`) OVER () AS `x`, (max(`arr_time`) OVER () - min(`arr_time`) OVER () / 100.0 * CASE WHEN (CAST(FLOOR((`arr_time` - min(`arr_time`) OVER ()) / max(`arr_time`) OVER () - min(`arr_time`) OVER () / 100.0) AS INT) = 100.0) THEN (CAST(FLOOR((`arr_time` - min(`arr_time`) OVER ()) / max(`arr_time`) OVER () - min(`arr_time`) OVER () / 100.0) AS INT) - 1.0) WHEN NOT(CAST(FLOOR((`arr_time` - min(`arr_time`) OVER ()) / max(`arr_time`) OVER () - min(`arr_time`) OVER () / 100.0) AS INT) = 100.0) THEN (CAST(FLOOR((`arr_time` - min(`arr_time`) OVER ()) / max(`arr_time`) OVER () - min(`arr_time`) OVER () / 100.0) AS INT)) END) + min(`arr_time`) OVER () AS `y`
FROM `spark_flights`) `bqizrqcvet`
GROUP BY `x`, `y`
18/02/28 13:08:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:08:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:08:27 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 13:08:27 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 13:08:27 INFO FileSourceStrategy: Output Data Schema: struct<dep_time: string, arr_time: string>
18/02/28 13:08:27 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 13:08:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
18/02/28 13:08:27 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
18/02/28 13:08:27 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:60941 in memory (size: 12.4 KB, free: 366.2 MB)
18/02/28 13:08:27 INFO CodeGenerator: Code generated in 104.543857 ms
18/02/28 13:08:27 INFO CodeGenerator: Code generated in 7.0742 ms
18/02/28 13:08:27 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 282.5 KB, free 364.7 MB)
18/02/28 13:08:27 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.7 MB)
18/02/28 13:08:27 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:60941 (size: 24.1 KB, free: 366.1 MB)
18/02/28 13:08:27 INFO SparkContext: Created broadcast 13 from collect at utils.scala:211
18/02/28 13:08:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21019222 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 13:08:27 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:08:27 INFO DAGScheduler: Registering RDD 31 (collect at utils.scala:211)
18/02/28 13:08:27 INFO DAGScheduler: Got job 5 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:08:27 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:211)
18/02/28 13:08:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
18/02/28 13:08:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
18/02/28 13:08:27 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[31] at collect at utils.scala:211), which has no missing parents
18/02/28 13:08:27 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 13.7 KB, free 364.7 MB)
18/02/28 13:08:27 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 7.8 KB, free 364.6 MB)
18/02/28 13:08:27 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:60941 (size: 7.8 KB, free: 366.1 MB)
18/02/28 13:08:27 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
18/02/28 13:08:27 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[31] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:08:27 INFO TaskSchedulerImpl: Adding task set 9.0 with 4 tasks
18/02/28 13:08:27 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:08:27 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 31, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:08:27 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 32, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:08:27 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 33, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:08:27 INFO Executor: Running task 0.0 in stage 9.0 (TID 30)
18/02/28 13:08:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_7.csv, range: 0-2938867, partition values: [empty row]
18/02/28 13:08:27 INFO Executor: Running task 3.0 in stage 9.0 (TID 33)
18/02/28 13:08:27 INFO Executor: Running task 1.0 in stage 9.0 (TID 31)
18/02/28 13:08:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_11.csv, range: 0-2757037, partition values: [empty row]
18/02/28 13:08:27 INFO Executor: Running task 2.0 in stage 9.0 (TID 32)
18/02/28 13:08:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_3.csv, range: 0-2881793, partition values: [empty row]
18/02/28 13:08:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_4.csv, range: 0-2830543, partition values: [empty row]
18/02/28 13:08:27 INFO CodeGenerator: Code generated in 17.664343 ms
18/02/28 13:08:27 INFO ContextCleaner: Cleaned accumulator 305
18/02/28 13:08:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_6.csv, range: 0-2820227, partition values: [empty row]
18/02/28 13:08:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_8.csv, range: 0-2932019, partition values: [empty row]
18/02/28 13:08:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_5.csv, range: 0-2880181, partition values: [empty row]
18/02/28 13:08:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_1.csv, range: 0-2697256, partition values: [empty row]
18/02/28 13:08:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_12.csv, range: 0-2836468, partition values: [empty row]
18/02/28 13:08:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_2.csv, range: 0-2487144, partition values: [empty row]
18/02/28 13:08:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_10.csv, range: 0-2920629, partition values: [empty row]
18/02/28 13:08:28 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_9.csv, range: 0-2763076, partition values: [empty row]
18/02/28 13:08:28 INFO Executor: Finished task 1.0 in stage 9.0 (TID 31). 1427 bytes result sent to driver
18/02/28 13:08:28 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 31) in 607 ms on localhost (executor driver) (1/4)
18/02/28 13:08:28 INFO Executor: Finished task 3.0 in stage 9.0 (TID 33). 1470 bytes result sent to driver
18/02/28 13:08:28 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 33) in 608 ms on localhost (executor driver) (2/4)
18/02/28 13:08:28 INFO Executor: Finished task 0.0 in stage 9.0 (TID 30). 1427 bytes result sent to driver
18/02/28 13:08:28 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 30) in 613 ms on localhost (executor driver) (3/4)
18/02/28 13:08:28 INFO Executor: Finished task 2.0 in stage 9.0 (TID 32). 1427 bytes result sent to driver
18/02/28 13:08:28 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 32) in 619 ms on localhost (executor driver) (4/4)
18/02/28 13:08:28 INFO DAGScheduler: ShuffleMapStage 9 (collect at utils.scala:211) finished in 0.621 s
18/02/28 13:08:28 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:08:28 INFO DAGScheduler: running: Set()
18/02/28 13:08:28 INFO DAGScheduler: waiting: Set(ResultStage 10)
18/02/28 13:08:28 INFO DAGScheduler: failed: Set()
18/02/28 13:08:28 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
18/02/28 13:08:28 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[35] at collect at utils.scala:211), which has no missing parents
18/02/28 13:08:28 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 89.3 KB, free 364.6 MB)
18/02/28 13:08:28 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 31.9 KB, free 364.5 MB)
18/02/28 13:08:28 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:60941 (size: 31.9 KB, free: 366.1 MB)
18/02/28 13:08:28 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
18/02/28 13:08:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[35] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:08:28 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
18/02/28 13:08:28 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 34, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:08:28 INFO Executor: Running task 0.0 in stage 10.0 (TID 34)
18/02/28 13:08:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:08:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:08:28 INFO CodeGenerator: Code generated in 33.852985 ms
18/02/28 13:08:28 INFO CodeGenerator: Code generated in 40.496639 ms
18/02/28 13:08:28 INFO CodeGenerator: Code generated in 48.24328 ms
18/02/28 13:08:28 INFO CodeGenerator: Code generated in 25.313662 ms
18/02/28 13:08:28 INFO CodeGenerator: Code generated in 8.964579 ms
18/02/28 13:08:28 INFO CodeGenerator: Code generated in 15.633623 ms
18/02/28 13:08:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (0  time so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (1  time so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (2  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (3  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (4  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (5  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (6  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (7  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (8  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (9  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (10  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (11  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (12  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (13  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (14  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (15  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (16  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (17  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (18  times so far)
18/02/28 13:08:28 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:60941 in memory (size: 7.8 KB, free: 366.1 MB)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (19  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (20  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (21  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (22  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (23  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (24  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (25  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (26  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (27  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (28  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (29  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (30  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (31  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (32  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (33  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (34  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (35  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (36  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (37  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (38  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (39  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (40  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (41  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (42  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (43  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (44  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (45  times so far)
18/02/28 13:08:28 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:28 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (46  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (47  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (48  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (49  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (50  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (51  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (52  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (53  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (54  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (55  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (56  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (57  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (58  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (59  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (60  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (61  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (62  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (63  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (64  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (65  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (66  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (67  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (68  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (69  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (70  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (71  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (72  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (73  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (74  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (75  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (76  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (77  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (78  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (79  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (80  times so far)
18/02/28 13:08:29 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:08:29 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (81  times so far)
18/02/28 13:08:32 INFO Executor: Finished task 0.0 in stage 10.0 (TID 34). 2636 bytes result sent to driver
18/02/28 13:08:32 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 34) in 4344 ms on localhost (executor driver) (1/1)
18/02/28 13:08:32 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
18/02/28 13:08:32 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:211) finished in 4.345 s
18/02/28 13:08:32 INFO DAGScheduler: Job 5 finished: collect at utils.scala:211, took 4.986840 s
18/02/28 13:08:32 INFO CodeGenerator: Code generated in 5.348141 ms
18/02/28 13:09:21 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:09:21 INFO SparkSqlParser: Parsing command: SELECT `x`, `y`, count(*) AS `fillname`
FROM (SELECT `year`, `month`, `day`, `dep_time`, `sched_dep_time`, `dep_delay`, `arr_time`, `sched_arr_time`, `arr_delay`, `carrier`, `flight`, `tailnum`, `origin`, `dest`, `air_time`, `distance`, `hour`, `minute`, `time_hour`, (max(`dep_time`) OVER () - min(`dep_time`) OVER () / 100.0 * CASE WHEN (CAST(FLOOR((`dep_time` - min(`dep_time`) OVER ()) / max(`dep_time`) OVER () - min(`dep_time`) OVER () / 100.0) AS INT) = 100.0) THEN (CAST(FLOOR((`dep_time` - min(`dep_time`) OVER ()) / max(`dep_time`) OVER () - min(`dep_time`) OVER () / 100.0) AS INT) - 1.0) WHEN NOT(CAST(FLOOR((`dep_time` - min(`dep_time`) OVER ()) / max(`dep_time`) OVER () - min(`dep_time`) OVER () / 100.0) AS INT) = 100.0) THEN (CAST(FLOOR((`dep_time` - min(`dep_time`) OVER ()) / max(`dep_time`) OVER () - min(`dep_time`) OVER () / 100.0) AS INT)) END) + min(`dep_time`) OVER () AS `x`, (max(`arr_time`) OVER () - min(`arr_time`) OVER () / 100.0 * CASE WHEN (CAST(FLOOR((`arr_time` - min(`arr_time`) OVER ()) / max(`arr_time`) OVER () - min(`arr_time`) OVER () / 100.0) AS INT) = 100.0) THEN (CAST(FLOOR((`arr_time` - min(`arr_time`) OVER ()) / max(`arr_time`) OVER () - min(`arr_time`) OVER () / 100.0) AS INT) - 1.0) WHEN NOT(CAST(FLOOR((`arr_time` - min(`arr_time`) OVER ()) / max(`arr_time`) OVER () - min(`arr_time`) OVER () / 100.0) AS INT) = 100.0) THEN (CAST(FLOOR((`arr_time` - min(`arr_time`) OVER ()) / max(`arr_time`) OVER () - min(`arr_time`) OVER () / 100.0) AS INT)) END) + min(`arr_time`) OVER () AS `y`
FROM `spark_flights`) `ajknftkizg`
GROUP BY `x`, `y`
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:09:21 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:09:21 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 13:09:21 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 13:09:21 INFO FileSourceStrategy: Output Data Schema: struct<dep_time: string, arr_time: string>
18/02/28 13:09:21 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 13:09:21 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
18/02/28 13:09:21 INFO ContextCleaner: Cleaned accumulator 369
18/02/28 13:09:21 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 282.5 KB, free 364.3 MB)
18/02/28 13:09:21 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.2 MB)
18/02/28 13:09:21 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:60941 (size: 24.1 KB, free: 366.1 MB)
18/02/28 13:09:21 INFO SparkContext: Created broadcast 16 from collect at utils.scala:211
18/02/28 13:09:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21019222 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 13:09:21 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:09:21 INFO DAGScheduler: Registering RDD 38 (collect at utils.scala:211)
18/02/28 13:09:21 INFO DAGScheduler: Got job 6 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:09:21 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:211)
18/02/28 13:09:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
18/02/28 13:09:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
18/02/28 13:09:21 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[38] at collect at utils.scala:211), which has no missing parents
18/02/28 13:09:21 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 13.7 KB, free 364.2 MB)
18/02/28 13:09:21 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 7.8 KB, free 364.2 MB)
18/02/28 13:09:21 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:60941 (size: 7.8 KB, free: 366.1 MB)
18/02/28 13:09:21 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
18/02/28 13:09:21 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[38] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:09:21 INFO TaskSchedulerImpl: Adding task set 11.0 with 4 tasks
18/02/28 13:09:21 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:09:21 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 36, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:09:21 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 37, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:09:21 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 38, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:09:21 INFO Executor: Running task 0.0 in stage 11.0 (TID 35)
18/02/28 13:09:21 INFO Executor: Running task 1.0 in stage 11.0 (TID 36)
18/02/28 13:09:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_7.csv, range: 0-2938867, partition values: [empty row]
18/02/28 13:09:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_3.csv, range: 0-2881793, partition values: [empty row]
18/02/28 13:09:21 INFO Executor: Running task 2.0 in stage 11.0 (TID 37)
18/02/28 13:09:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_4.csv, range: 0-2830543, partition values: [empty row]
18/02/28 13:09:21 INFO Executor: Running task 3.0 in stage 11.0 (TID 38)
18/02/28 13:09:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_11.csv, range: 0-2757037, partition values: [empty row]
18/02/28 13:09:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_5.csv, range: 0-2880181, partition values: [empty row]
18/02/28 13:09:21 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_8.csv, range: 0-2932019, partition values: [empty row]
18/02/28 13:09:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_6.csv, range: 0-2820227, partition values: [empty row]
18/02/28 13:09:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_1.csv, range: 0-2697256, partition values: [empty row]
18/02/28 13:09:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_12.csv, range: 0-2836468, partition values: [empty row]
18/02/28 13:09:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_9.csv, range: 0-2763076, partition values: [empty row]
18/02/28 13:09:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_10.csv, range: 0-2920629, partition values: [empty row]
18/02/28 13:09:22 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_2.csv, range: 0-2487144, partition values: [empty row]
18/02/28 13:09:22 INFO Executor: Finished task 1.0 in stage 11.0 (TID 36). 1470 bytes result sent to driver
18/02/28 13:09:22 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 36) in 445 ms on localhost (executor driver) (1/4)
18/02/28 13:09:22 INFO Executor: Finished task 3.0 in stage 11.0 (TID 38). 1427 bytes result sent to driver
18/02/28 13:09:22 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 38) in 459 ms on localhost (executor driver) (2/4)
18/02/28 13:09:22 INFO Executor: Finished task 2.0 in stage 11.0 (TID 37). 1427 bytes result sent to driver
18/02/28 13:09:22 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 37) in 474 ms on localhost (executor driver) (3/4)
18/02/28 13:09:22 INFO Executor: Finished task 0.0 in stage 11.0 (TID 35). 1427 bytes result sent to driver
18/02/28 13:09:22 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 35) in 481 ms on localhost (executor driver) (4/4)
18/02/28 13:09:22 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
18/02/28 13:09:22 INFO DAGScheduler: ShuffleMapStage 11 (collect at utils.scala:211) finished in 0.481 s
18/02/28 13:09:22 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:09:22 INFO DAGScheduler: running: Set()
18/02/28 13:09:22 INFO DAGScheduler: waiting: Set(ResultStage 12)
18/02/28 13:09:22 INFO DAGScheduler: failed: Set()
18/02/28 13:09:22 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[42] at collect at utils.scala:211), which has no missing parents
18/02/28 13:09:22 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 89.3 KB, free 364.1 MB)
18/02/28 13:09:22 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 31.8 KB, free 364.1 MB)
18/02/28 13:09:22 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:60941 (size: 31.8 KB, free: 366.0 MB)
18/02/28 13:09:22 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
18/02/28 13:09:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[42] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:09:22 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
18/02/28 13:09:22 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 39, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:09:22 INFO Executor: Running task 0.0 in stage 12.0 (TID 39)
18/02/28 13:09:22 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:09:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:09:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (0  time so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (1  time so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (2  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (3  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (4  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (5  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (6  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (7  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (8  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (9  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (10  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (11  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (12  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (13  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (14  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (15  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (16  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (17  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (18  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (19  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (20  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (21  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (22  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (23  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (24  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (25  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (26  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (27  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (28  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (29  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (30  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (31  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (32  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (33  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (34  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (35  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (36  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (37  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (38  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (39  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (40  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (41  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (42  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (43  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (44  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (45  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (46  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (47  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (48  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (49  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (50  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (51  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (52  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (53  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (54  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (55  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (56  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (57  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (58  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (59  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (60  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (61  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (62  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (63  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (64  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (65  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (66  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (67  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (68  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (69  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (70  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (71  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (72  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (73  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (74  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (75  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (76  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (77  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (78  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (79  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (80  times so far)
18/02/28 13:09:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:09:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 4.1 MB to disk (81  times so far)
18/02/28 13:09:23 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:60941 in memory (size: 13.3 KB, free: 366.1 MB)
18/02/28 13:09:23 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:60941 in memory (size: 13.3 KB, free: 366.1 MB)
18/02/28 13:09:23 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:60941 in memory (size: 8.0 KB, free: 366.1 MB)
18/02/28 13:09:23 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:60941 in memory (size: 13.3 KB, free: 366.1 MB)
18/02/28 13:09:23 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:60941 in memory (size: 31.9 KB, free: 366.1 MB)
18/02/28 13:09:23 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:60941 in memory (size: 7.8 KB, free: 366.1 MB)
18/02/28 13:09:25 INFO Executor: Finished task 0.0 in stage 12.0 (TID 39). 2593 bytes result sent to driver
18/02/28 13:09:25 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 39) in 3382 ms on localhost (executor driver) (1/1)
18/02/28 13:09:25 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
18/02/28 13:09:25 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:211) finished in 3.383 s
18/02/28 13:09:25 INFO DAGScheduler: Job 6 finished: collect at utils.scala:211, took 3.882042 s
18/02/28 13:11:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:11:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_flights`
18/02/28 13:11:42 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e0266a72c4
18/02/28 13:11:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:11:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0266a72c4` AS `zzz57`
WHERE (0 = 1)
18/02/28 13:11:42 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e06d8933a9
18/02/28 13:11:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:11:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e06d8933a9` AS `zzz58`
WHERE (0 = 1)
18/02/28 13:11:42 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e035854c80
18/02/28 13:11:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:11:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e035854c80` AS `zzz59`
WHERE (0 = 1)
18/02/28 13:11:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:11:45 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e0266a72c4`
18/02/28 13:11:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:11:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:11:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:11:45 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e0266a72c4`
18/02/28 13:11:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:11:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:11:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:11:45 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e0266a72c4`
18/02/28 13:11:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:11:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:11:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:11:45 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e0266a72c4`
18/02/28 13:11:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:11:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:11:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:11:45 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e0266a72c4`
18/02/28 13:11:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:11:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:11:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:11:45 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e0266a72c4`
LIMIT 1000
18/02/28 13:11:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:11:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:11:45 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 13:11:45 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 13:11:45 INFO FileSourceStrategy: Output Data Schema: struct<year: string, month: string, day: string, dep_time: string, sched_dep_time: string ... 17 more fields>
18/02/28 13:11:45 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 13:11:45 INFO CodeGenerator: Code generated in 21.863657 ms
18/02/28 13:11:45 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 282.5 KB, free 364.1 MB)
18/02/28 13:11:45 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.1 MB)
18/02/28 13:11:45 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:60941 (size: 24.1 KB, free: 366.1 MB)
18/02/28 13:11:45 INFO SparkContext: Created broadcast 19 from collect at utils.scala:211
18/02/28 13:11:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21019222 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 13:11:45 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:11:45 INFO DAGScheduler: Registering RDD 45 (collect at utils.scala:211)
18/02/28 13:11:45 INFO DAGScheduler: Got job 7 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:11:45 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:211)
18/02/28 13:11:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
18/02/28 13:11:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
18/02/28 13:11:45 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[45] at collect at utils.scala:211), which has no missing parents
18/02/28 13:11:45 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 26.7 KB, free 364.1 MB)
18/02/28 13:11:45 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 12.7 KB, free 364.0 MB)
18/02/28 13:11:45 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:60941 (size: 12.7 KB, free: 366.1 MB)
18/02/28 13:11:45 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
18/02/28 13:11:45 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[45] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:11:45 INFO TaskSchedulerImpl: Adding task set 13.0 with 4 tasks
18/02/28 13:11:45 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 40, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:11:45 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 41, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:11:45 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 42, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:11:45 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 43, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:11:45 INFO Executor: Running task 0.0 in stage 13.0 (TID 40)
18/02/28 13:11:45 INFO Executor: Running task 3.0 in stage 13.0 (TID 43)
18/02/28 13:11:45 INFO Executor: Running task 1.0 in stage 13.0 (TID 41)
18/02/28 13:11:45 INFO Executor: Running task 2.0 in stage 13.0 (TID 42)
18/02/28 13:11:45 INFO CodeGenerator: Code generated in 22.852748 ms
18/02/28 13:11:45 INFO ContextCleaner: Cleaned accumulator 433
18/02/28 13:11:45 INFO CodeGenerator: Code generated in 12.835255 ms
18/02/28 13:11:45 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_3.csv, range: 0-2881793, partition values: [empty row]
18/02/28 13:11:45 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_7.csv, range: 0-2938867, partition values: [empty row]
18/02/28 13:11:45 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_4.csv, range: 0-2830543, partition values: [empty row]
18/02/28 13:11:45 INFO CodeGenerator: Code generated in 19.400629 ms
18/02/28 13:11:45 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_11.csv, range: 0-2757037, partition values: [empty row]
18/02/28 13:11:45 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_1.csv, range: 0-2697256, partition values: [empty row]
18/02/28 13:11:45 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_5.csv, range: 0-2880181, partition values: [empty row]
18/02/28 13:11:45 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_8.csv, range: 0-2932019, partition values: [empty row]
18/02/28 13:11:45 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_6.csv, range: 0-2820227, partition values: [empty row]
18/02/28 13:11:46 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_2.csv, range: 0-2487144, partition values: [empty row]
18/02/28 13:11:46 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_12.csv, range: 0-2836468, partition values: [empty row]
18/02/28 13:11:46 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_9.csv, range: 0-2763076, partition values: [empty row]
18/02/28 13:11:46 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_10.csv, range: 0-2920629, partition values: [empty row]
18/02/28 13:11:46 INFO Executor: Finished task 3.0 in stage 13.0 (TID 43). 2395 bytes result sent to driver
18/02/28 13:11:46 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 43) in 1503 ms on localhost (executor driver) (1/4)
18/02/28 13:11:46 INFO Executor: Finished task 1.0 in stage 13.0 (TID 41). 2395 bytes result sent to driver
18/02/28 13:11:46 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 41) in 1527 ms on localhost (executor driver) (2/4)
18/02/28 13:11:46 INFO Executor: Finished task 0.0 in stage 13.0 (TID 40). 2395 bytes result sent to driver
18/02/28 13:11:46 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 40) in 1534 ms on localhost (executor driver) (3/4)
18/02/28 13:11:46 INFO Executor: Finished task 2.0 in stage 13.0 (TID 42). 2395 bytes result sent to driver
18/02/28 13:11:46 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 42) in 1538 ms on localhost (executor driver) (4/4)
18/02/28 13:11:46 INFO DAGScheduler: ShuffleMapStage 13 (collect at utils.scala:211) finished in 1.542 s
18/02/28 13:11:46 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:11:46 INFO DAGScheduler: running: Set()
18/02/28 13:11:46 INFO DAGScheduler: waiting: Set(ResultStage 14)
18/02/28 13:11:46 INFO DAGScheduler: failed: Set()
18/02/28 13:11:46 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
18/02/28 13:11:46 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[48] at collect at utils.scala:211), which has no missing parents
18/02/28 13:11:46 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 6.9 KB, free 364.0 MB)
18/02/28 13:11:46 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.0 MB)
18/02/28 13:11:46 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 366.1 MB)
18/02/28 13:11:46 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
18/02/28 13:11:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[48] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:11:46 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
18/02/28 13:11:46 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 44, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:11:46 INFO Executor: Running task 0.0 in stage 14.0 (TID 44)
18/02/28 13:11:46 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:11:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:11:46 INFO Executor: Finished task 0.0 in stage 14.0 (TID 44). 1471 bytes result sent to driver
18/02/28 13:11:46 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 44) in 4 ms on localhost (executor driver) (1/1)
18/02/28 13:11:46 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
18/02/28 13:11:46 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:211) finished in 0.005 s
18/02/28 13:11:46 INFO DAGScheduler: Job 7 finished: collect at utils.scala:211, took 1.557073 s
18/02/28 13:11:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:11:54 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0266a72c4`
18/02/28 13:11:54 INFO SparkSqlParser: Parsing command: training
18/02/28 13:11:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:11:54 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training` AS `zzz60`
WHERE (0 = 1)
18/02/28 13:11:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:11:54 INFO SparkSqlParser: Parsing command: CACHE TABLE `training`
18/02/28 13:11:54 INFO SparkSqlParser: Parsing command: `training`
18/02/28 13:11:54 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 13:11:54 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 13:11:54 INFO FileSourceStrategy: Output Data Schema: struct<year: string, month: string, day: string, dep_time: string, sched_dep_time: string ... 17 more fields>
18/02/28 13:11:54 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 13:11:54 INFO CodeGenerator: Code generated in 14.422384 ms
18/02/28 13:11:54 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 282.5 KB, free 363.8 MB)
18/02/28 13:11:54 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 24.1 KB, free 363.7 MB)
18/02/28 13:11:54 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:60941 (size: 24.1 KB, free: 366.1 MB)
18/02/28 13:11:54 INFO SparkContext: Created broadcast 22 from sql at <unknown>:0
18/02/28 13:11:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21019222 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 13:11:54 INFO CodeGenerator: Code generated in 5.544196 ms
18/02/28 13:11:54 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 13:11:54 INFO DAGScheduler: Registering RDD 54 (sql at <unknown>:0)
18/02/28 13:11:54 INFO DAGScheduler: Got job 8 (sql at <unknown>:0) with 1 output partitions
18/02/28 13:11:54 INFO DAGScheduler: Final stage: ResultStage 16 (sql at <unknown>:0)
18/02/28 13:11:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
18/02/28 13:11:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 15)
18/02/28 13:11:54 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[54] at sql at <unknown>:0), which has no missing parents
18/02/28 13:11:54 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 40.2 KB, free 363.7 MB)
18/02/28 13:11:54 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 16.8 KB, free 363.7 MB)
18/02/28 13:11:54 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:60941 (size: 16.8 KB, free: 366.0 MB)
18/02/28 13:11:54 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
18/02/28 13:11:54 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[54] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:11:54 INFO TaskSchedulerImpl: Adding task set 15.0 with 4 tasks
18/02/28 13:11:54 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 45, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:11:54 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 46, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:11:54 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 47, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:11:54 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 48, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:11:54 INFO Executor: Running task 0.0 in stage 15.0 (TID 45)
18/02/28 13:11:54 INFO Executor: Running task 1.0 in stage 15.0 (TID 46)
18/02/28 13:11:54 INFO Executor: Running task 2.0 in stage 15.0 (TID 47)
18/02/28 13:11:54 INFO Executor: Running task 3.0 in stage 15.0 (TID 48)
18/02/28 13:11:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_3.csv, range: 0-2881793, partition values: [empty row]
18/02/28 13:11:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_4.csv, range: 0-2830543, partition values: [empty row]
18/02/28 13:11:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_11.csv, range: 0-2757037, partition values: [empty row]
18/02/28 13:11:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_7.csv, range: 0-2938867, partition values: [empty row]
18/02/28 13:11:54 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 366.1 MB)
18/02/28 13:11:54 INFO ContextCleaner: Cleaned accumulator 511
18/02/28 13:11:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_5.csv, range: 0-2880181, partition values: [empty row]
18/02/28 13:11:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_6.csv, range: 0-2820227, partition values: [empty row]
18/02/28 13:11:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_1.csv, range: 0-2697256, partition values: [empty row]
18/02/28 13:11:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_8.csv, range: 0-2932019, partition values: [empty row]
18/02/28 13:11:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_9.csv, range: 0-2763076, partition values: [empty row]
18/02/28 13:11:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_12.csv, range: 0-2836468, partition values: [empty row]
18/02/28 13:11:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_2.csv, range: 0-2487144, partition values: [empty row]
18/02/28 13:11:54 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_10.csv, range: 0-2920629, partition values: [empty row]
18/02/28 13:11:55 INFO MemoryStore: Block rdd_51_3 stored as values in memory (estimated size 364.6 KB, free 363.3 MB)
18/02/28 13:11:55 INFO MemoryStore: Block rdd_51_1 stored as values in memory (estimated size 394.7 KB, free 363.0 MB)
18/02/28 13:11:55 INFO BlockManagerInfo: Added rdd_51_3 in memory on 127.0.0.1:60941 (size: 364.6 KB, free: 365.7 MB)
18/02/28 13:11:55 INFO BlockManagerInfo: Added rdd_51_1 in memory on 127.0.0.1:60941 (size: 394.7 KB, free: 365.3 MB)
18/02/28 13:11:55 INFO MemoryStore: Block rdd_51_0 stored as values in memory (estimated size 394.9 KB, free 362.6 MB)
18/02/28 13:11:55 INFO BlockManagerInfo: Added rdd_51_0 in memory on 127.0.0.1:60941 (size: 394.9 KB, free: 364.9 MB)
18/02/28 13:11:55 INFO CodeGenerator: Code generated in 6.299148 ms
18/02/28 13:11:55 INFO MemoryStore: Block rdd_51_2 stored as values in memory (estimated size 382.9 KB, free 362.2 MB)
18/02/28 13:11:55 INFO BlockManagerInfo: Added rdd_51_2 in memory on 127.0.0.1:60941 (size: 382.9 KB, free: 364.6 MB)
18/02/28 13:11:55 INFO CodeGenerator: Code generated in 21.635868 ms
18/02/28 13:11:55 INFO Executor: Finished task 2.0 in stage 15.0 (TID 47). 3129 bytes result sent to driver
18/02/28 13:11:55 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 47) in 1425 ms on localhost (executor driver) (1/4)
18/02/28 13:11:55 INFO Executor: Finished task 0.0 in stage 15.0 (TID 45). 3086 bytes result sent to driver
18/02/28 13:11:55 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 45) in 1431 ms on localhost (executor driver) (2/4)
18/02/28 13:11:55 INFO Executor: Finished task 1.0 in stage 15.0 (TID 46). 3086 bytes result sent to driver
18/02/28 13:11:55 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 46) in 1436 ms on localhost (executor driver) (3/4)
18/02/28 13:11:55 INFO Executor: Finished task 3.0 in stage 15.0 (TID 48). 3086 bytes result sent to driver
18/02/28 13:11:55 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 48) in 1437 ms on localhost (executor driver) (4/4)
18/02/28 13:11:55 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
18/02/28 13:11:55 INFO DAGScheduler: ShuffleMapStage 15 (sql at <unknown>:0) finished in 1.438 s
18/02/28 13:11:55 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:11:55 INFO DAGScheduler: running: Set()
18/02/28 13:11:55 INFO DAGScheduler: waiting: Set(ResultStage 16)
18/02/28 13:11:55 INFO DAGScheduler: failed: Set()
18/02/28 13:11:55 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[57] at sql at <unknown>:0), which has no missing parents
18/02/28 13:11:55 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 7.0 KB, free 362.2 MB)
18/02/28 13:11:55 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.7 KB, free 362.2 MB)
18/02/28 13:11:55 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 364.5 MB)
18/02/28 13:11:55 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
18/02/28 13:11:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[57] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 13:11:55 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
18/02/28 13:11:55 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 49, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:11:55 INFO Executor: Running task 0.0 in stage 16.0 (TID 49)
18/02/28 13:11:55 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:11:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:11:55 INFO Executor: Finished task 0.0 in stage 16.0 (TID 49). 1452 bytes result sent to driver
18/02/28 13:11:55 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 49) in 7 ms on localhost (executor driver) (1/1)
18/02/28 13:11:55 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
18/02/28 13:11:55 INFO DAGScheduler: ResultStage 16 (sql at <unknown>:0) finished in 0.008 s
18/02/28 13:11:55 INFO DAGScheduler: Job 8 finished: sql at <unknown>:0, took 1.471887 s
18/02/28 13:11:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:11:55 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `training`
18/02/28 13:11:55 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:11:55 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:11:55 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:11:55 INFO DAGScheduler: Registering RDD 60 (collect at utils.scala:211)
18/02/28 13:11:55 INFO DAGScheduler: Got job 9 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:11:55 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:211)
18/02/28 13:11:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
18/02/28 13:11:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
18/02/28 13:11:55 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[60] at collect at utils.scala:211), which has no missing parents
18/02/28 13:11:55 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 40.2 KB, free 362.1 MB)
18/02/28 13:11:55 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 16.9 KB, free 362.1 MB)
18/02/28 13:11:55 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:60941 (size: 16.9 KB, free: 364.5 MB)
18/02/28 13:11:55 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1006
18/02/28 13:11:55 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[60] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:11:55 INFO TaskSchedulerImpl: Adding task set 17.0 with 4 tasks
18/02/28 13:11:55 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:11:55 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 51, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:11:55 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 52, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:11:55 INFO TaskSetManager: Starting task 3.0 in stage 17.0 (TID 53, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:11:55 INFO Executor: Running task 1.0 in stage 17.0 (TID 51)
18/02/28 13:11:55 INFO Executor: Running task 0.0 in stage 17.0 (TID 50)
18/02/28 13:11:55 INFO BlockManager: Found block rdd_51_1 locally
18/02/28 13:11:55 INFO Executor: Running task 2.0 in stage 17.0 (TID 52)
18/02/28 13:11:55 INFO Executor: Running task 3.0 in stage 17.0 (TID 53)
18/02/28 13:11:55 INFO BlockManager: Found block rdd_51_0 locally
18/02/28 13:11:55 INFO BlockManager: Found block rdd_51_3 locally
18/02/28 13:11:55 INFO BlockManager: Found block rdd_51_2 locally
18/02/28 13:11:56 INFO Executor: Finished task 2.0 in stage 17.0 (TID 52). 2319 bytes result sent to driver
18/02/28 13:11:56 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 52) in 44 ms on localhost (executor driver) (1/4)
18/02/28 13:11:56 INFO Executor: Finished task 1.0 in stage 17.0 (TID 51). 2319 bytes result sent to driver
18/02/28 13:11:56 INFO Executor: Finished task 3.0 in stage 17.0 (TID 53). 2276 bytes result sent to driver
18/02/28 13:11:56 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 51) in 50 ms on localhost (executor driver) (2/4)
18/02/28 13:11:56 INFO TaskSetManager: Finished task 3.0 in stage 17.0 (TID 53) in 52 ms on localhost (executor driver) (3/4)
18/02/28 13:11:56 INFO Executor: Finished task 0.0 in stage 17.0 (TID 50). 2276 bytes result sent to driver
18/02/28 13:11:56 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 50) in 58 ms on localhost (executor driver) (4/4)
18/02/28 13:11:56 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
18/02/28 13:11:56 INFO DAGScheduler: ShuffleMapStage 17 (collect at utils.scala:211) finished in 0.058 s
18/02/28 13:11:56 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:11:56 INFO DAGScheduler: running: Set()
18/02/28 13:11:56 INFO DAGScheduler: waiting: Set(ResultStage 18)
18/02/28 13:11:56 INFO DAGScheduler: failed: Set()
18/02/28 13:11:56 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[63] at collect at utils.scala:211), which has no missing parents
18/02/28 13:11:56 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 7.0 KB, free 362.1 MB)
18/02/28 13:11:56 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 3.7 KB, free 362.1 MB)
18/02/28 13:11:56 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 364.5 MB)
18/02/28 13:11:56 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
18/02/28 13:11:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[63] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:11:56 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
18/02/28 13:11:56 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 54, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:11:56 INFO Executor: Running task 0.0 in stage 18.0 (TID 54)
18/02/28 13:11:56 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:11:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:11:56 INFO Executor: Finished task 0.0 in stage 18.0 (TID 54). 1495 bytes result sent to driver
18/02/28 13:11:56 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 54) in 5 ms on localhost (executor driver) (1/1)
18/02/28 13:11:56 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
18/02/28 13:11:56 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:211) finished in 0.006 s
18/02/28 13:11:56 INFO DAGScheduler: Job 9 finished: collect at utils.scala:211, took 0.080110 s
18/02/28 13:11:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:11:56 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 13:11:56 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:11:56 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:11:56 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:11:56 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:11:56 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 13:11:56 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 13:11:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:11:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 13:11:57 INFO CodeGenerator: Code generated in 6.055843 ms
18/02/28 13:11:57 INFO SparkContext: Starting job: countByValue at StringIndexer.scala:113
18/02/28 13:11:57 INFO DAGScheduler: Registering RDD 70 (countByValue at StringIndexer.scala:113)
18/02/28 13:11:57 INFO DAGScheduler: Got job 10 (countByValue at StringIndexer.scala:113) with 4 output partitions
18/02/28 13:11:57 INFO DAGScheduler: Final stage: ResultStage 20 (countByValue at StringIndexer.scala:113)
18/02/28 13:11:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
18/02/28 13:11:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 19)
18/02/28 13:11:57 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[70] at countByValue at StringIndexer.scala:113), which has no missing parents
18/02/28 13:11:57 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 42.3 KB, free 362.1 MB)
18/02/28 13:11:57 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 17.9 KB, free 362.1 MB)
18/02/28 13:11:57 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:60941 (size: 17.9 KB, free: 364.5 MB)
18/02/28 13:11:57 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
18/02/28 13:11:57 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[70] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:11:57 INFO TaskSchedulerImpl: Adding task set 19.0 with 4 tasks
18/02/28 13:11:57 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 55, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:11:57 INFO TaskSetManager: Starting task 1.0 in stage 19.0 (TID 56, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:11:57 INFO TaskSetManager: Starting task 2.0 in stage 19.0 (TID 57, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:11:57 INFO TaskSetManager: Starting task 3.0 in stage 19.0 (TID 58, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:11:57 INFO Executor: Running task 0.0 in stage 19.0 (TID 55)
18/02/28 13:11:57 INFO Executor: Running task 1.0 in stage 19.0 (TID 56)
18/02/28 13:11:57 INFO Executor: Running task 2.0 in stage 19.0 (TID 57)
18/02/28 13:11:57 INFO Executor: Running task 3.0 in stage 19.0 (TID 58)
18/02/28 13:11:57 INFO BlockManager: Found block rdd_51_2 locally
18/02/28 13:11:57 INFO BlockManager: Found block rdd_51_3 locally
18/02/28 13:11:57 INFO BlockManager: Found block rdd_51_0 locally
18/02/28 13:11:57 INFO BlockManager: Found block rdd_51_1 locally
18/02/28 13:11:58 INFO CodeGenerator: Code generated in 20.798755 ms
18/02/28 13:11:58 INFO CodeGenerator: Code generated in 15.9136 ms
18/02/28 13:11:58 INFO Executor: Finished task 2.0 in stage 19.0 (TID 57). 2264 bytes result sent to driver
18/02/28 13:11:58 INFO TaskSetManager: Finished task 2.0 in stage 19.0 (TID 57) in 248 ms on localhost (executor driver) (1/4)
18/02/28 13:11:58 INFO Executor: Finished task 1.0 in stage 19.0 (TID 56). 2307 bytes result sent to driver
18/02/28 13:11:58 INFO TaskSetManager: Finished task 1.0 in stage 19.0 (TID 56) in 269 ms on localhost (executor driver) (2/4)
18/02/28 13:11:58 INFO Executor: Finished task 0.0 in stage 19.0 (TID 55). 2264 bytes result sent to driver
18/02/28 13:11:58 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 55) in 275 ms on localhost (executor driver) (3/4)
18/02/28 13:11:58 INFO Executor: Finished task 3.0 in stage 19.0 (TID 58). 2264 bytes result sent to driver
18/02/28 13:11:58 INFO TaskSetManager: Finished task 3.0 in stage 19.0 (TID 58) in 275 ms on localhost (executor driver) (4/4)
18/02/28 13:11:58 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
18/02/28 13:11:58 INFO DAGScheduler: ShuffleMapStage 19 (countByValue at StringIndexer.scala:113) finished in 0.276 s
18/02/28 13:11:58 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:11:58 INFO DAGScheduler: running: Set()
18/02/28 13:11:58 INFO DAGScheduler: waiting: Set(ResultStage 20)
18/02/28 13:11:58 INFO DAGScheduler: failed: Set()
18/02/28 13:11:58 INFO DAGScheduler: Submitting ResultStage 20 (ShuffledRDD[71] at countByValue at StringIndexer.scala:113), which has no missing parents
18/02/28 13:11:58 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 3.2 KB, free 362.1 MB)
18/02/28 13:11:58 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 1963.0 B, free 362.1 MB)
18/02/28 13:11:58 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:60941 (size: 1963.0 B, free: 364.5 MB)
18/02/28 13:11:58 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
18/02/28 13:11:58 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 20 (ShuffledRDD[71] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:11:58 INFO TaskSchedulerImpl: Adding task set 20.0 with 4 tasks
18/02/28 13:11:58 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 59, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:11:58 INFO TaskSetManager: Starting task 2.0 in stage 20.0 (TID 60, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:11:58 INFO TaskSetManager: Starting task 3.0 in stage 20.0 (TID 61, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:11:58 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 62, localhost, executor driver, partition 0, ANY, 4621 bytes)
18/02/28 13:11:58 INFO Executor: Running task 2.0 in stage 20.0 (TID 60)
18/02/28 13:11:58 INFO Executor: Running task 1.0 in stage 20.0 (TID 59)
18/02/28 13:11:58 INFO Executor: Running task 0.0 in stage 20.0 (TID 62)
18/02/28 13:11:58 INFO Executor: Running task 3.0 in stage 20.0 (TID 61)
18/02/28 13:11:58 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 13:11:58 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 13:11:58 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:11:58 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 13:11:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:11:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:11:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:11:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:11:58 INFO Executor: Finished task 1.0 in stage 20.0 (TID 59). 1048 bytes result sent to driver
18/02/28 13:11:58 INFO Executor: Finished task 3.0 in stage 20.0 (TID 61). 1005 bytes result sent to driver
18/02/28 13:11:58 INFO Executor: Finished task 2.0 in stage 20.0 (TID 60). 1048 bytes result sent to driver
18/02/28 13:11:58 INFO Executor: Finished task 0.0 in stage 20.0 (TID 62). 1198 bytes result sent to driver
18/02/28 13:11:58 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 59) in 25 ms on localhost (executor driver) (1/4)
18/02/28 13:11:58 INFO TaskSetManager: Finished task 2.0 in stage 20.0 (TID 60) in 24 ms on localhost (executor driver) (2/4)
18/02/28 13:11:58 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 62) in 25 ms on localhost (executor driver) (3/4)
18/02/28 13:11:58 INFO TaskSetManager: Finished task 3.0 in stage 20.0 (TID 61) in 25 ms on localhost (executor driver) (4/4)
18/02/28 13:11:58 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
18/02/28 13:11:58 INFO DAGScheduler: ResultStage 20 (countByValue at StringIndexer.scala:113) finished in 0.026 s
18/02/28 13:11:58 INFO DAGScheduler: Job 10 finished: countByValue at StringIndexer.scala:113, took 0.444526 s
18/02/28 13:11:58 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:60941 in memory (size: 16.9 KB, free: 364.5 MB)
18/02/28 13:11:58 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:60941 in memory (size: 17.9 KB, free: 364.5 MB)
18/02/28 13:11:58 INFO ContextCleaner: Cleaned accumulator 635
18/02/28 13:11:58 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:60941 in memory (size: 1963.0 B, free: 364.5 MB)
18/02/28 13:11:58 INFO ContextCleaner: Cleaned accumulator 572
18/02/28 13:11:58 INFO ContextCleaner: Cleaned shuffle 9
18/02/28 13:11:58 INFO ContextCleaner: Cleaned accumulator 634
18/02/28 13:11:58 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 364.5 MB)
18/02/28 13:11:58 INFO ContextCleaner: Cleaned accumulator 633
18/02/28 13:11:58 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 364.6 MB)
18/02/28 13:13:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:13:10 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
LIMIT 6
18/02/28 13:13:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:13:10 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
LIMIT 6
18/02/28 13:13:10 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:13:10 INFO DAGScheduler: Got job 11 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:13:10 INFO DAGScheduler: Final stage: ResultStage 21 (collect at utils.scala:211)
18/02/28 13:13:10 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:13:10 INFO DAGScheduler: Missing parents: List()
18/02/28 13:13:10 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[73] at collect at utils.scala:211), which has no missing parents
18/02/28 13:13:10 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 36.3 KB, free 362.2 MB)
18/02/28 13:13:10 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 14.9 KB, free 362.1 MB)
18/02/28 13:13:10 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:60941 (size: 14.9 KB, free: 364.5 MB)
18/02/28 13:13:10 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
18/02/28 13:13:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[73] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:13:10 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
18/02/28 13:13:10 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 63, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:13:10 INFO Executor: Running task 0.0 in stage 21.0 (TID 63)
18/02/28 13:13:10 INFO BlockManager: Found block rdd_51_0 locally
18/02/28 13:13:10 INFO CodeGenerator: Code generated in 18.496519 ms
18/02/28 13:13:10 INFO Executor: 1 block locks were not released by TID = 63:
[rdd_51_0]
18/02/28 13:13:10 INFO Executor: Finished task 0.0 in stage 21.0 (TID 63). 2509 bytes result sent to driver
18/02/28 13:13:10 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 63) in 44 ms on localhost (executor driver) (1/1)
18/02/28 13:13:10 INFO DAGScheduler: ResultStage 21 (collect at utils.scala:211) finished in 0.045 s
18/02/28 13:13:10 INFO DAGScheduler: Job 11 finished: collect at utils.scala:211, took 0.050544 s
18/02/28 13:13:10 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
18/02/28 13:13:10 INFO CodeGenerator: Code generated in 10.504809 ms
18/02/28 13:16:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:16:05 INFO SparkSqlParser: Parsing command: SELECT `year`, CAST(`month` AS DOUBLE) AS `month`, `day`, `dep_time`, `sched_dep_time`, `dep_delay`, `arr_time`, `sched_arr_time`, `arr_delay`, `carrier`, `flight`, `tailnum`, `origin`, `dest`, `air_time`, `distance`, `hour`, `minute`, `time_hour`
FROM `spark_flights`
18/02/28 13:16:06 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:16:06 INFO SparkSqlParser: Parsing command: SELECT `year`, CAST(`month` AS DOUBLE) AS `month`, `day`, `dep_time`, `sched_dep_time`, `dep_delay`, `arr_time`, `sched_arr_time`, `arr_delay`, `carrier`, `flight`, `tailnum`, `origin`, `dest`, `air_time`, `distance`, `hour`, `minute`, `time_hour`
FROM `spark_flights`
LIMIT 10
18/02/28 13:16:06 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 13:16:06 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 13:16:06 INFO FileSourceStrategy: Output Data Schema: struct<year: string, month: string, day: string, dep_time: string, sched_dep_time: string ... 17 more fields>
18/02/28 13:16:06 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 13:16:06 INFO CodeGenerator: Code generated in 8.933196 ms
18/02/28 13:16:06 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 282.5 KB, free 361.9 MB)
18/02/28 13:16:06 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 24.1 KB, free 361.8 MB)
18/02/28 13:16:06 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:60941 (size: 24.1 KB, free: 364.5 MB)
18/02/28 13:16:06 INFO SparkContext: Created broadcast 30 from collect at utils.scala:211
18/02/28 13:16:06 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21019222 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 13:16:06 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:16:06 INFO DAGScheduler: Got job 12 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:16:06 INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:211)
18/02/28 13:16:06 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:16:06 INFO DAGScheduler: Missing parents: List()
18/02/28 13:16:06 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[76] at collect at utils.scala:211), which has no missing parents
18/02/28 13:16:06 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 17.7 KB, free 361.8 MB)
18/02/28 13:16:06 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 8.4 KB, free 361.8 MB)
18/02/28 13:16:06 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:60941 (size: 8.4 KB, free: 364.5 MB)
18/02/28 13:16:06 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1006
18/02/28 13:16:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[76] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:16:06 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
18/02/28 13:16:06 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:16:06 INFO Executor: Running task 0.0 in stage 22.0 (TID 64)
18/02/28 13:16:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_7.csv, range: 0-2938867, partition values: [empty row]
18/02/28 13:16:06 INFO Executor: Finished task 0.0 in stage 22.0 (TID 64). 2198 bytes result sent to driver
18/02/28 13:16:06 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 64) in 8 ms on localhost (executor driver) (1/1)
18/02/28 13:16:06 INFO DAGScheduler: ResultStage 22 (collect at utils.scala:211) finished in 0.008 s
18/02/28 13:16:06 INFO DAGScheduler: Job 12 finished: collect at utils.scala:211, took 0.012518 s
18/02/28 13:16:06 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
18/02/28 13:16:06 INFO CodeGenerator: Code generated in 11.029504 ms
18/02/28 13:16:58 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:16:58 INFO SparkSqlParser: Parsing command: SELECT `month`, count(*) AS `n()`
FROM `spark_flights`
GROUP BY `month`
18/02/28 13:16:58 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:16:58 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:16:58 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 13:16:58 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 13:16:58 INFO FileSourceStrategy: Output Data Schema: struct<month: string>
18/02/28 13:16:58 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 13:16:58 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 282.5 KB, free 361.5 MB)
18/02/28 13:16:58 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 24.1 KB, free 361.5 MB)
18/02/28 13:16:58 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:60941 (size: 24.1 KB, free: 364.5 MB)
18/02/28 13:16:58 INFO SparkContext: Created broadcast 32 from collect at utils.scala:211
18/02/28 13:16:58 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21019222 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 13:16:58 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:16:58 INFO DAGScheduler: Registering RDD 79 (collect at utils.scala:211)
18/02/28 13:16:58 INFO DAGScheduler: Got job 13 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:16:58 INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:211)
18/02/28 13:16:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
18/02/28 13:16:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 23)
18/02/28 13:16:58 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[79] at collect at utils.scala:211), which has no missing parents
18/02/28 13:16:58 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 26.6 KB, free 361.5 MB)
18/02/28 13:16:58 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 13.3 KB, free 361.5 MB)
18/02/28 13:16:58 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:60941 (size: 13.3 KB, free: 364.5 MB)
18/02/28 13:16:58 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1006
18/02/28 13:16:58 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[79] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:16:58 INFO TaskSchedulerImpl: Adding task set 23.0 with 4 tasks
18/02/28 13:16:58 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 65, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:16:58 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 66, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:16:58 INFO TaskSetManager: Starting task 2.0 in stage 23.0 (TID 67, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:16:58 INFO TaskSetManager: Starting task 3.0 in stage 23.0 (TID 68, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:16:58 INFO Executor: Running task 0.0 in stage 23.0 (TID 65)
18/02/28 13:16:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_7.csv, range: 0-2938867, partition values: [empty row]
18/02/28 13:16:58 INFO Executor: Running task 1.0 in stage 23.0 (TID 66)
18/02/28 13:16:58 INFO Executor: Running task 2.0 in stage 23.0 (TID 67)
18/02/28 13:16:58 INFO Executor: Running task 3.0 in stage 23.0 (TID 68)
18/02/28 13:16:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_4.csv, range: 0-2830543, partition values: [empty row]
18/02/28 13:16:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_3.csv, range: 0-2881793, partition values: [empty row]
18/02/28 13:16:59 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_11.csv, range: 0-2757037, partition values: [empty row]
18/02/28 13:16:59 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_5.csv, range: 0-2880181, partition values: [empty row]
18/02/28 13:16:59 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_8.csv, range: 0-2932019, partition values: [empty row]
18/02/28 13:16:59 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_1.csv, range: 0-2697256, partition values: [empty row]
18/02/28 13:16:59 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_6.csv, range: 0-2820227, partition values: [empty row]
18/02/28 13:16:59 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:60941 in memory (size: 14.9 KB, free: 364.5 MB)
18/02/28 13:16:59 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_12.csv, range: 0-2836468, partition values: [empty row]
18/02/28 13:16:59 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_10.csv, range: 0-2920629, partition values: [empty row]
18/02/28 13:16:59 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_2.csv, range: 0-2487144, partition values: [empty row]
18/02/28 13:16:59 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_9.csv, range: 0-2763076, partition values: [empty row]
18/02/28 13:16:59 INFO ContextCleaner: Cleaned accumulator 738
18/02/28 13:16:59 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:60941 in memory (size: 8.4 KB, free: 364.5 MB)
18/02/28 13:16:59 INFO Executor: Finished task 1.0 in stage 23.0 (TID 66). 2103 bytes result sent to driver
18/02/28 13:16:59 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 66) in 446 ms on localhost (executor driver) (1/4)
18/02/28 13:16:59 INFO Executor: Finished task 2.0 in stage 23.0 (TID 67). 2103 bytes result sent to driver
18/02/28 13:16:59 INFO TaskSetManager: Finished task 2.0 in stage 23.0 (TID 67) in 454 ms on localhost (executor driver) (2/4)
18/02/28 13:16:59 INFO Executor: Finished task 0.0 in stage 23.0 (TID 65). 2060 bytes result sent to driver
18/02/28 13:16:59 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 65) in 465 ms on localhost (executor driver) (3/4)
18/02/28 13:16:59 INFO Executor: Finished task 3.0 in stage 23.0 (TID 68). 2060 bytes result sent to driver
18/02/28 13:16:59 INFO TaskSetManager: Finished task 3.0 in stage 23.0 (TID 68) in 479 ms on localhost (executor driver) (4/4)
18/02/28 13:16:59 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
18/02/28 13:16:59 INFO DAGScheduler: ShuffleMapStage 23 (collect at utils.scala:211) finished in 0.482 s
18/02/28 13:16:59 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:16:59 INFO DAGScheduler: running: Set()
18/02/28 13:16:59 INFO DAGScheduler: waiting: Set(ResultStage 24)
18/02/28 13:16:59 INFO DAGScheduler: failed: Set()
18/02/28 13:16:59 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[82] at collect at utils.scala:211), which has no missing parents
18/02/28 13:16:59 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 25.0 KB, free 361.5 MB)
18/02/28 13:16:59 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 12.5 KB, free 361.5 MB)
18/02/28 13:16:59 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:60941 (size: 12.5 KB, free: 364.5 MB)
18/02/28 13:16:59 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1006
18/02/28 13:16:59 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 24 (MapPartitionsRDD[82] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:16:59 INFO TaskSchedulerImpl: Adding task set 24.0 with 4 tasks
18/02/28 13:16:59 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 69, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:16:59 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 70, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 13:16:59 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 71, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 13:16:59 INFO TaskSetManager: Starting task 3.0 in stage 24.0 (TID 72, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 13:16:59 INFO Executor: Running task 0.0 in stage 24.0 (TID 69)
18/02/28 13:16:59 INFO Executor: Running task 2.0 in stage 24.0 (TID 71)
18/02/28 13:16:59 INFO Executor: Running task 3.0 in stage 24.0 (TID 72)
18/02/28 13:16:59 INFO Executor: Running task 1.0 in stage 24.0 (TID 70)
18/02/28 13:16:59 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 4 blocks
18/02/28 13:16:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:16:59 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 13:16:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:16:59 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 13:16:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:16:59 INFO Executor: Finished task 1.0 in stage 24.0 (TID 70). 2492 bytes result sent to driver
18/02/28 13:16:59 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 13:16:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
18/02/28 13:16:59 INFO Executor: Finished task 0.0 in stage 24.0 (TID 69). 2518 bytes result sent to driver
18/02/28 13:16:59 INFO Executor: Finished task 2.0 in stage 24.0 (TID 71). 2526 bytes result sent to driver
18/02/28 13:16:59 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 70) in 12 ms on localhost (executor driver) (1/4)
18/02/28 13:16:59 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 71) in 13 ms on localhost (executor driver) (2/4)
18/02/28 13:16:59 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 69) in 13 ms on localhost (executor driver) (3/4)
18/02/28 13:16:59 INFO Executor: Finished task 3.0 in stage 24.0 (TID 72). 2551 bytes result sent to driver
18/02/28 13:16:59 INFO TaskSetManager: Finished task 3.0 in stage 24.0 (TID 72) in 15 ms on localhost (executor driver) (4/4)
18/02/28 13:16:59 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
18/02/28 13:16:59 INFO DAGScheduler: ResultStage 24 (collect at utils.scala:211) finished in 0.016 s
18/02/28 13:16:59 INFO DAGScheduler: Job 13 finished: collect at utils.scala:211, took 0.508858 s
18/02/28 13:17:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:17:04 INFO SparkSqlParser: Parsing command: SELECT `month`, count(*) AS `n()`
FROM `spark_flights`
GROUP BY `month`
18/02/28 13:17:04 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:17:04 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:17:04 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 13:17:04 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 13:17:04 INFO FileSourceStrategy: Output Data Schema: struct<month: string>
18/02/28 13:17:04 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 13:17:04 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 282.5 KB, free 361.2 MB)
18/02/28 13:17:04 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 24.1 KB, free 361.2 MB)
18/02/28 13:17:04 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:60941 (size: 24.1 KB, free: 364.5 MB)
18/02/28 13:17:04 INFO SparkContext: Created broadcast 35 from collect at utils.scala:211
18/02/28 13:17:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21019222 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 13:17:04 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:17:04 INFO DAGScheduler: Registering RDD 85 (collect at utils.scala:211)
18/02/28 13:17:04 INFO DAGScheduler: Got job 14 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:17:04 INFO DAGScheduler: Final stage: ResultStage 26 (collect at utils.scala:211)
18/02/28 13:17:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
18/02/28 13:17:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 25)
18/02/28 13:17:04 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[85] at collect at utils.scala:211), which has no missing parents
18/02/28 13:17:04 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 26.6 KB, free 361.2 MB)
18/02/28 13:17:04 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 13.3 KB, free 361.2 MB)
18/02/28 13:17:04 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:60941 (size: 13.3 KB, free: 364.4 MB)
18/02/28 13:17:04 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1006
18/02/28 13:17:04 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[85] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:17:04 INFO TaskSchedulerImpl: Adding task set 25.0 with 4 tasks
18/02/28 13:17:04 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 73, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:17:04 INFO TaskSetManager: Starting task 1.0 in stage 25.0 (TID 74, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:17:04 INFO TaskSetManager: Starting task 2.0 in stage 25.0 (TID 75, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:17:04 INFO TaskSetManager: Starting task 3.0 in stage 25.0 (TID 76, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:17:04 INFO Executor: Running task 0.0 in stage 25.0 (TID 73)
18/02/28 13:17:04 INFO Executor: Running task 1.0 in stage 25.0 (TID 74)
18/02/28 13:17:04 INFO Executor: Running task 2.0 in stage 25.0 (TID 75)
18/02/28 13:17:04 INFO Executor: Running task 3.0 in stage 25.0 (TID 76)
18/02/28 13:17:04 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_3.csv, range: 0-2881793, partition values: [empty row]
18/02/28 13:17:04 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_7.csv, range: 0-2938867, partition values: [empty row]
18/02/28 13:17:04 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_4.csv, range: 0-2830543, partition values: [empty row]
18/02/28 13:17:04 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_11.csv, range: 0-2757037, partition values: [empty row]
18/02/28 13:17:04 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:60941 in memory (size: 12.5 KB, free: 364.5 MB)
18/02/28 13:17:04 INFO ContextCleaner: Cleaned accumulator 802
18/02/28 13:17:04 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_6.csv, range: 0-2820227, partition values: [empty row]
18/02/28 13:17:04 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_8.csv, range: 0-2932019, partition values: [empty row]
18/02/28 13:17:04 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_5.csv, range: 0-2880181, partition values: [empty row]
18/02/28 13:17:04 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_1.csv, range: 0-2697256, partition values: [empty row]
18/02/28 13:17:04 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_9.csv, range: 0-2763076, partition values: [empty row]
18/02/28 13:17:04 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_10.csv, range: 0-2920629, partition values: [empty row]
18/02/28 13:17:04 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_12.csv, range: 0-2836468, partition values: [empty row]
18/02/28 13:17:04 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_2.csv, range: 0-2487144, partition values: [empty row]
18/02/28 13:17:04 INFO Executor: Finished task 2.0 in stage 25.0 (TID 75). 2103 bytes result sent to driver
18/02/28 13:17:04 INFO TaskSetManager: Finished task 2.0 in stage 25.0 (TID 75) in 378 ms on localhost (executor driver) (1/4)
18/02/28 13:17:04 INFO Executor: Finished task 1.0 in stage 25.0 (TID 74). 2103 bytes result sent to driver
18/02/28 13:17:04 INFO TaskSetManager: Finished task 1.0 in stage 25.0 (TID 74) in 395 ms on localhost (executor driver) (2/4)
18/02/28 13:17:04 INFO Executor: Finished task 0.0 in stage 25.0 (TID 73). 2060 bytes result sent to driver
18/02/28 13:17:04 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 73) in 413 ms on localhost (executor driver) (3/4)
18/02/28 13:17:05 INFO Executor: Finished task 3.0 in stage 25.0 (TID 76). 2103 bytes result sent to driver
18/02/28 13:17:05 INFO TaskSetManager: Finished task 3.0 in stage 25.0 (TID 76) in 499 ms on localhost (executor driver) (4/4)
18/02/28 13:17:05 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
18/02/28 13:17:05 INFO DAGScheduler: ShuffleMapStage 25 (collect at utils.scala:211) finished in 0.500 s
18/02/28 13:17:05 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:17:05 INFO DAGScheduler: running: Set()
18/02/28 13:17:05 INFO DAGScheduler: waiting: Set(ResultStage 26)
18/02/28 13:17:05 INFO DAGScheduler: failed: Set()
18/02/28 13:17:05 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[88] at collect at utils.scala:211), which has no missing parents
18/02/28 13:17:05 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 25.0 KB, free 361.2 MB)
18/02/28 13:17:05 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 12.5 KB, free 361.2 MB)
18/02/28 13:17:05 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:60941 (size: 12.5 KB, free: 364.4 MB)
18/02/28 13:17:05 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1006
18/02/28 13:17:05 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 26 (MapPartitionsRDD[88] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:17:05 INFO TaskSchedulerImpl: Adding task set 26.0 with 4 tasks
18/02/28 13:17:05 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 77, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:17:05 INFO TaskSetManager: Starting task 1.0 in stage 26.0 (TID 78, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 13:17:05 INFO TaskSetManager: Starting task 2.0 in stage 26.0 (TID 79, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 13:17:05 INFO TaskSetManager: Starting task 3.0 in stage 26.0 (TID 80, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 13:17:05 INFO Executor: Running task 0.0 in stage 26.0 (TID 77)
18/02/28 13:17:05 INFO Executor: Running task 3.0 in stage 26.0 (TID 80)
18/02/28 13:17:05 INFO Executor: Running task 2.0 in stage 26.0 (TID 79)
18/02/28 13:17:05 INFO Executor: Running task 1.0 in stage 26.0 (TID 78)
18/02/28 13:17:05 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 13:17:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:17:05 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 13:17:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:17:05 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 4 blocks
18/02/28 13:17:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:17:05 INFO Executor: Finished task 3.0 in stage 26.0 (TID 80). 2551 bytes result sent to driver
18/02/28 13:17:05 INFO Executor: Finished task 1.0 in stage 26.0 (TID 78). 2492 bytes result sent to driver
18/02/28 13:17:05 INFO TaskSetManager: Finished task 3.0 in stage 26.0 (TID 80) in 9 ms on localhost (executor driver) (1/4)
18/02/28 13:17:05 INFO TaskSetManager: Finished task 1.0 in stage 26.0 (TID 78) in 9 ms on localhost (executor driver) (2/4)
18/02/28 13:17:05 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 13:17:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:17:05 INFO Executor: Finished task 2.0 in stage 26.0 (TID 79). 2526 bytes result sent to driver
18/02/28 13:17:05 INFO TaskSetManager: Finished task 2.0 in stage 26.0 (TID 79) in 11 ms on localhost (executor driver) (3/4)
18/02/28 13:17:05 INFO Executor: Finished task 0.0 in stage 26.0 (TID 77). 2475 bytes result sent to driver
18/02/28 13:17:05 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 77) in 13 ms on localhost (executor driver) (4/4)
18/02/28 13:17:05 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
18/02/28 13:17:05 INFO DAGScheduler: ResultStage 26 (collect at utils.scala:211) finished in 0.013 s
18/02/28 13:17:05 INFO DAGScheduler: Job 14 finished: collect at utils.scala:211, took 0.523240 s
18/02/28 13:17:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:17:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_flights`
LIMIT 6
18/02/28 13:17:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:17:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_flights`
LIMIT 6
18/02/28 13:17:16 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 13:17:16 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 13:17:16 INFO FileSourceStrategy: Output Data Schema: struct<year: string, month: string, day: string, dep_time: string, sched_dep_time: string ... 17 more fields>
18/02/28 13:17:16 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 13:17:16 INFO CodeGenerator: Code generated in 4.529011 ms
18/02/28 13:17:16 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 282.5 KB, free 360.9 MB)
18/02/28 13:17:16 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 24.1 KB, free 360.9 MB)
18/02/28 13:17:16 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:60941 (size: 24.1 KB, free: 364.4 MB)
18/02/28 13:17:16 INFO SparkContext: Created broadcast 38 from collect at utils.scala:211
18/02/28 13:17:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21019222 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 13:17:16 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:17:16 INFO DAGScheduler: Got job 15 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:17:16 INFO DAGScheduler: Final stage: ResultStage 27 (collect at utils.scala:211)
18/02/28 13:17:16 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:17:16 INFO DAGScheduler: Missing parents: List()
18/02/28 13:17:16 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[91] at collect at utils.scala:211), which has no missing parents
18/02/28 13:17:16 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 12.6 KB, free 360.9 MB)
18/02/28 13:17:16 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 7.1 KB, free 360.9 MB)
18/02/28 13:17:16 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:60941 (size: 7.1 KB, free: 364.4 MB)
18/02/28 13:17:16 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1006
18/02/28 13:17:16 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:60941 in memory (size: 12.5 KB, free: 364.4 MB)
18/02/28 13:17:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[91] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:17:16 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
18/02/28 13:17:16 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 81, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:17:16 INFO Executor: Running task 0.0 in stage 27.0 (TID 81)
18/02/28 13:17:16 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_7.csv, range: 0-2938867, partition values: [empty row]
18/02/28 13:17:16 INFO Executor: Finished task 0.0 in stage 27.0 (TID 81). 1836 bytes result sent to driver
18/02/28 13:17:16 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 81) in 9 ms on localhost (executor driver) (1/1)
18/02/28 13:17:16 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
18/02/28 13:17:16 INFO DAGScheduler: ResultStage 27 (collect at utils.scala:211) finished in 0.009 s
18/02/28 13:17:16 INFO DAGScheduler: Job 15 finished: collect at utils.scala:211, took 0.014618 s
18/02/28 13:18:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:18:23 INFO SparkSqlParser: Parsing command: SELECT `month`, count(*) AS `n()`
FROM (SELECT `year`, `month`, `day`, `dep_time`, `sched_dep_time`, `dep_delay`, `arr_time`, `sched_arr_time`, `arr_delay`, `carrier`, `flight`, `tailnum`, `origin`, `dest`, `air_time`, `distance`, `hour`, `minute`, `time_hour`, CAST(`month` AS DOUBLE) AS `mont`
FROM `spark_flights`) `rmbezvzqtw`
GROUP BY `month`
18/02/28 13:18:23 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:18:23 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:18:23 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 13:18:23 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 13:18:23 INFO FileSourceStrategy: Output Data Schema: struct<month: string>
18/02/28 13:18:23 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 13:18:23 INFO CodeGenerator: Code generated in 22.388351 ms
18/02/28 13:18:23 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 282.5 KB, free 360.6 MB)
18/02/28 13:18:23 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 24.1 KB, free 360.6 MB)
18/02/28 13:18:23 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:60941 (size: 24.1 KB, free: 364.4 MB)
18/02/28 13:18:23 INFO SparkContext: Created broadcast 40 from collect at utils.scala:211
18/02/28 13:18:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21019222 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 13:18:23 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:18:23 INFO DAGScheduler: Registering RDD 94 (collect at utils.scala:211)
18/02/28 13:18:23 INFO DAGScheduler: Got job 16 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:18:23 INFO DAGScheduler: Final stage: ResultStage 29 (collect at utils.scala:211)
18/02/28 13:18:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
18/02/28 13:18:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 28)
18/02/28 13:18:23 INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[94] at collect at utils.scala:211), which has no missing parents
18/02/28 13:18:23 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 27.3 KB, free 360.6 MB)
18/02/28 13:18:23 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 13.5 KB, free 360.6 MB)
18/02/28 13:18:23 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:60941 (size: 13.5 KB, free: 364.4 MB)
18/02/28 13:18:23 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
18/02/28 13:18:23 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[94] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:18:23 INFO TaskSchedulerImpl: Adding task set 28.0 with 4 tasks
18/02/28 13:18:23 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 82, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:18:23 INFO TaskSetManager: Starting task 1.0 in stage 28.0 (TID 83, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:18:23 INFO TaskSetManager: Starting task 2.0 in stage 28.0 (TID 84, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:18:23 INFO TaskSetManager: Starting task 3.0 in stage 28.0 (TID 85, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:18:23 INFO Executor: Running task 0.0 in stage 28.0 (TID 82)
18/02/28 13:18:23 INFO Executor: Running task 2.0 in stage 28.0 (TID 84)
18/02/28 13:18:23 INFO Executor: Running task 3.0 in stage 28.0 (TID 85)
18/02/28 13:18:23 INFO Executor: Running task 1.0 in stage 28.0 (TID 83)
18/02/28 13:18:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_11.csv, range: 0-2757037, partition values: [empty row]
18/02/28 13:18:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_3.csv, range: 0-2881793, partition values: [empty row]
18/02/28 13:18:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_7.csv, range: 0-2938867, partition values: [empty row]
18/02/28 13:18:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_4.csv, range: 0-2830543, partition values: [empty row]
18/02/28 13:18:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_8.csv, range: 0-2932019, partition values: [empty row]
18/02/28 13:18:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_6.csv, range: 0-2820227, partition values: [empty row]
18/02/28 13:18:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_1.csv, range: 0-2697256, partition values: [empty row]
18/02/28 13:18:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_5.csv, range: 0-2880181, partition values: [empty row]
18/02/28 13:18:23 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:60941 in memory (size: 7.1 KB, free: 364.4 MB)
18/02/28 13:18:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_2.csv, range: 0-2487144, partition values: [empty row]
18/02/28 13:18:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_10.csv, range: 0-2920629, partition values: [empty row]
18/02/28 13:18:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_9.csv, range: 0-2763076, partition values: [empty row]
18/02/28 13:18:23 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_12.csv, range: 0-2836468, partition values: [empty row]
18/02/28 13:18:23 INFO ContextCleaner: Cleaned accumulator 895
18/02/28 13:18:23 INFO Executor: Finished task 3.0 in stage 28.0 (TID 85). 2060 bytes result sent to driver
18/02/28 13:18:23 INFO TaskSetManager: Finished task 3.0 in stage 28.0 (TID 85) in 612 ms on localhost (executor driver) (1/4)
18/02/28 13:18:23 INFO Executor: Finished task 0.0 in stage 28.0 (TID 82). 2060 bytes result sent to driver
18/02/28 13:18:23 INFO Executor: Finished task 2.0 in stage 28.0 (TID 84). 2060 bytes result sent to driver
18/02/28 13:18:23 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 82) in 640 ms on localhost (executor driver) (2/4)
18/02/28 13:18:23 INFO TaskSetManager: Finished task 2.0 in stage 28.0 (TID 84) in 639 ms on localhost (executor driver) (3/4)
18/02/28 13:18:23 INFO Executor: Finished task 1.0 in stage 28.0 (TID 83). 2060 bytes result sent to driver
18/02/28 13:18:23 INFO TaskSetManager: Finished task 1.0 in stage 28.0 (TID 83) in 642 ms on localhost (executor driver) (4/4)
18/02/28 13:18:23 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
18/02/28 13:18:23 INFO DAGScheduler: ShuffleMapStage 28 (collect at utils.scala:211) finished in 0.643 s
18/02/28 13:18:23 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:18:23 INFO DAGScheduler: running: Set()
18/02/28 13:18:23 INFO DAGScheduler: waiting: Set(ResultStage 29)
18/02/28 13:18:23 INFO DAGScheduler: failed: Set()
18/02/28 13:18:23 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[97] at collect at utils.scala:211), which has no missing parents
18/02/28 13:18:23 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 25.1 KB, free 360.6 MB)
18/02/28 13:18:23 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 12.5 KB, free 360.5 MB)
18/02/28 13:18:23 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:60941 (size: 12.5 KB, free: 364.4 MB)
18/02/28 13:18:23 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1006
18/02/28 13:18:23 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 29 (MapPartitionsRDD[97] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:18:23 INFO TaskSchedulerImpl: Adding task set 29.0 with 4 tasks
18/02/28 13:18:23 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 86, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:18:23 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 87, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 13:18:23 INFO TaskSetManager: Starting task 2.0 in stage 29.0 (TID 88, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 13:18:23 INFO TaskSetManager: Starting task 3.0 in stage 29.0 (TID 89, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 13:18:23 INFO Executor: Running task 0.0 in stage 29.0 (TID 86)
18/02/28 13:18:23 INFO Executor: Running task 3.0 in stage 29.0 (TID 89)
18/02/28 13:18:23 INFO Executor: Running task 1.0 in stage 29.0 (TID 87)
18/02/28 13:18:23 INFO Executor: Running task 2.0 in stage 29.0 (TID 88)
18/02/28 13:18:23 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 13:18:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:18:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 4 blocks
18/02/28 13:18:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:18:23 INFO Executor: Finished task 2.0 in stage 29.0 (TID 88). 2526 bytes result sent to driver
18/02/28 13:18:23 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 13:18:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:18:23 INFO Executor: Finished task 1.0 in stage 29.0 (TID 87). 2492 bytes result sent to driver
18/02/28 13:18:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 13:18:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
18/02/28 13:18:23 INFO TaskSetManager: Finished task 2.0 in stage 29.0 (TID 88) in 11 ms on localhost (executor driver) (1/4)
18/02/28 13:18:23 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 87) in 12 ms on localhost (executor driver) (2/4)
18/02/28 13:18:23 INFO Executor: Finished task 3.0 in stage 29.0 (TID 89). 2551 bytes result sent to driver
18/02/28 13:18:23 INFO TaskSetManager: Finished task 3.0 in stage 29.0 (TID 89) in 12 ms on localhost (executor driver) (3/4)
18/02/28 13:18:23 INFO Executor: Finished task 0.0 in stage 29.0 (TID 86). 2475 bytes result sent to driver
18/02/28 13:18:23 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 86) in 13 ms on localhost (executor driver) (4/4)
18/02/28 13:18:23 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
18/02/28 13:18:23 INFO DAGScheduler: ResultStage 29 (collect at utils.scala:211) finished in 0.013 s
18/02/28 13:18:23 INFO DAGScheduler: Job 16 finished: collect at utils.scala:211, took 0.665281 s
18/02/28 13:18:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:18:38 INFO SparkSqlParser: Parsing command: SELECT `month`, count(*) AS `n()`
FROM `spark_flights`
GROUP BY `month`
18/02/28 13:18:38 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:18:38 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:18:38 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 13:18:38 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 13:18:38 INFO FileSourceStrategy: Output Data Schema: struct<month: string>
18/02/28 13:18:38 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 13:18:38 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 282.5 KB, free 360.3 MB)
18/02/28 13:18:38 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 24.1 KB, free 360.2 MB)
18/02/28 13:18:38 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:60941 (size: 24.1 KB, free: 364.4 MB)
18/02/28 13:18:38 INFO SparkContext: Created broadcast 43 from collect at utils.scala:211
18/02/28 13:18:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21019222 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 13:18:38 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:18:38 INFO DAGScheduler: Registering RDD 100 (collect at utils.scala:211)
18/02/28 13:18:38 INFO DAGScheduler: Got job 17 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:18:38 INFO DAGScheduler: Final stage: ResultStage 31 (collect at utils.scala:211)
18/02/28 13:18:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)
18/02/28 13:18:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 30)
18/02/28 13:18:38 INFO DAGScheduler: Submitting ShuffleMapStage 30 (MapPartitionsRDD[100] at collect at utils.scala:211), which has no missing parents
18/02/28 13:18:38 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 26.6 KB, free 360.2 MB)
18/02/28 13:18:38 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 13.3 KB, free 360.2 MB)
18/02/28 13:18:38 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:60941 (size: 13.3 KB, free: 364.3 MB)
18/02/28 13:18:38 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1006
18/02/28 13:18:38 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[100] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:18:38 INFO TaskSchedulerImpl: Adding task set 30.0 with 4 tasks
18/02/28 13:18:38 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 90, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:18:38 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 91, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:18:38 INFO TaskSetManager: Starting task 2.0 in stage 30.0 (TID 92, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:18:38 INFO TaskSetManager: Starting task 3.0 in stage 30.0 (TID 93, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:18:38 INFO Executor: Running task 0.0 in stage 30.0 (TID 90)
18/02/28 13:18:38 INFO Executor: Running task 1.0 in stage 30.0 (TID 91)
18/02/28 13:18:38 INFO Executor: Running task 2.0 in stage 30.0 (TID 92)
18/02/28 13:18:38 INFO Executor: Running task 3.0 in stage 30.0 (TID 93)
18/02/28 13:18:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_7.csv, range: 0-2938867, partition values: [empty row]
18/02/28 13:18:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_3.csv, range: 0-2881793, partition values: [empty row]
18/02/28 13:18:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_4.csv, range: 0-2830543, partition values: [empty row]
18/02/28 13:18:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_11.csv, range: 0-2757037, partition values: [empty row]
18/02/28 13:18:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_8.csv, range: 0-2932019, partition values: [empty row]
18/02/28 13:18:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_6.csv, range: 0-2820227, partition values: [empty row]
18/02/28 13:18:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_5.csv, range: 0-2880181, partition values: [empty row]
18/02/28 13:18:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_1.csv, range: 0-2697256, partition values: [empty row]
18/02/28 13:18:38 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:60941 in memory (size: 12.5 KB, free: 364.4 MB)
18/02/28 13:18:38 INFO ContextCleaner: Cleaned accumulator 959
18/02/28 13:18:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_9.csv, range: 0-2763076, partition values: [empty row]
18/02/28 13:18:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_12.csv, range: 0-2836468, partition values: [empty row]
18/02/28 13:18:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_10.csv, range: 0-2920629, partition values: [empty row]
18/02/28 13:18:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_2.csv, range: 0-2487144, partition values: [empty row]
18/02/28 13:18:38 INFO Executor: Finished task 1.0 in stage 30.0 (TID 91). 2060 bytes result sent to driver
18/02/28 13:18:38 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 91) in 386 ms on localhost (executor driver) (1/4)
18/02/28 13:18:38 INFO Executor: Finished task 3.0 in stage 30.0 (TID 93). 2060 bytes result sent to driver
18/02/28 13:18:38 INFO TaskSetManager: Finished task 3.0 in stage 30.0 (TID 93) in 400 ms on localhost (executor driver) (2/4)
18/02/28 13:18:38 INFO Executor: Finished task 0.0 in stage 30.0 (TID 90). 2060 bytes result sent to driver
18/02/28 13:18:38 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 90) in 406 ms on localhost (executor driver) (3/4)
18/02/28 13:18:38 INFO Executor: Finished task 2.0 in stage 30.0 (TID 92). 2060 bytes result sent to driver
18/02/28 13:18:38 INFO TaskSetManager: Finished task 2.0 in stage 30.0 (TID 92) in 413 ms on localhost (executor driver) (4/4)
18/02/28 13:18:38 INFO DAGScheduler: ShuffleMapStage 30 (collect at utils.scala:211) finished in 0.415 s
18/02/28 13:18:38 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:18:38 INFO DAGScheduler: running: Set()
18/02/28 13:18:38 INFO DAGScheduler: waiting: Set(ResultStage 31)
18/02/28 13:18:38 INFO DAGScheduler: failed: Set()
18/02/28 13:18:38 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
18/02/28 13:18:38 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[103] at collect at utils.scala:211), which has no missing parents
18/02/28 13:18:38 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 25.0 KB, free 360.2 MB)
18/02/28 13:18:38 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 12.4 KB, free 360.2 MB)
18/02/28 13:18:38 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:60941 (size: 12.4 KB, free: 364.3 MB)
18/02/28 13:18:38 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1006
18/02/28 13:18:38 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 31 (MapPartitionsRDD[103] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:18:38 INFO TaskSchedulerImpl: Adding task set 31.0 with 4 tasks
18/02/28 13:18:38 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 94, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:18:38 INFO TaskSetManager: Starting task 1.0 in stage 31.0 (TID 95, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 13:18:38 INFO TaskSetManager: Starting task 2.0 in stage 31.0 (TID 96, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 13:18:38 INFO TaskSetManager: Starting task 3.0 in stage 31.0 (TID 97, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 13:18:38 INFO Executor: Running task 0.0 in stage 31.0 (TID 94)
18/02/28 13:18:38 INFO Executor: Running task 1.0 in stage 31.0 (TID 95)
18/02/28 13:18:38 INFO Executor: Running task 2.0 in stage 31.0 (TID 96)
18/02/28 13:18:38 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 4 blocks
18/02/28 13:18:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:18:38 INFO Executor: Running task 3.0 in stage 31.0 (TID 97)
18/02/28 13:18:38 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 13:18:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:18:38 INFO Executor: Finished task 1.0 in stage 31.0 (TID 95). 2492 bytes result sent to driver
18/02/28 13:18:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 13:18:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:18:38 INFO Executor: Finished task 0.0 in stage 31.0 (TID 94). 2475 bytes result sent to driver
18/02/28 13:18:38 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 13:18:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:18:38 INFO Executor: Finished task 2.0 in stage 31.0 (TID 96). 2526 bytes result sent to driver
18/02/28 13:18:38 INFO TaskSetManager: Finished task 1.0 in stage 31.0 (TID 95) in 11 ms on localhost (executor driver) (1/4)
18/02/28 13:18:38 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 94) in 11 ms on localhost (executor driver) (2/4)
18/02/28 13:18:38 INFO TaskSetManager: Finished task 2.0 in stage 31.0 (TID 96) in 11 ms on localhost (executor driver) (3/4)
18/02/28 13:18:38 INFO Executor: Finished task 3.0 in stage 31.0 (TID 97). 2551 bytes result sent to driver
18/02/28 13:18:38 INFO TaskSetManager: Finished task 3.0 in stage 31.0 (TID 97) in 13 ms on localhost (executor driver) (4/4)
18/02/28 13:18:38 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
18/02/28 13:18:38 INFO DAGScheduler: ResultStage 31 (collect at utils.scala:211) finished in 0.014 s
18/02/28 13:18:38 INFO DAGScheduler: Job 17 finished: collect at utils.scala:211, took 0.437040 s
18/02/28 13:19:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:19:48 INFO SparkSqlParser: Parsing command: SELECT `month`, `arr_time`, `arr_delay`, `dep_delay`, `distance`
FROM (SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`arr_time` AS DOUBLE) AS `arr_time`, CAST(`arr_delay` AS DOUBLE) AS `arr_delay`, CAST(`dep_delay` AS DOUBLE) AS `dep_delay`, CAST(`distance` AS DOUBLE) AS `distance`
FROM (SELECT `month`, `arr_time`, `arr_delay`, `dep_delay`, `distance`
FROM `spark_flights`) `qtckrmvbkr`) `zdkrswclkb`
18/02/28 13:19:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:19:57 INFO SparkSqlParser: Parsing command: SELECT `month`, `arr_time`, `arr_delay`, `dep_delay`, `distance`
FROM (SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`arr_time` AS DOUBLE) AS `arr_time`, CAST(`arr_delay` AS DOUBLE) AS `arr_delay`, CAST(`dep_delay` AS DOUBLE) AS `dep_delay`, CAST(`distance` AS DOUBLE) AS `distance`
FROM (SELECT `month`, `arr_time`, `arr_delay`, `dep_delay`, `distance`
FROM `spark_flights`) `utcrtqsfgt`) `xdujcrhbxc`
18/02/28 13:19:57 INFO SparkSqlParser: Parsing command: cached_flights
18/02/28 13:19:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:19:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights` AS `zzz61`
WHERE (0 = 1)
18/02/28 13:19:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:19:57 INFO SparkSqlParser: Parsing command: CACHE TABLE `cached_flights`
18/02/28 13:19:57 INFO SparkSqlParser: Parsing command: `cached_flights`
18/02/28 13:19:57 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 13:19:57 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 13:19:57 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dep_delay: string, arr_time: string, arr_delay: string, distance: string ... 3 more fields>
18/02/28 13:19:57 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 13:19:57 INFO CodeGenerator: Code generated in 8.532271 ms
18/02/28 13:19:57 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 282.5 KB, free 359.9 MB)
18/02/28 13:19:57 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 24.1 KB, free 359.9 MB)
18/02/28 13:19:57 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:60941 (size: 24.1 KB, free: 364.3 MB)
18/02/28 13:19:57 INFO SparkContext: Created broadcast 46 from sql at <unknown>:0
18/02/28 13:19:57 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21019222 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 13:19:57 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 13:19:57 INFO DAGScheduler: Registering RDD 109 (sql at <unknown>:0)
18/02/28 13:19:57 INFO DAGScheduler: Got job 18 (sql at <unknown>:0) with 1 output partitions
18/02/28 13:19:57 INFO DAGScheduler: Final stage: ResultStage 33 (sql at <unknown>:0)
18/02/28 13:19:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 32)
18/02/28 13:19:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 32)
18/02/28 13:19:57 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[109] at sql at <unknown>:0), which has no missing parents
18/02/28 13:19:57 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 23.3 KB, free 359.9 MB)
18/02/28 13:19:57 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 10.9 KB, free 359.9 MB)
18/02/28 13:19:57 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:60941 (size: 10.9 KB, free: 364.3 MB)
18/02/28 13:19:57 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1006
18/02/28 13:19:57 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[109] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:19:57 INFO TaskSchedulerImpl: Adding task set 32.0 with 4 tasks
18/02/28 13:19:57 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 98, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:19:57 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 99, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:19:57 INFO TaskSetManager: Starting task 2.0 in stage 32.0 (TID 100, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:19:57 INFO TaskSetManager: Starting task 3.0 in stage 32.0 (TID 101, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:19:57 INFO Executor: Running task 2.0 in stage 32.0 (TID 100)
18/02/28 13:19:57 INFO Executor: Running task 1.0 in stage 32.0 (TID 99)
18/02/28 13:19:57 INFO Executor: Running task 0.0 in stage 32.0 (TID 98)
18/02/28 13:19:57 INFO Executor: Running task 3.0 in stage 32.0 (TID 101)
18/02/28 13:19:57 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_11.csv, range: 0-2757037, partition values: [empty row]
18/02/28 13:19:57 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_3.csv, range: 0-2881793, partition values: [empty row]
18/02/28 13:19:57 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_4.csv, range: 0-2830543, partition values: [empty row]
18/02/28 13:19:57 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_7.csv, range: 0-2938867, partition values: [empty row]
18/02/28 13:19:57 INFO CodeGenerator: Code generated in 5.502234 ms
18/02/28 13:19:57 INFO ContextCleaner: Cleaned accumulator 1029
18/02/28 13:19:57 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:60941 in memory (size: 12.4 KB, free: 364.3 MB)
18/02/28 13:19:57 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_1.csv, range: 0-2697256, partition values: [empty row]
18/02/28 13:19:57 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_5.csv, range: 0-2880181, partition values: [empty row]
18/02/28 13:19:57 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_8.csv, range: 0-2932019, partition values: [empty row]
18/02/28 13:19:57 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_6.csv, range: 0-2820227, partition values: [empty row]
18/02/28 13:19:57 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_2.csv, range: 0-2487144, partition values: [empty row]
18/02/28 13:19:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_12.csv, range: 0-2836468, partition values: [empty row]
18/02/28 13:19:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_10.csv, range: 0-2920629, partition values: [empty row]
18/02/28 13:19:58 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_9.csv, range: 0-2763076, partition values: [empty row]
18/02/28 13:19:58 INFO MemoryStore: Block rdd_106_3 stored as values in memory (estimated size 3.0 MB, free 356.9 MB)
18/02/28 13:19:58 INFO BlockManagerInfo: Added rdd_106_3 in memory on 127.0.0.1:60941 (size: 3.0 MB, free: 361.3 MB)
18/02/28 13:19:58 INFO MemoryStore: Block rdd_106_2 stored as values in memory (estimated size 3.2 MB, free 350.4 MB)
18/02/28 13:19:58 INFO MemoryStore: Block rdd_106_0 stored as values in memory (estimated size 3.3 MB, free 350.4 MB)
18/02/28 13:19:58 INFO BlockManagerInfo: Added rdd_106_0 in memory on 127.0.0.1:60941 (size: 3.3 MB, free: 358.0 MB)
18/02/28 13:19:58 INFO BlockManagerInfo: Added rdd_106_2 in memory on 127.0.0.1:60941 (size: 3.2 MB, free: 354.8 MB)
18/02/28 13:19:58 INFO MemoryStore: Block rdd_106_1 stored as values in memory (estimated size 3.2 MB, free 347.1 MB)
18/02/28 13:19:58 INFO BlockManagerInfo: Added rdd_106_1 in memory on 127.0.0.1:60941 (size: 3.2 MB, free: 351.5 MB)
18/02/28 13:19:58 INFO Executor: Finished task 2.0 in stage 32.0 (TID 100). 2461 bytes result sent to driver
18/02/28 13:19:58 INFO TaskSetManager: Finished task 2.0 in stage 32.0 (TID 100) in 1046 ms on localhost (executor driver) (1/4)
18/02/28 13:19:58 INFO Executor: Finished task 3.0 in stage 32.0 (TID 101). 2461 bytes result sent to driver
18/02/28 13:19:58 INFO TaskSetManager: Finished task 3.0 in stage 32.0 (TID 101) in 1052 ms on localhost (executor driver) (2/4)
18/02/28 13:19:58 INFO Executor: Finished task 0.0 in stage 32.0 (TID 98). 2461 bytes result sent to driver
18/02/28 13:19:58 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 98) in 1059 ms on localhost (executor driver) (3/4)
18/02/28 13:19:58 INFO Executor: Finished task 1.0 in stage 32.0 (TID 99). 2461 bytes result sent to driver
18/02/28 13:19:58 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 99) in 1065 ms on localhost (executor driver) (4/4)
18/02/28 13:19:58 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
18/02/28 13:19:58 INFO DAGScheduler: ShuffleMapStage 32 (sql at <unknown>:0) finished in 1.066 s
18/02/28 13:19:58 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:19:58 INFO DAGScheduler: running: Set()
18/02/28 13:19:58 INFO DAGScheduler: waiting: Set(ResultStage 33)
18/02/28 13:19:58 INFO DAGScheduler: failed: Set()
18/02/28 13:19:58 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[112] at sql at <unknown>:0), which has no missing parents
18/02/28 13:19:58 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 7.0 KB, free 347.1 MB)
18/02/28 13:19:58 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 3.7 KB, free 347.1 MB)
18/02/28 13:19:58 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 351.5 MB)
18/02/28 13:19:58 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1006
18/02/28 13:19:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[112] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 13:19:58 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
18/02/28 13:19:58 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 102, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:19:58 INFO Executor: Running task 0.0 in stage 33.0 (TID 102)
18/02/28 13:19:58 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:19:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:19:58 INFO Executor: Finished task 0.0 in stage 33.0 (TID 102). 1538 bytes result sent to driver
18/02/28 13:19:58 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 102) in 5 ms on localhost (executor driver) (1/1)
18/02/28 13:19:58 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
18/02/28 13:19:58 INFO DAGScheduler: ResultStage 33 (sql at <unknown>:0) finished in 0.005 s
18/02/28 13:19:58 INFO DAGScheduler: Job 18 finished: sql at <unknown>:0, took 1.080405 s
18/02/28 13:19:58 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:19:58 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `cached_flights`
18/02/28 13:19:58 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:19:58 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:19:58 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:19:58 INFO DAGScheduler: Registering RDD 115 (collect at utils.scala:211)
18/02/28 13:19:58 INFO DAGScheduler: Got job 19 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:19:58 INFO DAGScheduler: Final stage: ResultStage 35 (collect at utils.scala:211)
18/02/28 13:19:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)
18/02/28 13:19:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 34)
18/02/28 13:19:58 INFO DAGScheduler: Submitting ShuffleMapStage 34 (MapPartitionsRDD[115] at collect at utils.scala:211), which has no missing parents
18/02/28 13:19:58 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 23.3 KB, free 347.1 MB)
18/02/28 13:19:58 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 10.9 KB, free 347.1 MB)
18/02/28 13:19:58 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:60941 (size: 10.9 KB, free: 351.5 MB)
18/02/28 13:19:58 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1006
18/02/28 13:19:58 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[115] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:19:58 INFO TaskSchedulerImpl: Adding task set 34.0 with 4 tasks
18/02/28 13:19:58 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 103, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:19:58 INFO TaskSetManager: Starting task 1.0 in stage 34.0 (TID 104, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:19:58 INFO TaskSetManager: Starting task 2.0 in stage 34.0 (TID 105, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:19:58 INFO TaskSetManager: Starting task 3.0 in stage 34.0 (TID 106, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:19:58 INFO Executor: Running task 0.0 in stage 34.0 (TID 103)
18/02/28 13:19:58 INFO Executor: Running task 1.0 in stage 34.0 (TID 104)
18/02/28 13:19:58 INFO BlockManager: Found block rdd_106_0 locally
18/02/28 13:19:58 INFO Executor: Running task 3.0 in stage 34.0 (TID 106)
18/02/28 13:19:58 INFO BlockManager: Found block rdd_106_1 locally
18/02/28 13:19:58 INFO Executor: Running task 2.0 in stage 34.0 (TID 105)
18/02/28 13:19:58 INFO BlockManager: Found block rdd_106_3 locally
18/02/28 13:19:58 INFO BlockManager: Found block rdd_106_2 locally
18/02/28 13:19:58 INFO Executor: Finished task 3.0 in stage 34.0 (TID 106). 1694 bytes result sent to driver
18/02/28 13:19:58 INFO Executor: Finished task 2.0 in stage 34.0 (TID 105). 1737 bytes result sent to driver
18/02/28 13:19:58 INFO TaskSetManager: Finished task 3.0 in stage 34.0 (TID 106) in 38 ms on localhost (executor driver) (1/4)
18/02/28 13:19:58 INFO TaskSetManager: Finished task 2.0 in stage 34.0 (TID 105) in 40 ms on localhost (executor driver) (2/4)
18/02/28 13:19:58 INFO Executor: Finished task 0.0 in stage 34.0 (TID 103). 1694 bytes result sent to driver
18/02/28 13:19:58 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 103) in 48 ms on localhost (executor driver) (3/4)
18/02/28 13:19:58 INFO Executor: Finished task 1.0 in stage 34.0 (TID 104). 1737 bytes result sent to driver
18/02/28 13:19:58 INFO TaskSetManager: Finished task 1.0 in stage 34.0 (TID 104) in 47 ms on localhost (executor driver) (4/4)
18/02/28 13:19:58 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
18/02/28 13:19:58 INFO DAGScheduler: ShuffleMapStage 34 (collect at utils.scala:211) finished in 0.051 s
18/02/28 13:19:58 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:19:58 INFO DAGScheduler: running: Set()
18/02/28 13:19:58 INFO DAGScheduler: waiting: Set(ResultStage 35)
18/02/28 13:19:58 INFO DAGScheduler: failed: Set()
18/02/28 13:19:58 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[118] at collect at utils.scala:211), which has no missing parents
18/02/28 13:19:58 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 7.0 KB, free 347.1 MB)
18/02/28 13:19:58 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 3.7 KB, free 347.1 MB)
18/02/28 13:19:58 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 351.5 MB)
18/02/28 13:19:58 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1006
18/02/28 13:19:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[118] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:19:58 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
18/02/28 13:19:58 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 107, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:19:58 INFO Executor: Running task 0.0 in stage 35.0 (TID 107)
18/02/28 13:19:58 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:19:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:19:58 INFO Executor: Finished task 0.0 in stage 35.0 (TID 107). 1538 bytes result sent to driver
18/02/28 13:19:58 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 107) in 5 ms on localhost (executor driver) (1/1)
18/02/28 13:19:58 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
18/02/28 13:19:58 INFO DAGScheduler: ResultStage 35 (collect at utils.scala:211) finished in 0.005 s
18/02/28 13:19:58 INFO DAGScheduler: Job 19 finished: collect at utils.scala:211, took 0.073831 s
18/02/28 13:19:58 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:19:58 INFO SparkSqlParser: Parsing command: SHOW TABLES LIKE"cached_flights"
18/02/28 13:19:58 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:19:58 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:19:58 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:19:58 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:19:58 INFO HiveMetaStore: 0: get_tables: db=default pat=cached_flights
18/02/28 13:19:58 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=cached_flights	
18/02/28 13:19:58 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:19:58 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights` AS `zzz62`
WHERE (0 = 1)
18/02/28 13:19:58 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:19:58 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 13:19:58 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:19:58 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:19:58 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:19:58 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:19:58 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 13:19:58 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 13:20:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:20:03 INFO SparkSqlParser: Parsing command: SELECT `month`, count(*) AS `n()`
FROM `cached_flights`
GROUP BY `month`
18/02/28 13:20:03 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:20:03 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:20:03 INFO CodeGenerator: Code generated in 15.871992 ms
18/02/28 13:20:03 INFO CodeGenerator: Code generated in 26.299931 ms
18/02/28 13:20:03 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:20:03 INFO DAGScheduler: Registering RDD 121 (collect at utils.scala:211)
18/02/28 13:20:03 INFO DAGScheduler: Got job 20 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:20:03 INFO DAGScheduler: Final stage: ResultStage 37 (collect at utils.scala:211)
18/02/28 13:20:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 36)
18/02/28 13:20:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 36)
18/02/28 13:20:03 INFO DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[121] at collect at utils.scala:211), which has no missing parents
18/02/28 13:20:03 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 33.9 KB, free 347.0 MB)
18/02/28 13:20:03 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 15.6 KB, free 347.0 MB)
18/02/28 13:20:03 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:60941 (size: 15.6 KB, free: 351.5 MB)
18/02/28 13:20:03 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1006
18/02/28 13:20:03 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[121] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:20:03 INFO TaskSchedulerImpl: Adding task set 36.0 with 4 tasks
18/02/28 13:20:03 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 108, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:20:03 INFO TaskSetManager: Starting task 1.0 in stage 36.0 (TID 109, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:20:03 INFO TaskSetManager: Starting task 2.0 in stage 36.0 (TID 110, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:20:03 INFO TaskSetManager: Starting task 3.0 in stage 36.0 (TID 111, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:20:03 INFO Executor: Running task 0.0 in stage 36.0 (TID 108)
18/02/28 13:20:03 INFO BlockManager: Found block rdd_106_0 locally
18/02/28 13:20:03 INFO Executor: Running task 1.0 in stage 36.0 (TID 109)
18/02/28 13:20:03 INFO BlockManager: Found block rdd_106_1 locally
18/02/28 13:20:03 INFO Executor: Running task 3.0 in stage 36.0 (TID 111)
18/02/28 13:20:03 INFO Executor: Running task 2.0 in stage 36.0 (TID 110)
18/02/28 13:20:03 INFO BlockManager: Found block rdd_106_2 locally
18/02/28 13:20:03 INFO BlockManager: Found block rdd_106_3 locally
18/02/28 13:20:03 INFO CodeGenerator: Code generated in 18.672475 ms
18/02/28 13:20:03 INFO CodeGenerator: Code generated in 9.01994 ms
18/02/28 13:20:04 INFO CodeGenerator: Code generated in 12.764026 ms
18/02/28 13:20:04 INFO CodeGenerator: Code generated in 5.441231 ms
18/02/28 13:20:04 INFO Executor: Finished task 2.0 in stage 36.0 (TID 110). 2011 bytes result sent to driver
18/02/28 13:20:04 INFO TaskSetManager: Finished task 2.0 in stage 36.0 (TID 110) in 254 ms on localhost (executor driver) (1/4)
18/02/28 13:20:04 INFO Executor: Finished task 3.0 in stage 36.0 (TID 111). 1968 bytes result sent to driver
18/02/28 13:20:04 INFO TaskSetManager: Finished task 3.0 in stage 36.0 (TID 111) in 285 ms on localhost (executor driver) (2/4)
18/02/28 13:20:04 INFO Executor: Finished task 0.0 in stage 36.0 (TID 108). 1968 bytes result sent to driver
18/02/28 13:20:04 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 108) in 302 ms on localhost (executor driver) (3/4)
18/02/28 13:20:04 INFO Executor: Finished task 1.0 in stage 36.0 (TID 109). 1968 bytes result sent to driver
18/02/28 13:20:04 INFO TaskSetManager: Finished task 1.0 in stage 36.0 (TID 109) in 323 ms on localhost (executor driver) (4/4)
18/02/28 13:20:04 INFO DAGScheduler: ShuffleMapStage 36 (collect at utils.scala:211) finished in 0.324 s
18/02/28 13:20:04 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:20:04 INFO DAGScheduler: running: Set()
18/02/28 13:20:04 INFO DAGScheduler: waiting: Set(ResultStage 37)
18/02/28 13:20:04 INFO DAGScheduler: failed: Set()
18/02/28 13:20:04 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[124] at collect at utils.scala:211), which has no missing parents
18/02/28 13:20:04 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
18/02/28 13:20:04 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 17.6 KB, free 347.0 MB)
18/02/28 13:20:04 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 8.2 KB, free 347.0 MB)
18/02/28 13:20:04 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:60941 (size: 8.2 KB, free: 351.5 MB)
18/02/28 13:20:04 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1006
18/02/28 13:20:04 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 37 (MapPartitionsRDD[124] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:20:04 INFO TaskSchedulerImpl: Adding task set 37.0 with 4 tasks
18/02/28 13:20:04 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 112, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:20:04 INFO TaskSetManager: Starting task 1.0 in stage 37.0 (TID 113, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 13:20:04 INFO TaskSetManager: Starting task 2.0 in stage 37.0 (TID 114, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 13:20:04 INFO TaskSetManager: Starting task 3.0 in stage 37.0 (TID 115, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 13:20:04 INFO Executor: Running task 0.0 in stage 37.0 (TID 112)
18/02/28 13:20:04 INFO Executor: Running task 1.0 in stage 37.0 (TID 113)
18/02/28 13:20:04 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 13:20:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:20:04 INFO Executor: Running task 3.0 in stage 37.0 (TID 115)
18/02/28 13:20:04 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:20:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:20:04 INFO Executor: Running task 2.0 in stage 37.0 (TID 114)
18/02/28 13:20:04 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 13:20:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
18/02/28 13:20:04 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 13:20:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:20:04 INFO Executor: Finished task 2.0 in stage 37.0 (TID 114). 2238 bytes result sent to driver
18/02/28 13:20:04 INFO Executor: Finished task 0.0 in stage 37.0 (TID 112). 2281 bytes result sent to driver
18/02/28 13:20:04 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 112) in 15 ms on localhost (executor driver) (1/4)
18/02/28 13:20:04 INFO TaskSetManager: Finished task 2.0 in stage 37.0 (TID 114) in 15 ms on localhost (executor driver) (2/4)
18/02/28 13:20:04 INFO Executor: Finished task 1.0 in stage 37.0 (TID 113). 2220 bytes result sent to driver
18/02/28 13:20:04 INFO TaskSetManager: Finished task 1.0 in stage 37.0 (TID 113) in 17 ms on localhost (executor driver) (3/4)
18/02/28 13:20:04 INFO Executor: Finished task 3.0 in stage 37.0 (TID 115). 2297 bytes result sent to driver
18/02/28 13:20:04 INFO TaskSetManager: Finished task 3.0 in stage 37.0 (TID 115) in 19 ms on localhost (executor driver) (4/4)
18/02/28 13:20:04 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
18/02/28 13:20:04 INFO DAGScheduler: ResultStage 37 (collect at utils.scala:211) finished in 0.019 s
18/02/28 13:20:04 INFO DAGScheduler: Job 20 finished: collect at utils.scala:211, took 0.354558 s
18/02/28 13:20:04 INFO CodeGenerator: Code generated in 5.502586 ms
18/02/28 13:20:07 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:20:07 INFO SparkSqlParser: Parsing command: SELECT `month`, count(*) AS `n()`
FROM `cached_flights`
GROUP BY `month`
18/02/28 13:20:07 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:20:07 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:20:07 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:20:07 INFO DAGScheduler: Registering RDD 127 (collect at utils.scala:211)
18/02/28 13:20:07 INFO DAGScheduler: Got job 21 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:20:07 INFO DAGScheduler: Final stage: ResultStage 39 (collect at utils.scala:211)
18/02/28 13:20:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 38)
18/02/28 13:20:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 38)
18/02/28 13:20:07 INFO DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[127] at collect at utils.scala:211), which has no missing parents
18/02/28 13:20:07 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 33.9 KB, free 347.0 MB)
18/02/28 13:20:07 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 15.6 KB, free 347.0 MB)
18/02/28 13:20:07 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:60941 (size: 15.6 KB, free: 351.5 MB)
18/02/28 13:20:07 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1006
18/02/28 13:20:07 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[127] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:20:07 INFO TaskSchedulerImpl: Adding task set 38.0 with 4 tasks
18/02/28 13:20:07 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 116, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:20:07 INFO TaskSetManager: Starting task 1.0 in stage 38.0 (TID 117, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:20:07 INFO TaskSetManager: Starting task 2.0 in stage 38.0 (TID 118, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:20:07 INFO TaskSetManager: Starting task 3.0 in stage 38.0 (TID 119, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:20:07 INFO Executor: Running task 0.0 in stage 38.0 (TID 116)
18/02/28 13:20:07 INFO Executor: Running task 1.0 in stage 38.0 (TID 117)
18/02/28 13:20:07 INFO Executor: Running task 2.0 in stage 38.0 (TID 118)
18/02/28 13:20:07 INFO Executor: Running task 3.0 in stage 38.0 (TID 119)
18/02/28 13:20:07 INFO BlockManager: Found block rdd_106_1 locally
18/02/28 13:20:07 INFO BlockManager: Found block rdd_106_0 locally
18/02/28 13:20:07 INFO BlockManager: Found block rdd_106_2 locally
18/02/28 13:20:07 INFO BlockManager: Found block rdd_106_3 locally
18/02/28 13:20:07 INFO Executor: Finished task 3.0 in stage 38.0 (TID 119). 1925 bytes result sent to driver
18/02/28 13:20:07 INFO TaskSetManager: Finished task 3.0 in stage 38.0 (TID 119) in 37 ms on localhost (executor driver) (1/4)
18/02/28 13:20:07 INFO Executor: Finished task 1.0 in stage 38.0 (TID 117). 1925 bytes result sent to driver
18/02/28 13:20:07 INFO TaskSetManager: Finished task 1.0 in stage 38.0 (TID 117) in 43 ms on localhost (executor driver) (2/4)
18/02/28 13:20:07 INFO Executor: Finished task 2.0 in stage 38.0 (TID 118). 1925 bytes result sent to driver
18/02/28 13:20:07 INFO TaskSetManager: Finished task 2.0 in stage 38.0 (TID 118) in 48 ms on localhost (executor driver) (3/4)
18/02/28 13:20:07 INFO Executor: Finished task 0.0 in stage 38.0 (TID 116). 1968 bytes result sent to driver
18/02/28 13:20:07 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 116) in 50 ms on localhost (executor driver) (4/4)
18/02/28 13:20:07 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
18/02/28 13:20:07 INFO DAGScheduler: ShuffleMapStage 38 (collect at utils.scala:211) finished in 0.050 s
18/02/28 13:20:07 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:20:07 INFO DAGScheduler: running: Set()
18/02/28 13:20:07 INFO DAGScheduler: waiting: Set(ResultStage 39)
18/02/28 13:20:07 INFO DAGScheduler: failed: Set()
18/02/28 13:20:07 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[130] at collect at utils.scala:211), which has no missing parents
18/02/28 13:20:07 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 17.6 KB, free 346.9 MB)
18/02/28 13:20:07 INFO ContextCleaner: Cleaned accumulator 1090
18/02/28 13:20:07 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 8.2 KB, free 346.9 MB)
18/02/28 13:20:07 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:60941 (size: 8.2 KB, free: 351.5 MB)
18/02/28 13:20:07 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:60941 in memory (size: 8.2 KB, free: 351.5 MB)
18/02/28 13:20:07 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1006
18/02/28 13:20:07 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 39 (MapPartitionsRDD[130] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:20:07 INFO TaskSchedulerImpl: Adding task set 39.0 with 4 tasks
18/02/28 13:20:07 INFO ContextCleaner: Cleaned accumulator 1151
18/02/28 13:20:07 INFO ContextCleaner: Cleaned accumulator 1212
18/02/28 13:20:07 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 120, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:20:07 INFO TaskSetManager: Starting task 1.0 in stage 39.0 (TID 121, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 13:20:07 INFO TaskSetManager: Starting task 2.0 in stage 39.0 (TID 122, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 13:20:07 INFO TaskSetManager: Starting task 3.0 in stage 39.0 (TID 123, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 13:20:07 INFO Executor: Running task 0.0 in stage 39.0 (TID 120)
18/02/28 13:20:07 INFO Executor: Running task 2.0 in stage 39.0 (TID 122)
18/02/28 13:20:07 INFO Executor: Running task 3.0 in stage 39.0 (TID 123)
18/02/28 13:20:07 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 13:20:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:20:07 INFO Executor: Running task 1.0 in stage 39.0 (TID 121)
18/02/28 13:20:07 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 13:20:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:20:07 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:60941 in memory (size: 15.6 KB, free: 351.5 MB)
18/02/28 13:20:07 INFO Executor: Finished task 0.0 in stage 39.0 (TID 120). 2238 bytes result sent to driver
18/02/28 13:20:07 INFO Executor: Finished task 2.0 in stage 39.0 (TID 122). 2238 bytes result sent to driver
18/02/28 13:20:07 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:20:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
18/02/28 13:20:07 INFO Executor: Finished task 3.0 in stage 39.0 (TID 123). 2297 bytes result sent to driver
18/02/28 13:20:07 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 13:20:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
18/02/28 13:20:07 INFO Executor: Finished task 1.0 in stage 39.0 (TID 121). 2220 bytes result sent to driver
18/02/28 13:20:07 INFO TaskSetManager: Finished task 2.0 in stage 39.0 (TID 122) in 14 ms on localhost (executor driver) (1/4)
18/02/28 13:20:07 INFO TaskSetManager: Finished task 3.0 in stage 39.0 (TID 123) in 14 ms on localhost (executor driver) (2/4)
18/02/28 13:20:07 INFO TaskSetManager: Finished task 1.0 in stage 39.0 (TID 121) in 15 ms on localhost (executor driver) (3/4)
18/02/28 13:20:07 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 120) in 16 ms on localhost (executor driver) (4/4)
18/02/28 13:20:07 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
18/02/28 13:20:07 INFO DAGScheduler: ResultStage 39 (collect at utils.scala:211) finished in 0.016 s
18/02/28 13:20:07 INFO DAGScheduler: Job 21 finished: collect at utils.scala:211, took 0.081642 s
18/02/28 13:20:07 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 351.5 MB)
18/02/28 13:20:07 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:60941 in memory (size: 10.9 KB, free: 351.5 MB)
18/02/28 13:20:07 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 351.5 MB)
18/02/28 13:22:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:22:38 INFO SparkSqlParser: Parsing command: SELECT `month`, `carrier`, `arr_time`, `arr_delay`, `dep_delay`, `distance`
FROM (SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`carrier` AS DOUBLE) AS `carrier`, CAST(`arr_time` AS DOUBLE) AS `arr_time`, CAST(`arr_delay` AS DOUBLE) AS `arr_delay`, CAST(`dep_delay` AS DOUBLE) AS `dep_delay`, CAST(`distance` AS DOUBLE) AS `distance`
FROM (SELECT `month`, `carrier`, `arr_time`, `arr_delay`, `dep_delay`, `distance`
FROM `spark_flights`) `zgqnkaqvvr`) `rbcexdxmeo`
18/02/28 13:22:38 INFO SparkSqlParser: Parsing command: cached_flights
18/02/28 13:22:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:22:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights` AS `zzz63`
WHERE (0 = 1)
18/02/28 13:22:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:22:38 INFO SparkSqlParser: Parsing command: CACHE TABLE `cached_flights`
18/02/28 13:22:38 INFO SparkSqlParser: Parsing command: `cached_flights`
18/02/28 13:22:38 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 13:22:38 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 13:22:38 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dep_delay: string, arr_time: string, arr_delay: string, carrier: string ... 1 more field>
18/02/28 13:22:38 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 13:22:38 INFO CodeGenerator: Code generated in 7.156712 ms
18/02/28 13:22:38 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 282.5 KB, free 346.8 MB)
18/02/28 13:22:38 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 24.1 KB, free 346.8 MB)
18/02/28 13:22:38 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:60941 (size: 24.1 KB, free: 351.5 MB)
18/02/28 13:22:38 INFO SparkContext: Created broadcast 55 from sql at <unknown>:0
18/02/28 13:22:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21019222 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 13:22:38 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 13:22:38 INFO DAGScheduler: Registering RDD 136 (sql at <unknown>:0)
18/02/28 13:22:38 INFO DAGScheduler: Got job 22 (sql at <unknown>:0) with 1 output partitions
18/02/28 13:22:38 INFO DAGScheduler: Final stage: ResultStage 41 (sql at <unknown>:0)
18/02/28 13:22:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 40)
18/02/28 13:22:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 40)
18/02/28 13:22:38 INFO DAGScheduler: Submitting ShuffleMapStage 40 (MapPartitionsRDD[136] at sql at <unknown>:0), which has no missing parents
18/02/28 13:22:38 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 24.4 KB, free 346.7 MB)
18/02/28 13:22:38 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 11.2 KB, free 346.7 MB)
18/02/28 13:22:38 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:60941 (size: 11.2 KB, free: 351.5 MB)
18/02/28 13:22:38 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1006
18/02/28 13:22:38 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[136] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:22:38 INFO TaskSchedulerImpl: Adding task set 40.0 with 4 tasks
18/02/28 13:22:38 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 124, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:22:38 INFO TaskSetManager: Starting task 1.0 in stage 40.0 (TID 125, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:22:38 INFO TaskSetManager: Starting task 2.0 in stage 40.0 (TID 126, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:22:38 INFO TaskSetManager: Starting task 3.0 in stage 40.0 (TID 127, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:22:38 INFO Executor: Running task 0.0 in stage 40.0 (TID 124)
18/02/28 13:22:38 INFO Executor: Running task 3.0 in stage 40.0 (TID 127)
18/02/28 13:22:38 INFO Executor: Running task 1.0 in stage 40.0 (TID 125)
18/02/28 13:22:38 INFO Executor: Running task 2.0 in stage 40.0 (TID 126)
18/02/28 13:22:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_7.csv, range: 0-2938867, partition values: [empty row]
18/02/28 13:22:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_3.csv, range: 0-2881793, partition values: [empty row]
18/02/28 13:22:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_4.csv, range: 0-2830543, partition values: [empty row]
18/02/28 13:22:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_11.csv, range: 0-2757037, partition values: [empty row]
18/02/28 13:22:38 INFO CodeGenerator: Code generated in 8.074574 ms
18/02/28 13:22:38 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:60941 in memory (size: 8.2 KB, free: 351.5 MB)
18/02/28 13:22:38 INFO ContextCleaner: Cleaned accumulator 1279
18/02/28 13:22:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_8.csv, range: 0-2932019, partition values: [empty row]
18/02/28 13:22:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_1.csv, range: 0-2697256, partition values: [empty row]
18/02/28 13:22:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_5.csv, range: 0-2880181, partition values: [empty row]
18/02/28 13:22:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_6.csv, range: 0-2820227, partition values: [empty row]
18/02/28 13:22:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_2.csv, range: 0-2487144, partition values: [empty row]
18/02/28 13:22:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_12.csv, range: 0-2836468, partition values: [empty row]
18/02/28 13:22:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_10.csv, range: 0-2920629, partition values: [empty row]
18/02/28 13:22:39 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_9.csv, range: 0-2763076, partition values: [empty row]
18/02/28 13:22:39 INFO MemoryStore: Block rdd_133_3 stored as values in memory (estimated size 3.3 MB, free 343.4 MB)
18/02/28 13:22:39 INFO BlockManagerInfo: Added rdd_133_3 in memory on 127.0.0.1:60941 (size: 3.3 MB, free: 348.2 MB)
18/02/28 13:22:39 INFO Executor: Finished task 3.0 in stage 40.0 (TID 127). 2504 bytes result sent to driver
18/02/28 13:22:39 INFO TaskSetManager: Finished task 3.0 in stage 40.0 (TID 127) in 1407 ms on localhost (executor driver) (1/4)
18/02/28 13:22:39 INFO MemoryStore: Block rdd_133_0 stored as values in memory (estimated size 3.7 MB, free 339.8 MB)
18/02/28 13:22:39 INFO BlockManagerInfo: Added rdd_133_0 in memory on 127.0.0.1:60941 (size: 3.7 MB, free: 344.5 MB)
18/02/28 13:22:39 INFO Executor: Finished task 0.0 in stage 40.0 (TID 124). 2461 bytes result sent to driver
18/02/28 13:22:39 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 124) in 1427 ms on localhost (executor driver) (2/4)
18/02/28 13:22:39 INFO MemoryStore: Block rdd_133_1 stored as values in memory (estimated size 3.6 MB, free 336.2 MB)
18/02/28 13:22:39 INFO BlockManagerInfo: Added rdd_133_1 in memory on 127.0.0.1:60941 (size: 3.6 MB, free: 340.9 MB)
18/02/28 13:22:39 INFO MemoryStore: Block rdd_133_2 stored as values in memory (estimated size 3.5 MB, free 332.7 MB)
18/02/28 13:22:39 INFO BlockManagerInfo: Added rdd_133_2 in memory on 127.0.0.1:60941 (size: 3.5 MB, free: 337.4 MB)
18/02/28 13:22:39 INFO Executor: Finished task 1.0 in stage 40.0 (TID 125). 2504 bytes result sent to driver
18/02/28 13:22:39 INFO TaskSetManager: Finished task 1.0 in stage 40.0 (TID 125) in 1446 ms on localhost (executor driver) (3/4)
18/02/28 13:22:39 INFO Executor: Finished task 2.0 in stage 40.0 (TID 126). 2461 bytes result sent to driver
18/02/28 13:22:39 INFO TaskSetManager: Finished task 2.0 in stage 40.0 (TID 126) in 1451 ms on localhost (executor driver) (4/4)
18/02/28 13:22:39 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
18/02/28 13:22:39 INFO DAGScheduler: ShuffleMapStage 40 (sql at <unknown>:0) finished in 1.453 s
18/02/28 13:22:39 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:22:39 INFO DAGScheduler: running: Set()
18/02/28 13:22:39 INFO DAGScheduler: waiting: Set(ResultStage 41)
18/02/28 13:22:39 INFO DAGScheduler: failed: Set()
18/02/28 13:22:39 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[139] at sql at <unknown>:0), which has no missing parents
18/02/28 13:22:39 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 7.0 KB, free 332.7 MB)
18/02/28 13:22:39 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 3.7 KB, free 332.7 MB)
18/02/28 13:22:39 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 337.4 MB)
18/02/28 13:22:39 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1006
18/02/28 13:22:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[139] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 13:22:39 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
18/02/28 13:22:39 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 128, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:22:39 INFO Executor: Running task 0.0 in stage 41.0 (TID 128)
18/02/28 13:22:39 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:22:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:22:39 INFO Executor: Finished task 0.0 in stage 41.0 (TID 128). 1495 bytes result sent to driver
18/02/28 13:22:39 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 128) in 5 ms on localhost (executor driver) (1/1)
18/02/28 13:22:39 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
18/02/28 13:22:39 INFO DAGScheduler: ResultStage 41 (sql at <unknown>:0) finished in 0.005 s
18/02/28 13:22:39 INFO DAGScheduler: Job 22 finished: sql at <unknown>:0, took 1.469303 s
18/02/28 13:22:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:22:39 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `cached_flights`
18/02/28 13:22:39 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:22:39 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:22:39 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:22:39 INFO DAGScheduler: Registering RDD 142 (collect at utils.scala:211)
18/02/28 13:22:39 INFO DAGScheduler: Got job 23 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:22:39 INFO DAGScheduler: Final stage: ResultStage 43 (collect at utils.scala:211)
18/02/28 13:22:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 42)
18/02/28 13:22:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 42)
18/02/28 13:22:39 INFO DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[142] at collect at utils.scala:211), which has no missing parents
18/02/28 13:22:39 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 24.4 KB, free 332.7 MB)
18/02/28 13:22:39 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 11.2 KB, free 332.6 MB)
18/02/28 13:22:39 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:60941 (size: 11.2 KB, free: 337.4 MB)
18/02/28 13:22:39 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1006
18/02/28 13:22:39 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[142] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:22:39 INFO TaskSchedulerImpl: Adding task set 42.0 with 4 tasks
18/02/28 13:22:39 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 129, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:22:39 INFO TaskSetManager: Starting task 1.0 in stage 42.0 (TID 130, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:22:39 INFO TaskSetManager: Starting task 2.0 in stage 42.0 (TID 131, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:22:39 INFO TaskSetManager: Starting task 3.0 in stage 42.0 (TID 132, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:22:39 INFO Executor: Running task 0.0 in stage 42.0 (TID 129)
18/02/28 13:22:39 INFO BlockManager: Found block rdd_133_0 locally
18/02/28 13:22:39 INFO Executor: Running task 1.0 in stage 42.0 (TID 130)
18/02/28 13:22:39 INFO Executor: Running task 2.0 in stage 42.0 (TID 131)
18/02/28 13:22:39 INFO BlockManager: Found block rdd_133_1 locally
18/02/28 13:22:39 INFO BlockManager: Found block rdd_133_2 locally
18/02/28 13:22:39 INFO Executor: Running task 3.0 in stage 42.0 (TID 132)
18/02/28 13:22:39 INFO BlockManager: Found block rdd_133_3 locally
18/02/28 13:22:39 INFO Executor: Finished task 0.0 in stage 42.0 (TID 129). 1780 bytes result sent to driver
18/02/28 13:22:39 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 129) in 28 ms on localhost (executor driver) (1/4)
18/02/28 13:22:39 INFO Executor: Finished task 3.0 in stage 42.0 (TID 132). 1694 bytes result sent to driver
18/02/28 13:22:39 INFO TaskSetManager: Finished task 3.0 in stage 42.0 (TID 132) in 28 ms on localhost (executor driver) (2/4)
18/02/28 13:22:39 INFO Executor: Finished task 1.0 in stage 42.0 (TID 130). 1694 bytes result sent to driver
18/02/28 13:22:39 INFO TaskSetManager: Finished task 1.0 in stage 42.0 (TID 130) in 30 ms on localhost (executor driver) (3/4)
18/02/28 13:22:39 INFO Executor: Finished task 2.0 in stage 42.0 (TID 131). 1694 bytes result sent to driver
18/02/28 13:22:39 INFO TaskSetManager: Finished task 2.0 in stage 42.0 (TID 131) in 33 ms on localhost (executor driver) (4/4)
18/02/28 13:22:39 INFO DAGScheduler: ShuffleMapStage 42 (collect at utils.scala:211) finished in 0.034 s
18/02/28 13:22:39 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:22:39 INFO DAGScheduler: running: Set()
18/02/28 13:22:39 INFO DAGScheduler: waiting: Set(ResultStage 43)
18/02/28 13:22:39 INFO DAGScheduler: failed: Set()
18/02/28 13:22:39 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[145] at collect at utils.scala:211), which has no missing parents
18/02/28 13:22:39 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 7.0 KB, free 332.6 MB)
18/02/28 13:22:39 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 3.7 KB, free 332.6 MB)
18/02/28 13:22:39 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
18/02/28 13:22:39 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 337.4 MB)
18/02/28 13:22:39 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1006
18/02/28 13:22:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[145] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:22:39 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
18/02/28 13:22:39 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 133, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:22:39 INFO Executor: Running task 0.0 in stage 43.0 (TID 133)
18/02/28 13:22:39 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:22:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:22:39 INFO Executor: Finished task 0.0 in stage 43.0 (TID 133). 1495 bytes result sent to driver
18/02/28 13:22:39 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 133) in 6 ms on localhost (executor driver) (1/1)
18/02/28 13:22:39 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
18/02/28 13:22:39 INFO DAGScheduler: ResultStage 43 (collect at utils.scala:211) finished in 0.007 s
18/02/28 13:22:39 INFO DAGScheduler: Job 23 finished: collect at utils.scala:211, took 0.049572 s
18/02/28 13:22:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:22:39 INFO SparkSqlParser: Parsing command: SHOW TABLES LIKE"cached_flights"
18/02/28 13:22:39 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:22:39 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:22:39 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:22:39 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:22:39 INFO HiveMetaStore: 0: get_tables: db=default pat=cached_flights
18/02/28 13:22:39 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=cached_flights	
18/02/28 13:22:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:22:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights` AS `zzz64`
WHERE (0 = 1)
18/02/28 13:22:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:22:40 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 13:22:40 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:22:40 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:22:40 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:22:40 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:22:40 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 13:22:40 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 13:23:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:23:27 INFO SparkSqlParser: Parsing command: SELECT `month`, `carrier`, `arr_time`, `arr_delay`, `dep_delay`, `distance`
FROM (SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`carrier` AS DOUBLE) AS `carrier`, CAST(`arr_time` AS DOUBLE) AS `arr_time`, CAST(`arr_delay` AS DOUBLE) AS `arr_delay`, CAST(`dep_delay` AS DOUBLE) AS `dep_delay`, CAST(`distance` AS DOUBLE) AS `distance`
FROM (SELECT `month`, `carrier`, `arr_time`, `arr_delay`, `dep_delay`, `distance`
FROM `spark_flights`) `vjfuqxords`) `tguqodkmkq`
18/02/28 13:23:27 INFO SparkSqlParser: Parsing command: cached_flights
18/02/28 13:23:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:23:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights` AS `zzz65`
WHERE (0 = 1)
18/02/28 13:23:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:23:27 INFO SparkSqlParser: Parsing command: CACHE TABLE `cached_flights`
18/02/28 13:23:27 INFO SparkSqlParser: Parsing command: `cached_flights`
18/02/28 13:23:27 WARN CacheManager: Asked to cache already cached data.
18/02/28 13:23:27 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 13:23:27 INFO DAGScheduler: Registering RDD 148 (sql at <unknown>:0)
18/02/28 13:23:27 INFO DAGScheduler: Got job 24 (sql at <unknown>:0) with 1 output partitions
18/02/28 13:23:27 INFO DAGScheduler: Final stage: ResultStage 45 (sql at <unknown>:0)
18/02/28 13:23:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)
18/02/28 13:23:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 44)
18/02/28 13:23:27 INFO DAGScheduler: Submitting ShuffleMapStage 44 (MapPartitionsRDD[148] at sql at <unknown>:0), which has no missing parents
18/02/28 13:23:27 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 24.5 KB, free 332.6 MB)
18/02/28 13:23:27 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 11.2 KB, free 332.6 MB)
18/02/28 13:23:27 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:60941 (size: 11.2 KB, free: 337.4 MB)
18/02/28 13:23:27 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1006
18/02/28 13:23:27 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[148] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:23:27 INFO TaskSchedulerImpl: Adding task set 44.0 with 4 tasks
18/02/28 13:23:27 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 134, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:23:27 INFO TaskSetManager: Starting task 1.0 in stage 44.0 (TID 135, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:23:27 INFO TaskSetManager: Starting task 2.0 in stage 44.0 (TID 136, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:23:27 INFO TaskSetManager: Starting task 3.0 in stage 44.0 (TID 137, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:23:27 INFO Executor: Running task 1.0 in stage 44.0 (TID 135)
18/02/28 13:23:27 INFO Executor: Running task 0.0 in stage 44.0 (TID 134)
18/02/28 13:23:27 INFO Executor: Running task 3.0 in stage 44.0 (TID 137)
18/02/28 13:23:27 INFO Executor: Running task 2.0 in stage 44.0 (TID 136)
18/02/28 13:23:27 INFO BlockManager: Found block rdd_133_3 locally
18/02/28 13:23:27 INFO BlockManager: Found block rdd_133_1 locally
18/02/28 13:23:27 INFO BlockManager: Found block rdd_133_0 locally
18/02/28 13:23:27 INFO BlockManager: Found block rdd_133_2 locally
18/02/28 13:23:27 INFO Executor: Finished task 1.0 in stage 44.0 (TID 135). 1694 bytes result sent to driver
18/02/28 13:23:27 INFO TaskSetManager: Finished task 1.0 in stage 44.0 (TID 135) in 17 ms on localhost (executor driver) (1/4)
18/02/28 13:23:27 INFO Executor: Finished task 0.0 in stage 44.0 (TID 134). 1694 bytes result sent to driver
18/02/28 13:23:27 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 134) in 18 ms on localhost (executor driver) (2/4)
18/02/28 13:23:27 INFO Executor: Finished task 3.0 in stage 44.0 (TID 137). 1694 bytes result sent to driver
18/02/28 13:23:27 INFO TaskSetManager: Finished task 3.0 in stage 44.0 (TID 137) in 20 ms on localhost (executor driver) (3/4)
18/02/28 13:23:27 INFO Executor: Finished task 2.0 in stage 44.0 (TID 136). 1737 bytes result sent to driver
18/02/28 13:23:27 INFO TaskSetManager: Finished task 2.0 in stage 44.0 (TID 136) in 22 ms on localhost (executor driver) (4/4)
18/02/28 13:23:27 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
18/02/28 13:23:27 INFO DAGScheduler: ShuffleMapStage 44 (sql at <unknown>:0) finished in 0.022 s
18/02/28 13:23:27 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:23:27 INFO DAGScheduler: running: Set()
18/02/28 13:23:27 INFO DAGScheduler: waiting: Set(ResultStage 45)
18/02/28 13:23:27 INFO DAGScheduler: failed: Set()
18/02/28 13:23:27 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[151] at sql at <unknown>:0), which has no missing parents
18/02/28 13:23:27 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 7.0 KB, free 332.6 MB)
18/02/28 13:23:27 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 3.7 KB, free 332.6 MB)
18/02/28 13:23:27 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 337.4 MB)
18/02/28 13:23:27 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1006
18/02/28 13:23:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[151] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 13:23:27 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
18/02/28 13:23:27 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 138, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:23:27 INFO Executor: Running task 0.0 in stage 45.0 (TID 138)
18/02/28 13:23:27 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:23:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:23:27 INFO Executor: Finished task 0.0 in stage 45.0 (TID 138). 1495 bytes result sent to driver
18/02/28 13:23:27 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 138) in 5 ms on localhost (executor driver) (1/1)
18/02/28 13:23:27 INFO DAGScheduler: ResultStage 45 (sql at <unknown>:0) finished in 0.005 s
18/02/28 13:23:27 INFO DAGScheduler: Job 24 finished: sql at <unknown>:0, took 0.035693 s
18/02/28 13:23:27 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
18/02/28 13:23:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:23:27 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `cached_flights`
18/02/28 13:23:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:23:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:23:27 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:23:27 INFO DAGScheduler: Registering RDD 154 (collect at utils.scala:211)
18/02/28 13:23:27 INFO DAGScheduler: Got job 25 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:23:27 INFO DAGScheduler: Final stage: ResultStage 47 (collect at utils.scala:211)
18/02/28 13:23:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 46)
18/02/28 13:23:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 46)
18/02/28 13:23:27 INFO DAGScheduler: Submitting ShuffleMapStage 46 (MapPartitionsRDD[154] at collect at utils.scala:211), which has no missing parents
18/02/28 13:23:27 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 24.5 KB, free 332.6 MB)
18/02/28 13:23:27 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 11.2 KB, free 332.5 MB)
18/02/28 13:23:27 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:60941 (size: 11.2 KB, free: 337.4 MB)
18/02/28 13:23:27 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1006
18/02/28 13:23:27 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[154] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:23:27 INFO TaskSchedulerImpl: Adding task set 46.0 with 4 tasks
18/02/28 13:23:27 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 139, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:23:27 INFO TaskSetManager: Starting task 1.0 in stage 46.0 (TID 140, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:23:27 INFO TaskSetManager: Starting task 2.0 in stage 46.0 (TID 141, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:23:27 INFO TaskSetManager: Starting task 3.0 in stage 46.0 (TID 142, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:23:27 INFO Executor: Running task 0.0 in stage 46.0 (TID 139)
18/02/28 13:23:27 INFO Executor: Running task 1.0 in stage 46.0 (TID 140)
18/02/28 13:23:27 INFO Executor: Running task 2.0 in stage 46.0 (TID 141)
18/02/28 13:23:27 INFO BlockManager: Found block rdd_133_0 locally
18/02/28 13:23:27 INFO BlockManager: Found block rdd_133_2 locally
18/02/28 13:23:27 INFO BlockManager: Found block rdd_133_1 locally
18/02/28 13:23:27 INFO Executor: Running task 3.0 in stage 46.0 (TID 142)
18/02/28 13:23:27 INFO BlockManager: Found block rdd_133_3 locally
18/02/28 13:23:27 INFO Executor: Finished task 0.0 in stage 46.0 (TID 139). 1737 bytes result sent to driver
18/02/28 13:23:27 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 139) in 21 ms on localhost (executor driver) (1/4)
18/02/28 13:23:27 INFO Executor: Finished task 2.0 in stage 46.0 (TID 141). 1737 bytes result sent to driver
18/02/28 13:23:27 INFO TaskSetManager: Finished task 2.0 in stage 46.0 (TID 141) in 26 ms on localhost (executor driver) (2/4)
18/02/28 13:23:27 INFO Executor: Finished task 3.0 in stage 46.0 (TID 142). 1694 bytes result sent to driver
18/02/28 13:23:27 INFO TaskSetManager: Finished task 3.0 in stage 46.0 (TID 142) in 31 ms on localhost (executor driver) (3/4)
18/02/28 13:23:27 INFO Executor: Finished task 1.0 in stage 46.0 (TID 140). 1737 bytes result sent to driver
18/02/28 13:23:27 INFO TaskSetManager: Finished task 1.0 in stage 46.0 (TID 140) in 32 ms on localhost (executor driver) (4/4)
18/02/28 13:23:27 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
18/02/28 13:23:27 INFO DAGScheduler: ShuffleMapStage 46 (collect at utils.scala:211) finished in 0.034 s
18/02/28 13:23:27 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:23:27 INFO DAGScheduler: running: Set()
18/02/28 13:23:27 INFO DAGScheduler: waiting: Set(ResultStage 47)
18/02/28 13:23:27 INFO DAGScheduler: failed: Set()
18/02/28 13:23:27 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[157] at collect at utils.scala:211), which has no missing parents
18/02/28 13:23:27 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 7.0 KB, free 332.5 MB)
18/02/28 13:23:27 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 3.7 KB, free 332.5 MB)
18/02/28 13:23:27 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 337.4 MB)
18/02/28 13:23:27 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1006
18/02/28 13:23:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[157] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:23:27 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
18/02/28 13:23:27 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 143, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:23:27 INFO Executor: Running task 0.0 in stage 47.0 (TID 143)
18/02/28 13:23:27 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:23:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:23:27 INFO Executor: Finished task 0.0 in stage 47.0 (TID 143). 1495 bytes result sent to driver
18/02/28 13:23:27 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 143) in 5 ms on localhost (executor driver) (1/1)
18/02/28 13:23:27 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
18/02/28 13:23:27 INFO DAGScheduler: ResultStage 47 (collect at utils.scala:211) finished in 0.006 s
18/02/28 13:23:27 INFO DAGScheduler: Job 25 finished: collect at utils.scala:211, took 0.047178 s
18/02/28 13:23:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:23:27 INFO SparkSqlParser: Parsing command: SHOW TABLES LIKE"cached_flights"
18/02/28 13:23:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:23:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:23:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:23:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:23:27 INFO HiveMetaStore: 0: get_tables: db=default pat=cached_flights
18/02/28 13:23:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=cached_flights	
18/02/28 13:23:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:23:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights` AS `zzz66`
WHERE (0 = 1)
18/02/28 13:23:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:23:27 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 13:23:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:23:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:23:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:23:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:23:27 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 13:23:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 13:23:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:23:37 INFO SparkSqlParser: Parsing command: SELECT `month`, count(*) AS `n()`
FROM `cached_flights`
GROUP BY `month`
18/02/28 13:23:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:23:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:23:37 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:23:37 INFO DAGScheduler: Registering RDD 160 (collect at utils.scala:211)
18/02/28 13:23:37 INFO DAGScheduler: Got job 26 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:23:37 INFO DAGScheduler: Final stage: ResultStage 49 (collect at utils.scala:211)
18/02/28 13:23:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 48)
18/02/28 13:23:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 48)
18/02/28 13:23:37 INFO DAGScheduler: Submitting ShuffleMapStage 48 (MapPartitionsRDD[160] at collect at utils.scala:211), which has no missing parents
18/02/28 13:23:37 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 35.1 KB, free 332.5 MB)
18/02/28 13:23:37 INFO ContextCleaner: Cleaned accumulator 1523
18/02/28 13:23:37 INFO ContextCleaner: Cleaned accumulator 1404
18/02/28 13:23:37 INFO ContextCleaner: Cleaned accumulator 1409
18/02/28 13:23:37 INFO ContextCleaner: Cleaned accumulator 1410
18/02/28 13:23:37 INFO ContextCleaner: Cleaned accumulator 1340
18/02/28 13:23:37 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 16.0 KB, free 332.5 MB)
18/02/28 13:23:37 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:60941 (size: 16.0 KB, free: 337.4 MB)
18/02/28 13:23:37 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1006
18/02/28 13:23:37 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 48 (MapPartitionsRDD[160] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:23:37 INFO TaskSchedulerImpl: Adding task set 48.0 with 4 tasks
18/02/28 13:23:37 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 144, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:23:37 INFO TaskSetManager: Starting task 1.0 in stage 48.0 (TID 145, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:23:37 INFO TaskSetManager: Starting task 2.0 in stage 48.0 (TID 146, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:23:37 INFO TaskSetManager: Starting task 3.0 in stage 48.0 (TID 147, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:23:37 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 337.4 MB)
18/02/28 13:23:37 INFO Executor: Running task 0.0 in stage 48.0 (TID 144)
18/02/28 13:23:37 INFO Executor: Running task 1.0 in stage 48.0 (TID 145)
18/02/28 13:23:37 INFO BlockManager: Found block rdd_133_0 locally
18/02/28 13:23:37 INFO Executor: Running task 2.0 in stage 48.0 (TID 146)
18/02/28 13:23:37 INFO BlockManager: Found block rdd_133_1 locally
18/02/28 13:23:37 INFO BlockManager: Found block rdd_133_2 locally
18/02/28 13:23:37 INFO Executor: Running task 3.0 in stage 48.0 (TID 147)
18/02/28 13:23:37 INFO BlockManager: Found block rdd_133_3 locally
18/02/28 13:23:37 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 127.0.0.1:60941 in memory (size: 11.2 KB, free: 337.4 MB)
18/02/28 13:23:37 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 337.4 MB)
18/02/28 13:23:37 INFO ContextCleaner: Cleaned accumulator 1413
18/02/28 13:23:37 INFO ContextCleaner: Cleaned accumulator 1403
18/02/28 13:23:37 INFO ContextCleaner: Cleaned accumulator 1462
18/02/28 13:23:37 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 337.4 MB)
18/02/28 13:23:37 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 337.4 MB)
18/02/28 13:23:37 INFO ContextCleaner: Cleaned accumulator 1407
18/02/28 13:23:37 INFO ContextCleaner: Cleaned accumulator 1401
18/02/28 13:23:37 INFO ContextCleaner: Cleaned accumulator 1411
18/02/28 13:23:37 INFO ContextCleaner: Cleaned accumulator 1402
18/02/28 13:23:37 INFO ContextCleaner: Cleaned accumulator 1406
18/02/28 13:23:37 INFO ContextCleaner: Cleaned accumulator 1412
18/02/28 13:23:37 INFO ContextCleaner: Cleaned accumulator 1405
18/02/28 13:23:37 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:60941 in memory (size: 11.2 KB, free: 337.4 MB)
18/02/28 13:23:37 INFO ContextCleaner: Cleaned accumulator 1408
18/02/28 13:23:37 INFO ContextCleaner: Cleaned shuffle 20
18/02/28 13:23:37 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:60941 in memory (size: 11.2 KB, free: 337.4 MB)
18/02/28 13:23:37 INFO Executor: Finished task 3.0 in stage 48.0 (TID 147). 1925 bytes result sent to driver
18/02/28 13:23:37 INFO TaskSetManager: Finished task 3.0 in stage 48.0 (TID 147) in 40 ms on localhost (executor driver) (1/4)
18/02/28 13:23:37 INFO Executor: Finished task 2.0 in stage 48.0 (TID 146). 1968 bytes result sent to driver
18/02/28 13:23:37 INFO TaskSetManager: Finished task 2.0 in stage 48.0 (TID 146) in 48 ms on localhost (executor driver) (2/4)
18/02/28 13:23:37 INFO Executor: Finished task 1.0 in stage 48.0 (TID 145). 1968 bytes result sent to driver
18/02/28 13:23:37 INFO TaskSetManager: Finished task 1.0 in stage 48.0 (TID 145) in 50 ms on localhost (executor driver) (3/4)
18/02/28 13:23:37 INFO Executor: Finished task 0.0 in stage 48.0 (TID 144). 1968 bytes result sent to driver
18/02/28 13:23:37 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 144) in 54 ms on localhost (executor driver) (4/4)
18/02/28 13:23:37 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
18/02/28 13:23:37 INFO DAGScheduler: ShuffleMapStage 48 (collect at utils.scala:211) finished in 0.054 s
18/02/28 13:23:37 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:23:37 INFO DAGScheduler: running: Set()
18/02/28 13:23:37 INFO DAGScheduler: waiting: Set(ResultStage 49)
18/02/28 13:23:37 INFO DAGScheduler: failed: Set()
18/02/28 13:23:37 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[163] at collect at utils.scala:211), which has no missing parents
18/02/28 13:23:37 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 17.6 KB, free 332.6 MB)
18/02/28 13:23:37 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 8.2 KB, free 332.6 MB)
18/02/28 13:23:37 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:60941 (size: 8.2 KB, free: 337.4 MB)
18/02/28 13:23:37 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1006
18/02/28 13:23:37 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 49 (MapPartitionsRDD[163] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:23:37 INFO TaskSchedulerImpl: Adding task set 49.0 with 4 tasks
18/02/28 13:23:37 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 148, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:23:37 INFO TaskSetManager: Starting task 1.0 in stage 49.0 (TID 149, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 13:23:37 INFO TaskSetManager: Starting task 2.0 in stage 49.0 (TID 150, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 13:23:37 INFO TaskSetManager: Starting task 3.0 in stage 49.0 (TID 151, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 13:23:37 INFO Executor: Running task 1.0 in stage 49.0 (TID 149)
18/02/28 13:23:37 INFO Executor: Running task 0.0 in stage 49.0 (TID 148)
18/02/28 13:23:37 INFO Executor: Running task 2.0 in stage 49.0 (TID 150)
18/02/28 13:23:37 INFO Executor: Running task 3.0 in stage 49.0 (TID 151)
18/02/28 13:23:37 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 13:23:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:23:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 13:23:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:23:37 INFO Executor: Finished task 1.0 in stage 49.0 (TID 149). 2220 bytes result sent to driver
18/02/28 13:23:37 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:23:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:23:37 INFO Executor: Finished task 0.0 in stage 49.0 (TID 148). 2238 bytes result sent to driver
18/02/28 13:23:37 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 13:23:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:23:37 INFO TaskSetManager: Finished task 1.0 in stage 49.0 (TID 149) in 7 ms on localhost (executor driver) (1/4)
18/02/28 13:23:37 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 148) in 8 ms on localhost (executor driver) (2/4)
18/02/28 13:23:37 INFO Executor: Finished task 2.0 in stage 49.0 (TID 150). 2238 bytes result sent to driver
18/02/28 13:23:37 INFO TaskSetManager: Finished task 2.0 in stage 49.0 (TID 150) in 10 ms on localhost (executor driver) (3/4)
18/02/28 13:23:37 INFO Executor: Finished task 3.0 in stage 49.0 (TID 151). 2254 bytes result sent to driver
18/02/28 13:23:37 INFO TaskSetManager: Finished task 3.0 in stage 49.0 (TID 151) in 11 ms on localhost (executor driver) (4/4)
18/02/28 13:23:37 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
18/02/28 13:23:37 INFO DAGScheduler: ResultStage 49 (collect at utils.scala:211) finished in 0.011 s
18/02/28 13:23:37 INFO DAGScheduler: Job 26 finished: collect at utils.scala:211, took 0.080069 s
18/02/28 13:23:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:23:55 INFO SparkSqlParser: Parsing command: SELECT `carrier`, count(*) AS `n()`
FROM `cached_flights`
GROUP BY `carrier`
18/02/28 13:23:55 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:23:55 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:23:55 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:23:55 INFO DAGScheduler: Registering RDD 166 (collect at utils.scala:211)
18/02/28 13:23:55 INFO DAGScheduler: Got job 27 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:23:55 INFO DAGScheduler: Final stage: ResultStage 51 (collect at utils.scala:211)
18/02/28 13:23:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)
18/02/28 13:23:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 50)
18/02/28 13:23:55 INFO DAGScheduler: Submitting ShuffleMapStage 50 (MapPartitionsRDD[166] at collect at utils.scala:211), which has no missing parents
18/02/28 13:23:55 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 35.1 KB, free 332.6 MB)
18/02/28 13:23:55 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 16.0 KB, free 332.6 MB)
18/02/28 13:23:55 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:60941 (size: 16.0 KB, free: 337.4 MB)
18/02/28 13:23:55 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1006
18/02/28 13:23:55 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[166] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:23:55 INFO TaskSchedulerImpl: Adding task set 50.0 with 4 tasks
18/02/28 13:23:55 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 152, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:23:55 INFO TaskSetManager: Starting task 1.0 in stage 50.0 (TID 153, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:23:55 INFO TaskSetManager: Starting task 2.0 in stage 50.0 (TID 154, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:23:55 INFO TaskSetManager: Starting task 3.0 in stage 50.0 (TID 155, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:23:55 INFO Executor: Running task 0.0 in stage 50.0 (TID 152)
18/02/28 13:23:55 INFO Executor: Running task 1.0 in stage 50.0 (TID 153)
18/02/28 13:23:55 INFO Executor: Running task 2.0 in stage 50.0 (TID 154)
18/02/28 13:23:55 INFO BlockManager: Found block rdd_133_0 locally
18/02/28 13:23:55 INFO BlockManager: Found block rdd_133_1 locally
18/02/28 13:23:55 INFO Executor: Running task 3.0 in stage 50.0 (TID 155)
18/02/28 13:23:55 INFO BlockManager: Found block rdd_133_3 locally
18/02/28 13:23:55 INFO BlockManager: Found block rdd_133_2 locally
18/02/28 13:23:56 INFO Executor: Finished task 3.0 in stage 50.0 (TID 155). 1968 bytes result sent to driver
18/02/28 13:23:56 INFO TaskSetManager: Finished task 3.0 in stage 50.0 (TID 155) in 104 ms on localhost (executor driver) (1/4)
18/02/28 13:23:56 INFO Executor: Finished task 1.0 in stage 50.0 (TID 153). 1968 bytes result sent to driver
18/02/28 13:23:56 INFO TaskSetManager: Finished task 1.0 in stage 50.0 (TID 153) in 105 ms on localhost (executor driver) (2/4)
18/02/28 13:23:56 INFO Executor: Finished task 0.0 in stage 50.0 (TID 152). 1968 bytes result sent to driver
18/02/28 13:23:56 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 152) in 111 ms on localhost (executor driver) (3/4)
18/02/28 13:23:56 INFO Executor: Finished task 2.0 in stage 50.0 (TID 154). 2011 bytes result sent to driver
18/02/28 13:23:56 INFO TaskSetManager: Finished task 2.0 in stage 50.0 (TID 154) in 112 ms on localhost (executor driver) (4/4)
18/02/28 13:23:56 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
18/02/28 13:23:56 INFO DAGScheduler: ShuffleMapStage 50 (collect at utils.scala:211) finished in 0.113 s
18/02/28 13:23:56 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:23:56 INFO DAGScheduler: running: Set()
18/02/28 13:23:56 INFO DAGScheduler: waiting: Set(ResultStage 51)
18/02/28 13:23:56 INFO DAGScheduler: failed: Set()
18/02/28 13:23:56 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[169] at collect at utils.scala:211), which has no missing parents
18/02/28 13:23:56 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 17.6 KB, free 332.5 MB)
18/02/28 13:23:56 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 8.2 KB, free 332.5 MB)
18/02/28 13:23:56 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:60941 (size: 8.2 KB, free: 337.4 MB)
18/02/28 13:23:56 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1006
18/02/28 13:23:56 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 51 (MapPartitionsRDD[169] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:23:56 INFO TaskSchedulerImpl: Adding task set 51.0 with 4 tasks
18/02/28 13:23:56 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 156, localhost, executor driver, partition 0, PROCESS_LOCAL, 4726 bytes)
18/02/28 13:23:56 INFO TaskSetManager: Starting task 1.0 in stage 51.0 (TID 157, localhost, executor driver, partition 1, PROCESS_LOCAL, 4726 bytes)
18/02/28 13:23:56 INFO TaskSetManager: Starting task 3.0 in stage 51.0 (TID 158, localhost, executor driver, partition 3, PROCESS_LOCAL, 4726 bytes)
18/02/28 13:23:56 INFO TaskSetManager: Starting task 2.0 in stage 51.0 (TID 159, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 13:23:56 INFO Executor: Running task 0.0 in stage 51.0 (TID 156)
18/02/28 13:23:56 INFO Executor: Running task 1.0 in stage 51.0 (TID 157)
18/02/28 13:23:56 INFO Executor: Running task 3.0 in stage 51.0 (TID 158)
18/02/28 13:23:56 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 13:23:56 INFO Executor: Running task 2.0 in stage 51.0 (TID 159)
18/02/28 13:23:56 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 13:23:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:23:56 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 13:23:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:23:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:23:56 INFO Executor: Finished task 3.0 in stage 51.0 (TID 158). 2201 bytes result sent to driver
18/02/28 13:23:56 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:23:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:23:56 INFO Executor: Finished task 0.0 in stage 51.0 (TID 156). 2201 bytes result sent to driver
18/02/28 13:23:56 INFO Executor: Finished task 1.0 in stage 51.0 (TID 157). 2201 bytes result sent to driver
18/02/28 13:23:56 INFO TaskSetManager: Finished task 3.0 in stage 51.0 (TID 158) in 4 ms on localhost (executor driver) (1/4)
18/02/28 13:23:56 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 156) in 5 ms on localhost (executor driver) (2/4)
18/02/28 13:23:56 INFO TaskSetManager: Finished task 1.0 in stage 51.0 (TID 157) in 5 ms on localhost (executor driver) (3/4)
18/02/28 13:23:56 INFO Executor: Finished task 2.0 in stage 51.0 (TID 159). 2219 bytes result sent to driver
18/02/28 13:23:56 INFO TaskSetManager: Finished task 2.0 in stage 51.0 (TID 159) in 7 ms on localhost (executor driver) (4/4)
18/02/28 13:23:56 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
18/02/28 13:23:56 INFO DAGScheduler: ResultStage 51 (collect at utils.scala:211) finished in 0.007 s
18/02/28 13:23:56 INFO DAGScheduler: Job 27 finished: collect at utils.scala:211, took 0.129010 s
18/02/28 13:25:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:25:24 INFO SparkSqlParser: Parsing command: SELECT `month`, `carrier`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`
FROM (SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`carrier` AS DOUBLE) AS `carrier`, CAST(`dep_time` AS DOUBLE) AS `dep_time`, CAST(`arr_time` AS DOUBLE) AS `arr_time`, CAST(`arr_delay` AS DOUBLE) AS `arr_delay`, CAST(`dep_delay` AS DOUBLE) AS `dep_delay`, CAST(`distance` AS DOUBLE) AS `distance`
FROM (SELECT `month`, `carrier`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`
FROM `spark_flights`) `cnrembnsug`) `ckvyrggzvr`
18/02/28 13:25:24 INFO SparkSqlParser: Parsing command: cached_flights
18/02/28 13:25:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:25:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights` AS `zzz67`
WHERE (0 = 1)
18/02/28 13:25:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:25:24 INFO SparkSqlParser: Parsing command: CACHE TABLE `cached_flights`
18/02/28 13:25:24 INFO SparkSqlParser: Parsing command: `cached_flights`
18/02/28 13:25:24 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 13:25:24 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 13:25:24 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dep_time: string, dep_delay: string, arr_time: string, arr_delay: string ... 5 more fields>
18/02/28 13:25:24 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 13:25:24 INFO CodeGenerator: Code generated in 8.683896 ms
18/02/28 13:25:24 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 282.5 KB, free 332.3 MB)
18/02/28 13:25:24 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 24.1 KB, free 332.2 MB)
18/02/28 13:25:24 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:60941 (size: 24.1 KB, free: 337.4 MB)
18/02/28 13:25:24 INFO SparkContext: Created broadcast 68 from sql at <unknown>:0
18/02/28 13:25:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21019222 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 13:25:24 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 13:25:24 INFO DAGScheduler: Registering RDD 175 (sql at <unknown>:0)
18/02/28 13:25:24 INFO DAGScheduler: Got job 28 (sql at <unknown>:0) with 1 output partitions
18/02/28 13:25:24 INFO DAGScheduler: Final stage: ResultStage 53 (sql at <unknown>:0)
18/02/28 13:25:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)
18/02/28 13:25:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 52)
18/02/28 13:25:24 INFO DAGScheduler: Submitting ShuffleMapStage 52 (MapPartitionsRDD[175] at sql at <unknown>:0), which has no missing parents
18/02/28 13:25:24 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 25.5 KB, free 332.2 MB)
18/02/28 13:25:24 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 11.4 KB, free 332.2 MB)
18/02/28 13:25:24 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:60941 (size: 11.4 KB, free: 337.4 MB)
18/02/28 13:25:24 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1006
18/02/28 13:25:24 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 52 (MapPartitionsRDD[175] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:25:24 INFO TaskSchedulerImpl: Adding task set 52.0 with 4 tasks
18/02/28 13:25:24 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 160, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:25:24 INFO TaskSetManager: Starting task 1.0 in stage 52.0 (TID 161, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:25:24 INFO TaskSetManager: Starting task 2.0 in stage 52.0 (TID 162, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:25:24 INFO TaskSetManager: Starting task 3.0 in stage 52.0 (TID 163, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:25:24 INFO Executor: Running task 0.0 in stage 52.0 (TID 160)
18/02/28 13:25:24 INFO Executor: Running task 2.0 in stage 52.0 (TID 162)
18/02/28 13:25:24 INFO Executor: Running task 3.0 in stage 52.0 (TID 163)
18/02/28 13:25:24 INFO Executor: Running task 1.0 in stage 52.0 (TID 161)
18/02/28 13:25:24 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_4.csv, range: 0-2830543, partition values: [empty row]
18/02/28 13:25:24 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_3.csv, range: 0-2881793, partition values: [empty row]
18/02/28 13:25:24 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_11.csv, range: 0-2757037, partition values: [empty row]
18/02/28 13:25:24 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_7.csv, range: 0-2938867, partition values: [empty row]
18/02/28 13:25:24 INFO CodeGenerator: Code generated in 8.370067 ms
18/02/28 13:25:25 INFO ContextCleaner: Cleaned accumulator 1584
18/02/28 13:25:25 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 127.0.0.1:60941 in memory (size: 16.0 KB, free: 337.4 MB)
18/02/28 13:25:25 INFO ContextCleaner: Cleaned accumulator 1651
18/02/28 13:25:25 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:60941 in memory (size: 16.0 KB, free: 337.4 MB)
18/02/28 13:25:25 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 127.0.0.1:60941 in memory (size: 8.2 KB, free: 337.4 MB)
18/02/28 13:25:25 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 127.0.0.1:60941 in memory (size: 8.2 KB, free: 337.4 MB)
18/02/28 13:25:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_1.csv, range: 0-2697256, partition values: [empty row]
18/02/28 13:25:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_8.csv, range: 0-2932019, partition values: [empty row]
18/02/28 13:25:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_5.csv, range: 0-2880181, partition values: [empty row]
18/02/28 13:25:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_6.csv, range: 0-2820227, partition values: [empty row]
18/02/28 13:25:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_2.csv, range: 0-2487144, partition values: [empty row]
18/02/28 13:25:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_9.csv, range: 0-2763076, partition values: [empty row]
18/02/28 13:25:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_10.csv, range: 0-2920629, partition values: [empty row]
18/02/28 13:25:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_12.csv, range: 0-2836468, partition values: [empty row]
18/02/28 13:25:26 INFO MemoryStore: Block rdd_172_3 stored as values in memory (estimated size 3.9 MB, free 328.4 MB)
18/02/28 13:25:26 INFO BlockManagerInfo: Added rdd_172_3 in memory on 127.0.0.1:60941 (size: 3.9 MB, free: 333.5 MB)
18/02/28 13:25:26 INFO Executor: Finished task 3.0 in stage 52.0 (TID 163). 2504 bytes result sent to driver
18/02/28 13:25:26 INFO TaskSetManager: Finished task 3.0 in stage 52.0 (TID 163) in 1409 ms on localhost (executor driver) (1/4)
18/02/28 13:25:26 INFO MemoryStore: Block rdd_172_2 stored as values in memory (estimated size 4.1 MB, free 324.3 MB)
18/02/28 13:25:26 INFO BlockManagerInfo: Added rdd_172_2 in memory on 127.0.0.1:60941 (size: 4.1 MB, free: 329.3 MB)
18/02/28 13:25:26 INFO Executor: Finished task 2.0 in stage 52.0 (TID 162). 2461 bytes result sent to driver
18/02/28 13:25:26 INFO TaskSetManager: Finished task 2.0 in stage 52.0 (TID 162) in 1448 ms on localhost (executor driver) (2/4)
18/02/28 13:25:26 INFO MemoryStore: Block rdd_172_0 stored as values in memory (estimated size 4.3 MB, free 320.0 MB)
18/02/28 13:25:26 INFO BlockManagerInfo: Added rdd_172_0 in memory on 127.0.0.1:60941 (size: 4.3 MB, free: 325.0 MB)
18/02/28 13:25:26 INFO MemoryStore: Block rdd_172_1 stored as values in memory (estimated size 4.2 MB, free 315.7 MB)
18/02/28 13:25:26 INFO BlockManagerInfo: Added rdd_172_1 in memory on 127.0.0.1:60941 (size: 4.2 MB, free: 320.8 MB)
18/02/28 13:25:26 INFO Executor: Finished task 0.0 in stage 52.0 (TID 160). 2461 bytes result sent to driver
18/02/28 13:25:26 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 160) in 1498 ms on localhost (executor driver) (3/4)
18/02/28 13:25:26 INFO Executor: Finished task 1.0 in stage 52.0 (TID 161). 2461 bytes result sent to driver
18/02/28 13:25:26 INFO TaskSetManager: Finished task 1.0 in stage 52.0 (TID 161) in 1504 ms on localhost (executor driver) (4/4)
18/02/28 13:25:26 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
18/02/28 13:25:26 INFO DAGScheduler: ShuffleMapStage 52 (sql at <unknown>:0) finished in 1.504 s
18/02/28 13:25:26 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:25:26 INFO DAGScheduler: running: Set()
18/02/28 13:25:26 INFO DAGScheduler: waiting: Set(ResultStage 53)
18/02/28 13:25:26 INFO DAGScheduler: failed: Set()
18/02/28 13:25:26 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[178] at sql at <unknown>:0), which has no missing parents
18/02/28 13:25:26 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 7.0 KB, free 315.7 MB)
18/02/28 13:25:26 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 3.7 KB, free 315.7 MB)
18/02/28 13:25:26 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 320.8 MB)
18/02/28 13:25:26 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1006
18/02/28 13:25:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[178] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 13:25:26 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
18/02/28 13:25:26 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 164, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:25:26 INFO Executor: Running task 0.0 in stage 53.0 (TID 164)
18/02/28 13:25:26 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:25:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:25:26 INFO Executor: Finished task 0.0 in stage 53.0 (TID 164). 1452 bytes result sent to driver
18/02/28 13:25:26 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 164) in 4 ms on localhost (executor driver) (1/1)
18/02/28 13:25:26 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
18/02/28 13:25:26 INFO DAGScheduler: ResultStage 53 (sql at <unknown>:0) finished in 0.004 s
18/02/28 13:25:26 INFO DAGScheduler: Job 28 finished: sql at <unknown>:0, took 1.516929 s
18/02/28 13:25:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:25:26 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `cached_flights`
18/02/28 13:25:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:26 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:25:26 INFO DAGScheduler: Registering RDD 181 (collect at utils.scala:211)
18/02/28 13:25:26 INFO DAGScheduler: Got job 29 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:25:26 INFO DAGScheduler: Final stage: ResultStage 55 (collect at utils.scala:211)
18/02/28 13:25:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 54)
18/02/28 13:25:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 54)
18/02/28 13:25:26 INFO DAGScheduler: Submitting ShuffleMapStage 54 (MapPartitionsRDD[181] at collect at utils.scala:211), which has no missing parents
18/02/28 13:25:26 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 25.5 KB, free 315.7 MB)
18/02/28 13:25:26 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 11.5 KB, free 315.7 MB)
18/02/28 13:25:26 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 127.0.0.1:60941 (size: 11.5 KB, free: 320.8 MB)
18/02/28 13:25:26 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1006
18/02/28 13:25:26 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[181] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:25:26 INFO TaskSchedulerImpl: Adding task set 54.0 with 4 tasks
18/02/28 13:25:26 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 165, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:25:26 INFO TaskSetManager: Starting task 1.0 in stage 54.0 (TID 166, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:25:26 INFO TaskSetManager: Starting task 2.0 in stage 54.0 (TID 167, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:25:26 INFO TaskSetManager: Starting task 3.0 in stage 54.0 (TID 168, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:25:26 INFO Executor: Running task 0.0 in stage 54.0 (TID 165)
18/02/28 13:25:26 INFO Executor: Running task 1.0 in stage 54.0 (TID 166)
18/02/28 13:25:26 INFO Executor: Running task 2.0 in stage 54.0 (TID 167)
18/02/28 13:25:26 INFO BlockManager: Found block rdd_172_1 locally
18/02/28 13:25:26 INFO BlockManager: Found block rdd_172_2 locally
18/02/28 13:25:26 INFO Executor: Running task 3.0 in stage 54.0 (TID 168)
18/02/28 13:25:26 INFO BlockManager: Found block rdd_172_0 locally
18/02/28 13:25:26 INFO BlockManager: Found block rdd_172_3 locally
18/02/28 13:25:26 INFO Executor: Finished task 0.0 in stage 54.0 (TID 165). 1694 bytes result sent to driver
18/02/28 13:25:26 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 165) in 16 ms on localhost (executor driver) (1/4)
18/02/28 13:25:26 INFO Executor: Finished task 3.0 in stage 54.0 (TID 168). 1694 bytes result sent to driver
18/02/28 13:25:26 INFO TaskSetManager: Finished task 3.0 in stage 54.0 (TID 168) in 18 ms on localhost (executor driver) (2/4)
18/02/28 13:25:26 INFO Executor: Finished task 2.0 in stage 54.0 (TID 167). 1694 bytes result sent to driver
18/02/28 13:25:26 INFO TaskSetManager: Finished task 2.0 in stage 54.0 (TID 167) in 21 ms on localhost (executor driver) (3/4)
18/02/28 13:25:26 INFO Executor: Finished task 1.0 in stage 54.0 (TID 166). 1737 bytes result sent to driver
18/02/28 13:25:26 INFO TaskSetManager: Finished task 1.0 in stage 54.0 (TID 166) in 22 ms on localhost (executor driver) (4/4)
18/02/28 13:25:26 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
18/02/28 13:25:26 INFO DAGScheduler: ShuffleMapStage 54 (collect at utils.scala:211) finished in 0.022 s
18/02/28 13:25:26 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:25:26 INFO DAGScheduler: running: Set()
18/02/28 13:25:26 INFO DAGScheduler: waiting: Set(ResultStage 55)
18/02/28 13:25:26 INFO DAGScheduler: failed: Set()
18/02/28 13:25:26 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[184] at collect at utils.scala:211), which has no missing parents
18/02/28 13:25:26 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 7.0 KB, free 315.7 MB)
18/02/28 13:25:26 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 3.7 KB, free 315.7 MB)
18/02/28 13:25:26 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 320.8 MB)
18/02/28 13:25:26 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1006
18/02/28 13:25:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[184] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:25:26 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks
18/02/28 13:25:26 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 169, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:25:26 INFO Executor: Running task 0.0 in stage 55.0 (TID 169)
18/02/28 13:25:26 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:25:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:25:26 INFO Executor: Finished task 0.0 in stage 55.0 (TID 169). 1495 bytes result sent to driver
18/02/28 13:25:26 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 169) in 4 ms on localhost (executor driver) (1/1)
18/02/28 13:25:26 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
18/02/28 13:25:26 INFO DAGScheduler: ResultStage 55 (collect at utils.scala:211) finished in 0.004 s
18/02/28 13:25:26 INFO DAGScheduler: Job 29 finished: collect at utils.scala:211, took 0.035653 s
18/02/28 13:25:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:25:26 INFO SparkSqlParser: Parsing command: SHOW TABLES LIKE"cached_flights"
18/02/28 13:25:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:26 INFO HiveMetaStore: 0: get_tables: db=default pat=cached_flights
18/02/28 13:25:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=cached_flights	
18/02/28 13:25:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:25:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights` AS `zzz68`
WHERE (0 = 1)
18/02/28 13:25:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:25:26 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 13:25:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:26 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 13:25:26 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 13:25:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:25:28 INFO SparkSqlParser: Parsing command: SELECT `month`, count(*) AS `n()`
FROM `cached_flights`
GROUP BY `month`
18/02/28 13:25:28 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:28 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:28 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:25:28 INFO DAGScheduler: Registering RDD 187 (collect at utils.scala:211)
18/02/28 13:25:28 INFO DAGScheduler: Got job 30 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:25:28 INFO DAGScheduler: Final stage: ResultStage 57 (collect at utils.scala:211)
18/02/28 13:25:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)
18/02/28 13:25:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 56)
18/02/28 13:25:28 INFO DAGScheduler: Submitting ShuffleMapStage 56 (MapPartitionsRDD[187] at collect at utils.scala:211), which has no missing parents
18/02/28 13:25:28 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 36.1 KB, free 315.7 MB)
18/02/28 13:25:28 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 16.3 KB, free 315.6 MB)
18/02/28 13:25:28 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 127.0.0.1:60941 (size: 16.3 KB, free: 320.8 MB)
18/02/28 13:25:28 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1006
18/02/28 13:25:28 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 56 (MapPartitionsRDD[187] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:25:28 INFO TaskSchedulerImpl: Adding task set 56.0 with 4 tasks
18/02/28 13:25:28 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 170, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:25:28 INFO TaskSetManager: Starting task 1.0 in stage 56.0 (TID 171, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:25:28 INFO TaskSetManager: Starting task 2.0 in stage 56.0 (TID 172, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:25:28 INFO TaskSetManager: Starting task 3.0 in stage 56.0 (TID 173, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:25:28 INFO Executor: Running task 2.0 in stage 56.0 (TID 172)
18/02/28 13:25:28 INFO Executor: Running task 1.0 in stage 56.0 (TID 171)
18/02/28 13:25:28 INFO Executor: Running task 3.0 in stage 56.0 (TID 173)
18/02/28 13:25:28 INFO Executor: Running task 0.0 in stage 56.0 (TID 170)
18/02/28 13:25:28 INFO BlockManager: Found block rdd_172_1 locally
18/02/28 13:25:28 INFO BlockManager: Found block rdd_172_0 locally
18/02/28 13:25:28 INFO BlockManager: Found block rdd_172_2 locally
18/02/28 13:25:28 INFO BlockManager: Found block rdd_172_3 locally
18/02/28 13:25:28 INFO Executor: Finished task 3.0 in stage 56.0 (TID 173). 1968 bytes result sent to driver
18/02/28 13:25:28 INFO TaskSetManager: Finished task 3.0 in stage 56.0 (TID 173) in 48 ms on localhost (executor driver) (1/4)
18/02/28 13:25:28 INFO Executor: Finished task 1.0 in stage 56.0 (TID 171). 1925 bytes result sent to driver
18/02/28 13:25:28 INFO TaskSetManager: Finished task 1.0 in stage 56.0 (TID 171) in 57 ms on localhost (executor driver) (2/4)
18/02/28 13:25:28 INFO Executor: Finished task 2.0 in stage 56.0 (TID 172). 1968 bytes result sent to driver
18/02/28 13:25:28 INFO TaskSetManager: Finished task 2.0 in stage 56.0 (TID 172) in 59 ms on localhost (executor driver) (3/4)
18/02/28 13:25:28 INFO Executor: Finished task 0.0 in stage 56.0 (TID 170). 1968 bytes result sent to driver
18/02/28 13:25:28 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 170) in 61 ms on localhost (executor driver) (4/4)
18/02/28 13:25:28 INFO DAGScheduler: ShuffleMapStage 56 (collect at utils.scala:211) finished in 0.062 s
18/02/28 13:25:28 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:25:28 INFO DAGScheduler: running: Set()
18/02/28 13:25:28 INFO DAGScheduler: waiting: Set(ResultStage 57)
18/02/28 13:25:28 INFO DAGScheduler: failed: Set()
18/02/28 13:25:28 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[190] at collect at utils.scala:211), which has no missing parents
18/02/28 13:25:28 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 17.6 KB, free 315.6 MB)
18/02/28 13:25:28 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 8.2 KB, free 315.6 MB)
18/02/28 13:25:28 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
18/02/28 13:25:28 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 127.0.0.1:60941 (size: 8.2 KB, free: 320.8 MB)
18/02/28 13:25:28 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1006
18/02/28 13:25:28 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 57 (MapPartitionsRDD[190] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:25:28 INFO TaskSchedulerImpl: Adding task set 57.0 with 4 tasks
18/02/28 13:25:28 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 174, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:25:28 INFO TaskSetManager: Starting task 1.0 in stage 57.0 (TID 175, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 13:25:28 INFO TaskSetManager: Starting task 2.0 in stage 57.0 (TID 176, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 13:25:28 INFO TaskSetManager: Starting task 3.0 in stage 57.0 (TID 177, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 13:25:28 INFO Executor: Running task 0.0 in stage 57.0 (TID 174)
18/02/28 13:25:28 INFO Executor: Running task 1.0 in stage 57.0 (TID 175)
18/02/28 13:25:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 13:25:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:25:28 INFO Executor: Finished task 1.0 in stage 57.0 (TID 175). 2220 bytes result sent to driver
18/02/28 13:25:28 INFO Executor: Running task 2.0 in stage 57.0 (TID 176)
18/02/28 13:25:28 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 13:25:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:25:28 INFO Executor: Running task 3.0 in stage 57.0 (TID 177)
18/02/28 13:25:28 INFO Executor: Finished task 0.0 in stage 57.0 (TID 174). 2238 bytes result sent to driver
18/02/28 13:25:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:25:28 INFO TaskSetManager: Finished task 1.0 in stage 57.0 (TID 175) in 17 ms on localhost (executor driver) (1/4)
18/02/28 13:25:28 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 13:25:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:25:28 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 174) in 18 ms on localhost (executor driver) (2/4)
18/02/28 13:25:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:25:28 INFO Executor: Finished task 3.0 in stage 57.0 (TID 177). 2297 bytes result sent to driver
18/02/28 13:25:28 INFO TaskSetManager: Finished task 3.0 in stage 57.0 (TID 177) in 23 ms on localhost (executor driver) (3/4)
18/02/28 13:25:28 INFO Executor: Finished task 2.0 in stage 57.0 (TID 176). 2281 bytes result sent to driver
18/02/28 13:25:28 INFO TaskSetManager: Finished task 2.0 in stage 57.0 (TID 176) in 25 ms on localhost (executor driver) (4/4)
18/02/28 13:25:28 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
18/02/28 13:25:28 INFO DAGScheduler: ResultStage 57 (collect at utils.scala:211) finished in 0.026 s
18/02/28 13:25:28 INFO DAGScheduler: Job 30 finished: collect at utils.scala:211, took 0.095610 s
18/02/28 13:25:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:25:37 INFO SparkSqlParser: Parsing command: SELECT `x`, `y`, count(*) AS `fillname`
FROM (SELECT `month`, `carrier`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`, (max(`dep_time`) OVER () - min(`dep_time`) OVER () / 100.0 * CASE WHEN (CAST(FLOOR((`dep_time` - min(`dep_time`) OVER ()) / max(`dep_time`) OVER () - min(`dep_time`) OVER () / 100.0) AS INT) = 100.0) THEN (CAST(FLOOR((`dep_time` - min(`dep_time`) OVER ()) / max(`dep_time`) OVER () - min(`dep_time`) OVER () / 100.0) AS INT) - 1.0) WHEN NOT(CAST(FLOOR((`dep_time` - min(`dep_time`) OVER ()) / max(`dep_time`) OVER () - min(`dep_time`) OVER () / 100.0) AS INT) = 100.0) THEN (CAST(FLOOR((`dep_time` - min(`dep_time`) OVER ()) / max(`dep_time`) OVER () - min(`dep_time`) OVER () / 100.0) AS INT)) END) + min(`dep_time`) OVER () AS `x`, (max(`arr_time`) OVER () - min(`arr_time`) OVER () / 100.0 * CASE WHEN (CAST(FLOOR((`arr_time` - min(`arr_time`) OVER ()) / max(`arr_time`) OVER () - min(`arr_time`) OVER () / 100.0) AS INT) = 100.0) THEN (CAST(FLOOR((`arr_time` - min(`arr_time`) OVER ()) / max(`arr_time`) OVER () - min(`arr_time`) OVER () / 100.0) AS INT) - 1.0) WHEN NOT(CAST(FLOOR((`arr_time` - min(`arr_time`) OVER ()) / max(`arr_time`) OVER () - min(`arr_time`) OVER () / 100.0) AS INT) = 100.0) THEN (CAST(FLOOR((`arr_time` - min(`arr_time`) OVER ()) / max(`arr_time`) OVER () - min(`arr_time`) OVER () / 100.0) AS INT)) END) + min(`arr_time`) OVER () AS `y`
FROM `cached_flights`) `dkghpidyvu`
GROUP BY `x`, `y`
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:25:37 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:25:37 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
18/02/28 13:25:38 INFO CodeGenerator: Code generated in 42.123614 ms
18/02/28 13:25:38 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:25:38 INFO DAGScheduler: Registering RDD 192 (collect at utils.scala:211)
18/02/28 13:25:38 INFO DAGScheduler: Got job 31 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:25:38 INFO DAGScheduler: Final stage: ResultStage 59 (collect at utils.scala:211)
18/02/28 13:25:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 58)
18/02/28 13:25:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 58)
18/02/28 13:25:38 INFO DAGScheduler: Submitting ShuffleMapStage 58 (MapPartitionsRDD[192] at collect at utils.scala:211), which has no missing parents
18/02/28 13:25:38 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 22.8 KB, free 315.6 MB)
18/02/28 13:25:38 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 10.7 KB, free 315.6 MB)
18/02/28 13:25:38 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 127.0.0.1:60941 (size: 10.7 KB, free: 320.7 MB)
18/02/28 13:25:38 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1006
18/02/28 13:25:38 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 58 (MapPartitionsRDD[192] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:25:38 INFO TaskSchedulerImpl: Adding task set 58.0 with 4 tasks
18/02/28 13:25:38 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 178, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:25:38 INFO TaskSetManager: Starting task 1.0 in stage 58.0 (TID 179, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:25:38 INFO TaskSetManager: Starting task 2.0 in stage 58.0 (TID 180, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:25:38 INFO TaskSetManager: Starting task 3.0 in stage 58.0 (TID 181, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:25:38 INFO Executor: Running task 0.0 in stage 58.0 (TID 178)
18/02/28 13:25:38 INFO BlockManager: Found block rdd_172_0 locally
18/02/28 13:25:38 INFO Executor: Running task 1.0 in stage 58.0 (TID 179)
18/02/28 13:25:38 INFO Executor: Running task 2.0 in stage 58.0 (TID 180)
18/02/28 13:25:38 INFO BlockManager: Found block rdd_172_1 locally
18/02/28 13:25:38 INFO Executor: Running task 3.0 in stage 58.0 (TID 181)
18/02/28 13:25:38 INFO BlockManager: Found block rdd_172_3 locally
18/02/28 13:25:38 INFO BlockManager: Found block rdd_172_2 locally
18/02/28 13:25:38 INFO CodeGenerator: Code generated in 12.583839 ms
18/02/28 13:25:38 INFO Executor: Finished task 3.0 in stage 58.0 (TID 181). 1489 bytes result sent to driver
18/02/28 13:25:38 INFO TaskSetManager: Finished task 3.0 in stage 58.0 (TID 181) in 86 ms on localhost (executor driver) (1/4)
18/02/28 13:25:38 INFO Executor: Finished task 2.0 in stage 58.0 (TID 180). 1489 bytes result sent to driver
18/02/28 13:25:38 INFO TaskSetManager: Finished task 2.0 in stage 58.0 (TID 180) in 91 ms on localhost (executor driver) (2/4)
18/02/28 13:25:38 INFO Executor: Finished task 0.0 in stage 58.0 (TID 178). 1489 bytes result sent to driver
18/02/28 13:25:38 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 178) in 95 ms on localhost (executor driver) (3/4)
18/02/28 13:25:38 INFO Executor: Finished task 1.0 in stage 58.0 (TID 179). 1489 bytes result sent to driver
18/02/28 13:25:38 INFO TaskSetManager: Finished task 1.0 in stage 58.0 (TID 179) in 97 ms on localhost (executor driver) (4/4)
18/02/28 13:25:38 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
18/02/28 13:25:38 INFO DAGScheduler: ShuffleMapStage 58 (collect at utils.scala:211) finished in 0.097 s
18/02/28 13:25:38 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:25:38 INFO DAGScheduler: running: Set()
18/02/28 13:25:38 INFO DAGScheduler: waiting: Set(ResultStage 59)
18/02/28 13:25:38 INFO DAGScheduler: failed: Set()
18/02/28 13:25:38 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[196] at collect at utils.scala:211), which has no missing parents
18/02/28 13:25:38 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 71.3 KB, free 315.5 MB)
18/02/28 13:25:38 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 24.7 KB, free 315.5 MB)
18/02/28 13:25:38 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 127.0.0.1:60941 (size: 24.7 KB, free: 320.7 MB)
18/02/28 13:25:38 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1006
18/02/28 13:25:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[196] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:25:38 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
18/02/28 13:25:38 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 182, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:25:38 INFO Executor: Running task 0.0 in stage 59.0 (TID 182)
18/02/28 13:25:38 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:25:38 INFO CodeGenerator: Code generated in 22.117894 ms
18/02/28 13:25:38 INFO CodeGenerator: Code generated in 13.902979 ms
18/02/28 13:25:38 INFO CodeGenerator: Code generated in 27.506939 ms
18/02/28 13:25:38 INFO CodeGenerator: Code generated in 10.164182 ms
18/02/28 13:25:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (0  time so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (1  time so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (2  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (3  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (4  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (5  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (6  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (7  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (8  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (9  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (10  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (11  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (12  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (13  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (14  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (15  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (16  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (17  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (18  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (19  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (20  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (21  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (22  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (23  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (24  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (25  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (26  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (27  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (28  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (29  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (30  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (31  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (32  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (33  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (34  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (35  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (36  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (37  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (38  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (39  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (40  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (41  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (42  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (43  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (44  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (45  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (46  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (47  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (48  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (49  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (50  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (51  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (52  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (53  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (54  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (55  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (56  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (57  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (58  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (59  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (60  times so far)
18/02/28 13:25:38 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 127.0.0.1:60941 in memory (size: 11.5 KB, free: 320.7 MB)
18/02/28 13:25:38 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 320.7 MB)
18/02/28 13:25:38 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 127.0.0.1:60941 in memory (size: 8.2 KB, free: 320.7 MB)
18/02/28 13:25:38 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 320.7 MB)
18/02/28 13:25:38 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 127.0.0.1:60941 in memory (size: 16.3 KB, free: 320.8 MB)
18/02/28 13:25:38 INFO ContextCleaner: Cleaned accumulator 1773
18/02/28 13:25:38 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 127.0.0.1:60941 in memory (size: 10.7 KB, free: 320.8 MB)
18/02/28 13:25:38 INFO ContextCleaner: Cleaned accumulator 1712
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (61  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (62  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (63  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (64  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (65  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (66  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (67  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (68  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (69  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (70  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (71  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (72  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (73  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (74  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (75  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (76  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (77  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (78  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (79  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (80  times so far)
18/02/28 13:25:38 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:25:38 INFO UnsafeExternalSorter: Thread 161 spilling sort data of 4.1 MB to disk (81  times so far)
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1282
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1653
18/02/28 13:25:40 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 127.0.0.1:60941 in memory (size: 11.4 KB, free: 320.8 MB)
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1287
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1656
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 516
18/02/28 13:25:40 INFO ContextCleaner: Cleaned shuffle 14
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1041
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1039
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1288
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1040
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1655
18/02/28 13:25:40 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:60941 in memory (size: 13.3 KB, free: 320.8 MB)
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1661
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 514
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 523
18/02/28 13:25:40 INFO ContextCleaner: Cleaned shuffle 7
18/02/28 13:25:40 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:60941 in memory (size: 10.9 KB, free: 320.8 MB)
18/02/28 13:25:40 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:60941 in memory (size: 16.8 KB, free: 320.8 MB)
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1657
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1660
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1285
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 518
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1281
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1290
18/02/28 13:25:40 INFO ContextCleaner: Cleaned shuffle 18
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1030
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1031
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 520
18/02/28 13:25:40 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:60941 in memory (size: 13.3 KB, free: 320.8 MB)
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1286
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 519
18/02/28 13:25:40 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:60941 in memory (size: 13.5 KB, free: 320.8 MB)
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1654
18/02/28 13:25:40 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:60941 in memory (size: 31.8 KB, free: 320.9 MB)
18/02/28 13:25:40 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:60941 in memory (size: 13.3 KB, free: 320.9 MB)
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1289
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 517
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1037
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1284
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 515
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 522
18/02/28 13:25:40 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:60941 in memory (size: 12.7 KB, free: 320.9 MB)
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1280
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1652
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1036
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 513
18/02/28 13:25:40 INFO ContextCleaner: Cleaned shuffle 24
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1033
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1659
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1658
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1035
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1032
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 512
18/02/28 13:25:40 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:60941 in memory (size: 15.6 KB, free: 320.9 MB)
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1663
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1662
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 521
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1291
18/02/28 13:25:40 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:60941 in memory (size: 11.2 KB, free: 320.9 MB)
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1038
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1034
18/02/28 13:25:40 INFO ContextCleaner: Cleaned accumulator 1283
18/02/28 13:25:40 INFO Executor: Finished task 0.0 in stage 59.0 (TID 182). 2339 bytes result sent to driver
18/02/28 13:25:40 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 182) in 2275 ms on localhost (executor driver) (1/1)
18/02/28 13:25:40 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
18/02/28 13:25:40 INFO DAGScheduler: ResultStage 59 (collect at utils.scala:211) finished in 2.275 s
18/02/28 13:25:40 INFO DAGScheduler: Job 31 finished: collect at utils.scala:211, took 2.381505 s
18/02/28 13:28:06 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:28:06 INFO SparkSqlParser: Parsing command: SELECT `month`, `carrier`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`
FROM (SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`carrier` AS DOUBLE) AS `carrier`, CAST(`dep_time` AS DOUBLE) AS `dep_time`, CAST(`arr_time` AS DOUBLE) AS `arr_time`, CAST(`arr_delay` AS DOUBLE) AS `arr_delay`, CAST(`dep_delay` AS DOUBLE) AS `dep_delay`, CAST(`distance` AS DOUBLE) AS `distance`
FROM (SELECT `month`, `carrier`, `dep_time`, `arr_time`, CASE WHEN (`arr_delay` = "NA") THEN (0.0) WHEN NOT(`arr_delay` = "NA") THEN (`arrdelay`) END AS `arr_delay`, CASE WHEN (`dep_delay` = "NA") THEN (0.0) WHEN NOT(`dep_delay` = "NA") THEN (`depdelay`) END AS `dep_delay`, `distance`
FROM (SELECT `month`, `carrier`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`
FROM `spark_flights`) `ljigxxymfv`) `xjqoydfinn`) `zdqbcrdnmv`
18/02/28 13:28:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:28:13 INFO SparkSqlParser: Parsing command: SELECT `month`, `carrier`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`
FROM (SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`carrier` AS DOUBLE) AS `carrier`, CAST(`dep_time` AS DOUBLE) AS `dep_time`, CAST(`arr_time` AS DOUBLE) AS `arr_time`, CAST(`arr_delay` AS DOUBLE) AS `arr_delay`, CAST(`dep_delay` AS DOUBLE) AS `dep_delay`, CAST(`distance` AS DOUBLE) AS `distance`
FROM (SELECT `month`, `carrier`, `dep_time`, `arr_time`, CASE WHEN (`arr_delay` = "NA") THEN (0.0) WHEN NOT(`arr_delay` = "NA") THEN (`arr_delay`) END AS `arr_delay`, CASE WHEN (`dep_delay` = "NA") THEN (0.0) WHEN NOT(`dep_delay` = "NA") THEN (`dep_delay`) END AS `dep_delay`, `distance`
FROM (SELECT `month`, `carrier`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`
FROM `spark_flights`) `dtbbrmvcjv`) `rygeufjmsf`) `orcrskdujd`
18/02/28 13:28:13 INFO SparkSqlParser: Parsing command: cached_flights
18/02/28 13:28:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:28:13 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights` AS `zzz69`
WHERE (0 = 1)
18/02/28 13:28:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:28:13 INFO SparkSqlParser: Parsing command: CACHE TABLE `cached_flights`
18/02/28 13:28:13 INFO SparkSqlParser: Parsing command: `cached_flights`
18/02/28 13:28:13 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 13:28:13 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 13:28:13 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dep_time: string, dep_delay: string, arr_time: string, arr_delay: string ... 5 more fields>
18/02/28 13:28:13 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 13:28:13 INFO CodeGenerator: Code generated in 10.808413 ms
18/02/28 13:28:13 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 282.5 KB, free 315.9 MB)
18/02/28 13:28:13 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 24.1 KB, free 315.9 MB)
18/02/28 13:28:13 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 127.0.0.1:60941 (size: 24.1 KB, free: 320.9 MB)
18/02/28 13:28:13 INFO SparkContext: Created broadcast 77 from sql at <unknown>:0
18/02/28 13:28:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21019222 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 13:28:13 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 13:28:13 INFO DAGScheduler: Registering RDD 202 (sql at <unknown>:0)
18/02/28 13:28:13 INFO DAGScheduler: Got job 32 (sql at <unknown>:0) with 1 output partitions
18/02/28 13:28:13 INFO DAGScheduler: Final stage: ResultStage 61 (sql at <unknown>:0)
18/02/28 13:28:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 60)
18/02/28 13:28:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 60)
18/02/28 13:28:13 INFO DAGScheduler: Submitting ShuffleMapStage 60 (MapPartitionsRDD[202] at sql at <unknown>:0), which has no missing parents
18/02/28 13:28:13 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 27.4 KB, free 315.8 MB)
18/02/28 13:28:13 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 12.1 KB, free 315.8 MB)
18/02/28 13:28:13 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 127.0.0.1:60941 (size: 12.1 KB, free: 320.9 MB)
18/02/28 13:28:13 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1006
18/02/28 13:28:13 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[202] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:28:13 INFO TaskSchedulerImpl: Adding task set 60.0 with 4 tasks
18/02/28 13:28:13 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 183, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:28:13 INFO TaskSetManager: Starting task 1.0 in stage 60.0 (TID 184, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:28:13 INFO TaskSetManager: Starting task 2.0 in stage 60.0 (TID 185, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:28:13 INFO TaskSetManager: Starting task 3.0 in stage 60.0 (TID 186, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:28:13 INFO Executor: Running task 0.0 in stage 60.0 (TID 183)
18/02/28 13:28:13 INFO Executor: Running task 3.0 in stage 60.0 (TID 186)
18/02/28 13:28:13 INFO Executor: Running task 2.0 in stage 60.0 (TID 185)
18/02/28 13:28:13 INFO Executor: Running task 1.0 in stage 60.0 (TID 184)
18/02/28 13:28:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_7.csv, range: 0-2938867, partition values: [empty row]
18/02/28 13:28:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_11.csv, range: 0-2757037, partition values: [empty row]
18/02/28 13:28:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_4.csv, range: 0-2830543, partition values: [empty row]
18/02/28 13:28:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_3.csv, range: 0-2881793, partition values: [empty row]
18/02/28 13:28:13 INFO ContextCleaner: Cleaned accumulator 1899
18/02/28 13:28:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_1.csv, range: 0-2697256, partition values: [empty row]
18/02/28 13:28:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_6.csv, range: 0-2820227, partition values: [empty row]
18/02/28 13:28:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_5.csv, range: 0-2880181, partition values: [empty row]
18/02/28 13:28:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_8.csv, range: 0-2932019, partition values: [empty row]
18/02/28 13:28:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_2.csv, range: 0-2487144, partition values: [empty row]
18/02/28 13:28:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_12.csv, range: 0-2836468, partition values: [empty row]
18/02/28 13:28:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_10.csv, range: 0-2920629, partition values: [empty row]
18/02/28 13:28:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_9.csv, range: 0-2763076, partition values: [empty row]
18/02/28 13:28:14 INFO MemoryStore: Block rdd_199_3 stored as values in memory (estimated size 3.9 MB, free 311.9 MB)
18/02/28 13:28:14 INFO BlockManagerInfo: Added rdd_199_3 in memory on 127.0.0.1:60941 (size: 3.9 MB, free: 317.0 MB)
18/02/28 13:28:14 INFO Executor: Finished task 3.0 in stage 60.0 (TID 186). 2461 bytes result sent to driver
18/02/28 13:28:14 INFO TaskSetManager: Finished task 3.0 in stage 60.0 (TID 186) in 1322 ms on localhost (executor driver) (1/4)
18/02/28 13:28:14 INFO MemoryStore: Block rdd_199_2 stored as values in memory (estimated size 4.2 MB, free 307.7 MB)
18/02/28 13:28:14 INFO BlockManagerInfo: Added rdd_199_2 in memory on 127.0.0.1:60941 (size: 4.2 MB, free: 312.8 MB)
18/02/28 13:28:14 INFO Executor: Finished task 2.0 in stage 60.0 (TID 185). 2461 bytes result sent to driver
18/02/28 13:28:14 INFO TaskSetManager: Finished task 2.0 in stage 60.0 (TID 185) in 1422 ms on localhost (executor driver) (2/4)
18/02/28 13:28:14 INFO MemoryStore: Block rdd_199_1 stored as values in memory (estimated size 4.2 MB, free 303.5 MB)
18/02/28 13:28:14 INFO BlockManagerInfo: Added rdd_199_1 in memory on 127.0.0.1:60941 (size: 4.2 MB, free: 308.6 MB)
18/02/28 13:28:14 INFO Executor: Finished task 1.0 in stage 60.0 (TID 184). 2461 bytes result sent to driver
18/02/28 13:28:14 INFO TaskSetManager: Finished task 1.0 in stage 60.0 (TID 184) in 1457 ms on localhost (executor driver) (3/4)
18/02/28 13:28:14 INFO MemoryStore: Block rdd_199_0 stored as values in memory (estimated size 4.3 MB, free 299.2 MB)
18/02/28 13:28:14 INFO BlockManagerInfo: Added rdd_199_0 in memory on 127.0.0.1:60941 (size: 4.3 MB, free: 304.2 MB)
18/02/28 13:28:14 INFO Executor: Finished task 0.0 in stage 60.0 (TID 183). 2461 bytes result sent to driver
18/02/28 13:28:14 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 183) in 1479 ms on localhost (executor driver) (4/4)
18/02/28 13:28:14 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
18/02/28 13:28:14 INFO DAGScheduler: ShuffleMapStage 60 (sql at <unknown>:0) finished in 1.479 s
18/02/28 13:28:14 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:28:14 INFO DAGScheduler: running: Set()
18/02/28 13:28:14 INFO DAGScheduler: waiting: Set(ResultStage 61)
18/02/28 13:28:14 INFO DAGScheduler: failed: Set()
18/02/28 13:28:14 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[205] at sql at <unknown>:0), which has no missing parents
18/02/28 13:28:14 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 7.0 KB, free 299.2 MB)
18/02/28 13:28:14 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 3.7 KB, free 299.2 MB)
18/02/28 13:28:14 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 304.2 MB)
18/02/28 13:28:14 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1006
18/02/28 13:28:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[205] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 13:28:14 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks
18/02/28 13:28:14 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 187, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:28:14 INFO Executor: Running task 0.0 in stage 61.0 (TID 187)
18/02/28 13:28:14 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:28:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:28:14 INFO Executor: Finished task 0.0 in stage 61.0 (TID 187). 1538 bytes result sent to driver
18/02/28 13:28:14 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 187) in 8 ms on localhost (executor driver) (1/1)
18/02/28 13:28:14 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
18/02/28 13:28:14 INFO DAGScheduler: ResultStage 61 (sql at <unknown>:0) finished in 0.008 s
18/02/28 13:28:14 INFO DAGScheduler: Job 32 finished: sql at <unknown>:0, took 1.497787 s
18/02/28 13:28:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:28:14 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `cached_flights`
18/02/28 13:28:14 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:14 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:15 INFO ContextCleaner: Cleaned accumulator 1960
18/02/28 13:28:15 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:28:15 INFO DAGScheduler: Registering RDD 208 (collect at utils.scala:211)
18/02/28 13:28:15 INFO DAGScheduler: Got job 33 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:28:15 INFO DAGScheduler: Final stage: ResultStage 63 (collect at utils.scala:211)
18/02/28 13:28:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 62)
18/02/28 13:28:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 62)
18/02/28 13:28:15 INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[208] at collect at utils.scala:211), which has no missing parents
18/02/28 13:28:15 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 27.4 KB, free 299.1 MB)
18/02/28 13:28:15 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 12.1 KB, free 299.1 MB)
18/02/28 13:28:15 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 127.0.0.1:60941 (size: 12.1 KB, free: 304.2 MB)
18/02/28 13:28:15 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1006
18/02/28 13:28:15 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[208] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:28:15 INFO TaskSchedulerImpl: Adding task set 62.0 with 4 tasks
18/02/28 13:28:15 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 304.2 MB)
18/02/28 13:28:15 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 188, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:28:15 INFO TaskSetManager: Starting task 1.0 in stage 62.0 (TID 189, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:28:15 INFO TaskSetManager: Starting task 2.0 in stage 62.0 (TID 190, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:28:15 INFO TaskSetManager: Starting task 3.0 in stage 62.0 (TID 191, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:28:15 INFO Executor: Running task 0.0 in stage 62.0 (TID 188)
18/02/28 13:28:15 INFO BlockManager: Found block rdd_199_0 locally
18/02/28 13:28:15 INFO Executor: Running task 1.0 in stage 62.0 (TID 189)
18/02/28 13:28:15 INFO BlockManager: Found block rdd_199_1 locally
18/02/28 13:28:15 INFO Executor: Running task 2.0 in stage 62.0 (TID 190)
18/02/28 13:28:15 INFO BlockManager: Found block rdd_199_2 locally
18/02/28 13:28:15 INFO Executor: Running task 3.0 in stage 62.0 (TID 191)
18/02/28 13:28:15 INFO BlockManager: Found block rdd_199_3 locally
18/02/28 13:28:15 INFO Executor: Finished task 0.0 in stage 62.0 (TID 188). 1737 bytes result sent to driver
18/02/28 13:28:15 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 188) in 45 ms on localhost (executor driver) (1/4)
18/02/28 13:28:15 INFO Executor: Finished task 1.0 in stage 62.0 (TID 189). 1694 bytes result sent to driver
18/02/28 13:28:15 INFO TaskSetManager: Finished task 1.0 in stage 62.0 (TID 189) in 47 ms on localhost (executor driver) (2/4)
18/02/28 13:28:15 INFO Executor: Finished task 2.0 in stage 62.0 (TID 190). 1694 bytes result sent to driver
18/02/28 13:28:15 INFO TaskSetManager: Finished task 2.0 in stage 62.0 (TID 190) in 52 ms on localhost (executor driver) (3/4)
18/02/28 13:28:15 INFO Executor: Finished task 3.0 in stage 62.0 (TID 191). 1694 bytes result sent to driver
18/02/28 13:28:15 INFO TaskSetManager: Finished task 3.0 in stage 62.0 (TID 191) in 61 ms on localhost (executor driver) (4/4)
18/02/28 13:28:15 INFO DAGScheduler: ShuffleMapStage 62 (collect at utils.scala:211) finished in 0.062 s
18/02/28 13:28:15 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:28:15 INFO DAGScheduler: running: Set()
18/02/28 13:28:15 INFO DAGScheduler: waiting: Set(ResultStage 63)
18/02/28 13:28:15 INFO DAGScheduler: failed: Set()
18/02/28 13:28:15 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[211] at collect at utils.scala:211), which has no missing parents
18/02/28 13:28:15 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 7.0 KB, free 299.1 MB)
18/02/28 13:28:15 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 3.7 KB, free 299.1 MB)
18/02/28 13:28:15 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
18/02/28 13:28:15 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 304.2 MB)
18/02/28 13:28:15 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1006
18/02/28 13:28:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[211] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:28:15 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks
18/02/28 13:28:15 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 192, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:28:15 INFO Executor: Running task 0.0 in stage 63.0 (TID 192)
18/02/28 13:28:15 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:28:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:28:15 INFO Executor: Finished task 0.0 in stage 63.0 (TID 192). 1495 bytes result sent to driver
18/02/28 13:28:15 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 192) in 6 ms on localhost (executor driver) (1/1)
18/02/28 13:28:15 INFO DAGScheduler: ResultStage 63 (collect at utils.scala:211) finished in 0.007 s
18/02/28 13:28:15 INFO DAGScheduler: Job 33 finished: collect at utils.scala:211, took 0.101651 s
18/02/28 13:28:15 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
18/02/28 13:28:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:28:15 INFO SparkSqlParser: Parsing command: SHOW TABLES LIKE"cached_flights"
18/02/28 13:28:15 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:15 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:15 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:15 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:15 INFO HiveMetaStore: 0: get_tables: db=default pat=cached_flights
18/02/28 13:28:15 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=cached_flights	
18/02/28 13:28:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:28:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights` AS `zzz70`
WHERE (0 = 1)
18/02/28 13:28:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:28:15 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 13:28:15 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:15 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:15 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:15 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:15 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 13:28:15 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 13:28:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:28:18 INFO SparkSqlParser: Parsing command: SELECT `month`, count(*) AS `n()`
FROM `cached_flights`
GROUP BY `month`
18/02/28 13:28:18 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:18 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:18 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:28:18 INFO DAGScheduler: Registering RDD 214 (collect at utils.scala:211)
18/02/28 13:28:18 INFO DAGScheduler: Got job 34 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:28:18 INFO DAGScheduler: Final stage: ResultStage 65 (collect at utils.scala:211)
18/02/28 13:28:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 64)
18/02/28 13:28:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 64)
18/02/28 13:28:18 INFO DAGScheduler: Submitting ShuffleMapStage 64 (MapPartitionsRDD[214] at collect at utils.scala:211), which has no missing parents
18/02/28 13:28:18 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 38.0 KB, free 299.1 MB)
18/02/28 13:28:18 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 17.2 KB, free 299.1 MB)
18/02/28 13:28:18 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 127.0.0.1:60941 (size: 17.2 KB, free: 304.2 MB)
18/02/28 13:28:18 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1006
18/02/28 13:28:18 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 64 (MapPartitionsRDD[214] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:28:18 INFO TaskSchedulerImpl: Adding task set 64.0 with 4 tasks
18/02/28 13:28:18 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 193, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:28:18 INFO TaskSetManager: Starting task 1.0 in stage 64.0 (TID 194, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:28:18 INFO TaskSetManager: Starting task 2.0 in stage 64.0 (TID 195, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:28:18 INFO TaskSetManager: Starting task 3.0 in stage 64.0 (TID 196, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:28:18 INFO Executor: Running task 0.0 in stage 64.0 (TID 193)
18/02/28 13:28:18 INFO Executor: Running task 1.0 in stage 64.0 (TID 194)
18/02/28 13:28:18 INFO Executor: Running task 2.0 in stage 64.0 (TID 195)
18/02/28 13:28:18 INFO BlockManager: Found block rdd_199_2 locally
18/02/28 13:28:18 INFO Executor: Running task 3.0 in stage 64.0 (TID 196)
18/02/28 13:28:18 INFO BlockManager: Found block rdd_199_3 locally
18/02/28 13:28:18 INFO BlockManager: Found block rdd_199_0 locally
18/02/28 13:28:18 INFO BlockManager: Found block rdd_199_1 locally
18/02/28 13:28:18 INFO Executor: Finished task 3.0 in stage 64.0 (TID 196). 1968 bytes result sent to driver
18/02/28 13:28:18 INFO TaskSetManager: Finished task 3.0 in stage 64.0 (TID 196) in 35 ms on localhost (executor driver) (1/4)
18/02/28 13:28:18 INFO Executor: Finished task 2.0 in stage 64.0 (TID 195). 1968 bytes result sent to driver
18/02/28 13:28:18 INFO TaskSetManager: Finished task 2.0 in stage 64.0 (TID 195) in 37 ms on localhost (executor driver) (2/4)
18/02/28 13:28:18 INFO Executor: Finished task 0.0 in stage 64.0 (TID 193). 1968 bytes result sent to driver
18/02/28 13:28:18 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 193) in 39 ms on localhost (executor driver) (3/4)
18/02/28 13:28:18 INFO Executor: Finished task 1.0 in stage 64.0 (TID 194). 1925 bytes result sent to driver
18/02/28 13:28:18 INFO TaskSetManager: Finished task 1.0 in stage 64.0 (TID 194) in 44 ms on localhost (executor driver) (4/4)
18/02/28 13:28:18 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
18/02/28 13:28:18 INFO DAGScheduler: ShuffleMapStage 64 (collect at utils.scala:211) finished in 0.045 s
18/02/28 13:28:18 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:28:18 INFO DAGScheduler: running: Set()
18/02/28 13:28:18 INFO DAGScheduler: waiting: Set(ResultStage 65)
18/02/28 13:28:18 INFO DAGScheduler: failed: Set()
18/02/28 13:28:18 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[217] at collect at utils.scala:211), which has no missing parents
18/02/28 13:28:18 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 17.6 KB, free 299.0 MB)
18/02/28 13:28:18 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 8.2 KB, free 299.0 MB)
18/02/28 13:28:18 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 127.0.0.1:60941 (size: 8.2 KB, free: 304.2 MB)
18/02/28 13:28:18 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1006
18/02/28 13:28:18 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 65 (MapPartitionsRDD[217] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:28:18 INFO TaskSchedulerImpl: Adding task set 65.0 with 4 tasks
18/02/28 13:28:18 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 197, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:28:18 INFO TaskSetManager: Starting task 1.0 in stage 65.0 (TID 198, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 13:28:18 INFO TaskSetManager: Starting task 2.0 in stage 65.0 (TID 199, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 13:28:18 INFO TaskSetManager: Starting task 3.0 in stage 65.0 (TID 200, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 13:28:18 INFO Executor: Running task 0.0 in stage 65.0 (TID 197)
18/02/28 13:28:18 INFO Executor: Running task 1.0 in stage 65.0 (TID 198)
18/02/28 13:28:18 INFO Executor: Running task 2.0 in stage 65.0 (TID 199)
18/02/28 13:28:18 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 13:28:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:28:18 INFO Executor: Running task 3.0 in stage 65.0 (TID 200)
18/02/28 13:28:18 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 13:28:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:28:18 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:28:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:28:18 INFO Executor: Finished task 0.0 in stage 65.0 (TID 197). 2238 bytes result sent to driver
18/02/28 13:28:18 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 13:28:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
18/02/28 13:28:18 INFO Executor: Finished task 1.0 in stage 65.0 (TID 198). 2220 bytes result sent to driver
18/02/28 13:28:18 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 197) in 9 ms on localhost (executor driver) (1/4)
18/02/28 13:28:18 INFO TaskSetManager: Finished task 1.0 in stage 65.0 (TID 198) in 9 ms on localhost (executor driver) (2/4)
18/02/28 13:28:18 INFO Executor: Finished task 3.0 in stage 65.0 (TID 200). 2254 bytes result sent to driver
18/02/28 13:28:18 INFO TaskSetManager: Finished task 3.0 in stage 65.0 (TID 200) in 10 ms on localhost (executor driver) (3/4)
18/02/28 13:28:18 INFO Executor: Finished task 2.0 in stage 65.0 (TID 199). 2238 bytes result sent to driver
18/02/28 13:28:18 INFO TaskSetManager: Finished task 2.0 in stage 65.0 (TID 199) in 11 ms on localhost (executor driver) (4/4)
18/02/28 13:28:18 INFO DAGScheduler: ResultStage 65 (collect at utils.scala:211) finished in 0.012 s
18/02/28 13:28:18 INFO DAGScheduler: Job 34 finished: collect at utils.scala:211, took 0.063125 s
18/02/28 13:28:18 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
18/02/28 13:28:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:28:22 INFO SparkSqlParser: Parsing command: SELECT `x`, `y`, count(*) AS `fillname`
FROM (SELECT `month`, `carrier`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`, (max(`dep_time`) OVER () - min(`dep_time`) OVER () / 100.0 * CASE WHEN (CAST(FLOOR((`dep_time` - min(`dep_time`) OVER ()) / max(`dep_time`) OVER () - min(`dep_time`) OVER () / 100.0) AS INT) = 100.0) THEN (CAST(FLOOR((`dep_time` - min(`dep_time`) OVER ()) / max(`dep_time`) OVER () - min(`dep_time`) OVER () / 100.0) AS INT) - 1.0) WHEN NOT(CAST(FLOOR((`dep_time` - min(`dep_time`) OVER ()) / max(`dep_time`) OVER () - min(`dep_time`) OVER () / 100.0) AS INT) = 100.0) THEN (CAST(FLOOR((`dep_time` - min(`dep_time`) OVER ()) / max(`dep_time`) OVER () - min(`dep_time`) OVER () / 100.0) AS INT)) END) + min(`dep_time`) OVER () AS `x`, (max(`arr_time`) OVER () - min(`arr_time`) OVER () / 100.0 * CASE WHEN (CAST(FLOOR((`arr_time` - min(`arr_time`) OVER ()) / max(`arr_time`) OVER () - min(`arr_time`) OVER () / 100.0) AS INT) = 100.0) THEN (CAST(FLOOR((`arr_time` - min(`arr_time`) OVER ()) / max(`arr_time`) OVER () - min(`arr_time`) OVER () / 100.0) AS INT) - 1.0) WHEN NOT(CAST(FLOOR((`arr_time` - min(`arr_time`) OVER ()) / max(`arr_time`) OVER () - min(`arr_time`) OVER () / 100.0) AS INT) = 100.0) THEN (CAST(FLOOR((`arr_time` - min(`arr_time`) OVER ()) / max(`arr_time`) OVER () - min(`arr_time`) OVER () / 100.0) AS INT)) END) + min(`arr_time`) OVER () AS `y`
FROM `cached_flights`) `vzraqkjpba`
GROUP BY `x`, `y`
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:28:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:28:22 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
18/02/28 13:28:22 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:28:22 INFO DAGScheduler: Registering RDD 219 (collect at utils.scala:211)
18/02/28 13:28:22 INFO DAGScheduler: Got job 35 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:28:22 INFO DAGScheduler: Final stage: ResultStage 67 (collect at utils.scala:211)
18/02/28 13:28:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 66)
18/02/28 13:28:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 66)
18/02/28 13:28:22 INFO DAGScheduler: Submitting ShuffleMapStage 66 (MapPartitionsRDD[219] at collect at utils.scala:211), which has no missing parents
18/02/28 13:28:22 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 24.8 KB, free 299.0 MB)
18/02/28 13:28:22 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 11.3 KB, free 299.0 MB)
18/02/28 13:28:22 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 127.0.0.1:60941 (size: 11.3 KB, free: 304.2 MB)
18/02/28 13:28:22 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1006
18/02/28 13:28:22 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 66 (MapPartitionsRDD[219] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:28:22 INFO TaskSchedulerImpl: Adding task set 66.0 with 4 tasks
18/02/28 13:28:22 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 201, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:28:22 INFO TaskSetManager: Starting task 1.0 in stage 66.0 (TID 202, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:28:22 INFO TaskSetManager: Starting task 2.0 in stage 66.0 (TID 203, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:28:22 INFO TaskSetManager: Starting task 3.0 in stage 66.0 (TID 204, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:28:22 INFO Executor: Running task 0.0 in stage 66.0 (TID 201)
18/02/28 13:28:22 INFO BlockManager: Found block rdd_199_0 locally
18/02/28 13:28:22 INFO Executor: Running task 1.0 in stage 66.0 (TID 202)
18/02/28 13:28:22 INFO BlockManager: Found block rdd_199_1 locally
18/02/28 13:28:22 INFO Executor: Running task 2.0 in stage 66.0 (TID 203)
18/02/28 13:28:22 INFO BlockManager: Found block rdd_199_2 locally
18/02/28 13:28:22 INFO Executor: Running task 3.0 in stage 66.0 (TID 204)
18/02/28 13:28:22 INFO BlockManager: Found block rdd_199_3 locally
18/02/28 13:28:22 INFO Executor: Finished task 1.0 in stage 66.0 (TID 202). 1446 bytes result sent to driver
18/02/28 13:28:22 INFO TaskSetManager: Finished task 1.0 in stage 66.0 (TID 202) in 84 ms on localhost (executor driver) (1/4)
18/02/28 13:28:22 INFO Executor: Finished task 3.0 in stage 66.0 (TID 204). 1489 bytes result sent to driver
18/02/28 13:28:22 INFO TaskSetManager: Finished task 3.0 in stage 66.0 (TID 204) in 89 ms on localhost (executor driver) (2/4)
18/02/28 13:28:22 INFO Executor: Finished task 0.0 in stage 66.0 (TID 201). 1489 bytes result sent to driver
18/02/28 13:28:22 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 201) in 91 ms on localhost (executor driver) (3/4)
18/02/28 13:28:22 INFO Executor: Finished task 2.0 in stage 66.0 (TID 203). 1532 bytes result sent to driver
18/02/28 13:28:22 INFO TaskSetManager: Finished task 2.0 in stage 66.0 (TID 203) in 97 ms on localhost (executor driver) (4/4)
18/02/28 13:28:22 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
18/02/28 13:28:22 INFO DAGScheduler: ShuffleMapStage 66 (collect at utils.scala:211) finished in 0.100 s
18/02/28 13:28:22 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:28:22 INFO DAGScheduler: running: Set()
18/02/28 13:28:22 INFO DAGScheduler: waiting: Set(ResultStage 67)
18/02/28 13:28:22 INFO DAGScheduler: failed: Set()
18/02/28 13:28:22 INFO DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[223] at collect at utils.scala:211), which has no missing parents
18/02/28 13:28:22 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 71.3 KB, free 298.9 MB)
18/02/28 13:28:22 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 24.6 KB, free 298.9 MB)
18/02/28 13:28:22 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 127.0.0.1:60941 (size: 24.6 KB, free: 304.1 MB)
18/02/28 13:28:22 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1006
18/02/28 13:28:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[223] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:28:22 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks
18/02/28 13:28:22 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 205, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:28:22 INFO Executor: Running task 0.0 in stage 67.0 (TID 205)
18/02/28 13:28:22 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:28:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:28:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
18/02/28 13:28:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:22 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (0  time so far)
18/02/28 13:28:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:22 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (1  time so far)
18/02/28 13:28:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:22 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (2  times so far)
18/02/28 13:28:22 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:22 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (3  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (4  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (5  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (6  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (7  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (8  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (9  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (10  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (11  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (12  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (13  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (14  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (15  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (16  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (17  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (18  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (19  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (20  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (21  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (22  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (23  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (24  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (25  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (26  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (27  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (28  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (29  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (30  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (31  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (32  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (33  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (34  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (35  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (36  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (37  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (38  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (39  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (40  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (41  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (42  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (43  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (44  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (45  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (46  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (47  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (48  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (49  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (50  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (51  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (52  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (53  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (54  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (55  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (56  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (57  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (58  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (59  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (60  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (61  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (62  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (63  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (64  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (65  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (66  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (67  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (68  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (69  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (70  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (71  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (72  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (73  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (74  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (75  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (76  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (77  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (78  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (79  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (80  times so far)
18/02/28 13:28:23 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:28:23 INFO UnsafeExternalSorter: Thread 176 spilling sort data of 4.1 MB to disk (81  times so far)
18/02/28 13:28:23 INFO ContextCleaner: Cleaned accumulator 2021
18/02/28 13:28:23 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 127.0.0.1:60941 in memory (size: 12.1 KB, free: 304.2 MB)
18/02/28 13:28:23 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 127.0.0.1:60941 in memory (size: 11.3 KB, free: 304.2 MB)
18/02/28 13:28:23 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 127.0.0.1:60941 in memory (size: 8.2 KB, free: 304.2 MB)
18/02/28 13:28:23 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 304.2 MB)
18/02/28 13:28:23 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 127.0.0.1:60941 in memory (size: 17.2 KB, free: 304.2 MB)
18/02/28 13:28:24 INFO Executor: Finished task 0.0 in stage 67.0 (TID 205). 2339 bytes result sent to driver
18/02/28 13:28:24 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 205) in 1649 ms on localhost (executor driver) (1/1)
18/02/28 13:28:24 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
18/02/28 13:28:24 INFO DAGScheduler: ResultStage 67 (collect at utils.scala:211) finished in 1.649 s
18/02/28 13:28:24 INFO DAGScheduler: Job 35 finished: collect at utils.scala:211, took 1.760558 s
18/02/28 13:29:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:29:23 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `cached_flights`
18/02/28 13:29:23 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:29:23 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:29:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:29:23 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `cached_flights`
18/02/28 13:29:23 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:29:23 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:29:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:29:23 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `cached_flights`
18/02/28 13:29:23 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:29:23 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:29:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:29:23 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `cached_flights`
18/02/28 13:29:23 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:29:23 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:29:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:29:23 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `cached_flights`
18/02/28 13:29:23 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:29:23 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:29:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:29:23 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `cached_flights`
LIMIT 1000
18/02/28 13:29:23 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:29:23 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:29:23 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:29:23 INFO DAGScheduler: Registering RDD 226 (collect at utils.scala:211)
18/02/28 13:29:23 INFO DAGScheduler: Got job 36 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:29:23 INFO DAGScheduler: Final stage: ResultStage 69 (collect at utils.scala:211)
18/02/28 13:29:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 68)
18/02/28 13:29:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 68)
18/02/28 13:29:23 INFO DAGScheduler: Submitting ShuffleMapStage 68 (MapPartitionsRDD[226] at collect at utils.scala:211), which has no missing parents
18/02/28 13:29:23 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 27.4 KB, free 299.0 MB)
18/02/28 13:29:23 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 12.1 KB, free 299.0 MB)
18/02/28 13:29:23 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 127.0.0.1:60941 (size: 12.1 KB, free: 304.2 MB)
18/02/28 13:29:23 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1006
18/02/28 13:29:23 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 68 (MapPartitionsRDD[226] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:29:23 INFO TaskSchedulerImpl: Adding task set 68.0 with 4 tasks
18/02/28 13:29:23 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 206, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:29:23 INFO TaskSetManager: Starting task 1.0 in stage 68.0 (TID 207, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:29:23 INFO TaskSetManager: Starting task 2.0 in stage 68.0 (TID 208, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:29:23 INFO TaskSetManager: Starting task 3.0 in stage 68.0 (TID 209, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:29:23 INFO Executor: Running task 0.0 in stage 68.0 (TID 206)
18/02/28 13:29:23 INFO BlockManager: Found block rdd_199_0 locally
18/02/28 13:29:23 INFO Executor: Running task 1.0 in stage 68.0 (TID 207)
18/02/28 13:29:23 INFO Executor: Running task 3.0 in stage 68.0 (TID 209)
18/02/28 13:29:23 INFO Executor: Running task 2.0 in stage 68.0 (TID 208)
18/02/28 13:29:23 INFO BlockManager: Found block rdd_199_3 locally
18/02/28 13:29:23 INFO BlockManager: Found block rdd_199_2 locally
18/02/28 13:29:23 INFO BlockManager: Found block rdd_199_1 locally
18/02/28 13:29:23 INFO Executor: Finished task 0.0 in stage 68.0 (TID 206). 1694 bytes result sent to driver
18/02/28 13:29:23 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 206) in 27 ms on localhost (executor driver) (1/4)
18/02/28 13:29:23 INFO Executor: Finished task 1.0 in stage 68.0 (TID 207). 1737 bytes result sent to driver
18/02/28 13:29:23 INFO TaskSetManager: Finished task 1.0 in stage 68.0 (TID 207) in 29 ms on localhost (executor driver) (2/4)
18/02/28 13:29:23 INFO Executor: Finished task 3.0 in stage 68.0 (TID 209). 1737 bytes result sent to driver
18/02/28 13:29:23 INFO TaskSetManager: Finished task 3.0 in stage 68.0 (TID 209) in 32 ms on localhost (executor driver) (3/4)
18/02/28 13:29:23 INFO Executor: Finished task 2.0 in stage 68.0 (TID 208). 1694 bytes result sent to driver
18/02/28 13:29:23 INFO TaskSetManager: Finished task 2.0 in stage 68.0 (TID 208) in 34 ms on localhost (executor driver) (4/4)
18/02/28 13:29:23 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
18/02/28 13:29:23 INFO DAGScheduler: ShuffleMapStage 68 (collect at utils.scala:211) finished in 0.035 s
18/02/28 13:29:23 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:29:23 INFO DAGScheduler: running: Set()
18/02/28 13:29:23 INFO DAGScheduler: waiting: Set(ResultStage 69)
18/02/28 13:29:23 INFO DAGScheduler: failed: Set()
18/02/28 13:29:23 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[229] at collect at utils.scala:211), which has no missing parents
18/02/28 13:29:23 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 6.9 KB, free 299.0 MB)
18/02/28 13:29:23 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 3.7 KB, free 299.0 MB)
18/02/28 13:29:23 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 304.2 MB)
18/02/28 13:29:23 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1006
18/02/28 13:29:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[229] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:29:23 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks
18/02/28 13:29:23 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 210, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:29:23 INFO Executor: Running task 0.0 in stage 69.0 (TID 210)
18/02/28 13:29:23 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:29:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:29:23 INFO Executor: Finished task 0.0 in stage 69.0 (TID 210). 1471 bytes result sent to driver
18/02/28 13:29:23 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 210) in 4 ms on localhost (executor driver) (1/1)
18/02/28 13:29:23 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
18/02/28 13:29:23 INFO DAGScheduler: ResultStage 69 (collect at utils.scala:211) finished in 0.004 s
18/02/28 13:29:23 INFO DAGScheduler: Job 36 finished: collect at utils.scala:211, took 0.047458 s
18/02/28 13:30:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:00 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
LIMIT 6
18/02/28 13:30:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:00 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
LIMIT 6
18/02/28 13:30:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:00 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
LIMIT 6
18/02/28 13:30:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:00 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
LIMIT 6
18/02/28 13:30:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:00 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
LIMIT 6
18/02/28 13:30:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:00 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
LIMIT 6
18/02/28 13:30:00 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:30:00 INFO DAGScheduler: Got job 37 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:30:00 INFO DAGScheduler: Final stage: ResultStage 70 (collect at utils.scala:211)
18/02/28 13:30:00 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:30:00 INFO DAGScheduler: Missing parents: List()
18/02/28 13:30:00 INFO DAGScheduler: Submitting ResultStage 70 (MapPartitionsRDD[231] at collect at utils.scala:211), which has no missing parents
18/02/28 13:30:00 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 23.5 KB, free 299.0 MB)
18/02/28 13:30:00 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 10.7 KB, free 299.0 MB)
18/02/28 13:30:00 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 127.0.0.1:60941 (size: 10.7 KB, free: 304.2 MB)
18/02/28 13:30:00 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1006
18/02/28 13:30:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 70 (MapPartitionsRDD[231] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:30:00 INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks
18/02/28 13:30:00 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 211, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:30:00 INFO Executor: Running task 0.0 in stage 70.0 (TID 211)
18/02/28 13:30:00 INFO BlockManager: Found block rdd_199_0 locally
18/02/28 13:30:00 INFO CodeGenerator: Code generated in 9.935686 ms
18/02/28 13:30:00 INFO Executor: 1 block locks were not released by TID = 211:
[rdd_199_0]
18/02/28 13:30:00 INFO Executor: Finished task 0.0 in stage 70.0 (TID 211). 1432 bytes result sent to driver
18/02/28 13:30:00 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 211) in 15 ms on localhost (executor driver) (1/1)
18/02/28 13:30:00 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
18/02/28 13:30:00 INFO DAGScheduler: ResultStage 70 (collect at utils.scala:211) finished in 0.015 s
18/02/28 13:30:00 INFO DAGScheduler: Job 37 finished: collect at utils.scala:211, took 0.019398 s
18/02/28 13:30:00 INFO CodeGenerator: Code generated in 4.72295 ms
18/02/28 13:30:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
LIMIT 6
18/02/28 13:30:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
LIMIT 6
18/02/28 13:30:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
LIMIT 6
18/02/28 13:30:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
LIMIT 6
18/02/28 13:30:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
LIMIT 6
18/02/28 13:30:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
LIMIT 6
18/02/28 13:30:05 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:30:05 INFO DAGScheduler: Got job 38 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:30:05 INFO DAGScheduler: Final stage: ResultStage 71 (collect at utils.scala:211)
18/02/28 13:30:05 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:30:05 INFO DAGScheduler: Missing parents: List()
18/02/28 13:30:05 INFO DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[233] at collect at utils.scala:211), which has no missing parents
18/02/28 13:30:05 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 23.5 KB, free 299.0 MB)
18/02/28 13:30:05 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 10.7 KB, free 299.0 MB)
18/02/28 13:30:05 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 127.0.0.1:60941 (size: 10.7 KB, free: 304.2 MB)
18/02/28 13:30:05 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1006
18/02/28 13:30:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[233] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:30:05 INFO TaskSchedulerImpl: Adding task set 71.0 with 1 tasks
18/02/28 13:30:05 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 212, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:30:05 INFO Executor: Running task 0.0 in stage 71.0 (TID 212)
18/02/28 13:30:05 INFO BlockManager: Found block rdd_199_0 locally
18/02/28 13:30:05 INFO Executor: 1 block locks were not released by TID = 212:
[rdd_199_0]
18/02/28 13:30:05 INFO Executor: Finished task 0.0 in stage 71.0 (TID 212). 1389 bytes result sent to driver
18/02/28 13:30:05 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 212) in 3 ms on localhost (executor driver) (1/1)
18/02/28 13:30:05 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
18/02/28 13:30:05 INFO DAGScheduler: ResultStage 71 (collect at utils.scala:211) finished in 0.004 s
18/02/28 13:30:05 INFO DAGScheduler: Job 38 finished: collect at utils.scala:211, took 0.007566 s
18/02/28 13:30:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:31 INFO SparkSqlParser: Parsing command: SELECT `month`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`
FROM (SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`dep_time` AS DOUBLE) AS `dep_time`, CAST(`arr_time` AS DOUBLE) AS `arr_time`, CAST(`arr_delay` AS DOUBLE) AS `arr_delay`, CAST(`dep_delay` AS DOUBLE) AS `dep_delay`, CAST(`distance` AS DOUBLE) AS `distance`
FROM (SELECT `month`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`
FROM `spark_flights`) `ttbprthapn`) `novvqctfjy`
18/02/28 13:30:31 INFO SparkSqlParser: Parsing command: cached_flights
18/02/28 13:30:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights` AS `zzz71`
WHERE (0 = 1)
18/02/28 13:30:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:31 INFO SparkSqlParser: Parsing command: CACHE TABLE `cached_flights`
18/02/28 13:30:31 INFO SparkSqlParser: Parsing command: `cached_flights`
18/02/28 13:30:31 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 13:30:31 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 13:30:31 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dep_time: string, dep_delay: string, arr_time: string, arr_delay: string ... 1 more field>
18/02/28 13:30:31 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 13:30:31 INFO CodeGenerator: Code generated in 7.578795 ms
18/02/28 13:30:31 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 282.5 KB, free 298.7 MB)
18/02/28 13:30:31 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 24.1 KB, free 298.7 MB)
18/02/28 13:30:31 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 127.0.0.1:60941 (size: 24.1 KB, free: 304.1 MB)
18/02/28 13:30:31 INFO SparkContext: Created broadcast 90 from sql at <unknown>:0
18/02/28 13:30:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21019222 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 13:30:31 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 13:30:31 INFO DAGScheduler: Registering RDD 239 (sql at <unknown>:0)
18/02/28 13:30:31 INFO DAGScheduler: Got job 39 (sql at <unknown>:0) with 1 output partitions
18/02/28 13:30:31 INFO DAGScheduler: Final stage: ResultStage 73 (sql at <unknown>:0)
18/02/28 13:30:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 72)
18/02/28 13:30:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 72)
18/02/28 13:30:31 INFO DAGScheduler: Submitting ShuffleMapStage 72 (MapPartitionsRDD[239] at sql at <unknown>:0), which has no missing parents
18/02/28 13:30:31 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 24.4 KB, free 298.6 MB)
18/02/28 13:30:31 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 11.2 KB, free 298.6 MB)
18/02/28 13:30:31 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 127.0.0.1:60941 (size: 11.2 KB, free: 304.1 MB)
18/02/28 13:30:31 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1006
18/02/28 13:30:31 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 72 (MapPartitionsRDD[239] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:30:31 INFO TaskSchedulerImpl: Adding task set 72.0 with 4 tasks
18/02/28 13:30:31 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 213, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:30:31 INFO TaskSetManager: Starting task 1.0 in stage 72.0 (TID 214, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:30:31 INFO TaskSetManager: Starting task 2.0 in stage 72.0 (TID 215, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:30:31 INFO TaskSetManager: Starting task 3.0 in stage 72.0 (TID 216, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:30:31 INFO Executor: Running task 0.0 in stage 72.0 (TID 213)
18/02/28 13:30:31 INFO Executor: Running task 3.0 in stage 72.0 (TID 216)
18/02/28 13:30:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_7.csv, range: 0-2938867, partition values: [empty row]
18/02/28 13:30:31 INFO Executor: Running task 1.0 in stage 72.0 (TID 214)
18/02/28 13:30:31 INFO Executor: Running task 2.0 in stage 72.0 (TID 215)
18/02/28 13:30:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_11.csv, range: 0-2757037, partition values: [empty row]
18/02/28 13:30:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_3.csv, range: 0-2881793, partition values: [empty row]
18/02/28 13:30:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_4.csv, range: 0-2830543, partition values: [empty row]
18/02/28 13:30:31 INFO ContextCleaner: Cleaned accumulator 2141
18/02/28 13:30:31 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 127.0.0.1:60941 in memory (size: 12.1 KB, free: 304.1 MB)
18/02/28 13:30:31 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 304.1 MB)
18/02/28 13:30:31 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 127.0.0.1:60941 in memory (size: 10.7 KB, free: 304.2 MB)
18/02/28 13:30:31 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 127.0.0.1:60941 in memory (size: 10.7 KB, free: 304.2 MB)
18/02/28 13:30:31 INFO ContextCleaner: Cleaned accumulator 2258
18/02/28 13:30:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_1.csv, range: 0-2697256, partition values: [empty row]
18/02/28 13:30:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_8.csv, range: 0-2932019, partition values: [empty row]
18/02/28 13:30:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_6.csv, range: 0-2820227, partition values: [empty row]
18/02/28 13:30:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_5.csv, range: 0-2880181, partition values: [empty row]
18/02/28 13:30:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_2.csv, range: 0-2487144, partition values: [empty row]
18/02/28 13:30:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_10.csv, range: 0-2920629, partition values: [empty row]
18/02/28 13:30:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_9.csv, range: 0-2763076, partition values: [empty row]
18/02/28 13:30:31 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_12.csv, range: 0-2836468, partition values: [empty row]
18/02/28 13:30:32 INFO MemoryStore: Block rdd_236_3 stored as values in memory (estimated size 3.6 MB, free 295.1 MB)
18/02/28 13:30:32 INFO BlockManagerInfo: Added rdd_236_3 in memory on 127.0.0.1:60941 (size: 3.6 MB, free: 300.6 MB)
18/02/28 13:30:32 INFO Executor: Finished task 3.0 in stage 72.0 (TID 216). 2461 bytes result sent to driver
18/02/28 13:30:32 INFO TaskSetManager: Finished task 3.0 in stage 72.0 (TID 216) in 844 ms on localhost (executor driver) (1/4)
18/02/28 13:30:32 INFO MemoryStore: Block rdd_236_2 stored as values in memory (estimated size 3.8 MB, free 291.3 MB)
18/02/28 13:30:32 INFO BlockManagerInfo: Added rdd_236_2 in memory on 127.0.0.1:60941 (size: 3.8 MB, free: 296.7 MB)
18/02/28 13:30:32 INFO MemoryStore: Block rdd_236_0 stored as values in memory (estimated size 4.0 MB, free 287.3 MB)
18/02/28 13:30:32 INFO BlockManagerInfo: Added rdd_236_0 in memory on 127.0.0.1:60941 (size: 4.0 MB, free: 292.7 MB)
18/02/28 13:30:32 INFO Executor: Finished task 2.0 in stage 72.0 (TID 215). 2461 bytes result sent to driver
18/02/28 13:30:32 INFO TaskSetManager: Finished task 2.0 in stage 72.0 (TID 215) in 899 ms on localhost (executor driver) (2/4)
18/02/28 13:30:32 INFO Executor: Finished task 0.0 in stage 72.0 (TID 213). 2461 bytes result sent to driver
18/02/28 13:30:32 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 213) in 904 ms on localhost (executor driver) (3/4)
18/02/28 13:30:32 INFO MemoryStore: Block rdd_236_1 stored as values in memory (estimated size 3.9 MB, free 283.4 MB)
18/02/28 13:30:32 INFO BlockManagerInfo: Added rdd_236_1 in memory on 127.0.0.1:60941 (size: 3.9 MB, free: 288.8 MB)
18/02/28 13:30:32 INFO Executor: Finished task 1.0 in stage 72.0 (TID 214). 2461 bytes result sent to driver
18/02/28 13:30:32 INFO TaskSetManager: Finished task 1.0 in stage 72.0 (TID 214) in 922 ms on localhost (executor driver) (4/4)
18/02/28 13:30:32 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
18/02/28 13:30:32 INFO DAGScheduler: ShuffleMapStage 72 (sql at <unknown>:0) finished in 0.922 s
18/02/28 13:30:32 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:30:32 INFO DAGScheduler: running: Set()
18/02/28 13:30:32 INFO DAGScheduler: waiting: Set(ResultStage 73)
18/02/28 13:30:32 INFO DAGScheduler: failed: Set()
18/02/28 13:30:32 INFO DAGScheduler: Submitting ResultStage 73 (MapPartitionsRDD[242] at sql at <unknown>:0), which has no missing parents
18/02/28 13:30:32 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 7.0 KB, free 283.4 MB)
18/02/28 13:30:32 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 3.7 KB, free 283.4 MB)
18/02/28 13:30:32 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 288.8 MB)
18/02/28 13:30:32 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1006
18/02/28 13:30:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (MapPartitionsRDD[242] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 13:30:32 INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks
18/02/28 13:30:32 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 217, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:30:32 INFO Executor: Running task 0.0 in stage 73.0 (TID 217)
18/02/28 13:30:32 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:30:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:30:32 INFO Executor: Finished task 0.0 in stage 73.0 (TID 217). 1495 bytes result sent to driver
18/02/28 13:30:32 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 217) in 4 ms on localhost (executor driver) (1/1)
18/02/28 13:30:32 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
18/02/28 13:30:32 INFO DAGScheduler: ResultStage 73 (sql at <unknown>:0) finished in 0.004 s
18/02/28 13:30:32 INFO DAGScheduler: Job 39 finished: sql at <unknown>:0, took 0.937081 s
18/02/28 13:30:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:32 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `cached_flights`
18/02/28 13:30:32 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:32 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:32 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:30:32 INFO DAGScheduler: Registering RDD 245 (collect at utils.scala:211)
18/02/28 13:30:32 INFO DAGScheduler: Got job 40 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:30:32 INFO DAGScheduler: Final stage: ResultStage 75 (collect at utils.scala:211)
18/02/28 13:30:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 74)
18/02/28 13:30:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 74)
18/02/28 13:30:32 INFO DAGScheduler: Submitting ShuffleMapStage 74 (MapPartitionsRDD[245] at collect at utils.scala:211), which has no missing parents
18/02/28 13:30:32 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 24.4 KB, free 283.4 MB)
18/02/28 13:30:32 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 11.2 KB, free 283.4 MB)
18/02/28 13:30:32 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 127.0.0.1:60941 (size: 11.2 KB, free: 288.8 MB)
18/02/28 13:30:32 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1006
18/02/28 13:30:32 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 74 (MapPartitionsRDD[245] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:30:32 INFO TaskSchedulerImpl: Adding task set 74.0 with 4 tasks
18/02/28 13:30:32 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 218, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:30:32 INFO TaskSetManager: Starting task 1.0 in stage 74.0 (TID 219, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:30:32 INFO TaskSetManager: Starting task 2.0 in stage 74.0 (TID 220, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:30:32 INFO TaskSetManager: Starting task 3.0 in stage 74.0 (TID 221, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:30:32 INFO Executor: Running task 0.0 in stage 74.0 (TID 218)
18/02/28 13:30:32 INFO Executor: Running task 1.0 in stage 74.0 (TID 219)
18/02/28 13:30:32 INFO Executor: Running task 2.0 in stage 74.0 (TID 220)
18/02/28 13:30:32 INFO BlockManager: Found block rdd_236_1 locally
18/02/28 13:30:32 INFO BlockManager: Found block rdd_236_2 locally
18/02/28 13:30:32 INFO Executor: Running task 3.0 in stage 74.0 (TID 221)
18/02/28 13:30:32 INFO BlockManager: Found block rdd_236_0 locally
18/02/28 13:30:32 INFO BlockManager: Found block rdd_236_3 locally
18/02/28 13:30:32 INFO Executor: Finished task 0.0 in stage 74.0 (TID 218). 1694 bytes result sent to driver
18/02/28 13:30:32 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 218) in 18 ms on localhost (executor driver) (1/4)
18/02/28 13:30:32 INFO Executor: Finished task 1.0 in stage 74.0 (TID 219). 1694 bytes result sent to driver
18/02/28 13:30:32 INFO TaskSetManager: Finished task 1.0 in stage 74.0 (TID 219) in 20 ms on localhost (executor driver) (2/4)
18/02/28 13:30:32 INFO Executor: Finished task 2.0 in stage 74.0 (TID 220). 1694 bytes result sent to driver
18/02/28 13:30:32 INFO TaskSetManager: Finished task 2.0 in stage 74.0 (TID 220) in 21 ms on localhost (executor driver) (3/4)
18/02/28 13:30:32 INFO Executor: Finished task 3.0 in stage 74.0 (TID 221). 1694 bytes result sent to driver
18/02/28 13:30:32 INFO TaskSetManager: Finished task 3.0 in stage 74.0 (TID 221) in 23 ms on localhost (executor driver) (4/4)
18/02/28 13:30:32 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
18/02/28 13:30:32 INFO DAGScheduler: ShuffleMapStage 74 (collect at utils.scala:211) finished in 0.024 s
18/02/28 13:30:32 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:30:32 INFO DAGScheduler: running: Set()
18/02/28 13:30:32 INFO DAGScheduler: waiting: Set(ResultStage 75)
18/02/28 13:30:32 INFO DAGScheduler: failed: Set()
18/02/28 13:30:32 INFO DAGScheduler: Submitting ResultStage 75 (MapPartitionsRDD[248] at collect at utils.scala:211), which has no missing parents
18/02/28 13:30:32 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 7.0 KB, free 283.4 MB)
18/02/28 13:30:32 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 3.7 KB, free 283.4 MB)
18/02/28 13:30:32 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 288.8 MB)
18/02/28 13:30:32 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1006
18/02/28 13:30:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 75 (MapPartitionsRDD[248] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:30:32 INFO TaskSchedulerImpl: Adding task set 75.0 with 1 tasks
18/02/28 13:30:32 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 222, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:30:32 INFO Executor: Running task 0.0 in stage 75.0 (TID 222)
18/02/28 13:30:32 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:30:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:30:32 INFO Executor: Finished task 0.0 in stage 75.0 (TID 222). 1495 bytes result sent to driver
18/02/28 13:30:32 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 222) in 4 ms on localhost (executor driver) (1/1)
18/02/28 13:30:32 INFO DAGScheduler: ResultStage 75 (collect at utils.scala:211) finished in 0.005 s
18/02/28 13:30:32 INFO DAGScheduler: Job 40 finished: collect at utils.scala:211, took 0.036627 s
18/02/28 13:30:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:32 INFO SparkSqlParser: Parsing command: SHOW TABLES LIKE"cached_flights"
18/02/28 13:30:32 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:32 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:32 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:32 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:32 INFO HiveMetaStore: 0: get_tables: db=default pat=cached_flights
18/02/28 13:30:32 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=cached_flights	
18/02/28 13:30:32 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
18/02/28 13:30:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights` AS `zzz72`
WHERE (0 = 1)
18/02/28 13:30:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:32 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 13:30:32 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:32 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:32 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:32 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:32 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 13:30:32 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 13:30:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:34 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `cached_flights`
18/02/28 13:30:34 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:34 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:34 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `cached_flights`
18/02/28 13:30:34 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:34 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:34 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `cached_flights`
18/02/28 13:30:34 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:34 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:34 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `cached_flights`
18/02/28 13:30:34 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:34 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:34 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `cached_flights`
18/02/28 13:30:34 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:34 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:34 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `cached_flights`
LIMIT 1000
18/02/28 13:30:34 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:34 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:34 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:30:34 INFO DAGScheduler: Registering RDD 251 (collect at utils.scala:211)
18/02/28 13:30:34 INFO DAGScheduler: Got job 41 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:30:34 INFO DAGScheduler: Final stage: ResultStage 77 (collect at utils.scala:211)
18/02/28 13:30:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 76)
18/02/28 13:30:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 76)
18/02/28 13:30:34 INFO DAGScheduler: Submitting ShuffleMapStage 76 (MapPartitionsRDD[251] at collect at utils.scala:211), which has no missing parents
18/02/28 13:30:34 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 24.4 KB, free 283.3 MB)
18/02/28 13:30:34 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 11.2 KB, free 283.3 MB)
18/02/28 13:30:34 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 127.0.0.1:60941 (size: 11.2 KB, free: 288.8 MB)
18/02/28 13:30:34 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1006
18/02/28 13:30:34 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 76 (MapPartitionsRDD[251] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:30:34 INFO TaskSchedulerImpl: Adding task set 76.0 with 4 tasks
18/02/28 13:30:34 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 223, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:30:34 INFO TaskSetManager: Starting task 1.0 in stage 76.0 (TID 224, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:30:34 INFO TaskSetManager: Starting task 2.0 in stage 76.0 (TID 225, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:30:34 INFO TaskSetManager: Starting task 3.0 in stage 76.0 (TID 226, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:30:34 INFO Executor: Running task 0.0 in stage 76.0 (TID 223)
18/02/28 13:30:34 INFO Executor: Running task 1.0 in stage 76.0 (TID 224)
18/02/28 13:30:34 INFO BlockManager: Found block rdd_236_1 locally
18/02/28 13:30:34 INFO Executor: Running task 2.0 in stage 76.0 (TID 225)
18/02/28 13:30:34 INFO BlockManager: Found block rdd_236_0 locally
18/02/28 13:30:34 INFO Executor: Running task 3.0 in stage 76.0 (TID 226)
18/02/28 13:30:34 INFO BlockManager: Found block rdd_236_3 locally
18/02/28 13:30:34 INFO BlockManager: Found block rdd_236_2 locally
18/02/28 13:30:34 INFO Executor: Finished task 0.0 in stage 76.0 (TID 223). 1737 bytes result sent to driver
18/02/28 13:30:34 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 223) in 31 ms on localhost (executor driver) (1/4)
18/02/28 13:30:34 INFO Executor: Finished task 1.0 in stage 76.0 (TID 224). 1737 bytes result sent to driver
18/02/28 13:30:34 INFO TaskSetManager: Finished task 1.0 in stage 76.0 (TID 224) in 38 ms on localhost (executor driver) (2/4)
18/02/28 13:30:34 INFO Executor: Finished task 3.0 in stage 76.0 (TID 226). 1694 bytes result sent to driver
18/02/28 13:30:34 INFO TaskSetManager: Finished task 3.0 in stage 76.0 (TID 226) in 47 ms on localhost (executor driver) (3/4)
18/02/28 13:30:34 INFO Executor: Finished task 2.0 in stage 76.0 (TID 225). 1694 bytes result sent to driver
18/02/28 13:30:34 INFO TaskSetManager: Finished task 2.0 in stage 76.0 (TID 225) in 51 ms on localhost (executor driver) (4/4)
18/02/28 13:30:34 INFO DAGScheduler: ShuffleMapStage 76 (collect at utils.scala:211) finished in 0.052 s
18/02/28 13:30:34 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:30:34 INFO DAGScheduler: running: Set()
18/02/28 13:30:34 INFO DAGScheduler: waiting: Set(ResultStage 77)
18/02/28 13:30:34 INFO DAGScheduler: failed: Set()
18/02/28 13:30:34 INFO DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[254] at collect at utils.scala:211), which has no missing parents
18/02/28 13:30:34 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 6.9 KB, free 283.3 MB)
18/02/28 13:30:34 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 3.7 KB, free 283.3 MB)
18/02/28 13:30:34 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
18/02/28 13:30:34 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 288.8 MB)
18/02/28 13:30:34 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1006
18/02/28 13:30:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 77 (MapPartitionsRDD[254] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:30:34 INFO TaskSchedulerImpl: Adding task set 77.0 with 1 tasks
18/02/28 13:30:34 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 227, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:30:34 INFO Executor: Running task 0.0 in stage 77.0 (TID 227)
18/02/28 13:30:34 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:30:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:30:34 INFO Executor: Finished task 0.0 in stage 77.0 (TID 227). 1471 bytes result sent to driver
18/02/28 13:30:34 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 227) in 4 ms on localhost (executor driver) (1/1)
18/02/28 13:30:34 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
18/02/28 13:30:34 INFO DAGScheduler: ResultStage 77 (collect at utils.scala:211) finished in 0.005 s
18/02/28 13:30:34 INFO DAGScheduler: Job 41 finished: collect at utils.scala:211, took 0.066259 s
18/02/28 13:30:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
LIMIT 6
18/02/28 13:30:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
LIMIT 6
18/02/28 13:30:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
LIMIT 6
18/02/28 13:30:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
LIMIT 6
18/02/28 13:30:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
LIMIT 6
18/02/28 13:30:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
LIMIT 6
18/02/28 13:30:36 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:30:36 INFO DAGScheduler: Got job 42 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:30:36 INFO DAGScheduler: Final stage: ResultStage 78 (collect at utils.scala:211)
18/02/28 13:30:36 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:30:36 INFO DAGScheduler: Missing parents: List()
18/02/28 13:30:36 INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[256] at collect at utils.scala:211), which has no missing parents
18/02/28 13:30:36 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 20.5 KB, free 283.3 MB)
18/02/28 13:30:36 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 9.8 KB, free 283.3 MB)
18/02/28 13:30:36 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 127.0.0.1:60941 (size: 9.8 KB, free: 288.8 MB)
18/02/28 13:30:36 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1006
18/02/28 13:30:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[256] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:30:36 INFO TaskSchedulerImpl: Adding task set 78.0 with 1 tasks
18/02/28 13:30:36 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 228, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:30:36 INFO Executor: Running task 0.0 in stage 78.0 (TID 228)
18/02/28 13:30:36 INFO BlockManager: Found block rdd_236_0 locally
18/02/28 13:30:36 INFO CodeGenerator: Code generated in 9.94027 ms
18/02/28 13:30:36 INFO Executor: 1 block locks were not released by TID = 228:
[rdd_236_0]
18/02/28 13:30:36 INFO Executor: Finished task 0.0 in stage 78.0 (TID 228). 1385 bytes result sent to driver
18/02/28 13:30:36 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 228) in 16 ms on localhost (executor driver) (1/1)
18/02/28 13:30:36 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
18/02/28 13:30:36 INFO DAGScheduler: ResultStage 78 (collect at utils.scala:211) finished in 0.016 s
18/02/28 13:30:36 INFO DAGScheduler: Job 42 finished: collect at utils.scala:211, took 0.021160 s
18/02/28 13:30:36 INFO CodeGenerator: Code generated in 5.294191 ms
18/02/28 13:30:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:40 INFO SparkSqlParser: Parsing command: SELECT `month`, count(*) AS `n()`
FROM `cached_flights`
GROUP BY `month`
18/02/28 13:30:40 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:40 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:40 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:30:40 INFO DAGScheduler: Registering RDD 259 (collect at utils.scala:211)
18/02/28 13:30:40 INFO DAGScheduler: Got job 43 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:30:40 INFO DAGScheduler: Final stage: ResultStage 80 (collect at utils.scala:211)
18/02/28 13:30:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 79)
18/02/28 13:30:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 79)
18/02/28 13:30:40 INFO DAGScheduler: Submitting ShuffleMapStage 79 (MapPartitionsRDD[259] at collect at utils.scala:211), which has no missing parents
18/02/28 13:30:40 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 35.0 KB, free 283.3 MB)
18/02/28 13:30:40 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 16.0 KB, free 283.2 MB)
18/02/28 13:30:40 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 127.0.0.1:60941 (size: 16.0 KB, free: 288.8 MB)
18/02/28 13:30:40 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1006
18/02/28 13:30:40 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 79 (MapPartitionsRDD[259] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:30:40 INFO TaskSchedulerImpl: Adding task set 79.0 with 4 tasks
18/02/28 13:30:40 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 229, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:30:40 INFO TaskSetManager: Starting task 1.0 in stage 79.0 (TID 230, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:30:40 INFO TaskSetManager: Starting task 2.0 in stage 79.0 (TID 231, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:30:40 INFO TaskSetManager: Starting task 3.0 in stage 79.0 (TID 232, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:30:40 INFO Executor: Running task 0.0 in stage 79.0 (TID 229)
18/02/28 13:30:40 INFO Executor: Running task 1.0 in stage 79.0 (TID 230)
18/02/28 13:30:40 INFO BlockManager: Found block rdd_236_0 locally
18/02/28 13:30:40 INFO BlockManager: Found block rdd_236_1 locally
18/02/28 13:30:40 INFO Executor: Running task 2.0 in stage 79.0 (TID 231)
18/02/28 13:30:40 INFO BlockManager: Found block rdd_236_2 locally
18/02/28 13:30:40 INFO Executor: Running task 3.0 in stage 79.0 (TID 232)
18/02/28 13:30:40 INFO BlockManager: Found block rdd_236_3 locally
18/02/28 13:30:40 INFO Executor: Finished task 3.0 in stage 79.0 (TID 232). 1968 bytes result sent to driver
18/02/28 13:30:40 INFO TaskSetManager: Finished task 3.0 in stage 79.0 (TID 232) in 53 ms on localhost (executor driver) (1/4)
18/02/28 13:30:40 INFO Executor: Finished task 2.0 in stage 79.0 (TID 231). 1968 bytes result sent to driver
18/02/28 13:30:40 INFO TaskSetManager: Finished task 2.0 in stage 79.0 (TID 231) in 63 ms on localhost (executor driver) (2/4)
18/02/28 13:30:40 INFO Executor: Finished task 0.0 in stage 79.0 (TID 229). 1968 bytes result sent to driver
18/02/28 13:30:40 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 229) in 65 ms on localhost (executor driver) (3/4)
18/02/28 13:30:40 INFO Executor: Finished task 1.0 in stage 79.0 (TID 230). 1968 bytes result sent to driver
18/02/28 13:30:40 INFO TaskSetManager: Finished task 1.0 in stage 79.0 (TID 230) in 67 ms on localhost (executor driver) (4/4)
18/02/28 13:30:40 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
18/02/28 13:30:40 INFO DAGScheduler: ShuffleMapStage 79 (collect at utils.scala:211) finished in 0.067 s
18/02/28 13:30:40 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:30:40 INFO DAGScheduler: running: Set()
18/02/28 13:30:40 INFO DAGScheduler: waiting: Set(ResultStage 80)
18/02/28 13:30:40 INFO DAGScheduler: failed: Set()
18/02/28 13:30:40 INFO DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[262] at collect at utils.scala:211), which has no missing parents
18/02/28 13:30:40 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 17.6 KB, free 283.2 MB)
18/02/28 13:30:40 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 8.2 KB, free 283.2 MB)
18/02/28 13:30:40 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 127.0.0.1:60941 (size: 8.2 KB, free: 288.8 MB)
18/02/28 13:30:40 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1006
18/02/28 13:30:40 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 80 (MapPartitionsRDD[262] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:30:40 INFO TaskSchedulerImpl: Adding task set 80.0 with 4 tasks
18/02/28 13:30:40 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 233, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:30:40 INFO TaskSetManager: Starting task 1.0 in stage 80.0 (TID 234, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 13:30:40 INFO TaskSetManager: Starting task 2.0 in stage 80.0 (TID 235, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 13:30:40 INFO TaskSetManager: Starting task 3.0 in stage 80.0 (TID 236, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 13:30:40 INFO Executor: Running task 0.0 in stage 80.0 (TID 233)
18/02/28 13:30:40 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 13:30:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:30:40 INFO Executor: Finished task 0.0 in stage 80.0 (TID 233). 2238 bytes result sent to driver
18/02/28 13:30:40 INFO Executor: Running task 1.0 in stage 80.0 (TID 234)
18/02/28 13:30:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 13:30:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:30:40 INFO Executor: Finished task 1.0 in stage 80.0 (TID 234). 2220 bytes result sent to driver
18/02/28 13:30:40 INFO Executor: Running task 2.0 in stage 80.0 (TID 235)
18/02/28 13:30:40 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 13:30:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:30:40 INFO Executor: Finished task 2.0 in stage 80.0 (TID 235). 2238 bytes result sent to driver
18/02/28 13:30:40 INFO Executor: Running task 3.0 in stage 80.0 (TID 236)
18/02/28 13:30:40 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 233) in 14 ms on localhost (executor driver) (1/4)
18/02/28 13:30:40 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:30:40 INFO TaskSetManager: Finished task 1.0 in stage 80.0 (TID 234) in 15 ms on localhost (executor driver) (2/4)
18/02/28 13:30:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:30:40 INFO TaskSetManager: Finished task 2.0 in stage 80.0 (TID 235) in 15 ms on localhost (executor driver) (3/4)
18/02/28 13:30:40 INFO Executor: Finished task 3.0 in stage 80.0 (TID 236). 2297 bytes result sent to driver
18/02/28 13:30:40 INFO TaskSetManager: Finished task 3.0 in stage 80.0 (TID 236) in 17 ms on localhost (executor driver) (4/4)
18/02/28 13:30:40 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
18/02/28 13:30:40 INFO DAGScheduler: ResultStage 80 (collect at utils.scala:211) finished in 0.019 s
18/02/28 13:30:40 INFO DAGScheduler: Job 43 finished: collect at utils.scala:211, took 0.094145 s
18/02/28 13:30:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:30:45 INFO SparkSqlParser: Parsing command: SELECT `x`, `y`, count(*) AS `fillname`
FROM (SELECT `month`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`, (max(`dep_time`) OVER () - min(`dep_time`) OVER () / 100.0 * CASE WHEN (CAST(FLOOR((`dep_time` - min(`dep_time`) OVER ()) / max(`dep_time`) OVER () - min(`dep_time`) OVER () / 100.0) AS INT) = 100.0) THEN (CAST(FLOOR((`dep_time` - min(`dep_time`) OVER ()) / max(`dep_time`) OVER () - min(`dep_time`) OVER () / 100.0) AS INT) - 1.0) WHEN NOT(CAST(FLOOR((`dep_time` - min(`dep_time`) OVER ()) / max(`dep_time`) OVER () - min(`dep_time`) OVER () / 100.0) AS INT) = 100.0) THEN (CAST(FLOOR((`dep_time` - min(`dep_time`) OVER ()) / max(`dep_time`) OVER () - min(`dep_time`) OVER () / 100.0) AS INT)) END) + min(`dep_time`) OVER () AS `x`, (max(`arr_time`) OVER () - min(`arr_time`) OVER () / 100.0 * CASE WHEN (CAST(FLOOR((`arr_time` - min(`arr_time`) OVER ()) / max(`arr_time`) OVER () - min(`arr_time`) OVER () / 100.0) AS INT) = 100.0) THEN (CAST(FLOOR((`arr_time` - min(`arr_time`) OVER ()) / max(`arr_time`) OVER () - min(`arr_time`) OVER () / 100.0) AS INT) - 1.0) WHEN NOT(CAST(FLOOR((`arr_time` - min(`arr_time`) OVER ()) / max(`arr_time`) OVER () - min(`arr_time`) OVER () / 100.0) AS INT) = 100.0) THEN (CAST(FLOOR((`arr_time` - min(`arr_time`) OVER ()) / max(`arr_time`) OVER () - min(`arr_time`) OVER () / 100.0) AS INT)) END) + min(`arr_time`) OVER () AS `y`
FROM `cached_flights`) `vlvvjslnvs`
GROUP BY `x`, `y`
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:30:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:30:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
18/02/28 13:30:45 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 127.0.0.1:60941 in memory (size: 11.2 KB, free: 288.8 MB)
18/02/28 13:30:45 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 127.0.0.1:60941 in memory (size: 16.0 KB, free: 288.8 MB)
18/02/28 13:30:45 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 288.8 MB)
18/02/28 13:30:45 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 288.8 MB)
18/02/28 13:30:45 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 127.0.0.1:60941 in memory (size: 8.2 KB, free: 288.8 MB)
18/02/28 13:30:45 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 288.8 MB)
18/02/28 13:30:45 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 127.0.0.1:60941 in memory (size: 11.2 KB, free: 288.8 MB)
18/02/28 13:30:45 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 127.0.0.1:60941 in memory (size: 9.8 KB, free: 288.8 MB)
18/02/28 13:30:45 INFO ContextCleaner: Cleaned accumulator 2319
18/02/28 13:30:45 INFO ContextCleaner: Cleaned accumulator 2466
18/02/28 13:30:45 INFO ContextCleaner: Cleaned accumulator 2380
18/02/28 13:30:45 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:30:45 INFO DAGScheduler: Registering RDD 264 (collect at utils.scala:211)
18/02/28 13:30:45 INFO DAGScheduler: Got job 44 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:30:45 INFO DAGScheduler: Final stage: ResultStage 82 (collect at utils.scala:211)
18/02/28 13:30:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 81)
18/02/28 13:30:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 81)
18/02/28 13:30:45 INFO DAGScheduler: Submitting ShuffleMapStage 81 (MapPartitionsRDD[264] at collect at utils.scala:211), which has no missing parents
18/02/28 13:30:45 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 21.7 KB, free 283.4 MB)
18/02/28 13:30:45 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 10.4 KB, free 283.4 MB)
18/02/28 13:30:45 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 127.0.0.1:60941 (size: 10.4 KB, free: 288.8 MB)
18/02/28 13:30:45 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1006
18/02/28 13:30:45 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 81 (MapPartitionsRDD[264] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:30:45 INFO TaskSchedulerImpl: Adding task set 81.0 with 4 tasks
18/02/28 13:30:45 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 237, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:30:45 INFO TaskSetManager: Starting task 1.0 in stage 81.0 (TID 238, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:30:45 INFO TaskSetManager: Starting task 2.0 in stage 81.0 (TID 239, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:30:45 INFO TaskSetManager: Starting task 3.0 in stage 81.0 (TID 240, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:30:45 INFO Executor: Running task 0.0 in stage 81.0 (TID 237)
18/02/28 13:30:45 INFO Executor: Running task 1.0 in stage 81.0 (TID 238)
18/02/28 13:30:45 INFO Executor: Running task 2.0 in stage 81.0 (TID 239)
18/02/28 13:30:45 INFO Executor: Running task 3.0 in stage 81.0 (TID 240)
18/02/28 13:30:45 INFO BlockManager: Found block rdd_236_0 locally
18/02/28 13:30:45 INFO BlockManager: Found block rdd_236_3 locally
18/02/28 13:30:45 INFO BlockManager: Found block rdd_236_1 locally
18/02/28 13:30:45 INFO BlockManager: Found block rdd_236_2 locally
18/02/28 13:30:45 INFO Executor: Finished task 3.0 in stage 81.0 (TID 240). 1489 bytes result sent to driver
18/02/28 13:30:45 INFO TaskSetManager: Finished task 3.0 in stage 81.0 (TID 240) in 54 ms on localhost (executor driver) (1/4)
18/02/28 13:30:45 INFO Executor: Finished task 1.0 in stage 81.0 (TID 238). 1532 bytes result sent to driver
18/02/28 13:30:45 INFO TaskSetManager: Finished task 1.0 in stage 81.0 (TID 238) in 58 ms on localhost (executor driver) (2/4)
18/02/28 13:30:45 INFO Executor: Finished task 2.0 in stage 81.0 (TID 239). 1489 bytes result sent to driver
18/02/28 13:30:45 INFO TaskSetManager: Finished task 2.0 in stage 81.0 (TID 239) in 63 ms on localhost (executor driver) (3/4)
18/02/28 13:30:45 INFO Executor: Finished task 0.0 in stage 81.0 (TID 237). 1532 bytes result sent to driver
18/02/28 13:30:45 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 237) in 70 ms on localhost (executor driver) (4/4)
18/02/28 13:30:45 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
18/02/28 13:30:45 INFO DAGScheduler: ShuffleMapStage 81 (collect at utils.scala:211) finished in 0.071 s
18/02/28 13:30:45 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:30:45 INFO DAGScheduler: running: Set()
18/02/28 13:30:45 INFO DAGScheduler: waiting: Set(ResultStage 82)
18/02/28 13:30:45 INFO DAGScheduler: failed: Set()
18/02/28 13:30:45 INFO DAGScheduler: Submitting ResultStage 82 (MapPartitionsRDD[268] at collect at utils.scala:211), which has no missing parents
18/02/28 13:30:45 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 71.3 KB, free 283.3 MB)
18/02/28 13:30:45 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 24.6 KB, free 283.3 MB)
18/02/28 13:30:45 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 127.0.0.1:60941 (size: 24.6 KB, free: 288.8 MB)
18/02/28 13:30:45 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1006
18/02/28 13:30:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 82 (MapPartitionsRDD[268] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:30:45 INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks
18/02/28 13:30:45 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 241, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:30:45 INFO Executor: Running task 0.0 in stage 82.0 (TID 241)
18/02/28 13:30:45 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:30:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:30:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
18/02/28 13:30:45 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:45 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (0  time so far)
18/02/28 13:30:45 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:45 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (1  time so far)
18/02/28 13:30:45 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:45 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (2  times so far)
18/02/28 13:30:45 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:45 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (3  times so far)
18/02/28 13:30:45 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:45 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (4  times so far)
18/02/28 13:30:45 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:45 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (5  times so far)
18/02/28 13:30:45 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:45 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (6  times so far)
18/02/28 13:30:45 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:45 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (7  times so far)
18/02/28 13:30:45 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:45 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (8  times so far)
18/02/28 13:30:45 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:45 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (9  times so far)
18/02/28 13:30:45 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:45 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (10  times so far)
18/02/28 13:30:45 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:45 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (11  times so far)
18/02/28 13:30:45 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:45 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (12  times so far)
18/02/28 13:30:45 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:45 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (13  times so far)
18/02/28 13:30:45 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:45 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (14  times so far)
18/02/28 13:30:45 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:45 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (15  times so far)
18/02/28 13:30:45 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:45 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (16  times so far)
18/02/28 13:30:45 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:45 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (17  times so far)
18/02/28 13:30:45 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:45 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (18  times so far)
18/02/28 13:30:45 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:45 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (19  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (20  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (21  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (22  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (23  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (24  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (25  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (26  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (27  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (28  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (29  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (30  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (31  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (32  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (33  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (34  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (35  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (36  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (37  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (38  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (39  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (40  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (41  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (42  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (43  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (44  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (45  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (46  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (47  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (48  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (49  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (50  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (51  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (52  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (53  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (54  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (55  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (56  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (57  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (58  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (59  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (60  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (61  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (62  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (63  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (64  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (65  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (66  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (67  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (68  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (69  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (70  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (71  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (72  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (73  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (74  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (75  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (76  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (77  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (78  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (79  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (80  times so far)
18/02/28 13:30:46 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:30:46 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (81  times so far)
18/02/28 13:30:46 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 127.0.0.1:60941 in memory (size: 10.4 KB, free: 288.8 MB)
18/02/28 13:30:47 INFO Executor: Finished task 0.0 in stage 82.0 (TID 241). 2339 bytes result sent to driver
18/02/28 13:30:47 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 241) in 1437 ms on localhost (executor driver) (1/1)
18/02/28 13:30:47 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
18/02/28 13:30:47 INFO DAGScheduler: ResultStage 82 (collect at utils.scala:211) finished in 1.437 s
18/02/28 13:30:47 INFO DAGScheduler: Job 44 finished: collect at utils.scala:211, took 1.514678 s
18/02/28 13:31:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:31:11 INFO SparkSqlParser: Parsing command: SELECT `x`, count(*) AS `n`
FROM (SELECT `month`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`, (max(`distance`) OVER () - min(`distance`) OVER () / 30.0 * CASE WHEN (CAST(FLOOR((`distance` - min(`distance`) OVER ()) / max(`distance`) OVER () - min(`distance`) OVER () / 30.0) AS INT) = 30.0) THEN (CAST(FLOOR((`distance` - min(`distance`) OVER ()) / max(`distance`) OVER () - min(`distance`) OVER () / 30.0) AS INT) - 1.0) WHEN NOT(CAST(FLOOR((`distance` - min(`distance`) OVER ()) / max(`distance`) OVER () - min(`distance`) OVER () / 30.0) AS INT) = 30.0) THEN (CAST(FLOOR((`distance` - min(`distance`) OVER ()) / max(`distance`) OVER () - min(`distance`) OVER () / 30.0) AS INT)) END) + min(`distance`) OVER () AS `x`
FROM `cached_flights`) `wosucwrfjb`
GROUP BY `x`
18/02/28 13:31:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
18/02/28 13:31:11 INFO CodeGenerator: Code generated in 29.104293 ms
18/02/28 13:31:11 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:31:11 INFO DAGScheduler: Registering RDD 270 (collect at utils.scala:211)
18/02/28 13:31:11 INFO DAGScheduler: Got job 45 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:31:11 INFO DAGScheduler: Final stage: ResultStage 84 (collect at utils.scala:211)
18/02/28 13:31:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 83)
18/02/28 13:31:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 83)
18/02/28 13:31:11 INFO DAGScheduler: Submitting ShuffleMapStage 83 (MapPartitionsRDD[270] at collect at utils.scala:211), which has no missing parents
18/02/28 13:31:11 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 21.7 KB, free 283.3 MB)
18/02/28 13:31:11 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 10.4 KB, free 283.3 MB)
18/02/28 13:31:11 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 127.0.0.1:60941 (size: 10.4 KB, free: 288.8 MB)
18/02/28 13:31:11 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1006
18/02/28 13:31:11 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 83 (MapPartitionsRDD[270] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:31:11 INFO TaskSchedulerImpl: Adding task set 83.0 with 4 tasks
18/02/28 13:31:11 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 242, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:31:11 INFO TaskSetManager: Starting task 1.0 in stage 83.0 (TID 243, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:31:11 INFO TaskSetManager: Starting task 2.0 in stage 83.0 (TID 244, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:31:11 INFO TaskSetManager: Starting task 3.0 in stage 83.0 (TID 245, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:31:11 INFO Executor: Running task 0.0 in stage 83.0 (TID 242)
18/02/28 13:31:11 INFO Executor: Running task 1.0 in stage 83.0 (TID 243)
18/02/28 13:31:11 INFO Executor: Running task 2.0 in stage 83.0 (TID 244)
18/02/28 13:31:11 INFO Executor: Running task 3.0 in stage 83.0 (TID 245)
18/02/28 13:31:11 INFO BlockManager: Found block rdd_236_1 locally
18/02/28 13:31:11 INFO BlockManager: Found block rdd_236_3 locally
18/02/28 13:31:11 INFO BlockManager: Found block rdd_236_0 locally
18/02/28 13:31:11 INFO BlockManager: Found block rdd_236_2 locally
18/02/28 13:31:11 INFO Executor: Finished task 3.0 in stage 83.0 (TID 245). 1489 bytes result sent to driver
18/02/28 13:31:11 INFO TaskSetManager: Finished task 3.0 in stage 83.0 (TID 245) in 45 ms on localhost (executor driver) (1/4)
18/02/28 13:31:11 INFO Executor: Finished task 2.0 in stage 83.0 (TID 244). 1489 bytes result sent to driver
18/02/28 13:31:11 INFO TaskSetManager: Finished task 2.0 in stage 83.0 (TID 244) in 54 ms on localhost (executor driver) (2/4)
18/02/28 13:31:11 INFO Executor: Finished task 1.0 in stage 83.0 (TID 243). 1489 bytes result sent to driver
18/02/28 13:31:11 INFO TaskSetManager: Finished task 1.0 in stage 83.0 (TID 243) in 59 ms on localhost (executor driver) (3/4)
18/02/28 13:31:11 INFO Executor: Finished task 0.0 in stage 83.0 (TID 242). 1489 bytes result sent to driver
18/02/28 13:31:11 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 242) in 62 ms on localhost (executor driver) (4/4)
18/02/28 13:31:11 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool 
18/02/28 13:31:11 INFO DAGScheduler: ShuffleMapStage 83 (collect at utils.scala:211) finished in 0.062 s
18/02/28 13:31:11 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:31:11 INFO DAGScheduler: running: Set()
18/02/28 13:31:11 INFO DAGScheduler: waiting: Set(ResultStage 84)
18/02/28 13:31:11 INFO DAGScheduler: failed: Set()
18/02/28 13:31:11 INFO DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[274] at collect at utils.scala:211), which has no missing parents
18/02/28 13:31:11 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 51.2 KB, free 283.2 MB)
18/02/28 13:31:11 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 19.6 KB, free 283.2 MB)
18/02/28 13:31:11 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 127.0.0.1:60941 (size: 19.6 KB, free: 288.8 MB)
18/02/28 13:31:11 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1006
18/02/28 13:31:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[274] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:31:11 INFO TaskSchedulerImpl: Adding task set 84.0 with 1 tasks
18/02/28 13:31:11 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 246, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:31:11 INFO Executor: Running task 0.0 in stage 84.0 (TID 246)
18/02/28 13:31:11 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:31:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:31:11 INFO CodeGenerator: Code generated in 5.525155 ms
18/02/28 13:31:11 INFO CodeGenerator: Code generated in 8.495598 ms
18/02/28 13:31:11 INFO CodeGenerator: Code generated in 15.098703 ms
18/02/28 13:31:11 INFO CodeGenerator: Code generated in 10.629283 ms
18/02/28 13:31:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
18/02/28 13:31:11 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:11 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (0  time so far)
18/02/28 13:31:11 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:11 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (1  time so far)
18/02/28 13:31:11 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:11 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (2  times so far)
18/02/28 13:31:11 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:11 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (3  times so far)
18/02/28 13:31:11 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:11 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (4  times so far)
18/02/28 13:31:11 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:11 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (5  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (6  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (7  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (8  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (9  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (10  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (11  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (12  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (13  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (14  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (15  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (16  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (17  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (18  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (19  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (20  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (21  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (22  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (23  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (24  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (25  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (26  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (27  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (28  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (29  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (30  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (31  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (32  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (33  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (34  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (35  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (36  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (37  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (38  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (39  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (40  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (41  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (42  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (43  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (44  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (45  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (46  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (47  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (48  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (49  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (50  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (51  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (52  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (53  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (54  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (55  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (56  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (57  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (58  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (59  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (60  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (61  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (62  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (63  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (64  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (65  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (66  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (67  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (68  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (69  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (70  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (71  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (72  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (73  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (74  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (75  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (76  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (77  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (78  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (79  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (80  times so far)
18/02/28 13:31:12 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:12 INFO UnsafeExternalSorter: Thread 186 spilling sort data of 4.1 MB to disk (81  times so far)
18/02/28 13:31:12 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 127.0.0.1:60941 in memory (size: 10.4 KB, free: 288.8 MB)
18/02/28 13:31:13 INFO Executor: Finished task 0.0 in stage 84.0 (TID 246). 2281 bytes result sent to driver
18/02/28 13:31:13 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 246) in 1421 ms on localhost (executor driver) (1/1)
18/02/28 13:31:13 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
18/02/28 13:31:13 INFO DAGScheduler: ResultStage 84 (collect at utils.scala:211) finished in 1.421 s
18/02/28 13:31:13 INFO DAGScheduler: Job 45 finished: collect at utils.scala:211, took 1.493267 s
18/02/28 13:31:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:31:45 INFO SparkSqlParser: Parsing command: SELECT `month`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`
FROM (SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`dep_time` AS DOUBLE) AS `dep_time`, CAST(`arr_time` AS DOUBLE) AS `arr_time`, CAST(`arr_delay` AS DOUBLE) AS `arr_delay`, CAST(`dep_delay` AS DOUBLE) AS `dep_delay`, CAST(`distance` AS DOUBLE) AS `distance`
FROM (SELECT `month`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`
FROM `spark_flights`) `crgorzcvwl`) `anqczvwwpu`
18/02/28 13:31:45 INFO SparkSqlParser: Parsing command: cached_flights
18/02/28 13:31:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:31:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights` AS `zzz73`
WHERE (0 = 1)
18/02/28 13:31:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:31:45 INFO SparkSqlParser: Parsing command: CACHE TABLE `cached_flights`
18/02/28 13:31:45 INFO SparkSqlParser: Parsing command: `cached_flights`
18/02/28 13:31:45 WARN CacheManager: Asked to cache already cached data.
18/02/28 13:31:45 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 13:31:45 INFO DAGScheduler: Registering RDD 277 (sql at <unknown>:0)
18/02/28 13:31:45 INFO DAGScheduler: Got job 46 (sql at <unknown>:0) with 1 output partitions
18/02/28 13:31:45 INFO DAGScheduler: Final stage: ResultStage 86 (sql at <unknown>:0)
18/02/28 13:31:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 85)
18/02/28 13:31:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 85)
18/02/28 13:31:45 INFO DAGScheduler: Submitting ShuffleMapStage 85 (MapPartitionsRDD[277] at sql at <unknown>:0), which has no missing parents
18/02/28 13:31:45 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 24.5 KB, free 283.2 MB)
18/02/28 13:31:45 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 11.3 KB, free 283.2 MB)
18/02/28 13:31:45 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 127.0.0.1:60941 (size: 11.3 KB, free: 288.8 MB)
18/02/28 13:31:45 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1006
18/02/28 13:31:45 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 85 (MapPartitionsRDD[277] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:31:45 INFO TaskSchedulerImpl: Adding task set 85.0 with 4 tasks
18/02/28 13:31:45 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 247, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:31:45 INFO TaskSetManager: Starting task 1.0 in stage 85.0 (TID 248, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:31:45 INFO TaskSetManager: Starting task 2.0 in stage 85.0 (TID 249, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:31:45 INFO TaskSetManager: Starting task 3.0 in stage 85.0 (TID 250, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:31:45 INFO Executor: Running task 1.0 in stage 85.0 (TID 248)
18/02/28 13:31:45 INFO Executor: Running task 0.0 in stage 85.0 (TID 247)
18/02/28 13:31:45 INFO Executor: Running task 2.0 in stage 85.0 (TID 249)
18/02/28 13:31:45 INFO BlockManager: Found block rdd_236_1 locally
18/02/28 13:31:45 INFO BlockManager: Found block rdd_236_2 locally
18/02/28 13:31:45 INFO Executor: Running task 3.0 in stage 85.0 (TID 250)
18/02/28 13:31:45 INFO BlockManager: Found block rdd_236_3 locally
18/02/28 13:31:45 INFO BlockManager: Found block rdd_236_0 locally
18/02/28 13:31:45 INFO Executor: Finished task 2.0 in stage 85.0 (TID 249). 1694 bytes result sent to driver
18/02/28 13:31:45 INFO TaskSetManager: Finished task 2.0 in stage 85.0 (TID 249) in 23 ms on localhost (executor driver) (1/4)
18/02/28 13:31:45 INFO Executor: Finished task 3.0 in stage 85.0 (TID 250). 1694 bytes result sent to driver
18/02/28 13:31:45 INFO TaskSetManager: Finished task 3.0 in stage 85.0 (TID 250) in 27 ms on localhost (executor driver) (2/4)
18/02/28 13:31:45 INFO Executor: Finished task 0.0 in stage 85.0 (TID 247). 1694 bytes result sent to driver
18/02/28 13:31:45 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 247) in 29 ms on localhost (executor driver) (3/4)
18/02/28 13:31:45 INFO Executor: Finished task 1.0 in stage 85.0 (TID 248). 1694 bytes result sent to driver
18/02/28 13:31:45 INFO TaskSetManager: Finished task 1.0 in stage 85.0 (TID 248) in 32 ms on localhost (executor driver) (4/4)
18/02/28 13:31:45 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool 
18/02/28 13:31:45 INFO DAGScheduler: ShuffleMapStage 85 (sql at <unknown>:0) finished in 0.032 s
18/02/28 13:31:45 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:31:45 INFO DAGScheduler: running: Set()
18/02/28 13:31:45 INFO DAGScheduler: waiting: Set(ResultStage 86)
18/02/28 13:31:45 INFO DAGScheduler: failed: Set()
18/02/28 13:31:45 INFO DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[280] at sql at <unknown>:0), which has no missing parents
18/02/28 13:31:45 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 7.0 KB, free 283.2 MB)
18/02/28 13:31:45 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 3.7 KB, free 283.2 MB)
18/02/28 13:31:45 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 288.8 MB)
18/02/28 13:31:45 INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1006
18/02/28 13:31:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 86 (MapPartitionsRDD[280] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 13:31:45 INFO TaskSchedulerImpl: Adding task set 86.0 with 1 tasks
18/02/28 13:31:45 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 251, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:31:45 INFO Executor: Running task 0.0 in stage 86.0 (TID 251)
18/02/28 13:31:45 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:31:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:31:45 INFO Executor: Finished task 0.0 in stage 86.0 (TID 251). 1495 bytes result sent to driver
18/02/28 13:31:45 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 251) in 3 ms on localhost (executor driver) (1/1)
18/02/28 13:31:45 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
18/02/28 13:31:45 INFO DAGScheduler: ResultStage 86 (sql at <unknown>:0) finished in 0.003 s
18/02/28 13:31:45 INFO DAGScheduler: Job 46 finished: sql at <unknown>:0, took 0.043016 s
18/02/28 13:31:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:31:45 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `cached_flights`
18/02/28 13:31:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:45 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:31:45 INFO DAGScheduler: Registering RDD 283 (collect at utils.scala:211)
18/02/28 13:31:45 INFO DAGScheduler: Got job 47 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:31:45 INFO DAGScheduler: Final stage: ResultStage 88 (collect at utils.scala:211)
18/02/28 13:31:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 87)
18/02/28 13:31:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 87)
18/02/28 13:31:45 INFO DAGScheduler: Submitting ShuffleMapStage 87 (MapPartitionsRDD[283] at collect at utils.scala:211), which has no missing parents
18/02/28 13:31:45 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 24.5 KB, free 283.2 MB)
18/02/28 13:31:45 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 11.2 KB, free 283.2 MB)
18/02/28 13:31:45 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 127.0.0.1:60941 (size: 11.2 KB, free: 288.8 MB)
18/02/28 13:31:45 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1006
18/02/28 13:31:45 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 87 (MapPartitionsRDD[283] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:31:45 INFO TaskSchedulerImpl: Adding task set 87.0 with 4 tasks
18/02/28 13:31:45 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 252, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:31:45 INFO TaskSetManager: Starting task 1.0 in stage 87.0 (TID 253, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:31:45 INFO TaskSetManager: Starting task 2.0 in stage 87.0 (TID 254, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:31:45 INFO TaskSetManager: Starting task 3.0 in stage 87.0 (TID 255, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:31:45 INFO Executor: Running task 0.0 in stage 87.0 (TID 252)
18/02/28 13:31:45 INFO Executor: Running task 1.0 in stage 87.0 (TID 253)
18/02/28 13:31:45 INFO Executor: Running task 3.0 in stage 87.0 (TID 255)
18/02/28 13:31:45 INFO BlockManager: Found block rdd_236_0 locally
18/02/28 13:31:45 INFO Executor: Running task 2.0 in stage 87.0 (TID 254)
18/02/28 13:31:45 INFO BlockManager: Found block rdd_236_1 locally
18/02/28 13:31:45 INFO BlockManager: Found block rdd_236_3 locally
18/02/28 13:31:45 INFO BlockManager: Found block rdd_236_2 locally
18/02/28 13:31:45 INFO Executor: Finished task 1.0 in stage 87.0 (TID 253). 1737 bytes result sent to driver
18/02/28 13:31:45 INFO TaskSetManager: Finished task 1.0 in stage 87.0 (TID 253) in 18 ms on localhost (executor driver) (1/4)
18/02/28 13:31:45 INFO Executor: Finished task 2.0 in stage 87.0 (TID 254). 1780 bytes result sent to driver
18/02/28 13:31:45 INFO TaskSetManager: Finished task 2.0 in stage 87.0 (TID 254) in 21 ms on localhost (executor driver) (2/4)
18/02/28 13:31:45 INFO Executor: Finished task 3.0 in stage 87.0 (TID 255). 1737 bytes result sent to driver
18/02/28 13:31:45 INFO TaskSetManager: Finished task 3.0 in stage 87.0 (TID 255) in 23 ms on localhost (executor driver) (3/4)
18/02/28 13:31:45 INFO Executor: Finished task 0.0 in stage 87.0 (TID 252). 1694 bytes result sent to driver
18/02/28 13:31:45 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 252) in 26 ms on localhost (executor driver) (4/4)
18/02/28 13:31:45 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool 
18/02/28 13:31:45 INFO DAGScheduler: ShuffleMapStage 87 (collect at utils.scala:211) finished in 0.026 s
18/02/28 13:31:45 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:31:45 INFO DAGScheduler: running: Set()
18/02/28 13:31:45 INFO DAGScheduler: waiting: Set(ResultStage 88)
18/02/28 13:31:45 INFO DAGScheduler: failed: Set()
18/02/28 13:31:45 INFO DAGScheduler: Submitting ResultStage 88 (MapPartitionsRDD[286] at collect at utils.scala:211), which has no missing parents
18/02/28 13:31:45 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 7.0 KB, free 283.2 MB)
18/02/28 13:31:45 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 3.7 KB, free 283.2 MB)
18/02/28 13:31:45 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 288.8 MB)
18/02/28 13:31:45 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1006
18/02/28 13:31:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 88 (MapPartitionsRDD[286] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:31:45 INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks
18/02/28 13:31:45 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 256, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:31:45 INFO Executor: Running task 0.0 in stage 88.0 (TID 256)
18/02/28 13:31:45 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:31:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:31:45 INFO Executor: Finished task 0.0 in stage 88.0 (TID 256). 1452 bytes result sent to driver
18/02/28 13:31:45 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 256) in 3 ms on localhost (executor driver) (1/1)
18/02/28 13:31:45 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
18/02/28 13:31:45 INFO DAGScheduler: ResultStage 88 (collect at utils.scala:211) finished in 0.004 s
18/02/28 13:31:45 INFO DAGScheduler: Job 47 finished: collect at utils.scala:211, took 0.038494 s
18/02/28 13:31:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:31:45 INFO SparkSqlParser: Parsing command: SHOW TABLES LIKE"cached_flights"
18/02/28 13:31:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:45 INFO HiveMetaStore: 0: get_tables: db=default pat=cached_flights
18/02/28 13:31:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=cached_flights	
18/02/28 13:31:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:31:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights` AS `zzz74`
WHERE (0 = 1)
18/02/28 13:31:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:31:45 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 13:31:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:45 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:45 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 13:31:45 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 13:31:45 INFO ContextCleaner: Cleaned accumulator 2656
18/02/28 13:31:45 INFO ContextCleaner: Cleaned accumulator 2652
18/02/28 13:31:45 INFO ContextCleaner: Cleaned accumulator 2655
18/02/28 13:31:45 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 127.0.0.1:60941 in memory (size: 11.3 KB, free: 288.8 MB)
18/02/28 13:31:45 INFO ContextCleaner: Cleaned accumulator 2706
18/02/28 13:31:45 INFO ContextCleaner: Cleaned accumulator 2647
18/02/28 13:31:45 INFO ContextCleaner: Cleaned accumulator 2651
18/02/28 13:31:45 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 127.0.0.1:60941 in memory (size: 11.2 KB, free: 288.8 MB)
18/02/28 13:31:45 INFO ContextCleaner: Cleaned shuffle 39
18/02/28 13:31:45 INFO ContextCleaner: Cleaned accumulator 2648
18/02/28 13:31:45 INFO ContextCleaner: Cleaned accumulator 2650
18/02/28 13:31:45 INFO ContextCleaner: Cleaned accumulator 2645
18/02/28 13:31:45 INFO ContextCleaner: Cleaned accumulator 2646
18/02/28 13:31:45 INFO ContextCleaner: Cleaned accumulator 2654
18/02/28 13:31:45 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 288.8 MB)
18/02/28 13:31:45 INFO ContextCleaner: Cleaned accumulator 2657
18/02/28 13:31:45 INFO ContextCleaner: Cleaned accumulator 2649
18/02/28 13:31:45 INFO ContextCleaner: Cleaned accumulator 2653
18/02/28 13:31:45 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 288.8 MB)
18/02/28 13:31:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:31:59 INFO SparkSqlParser: Parsing command: SELECT `x`, count(*) AS `n`
FROM (SELECT `month`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`, (max(`distance`) OVER () - min(`distance`) OVER () / 30.0 * CASE WHEN (CAST(FLOOR((`distance` - min(`distance`) OVER ()) / max(`distance`) OVER () - min(`distance`) OVER () / 30.0) AS INT) = 30.0) THEN (CAST(FLOOR((`distance` - min(`distance`) OVER ()) / max(`distance`) OVER () - min(`distance`) OVER () / 30.0) AS INT) - 1.0) WHEN NOT(CAST(FLOOR((`distance` - min(`distance`) OVER ()) / max(`distance`) OVER () - min(`distance`) OVER () / 30.0) AS INT) = 30.0) THEN (CAST(FLOOR((`distance` - min(`distance`) OVER ()) / max(`distance`) OVER () - min(`distance`) OVER () / 30.0) AS INT)) END) + min(`distance`) OVER () AS `x`
FROM `cached_flights`) `ispalnjcxf`
GROUP BY `x`
18/02/28 13:31:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:31:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:31:59 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
18/02/28 13:31:59 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:31:59 INFO DAGScheduler: Registering RDD 288 (collect at utils.scala:211)
18/02/28 13:31:59 INFO DAGScheduler: Got job 48 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:31:59 INFO DAGScheduler: Final stage: ResultStage 90 (collect at utils.scala:211)
18/02/28 13:31:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 89)
18/02/28 13:31:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 89)
18/02/28 13:31:59 INFO DAGScheduler: Submitting ShuffleMapStage 89 (MapPartitionsRDD[288] at collect at utils.scala:211), which has no missing parents
18/02/28 13:31:59 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 21.8 KB, free 283.2 MB)
18/02/28 13:31:59 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 10.4 KB, free 283.2 MB)
18/02/28 13:31:59 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 127.0.0.1:60941 (size: 10.4 KB, free: 288.8 MB)
18/02/28 13:31:59 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1006
18/02/28 13:31:59 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 89 (MapPartitionsRDD[288] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:31:59 INFO TaskSchedulerImpl: Adding task set 89.0 with 4 tasks
18/02/28 13:31:59 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 257, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:31:59 INFO TaskSetManager: Starting task 1.0 in stage 89.0 (TID 258, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:31:59 INFO TaskSetManager: Starting task 2.0 in stage 89.0 (TID 259, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:31:59 INFO TaskSetManager: Starting task 3.0 in stage 89.0 (TID 260, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:31:59 INFO Executor: Running task 0.0 in stage 89.0 (TID 257)
18/02/28 13:31:59 INFO BlockManager: Found block rdd_236_0 locally
18/02/28 13:31:59 INFO Executor: Running task 1.0 in stage 89.0 (TID 258)
18/02/28 13:31:59 INFO BlockManager: Found block rdd_236_1 locally
18/02/28 13:31:59 INFO Executor: Running task 2.0 in stage 89.0 (TID 259)
18/02/28 13:31:59 INFO Executor: Running task 3.0 in stage 89.0 (TID 260)
18/02/28 13:31:59 INFO BlockManager: Found block rdd_236_2 locally
18/02/28 13:31:59 INFO BlockManager: Found block rdd_236_3 locally
18/02/28 13:31:59 INFO Executor: Finished task 0.0 in stage 89.0 (TID 257). 1489 bytes result sent to driver
18/02/28 13:31:59 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 257) in 55 ms on localhost (executor driver) (1/4)
18/02/28 13:31:59 INFO Executor: Finished task 3.0 in stage 89.0 (TID 260). 1489 bytes result sent to driver
18/02/28 13:31:59 INFO TaskSetManager: Finished task 3.0 in stage 89.0 (TID 260) in 55 ms on localhost (executor driver) (2/4)
18/02/28 13:31:59 INFO Executor: Finished task 2.0 in stage 89.0 (TID 259). 1489 bytes result sent to driver
18/02/28 13:31:59 INFO TaskSetManager: Finished task 2.0 in stage 89.0 (TID 259) in 60 ms on localhost (executor driver) (3/4)
18/02/28 13:31:59 INFO Executor: Finished task 1.0 in stage 89.0 (TID 258). 1489 bytes result sent to driver
18/02/28 13:31:59 INFO TaskSetManager: Finished task 1.0 in stage 89.0 (TID 258) in 62 ms on localhost (executor driver) (4/4)
18/02/28 13:31:59 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
18/02/28 13:31:59 INFO DAGScheduler: ShuffleMapStage 89 (collect at utils.scala:211) finished in 0.064 s
18/02/28 13:31:59 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:31:59 INFO DAGScheduler: running: Set()
18/02/28 13:31:59 INFO DAGScheduler: waiting: Set(ResultStage 90)
18/02/28 13:31:59 INFO DAGScheduler: failed: Set()
18/02/28 13:31:59 INFO DAGScheduler: Submitting ResultStage 90 (MapPartitionsRDD[292] at collect at utils.scala:211), which has no missing parents
18/02/28 13:31:59 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 51.2 KB, free 283.2 MB)
18/02/28 13:31:59 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 19.6 KB, free 283.2 MB)
18/02/28 13:31:59 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 127.0.0.1:60941 (size: 19.6 KB, free: 288.8 MB)
18/02/28 13:31:59 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1006
18/02/28 13:31:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 90 (MapPartitionsRDD[292] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:31:59 INFO TaskSchedulerImpl: Adding task set 90.0 with 1 tasks
18/02/28 13:31:59 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 261, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:31:59 INFO Executor: Running task 0.0 in stage 90.0 (TID 261)
18/02/28 13:31:59 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:31:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:31:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (0  time so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (1  time so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (2  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (3  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (4  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (5  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (6  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (7  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (8  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (9  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (10  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (11  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (12  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (13  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (14  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (15  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (16  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (17  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (18  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (19  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (20  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (21  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (22  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (23  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (24  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (25  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (26  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (27  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (28  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (29  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (30  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (31  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (32  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (33  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (34  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (35  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (36  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (37  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (38  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (39  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (40  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (41  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (42  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (43  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (44  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (45  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (46  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (47  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (48  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (49  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (50  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (51  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (52  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (53  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (54  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (55  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (56  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (57  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (58  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (59  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (60  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (61  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (62  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (63  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (64  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (65  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (66  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (67  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (68  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (69  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (70  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (71  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (72  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (73  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (74  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (75  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (76  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (77  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (78  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (79  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (80  times so far)
18/02/28 13:31:59 INFO UnsafeExternalSorter: Spilling data because number of spilledRecords crossed the threshold 4096
18/02/28 13:31:59 INFO UnsafeExternalSorter: Thread 185 spilling sort data of 4.1 MB to disk (81  times so far)
18/02/28 13:31:59 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 127.0.0.1:60941 in memory (size: 10.4 KB, free: 288.8 MB)
18/02/28 13:32:00 INFO Executor: Finished task 0.0 in stage 90.0 (TID 261). 2281 bytes result sent to driver
18/02/28 13:32:00 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 261) in 1148 ms on localhost (executor driver) (1/1)
18/02/28 13:32:00 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
18/02/28 13:32:00 INFO DAGScheduler: ResultStage 90 (collect at utils.scala:211) finished in 1.148 s
18/02/28 13:32:00 INFO DAGScheduler: Job 48 finished: collect at utils.scala:211, took 1.219659 s
18/02/28 13:33:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:33:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_flights`
18/02/28 13:33:25 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e01cb8f12
18/02/28 13:33:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:33:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e01cb8f12` AS `zzz75`
WHERE (0 = 1)
18/02/28 13:33:25 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e01d5012f8
18/02/28 13:33:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:33:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e01d5012f8` AS `zzz76`
WHERE (0 = 1)
18/02/28 13:33:25 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e04116f1
18/02/28 13:33:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:33:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e04116f1` AS `zzz77`
WHERE (0 = 1)
18/02/28 13:33:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:33:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
18/02/28 13:33:32 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e04984212d
18/02/28 13:33:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:33:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e04984212d` AS `zzz78`
WHERE (0 = 1)
18/02/28 13:33:32 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e04a94a21
18/02/28 13:33:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:33:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e04a94a21` AS `zzz79`
WHERE (0 = 1)
18/02/28 13:33:32 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e01c1a34cd
18/02/28 13:33:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:33:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e01c1a34cd` AS `zzz80`
WHERE (0 = 1)
18/02/28 13:33:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:33:38 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e04984212d`
18/02/28 13:33:38 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:33:38 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:33:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:33:38 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e04984212d`
18/02/28 13:33:38 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:33:38 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:33:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:33:38 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e04984212d`
18/02/28 13:33:38 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:33:38 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:33:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:33:38 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e04984212d`
18/02/28 13:33:38 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:33:38 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:33:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:33:38 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e04984212d`
18/02/28 13:33:38 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:33:38 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:33:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:33:38 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e04984212d`
LIMIT 1000
18/02/28 13:33:38 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:33:38 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:33:38 INFO CodeGenerator: Code generated in 10.148667 ms
18/02/28 13:33:38 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:33:38 INFO DAGScheduler: Registering RDD 295 (collect at utils.scala:211)
18/02/28 13:33:38 INFO DAGScheduler: Got job 49 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:33:38 INFO DAGScheduler: Final stage: ResultStage 92 (collect at utils.scala:211)
18/02/28 13:33:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 91)
18/02/28 13:33:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 91)
18/02/28 13:33:38 INFO DAGScheduler: Submitting ShuffleMapStage 91 (MapPartitionsRDD[295] at collect at utils.scala:211), which has no missing parents
18/02/28 13:33:38 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 32.1 KB, free 283.2 MB)
18/02/28 13:33:38 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 14.3 KB, free 283.1 MB)
18/02/28 13:33:38 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 127.0.0.1:60941 (size: 14.3 KB, free: 288.8 MB)
18/02/28 13:33:38 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1006
18/02/28 13:33:38 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 91 (MapPartitionsRDD[295] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:33:38 INFO TaskSchedulerImpl: Adding task set 91.0 with 4 tasks
18/02/28 13:33:38 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 262, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:33:38 INFO TaskSetManager: Starting task 1.0 in stage 91.0 (TID 263, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:33:38 INFO TaskSetManager: Starting task 2.0 in stage 91.0 (TID 264, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:33:38 INFO TaskSetManager: Starting task 3.0 in stage 91.0 (TID 265, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:33:38 INFO Executor: Running task 0.0 in stage 91.0 (TID 262)
18/02/28 13:33:38 INFO Executor: Running task 2.0 in stage 91.0 (TID 264)
18/02/28 13:33:38 INFO Executor: Running task 3.0 in stage 91.0 (TID 265)
18/02/28 13:33:38 INFO Executor: Running task 1.0 in stage 91.0 (TID 263)
18/02/28 13:33:38 INFO BlockManager: Found block rdd_236_1 locally
18/02/28 13:33:38 INFO BlockManager: Found block rdd_236_2 locally
18/02/28 13:33:38 INFO BlockManager: Found block rdd_236_0 locally
18/02/28 13:33:38 INFO BlockManager: Found block rdd_236_3 locally
18/02/28 13:33:38 INFO CodeGenerator: Code generated in 10.675829 ms
18/02/28 13:33:38 INFO CodeGenerator: Code generated in 6.71982 ms
18/02/28 13:33:39 INFO Executor: Finished task 2.0 in stage 91.0 (TID 264). 2303 bytes result sent to driver
18/02/28 13:33:39 INFO TaskSetManager: Finished task 2.0 in stage 91.0 (TID 264) in 614 ms on localhost (executor driver) (1/4)
18/02/28 13:33:39 INFO Executor: Finished task 3.0 in stage 91.0 (TID 265). 2303 bytes result sent to driver
18/02/28 13:33:39 INFO TaskSetManager: Finished task 3.0 in stage 91.0 (TID 265) in 616 ms on localhost (executor driver) (2/4)
18/02/28 13:33:39 INFO Executor: Finished task 1.0 in stage 91.0 (TID 263). 2303 bytes result sent to driver
18/02/28 13:33:39 INFO TaskSetManager: Finished task 1.0 in stage 91.0 (TID 263) in 621 ms on localhost (executor driver) (3/4)
18/02/28 13:33:39 INFO Executor: Finished task 0.0 in stage 91.0 (TID 262). 2303 bytes result sent to driver
18/02/28 13:33:39 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 262) in 623 ms on localhost (executor driver) (4/4)
18/02/28 13:33:39 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool 
18/02/28 13:33:39 INFO DAGScheduler: ShuffleMapStage 91 (collect at utils.scala:211) finished in 0.623 s
18/02/28 13:33:39 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:33:39 INFO DAGScheduler: running: Set()
18/02/28 13:33:39 INFO DAGScheduler: waiting: Set(ResultStage 92)
18/02/28 13:33:39 INFO DAGScheduler: failed: Set()
18/02/28 13:33:39 INFO DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[298] at collect at utils.scala:211), which has no missing parents
18/02/28 13:33:39 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 6.9 KB, free 283.1 MB)
18/02/28 13:33:39 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 3.7 KB, free 283.1 MB)
18/02/28 13:33:39 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 288.8 MB)
18/02/28 13:33:39 INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1006
18/02/28 13:33:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 92 (MapPartitionsRDD[298] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:33:39 INFO TaskSchedulerImpl: Adding task set 92.0 with 1 tasks
18/02/28 13:33:39 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 266, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:33:39 INFO Executor: Running task 0.0 in stage 92.0 (TID 266)
18/02/28 13:33:39 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:33:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:33:39 INFO Executor: Finished task 0.0 in stage 92.0 (TID 266). 1471 bytes result sent to driver
18/02/28 13:33:39 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 266) in 3 ms on localhost (executor driver) (1/1)
18/02/28 13:33:39 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
18/02/28 13:33:39 INFO DAGScheduler: ResultStage 92 (collect at utils.scala:211) finished in 0.003 s
18/02/28 13:33:39 INFO DAGScheduler: Job 49 finished: collect at utils.scala:211, took 0.635075 s
18/02/28 13:33:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:33:54 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e04984212d`
18/02/28 13:33:54 INFO SparkSqlParser: Parsing command: training
18/02/28 13:33:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:33:54 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training` AS `zzz81`
WHERE (0 = 1)
18/02/28 13:33:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:33:55 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 13:33:55 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:33:55 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:33:55 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:33:55 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:33:55 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 13:33:55 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 13:34:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:34:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e04984212d`
18/02/28 13:34:05 INFO SparkSqlParser: Parsing command: training
18/02/28 13:34:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:34:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training` AS `zzz82`
WHERE (0 = 1)
18/02/28 13:34:06 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:34:06 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 13:34:06 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:34:06 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:34:06 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:34:06 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:34:06 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 13:34:06 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 13:34:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:34:09 INFO SparkSqlParser: Parsing command: CACHE TABLE `training`
18/02/28 13:34:09 INFO SparkSqlParser: Parsing command: `training`
18/02/28 13:34:09 INFO CodeGenerator: Code generated in 8.297781 ms
18/02/28 13:34:09 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 13:34:09 INFO DAGScheduler: Registering RDD 304 (sql at <unknown>:0)
18/02/28 13:34:09 INFO DAGScheduler: Got job 50 (sql at <unknown>:0) with 1 output partitions
18/02/28 13:34:09 INFO DAGScheduler: Final stage: ResultStage 94 (sql at <unknown>:0)
18/02/28 13:34:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 93)
18/02/28 13:34:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 93)
18/02/28 13:34:09 INFO DAGScheduler: Submitting ShuffleMapStage 93 (MapPartitionsRDD[304] at sql at <unknown>:0), which has no missing parents
18/02/28 13:34:09 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 34.6 KB, free 283.1 MB)
18/02/28 13:34:09 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 14.9 KB, free 283.1 MB)
18/02/28 13:34:09 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 127.0.0.1:60941 (size: 14.9 KB, free: 288.8 MB)
18/02/28 13:34:09 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1006
18/02/28 13:34:09 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 93 (MapPartitionsRDD[304] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:34:09 INFO TaskSchedulerImpl: Adding task set 93.0 with 4 tasks
18/02/28 13:34:09 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 267, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:34:09 INFO TaskSetManager: Starting task 1.0 in stage 93.0 (TID 268, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:34:09 INFO TaskSetManager: Starting task 2.0 in stage 93.0 (TID 269, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:34:09 INFO TaskSetManager: Starting task 3.0 in stage 93.0 (TID 270, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:34:09 INFO Executor: Running task 0.0 in stage 93.0 (TID 267)
18/02/28 13:34:09 INFO Executor: Running task 1.0 in stage 93.0 (TID 268)
18/02/28 13:34:09 INFO Executor: Running task 2.0 in stage 93.0 (TID 269)
18/02/28 13:34:09 INFO Executor: Running task 3.0 in stage 93.0 (TID 270)
18/02/28 13:34:09 INFO BlockManager: Found block rdd_236_2 locally
18/02/28 13:34:09 INFO BlockManager: Found block rdd_236_0 locally
18/02/28 13:34:09 INFO BlockManager: Found block rdd_236_1 locally
18/02/28 13:34:09 INFO BlockManager: Found block rdd_236_3 locally
18/02/28 13:34:09 INFO MemoryStore: Block rdd_301_1 stored as values in memory (estimated size 401.4 KB, free 250.7 MB)
18/02/28 13:34:09 INFO BlockManagerInfo: Added rdd_301_1 in memory on 127.0.0.1:60941 (size: 401.4 KB, free: 288.4 MB)
18/02/28 13:34:09 INFO MemoryStore: Block rdd_301_2 stored as values in memory (estimated size 393.8 KB, free 269.9 MB)
18/02/28 13:34:09 INFO MemoryStore: Block rdd_301_3 stored as values in memory (estimated size 376.1 KB, free 269.9 MB)
18/02/28 13:34:09 INFO BlockManagerInfo: Added rdd_301_2 in memory on 127.0.0.1:60941 (size: 393.8 KB, free: 288.0 MB)
18/02/28 13:34:09 INFO BlockManagerInfo: Added rdd_301_3 in memory on 127.0.0.1:60941 (size: 376.1 KB, free: 287.6 MB)
18/02/28 13:34:09 INFO Executor: Finished task 3.0 in stage 93.0 (TID 270). 2994 bytes result sent to driver
18/02/28 13:34:09 INFO TaskSetManager: Finished task 3.0 in stage 93.0 (TID 270) in 172 ms on localhost (executor driver) (1/4)
18/02/28 13:34:09 INFO Executor: Finished task 1.0 in stage 93.0 (TID 268). 2994 bytes result sent to driver
18/02/28 13:34:09 INFO TaskSetManager: Finished task 1.0 in stage 93.0 (TID 268) in 176 ms on localhost (executor driver) (2/4)
18/02/28 13:34:09 INFO MemoryStore: Block rdd_301_0 stored as values in memory (estimated size 408.6 KB, free 281.5 MB)
18/02/28 13:34:09 INFO BlockManagerInfo: Added rdd_301_0 in memory on 127.0.0.1:60941 (size: 408.6 KB, free: 287.2 MB)
18/02/28 13:34:09 INFO Executor: Finished task 2.0 in stage 93.0 (TID 269). 2994 bytes result sent to driver
18/02/28 13:34:09 INFO TaskSetManager: Finished task 2.0 in stage 93.0 (TID 269) in 182 ms on localhost (executor driver) (3/4)
18/02/28 13:34:09 INFO Executor: Finished task 0.0 in stage 93.0 (TID 267). 2994 bytes result sent to driver
18/02/28 13:34:09 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 267) in 189 ms on localhost (executor driver) (4/4)
18/02/28 13:34:09 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool 
18/02/28 13:34:09 INFO DAGScheduler: ShuffleMapStage 93 (sql at <unknown>:0) finished in 0.192 s
18/02/28 13:34:09 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:34:09 INFO DAGScheduler: running: Set()
18/02/28 13:34:09 INFO DAGScheduler: waiting: Set(ResultStage 94)
18/02/28 13:34:09 INFO DAGScheduler: failed: Set()
18/02/28 13:34:09 INFO DAGScheduler: Submitting ResultStage 94 (MapPartitionsRDD[307] at sql at <unknown>:0), which has no missing parents
18/02/28 13:34:09 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 7.0 KB, free 281.5 MB)
18/02/28 13:34:09 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 3.7 KB, free 281.5 MB)
18/02/28 13:34:09 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 287.2 MB)
18/02/28 13:34:09 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1006
18/02/28 13:34:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 94 (MapPartitionsRDD[307] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 13:34:09 INFO TaskSchedulerImpl: Adding task set 94.0 with 1 tasks
18/02/28 13:34:09 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 271, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:34:09 INFO Executor: Running task 0.0 in stage 94.0 (TID 271)
18/02/28 13:34:09 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:34:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:34:09 INFO Executor: Finished task 0.0 in stage 94.0 (TID 271). 1495 bytes result sent to driver
18/02/28 13:34:09 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 271) in 4 ms on localhost (executor driver) (1/1)
18/02/28 13:34:09 INFO DAGScheduler: ResultStage 94 (sql at <unknown>:0) finished in 0.005 s
18/02/28 13:34:09 INFO DAGScheduler: Job 50 finished: sql at <unknown>:0, took 0.204550 s
18/02/28 13:34:09 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool 
18/02/28 13:34:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:34:09 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `training`
18/02/28 13:34:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:34:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:34:09 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:34:09 INFO DAGScheduler: Registering RDD 310 (collect at utils.scala:211)
18/02/28 13:34:09 INFO DAGScheduler: Got job 51 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:34:09 INFO DAGScheduler: Final stage: ResultStage 96 (collect at utils.scala:211)
18/02/28 13:34:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 95)
18/02/28 13:34:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 95)
18/02/28 13:34:09 INFO DAGScheduler: Submitting ShuffleMapStage 95 (MapPartitionsRDD[310] at collect at utils.scala:211), which has no missing parents
18/02/28 13:34:09 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 34.6 KB, free 281.5 MB)
18/02/28 13:34:09 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 15.0 KB, free 281.5 MB)
18/02/28 13:34:09 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 127.0.0.1:60941 (size: 15.0 KB, free: 287.2 MB)
18/02/28 13:34:09 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1006
18/02/28 13:34:09 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 95 (MapPartitionsRDD[310] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:34:09 INFO TaskSchedulerImpl: Adding task set 95.0 with 4 tasks
18/02/28 13:34:09 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 272, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:34:09 INFO TaskSetManager: Starting task 1.0 in stage 95.0 (TID 273, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:34:09 INFO TaskSetManager: Starting task 2.0 in stage 95.0 (TID 274, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:34:09 INFO TaskSetManager: Starting task 3.0 in stage 95.0 (TID 275, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:34:09 INFO Executor: Running task 0.0 in stage 95.0 (TID 272)
18/02/28 13:34:09 INFO Executor: Running task 2.0 in stage 95.0 (TID 274)
18/02/28 13:34:09 INFO Executor: Running task 3.0 in stage 95.0 (TID 275)
18/02/28 13:34:09 INFO Executor: Running task 1.0 in stage 95.0 (TID 273)
18/02/28 13:34:09 INFO BlockManager: Found block rdd_301_0 locally
18/02/28 13:34:09 INFO BlockManager: Found block rdd_301_1 locally
18/02/28 13:34:09 INFO BlockManager: Found block rdd_301_2 locally
18/02/28 13:34:09 INFO BlockManager: Found block rdd_301_3 locally
18/02/28 13:34:09 INFO Executor: Finished task 2.0 in stage 95.0 (TID 274). 2270 bytes result sent to driver
18/02/28 13:34:09 INFO TaskSetManager: Finished task 2.0 in stage 95.0 (TID 274) in 10 ms on localhost (executor driver) (1/4)
18/02/28 13:34:09 INFO Executor: Finished task 3.0 in stage 95.0 (TID 275). 2270 bytes result sent to driver
18/02/28 13:34:09 INFO TaskSetManager: Finished task 3.0 in stage 95.0 (TID 275) in 12 ms on localhost (executor driver) (2/4)
18/02/28 13:34:09 INFO Executor: Finished task 1.0 in stage 95.0 (TID 273). 2270 bytes result sent to driver
18/02/28 13:34:09 INFO TaskSetManager: Finished task 1.0 in stage 95.0 (TID 273) in 14 ms on localhost (executor driver) (3/4)
18/02/28 13:34:09 INFO Executor: Finished task 0.0 in stage 95.0 (TID 272). 2270 bytes result sent to driver
18/02/28 13:34:09 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 272) in 15 ms on localhost (executor driver) (4/4)
18/02/28 13:34:09 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool 
18/02/28 13:34:09 INFO DAGScheduler: ShuffleMapStage 95 (collect at utils.scala:211) finished in 0.015 s
18/02/28 13:34:09 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:34:09 INFO DAGScheduler: running: Set()
18/02/28 13:34:09 INFO DAGScheduler: waiting: Set(ResultStage 96)
18/02/28 13:34:09 INFO DAGScheduler: failed: Set()
18/02/28 13:34:09 INFO DAGScheduler: Submitting ResultStage 96 (MapPartitionsRDD[313] at collect at utils.scala:211), which has no missing parents
18/02/28 13:34:09 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 7.0 KB, free 281.5 MB)
18/02/28 13:34:09 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 3.7 KB, free 281.5 MB)
18/02/28 13:34:09 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 287.2 MB)
18/02/28 13:34:09 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1006
18/02/28 13:34:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 96 (MapPartitionsRDD[313] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:34:09 INFO TaskSchedulerImpl: Adding task set 96.0 with 1 tasks
18/02/28 13:34:09 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 276, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:34:09 INFO Executor: Running task 0.0 in stage 96.0 (TID 276)
18/02/28 13:34:09 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:34:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:34:09 INFO Executor: Finished task 0.0 in stage 96.0 (TID 276). 1495 bytes result sent to driver
18/02/28 13:34:09 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 276) in 5 ms on localhost (executor driver) (1/1)
18/02/28 13:34:09 INFO DAGScheduler: ResultStage 96 (collect at utils.scala:211) finished in 0.005 s
18/02/28 13:34:09 INFO DAGScheduler: Job 51 finished: collect at utils.scala:211, took 0.026901 s
18/02/28 13:34:09 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool 
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 2269
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 2268
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 2267
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 2902
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 2908
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 2906
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 2910
18/02/28 13:35:04 INFO ContextCleaner: Cleaned shuffle 43
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 2959
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 2907
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 2899
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 2909
18/02/28 13:35:04 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 127.0.0.1:60941 in memory (size: 14.3 KB, free: 287.2 MB)
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 2903
18/02/28 13:35:04 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 287.2 MB)
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 2901
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 2905
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 2900
18/02/28 13:35:04 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 127.0.0.1:60941 in memory (size: 15.0 KB, free: 287.2 MB)
18/02/28 13:35:04 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 127.0.0.1:60941 in memory (size: 14.9 KB, free: 287.2 MB)
18/02/28 13:35:04 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 287.2 MB)
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 2826
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 2904
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 2898
18/02/28 13:35:04 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 287.2 MB)
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 1911
18/02/28 13:35:04 INFO ContextCleaner: Cleaned shuffle 33
18/02/28 13:35:04 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 127.0.0.1:60941 in memory (size: 12.1 KB, free: 287.3 MB)
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 1902
18/02/28 13:35:04 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 127.0.0.1:60941 in memory (size: 24.6 KB, free: 287.3 MB)
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 2264
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 1907
18/02/28 13:35:04 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 127.0.0.1:60941 in memory (size: 19.6 KB, free: 287.3 MB)
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 1909
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 2260
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 2266
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 2265
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 1901
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 1900
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 2259
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 1903
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 2261
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 1908
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 1905
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 2270
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 2263
18/02/28 13:35:04 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 127.0.0.1:60941 in memory (size: 24.7 KB, free: 287.3 MB)
18/02/28 13:35:04 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 127.0.0.1:60941 in memory (size: 24.6 KB, free: 287.3 MB)
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 1904
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 1910
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 1906
18/02/28 13:35:04 INFO ContextCleaner: Cleaned shuffle 28
18/02/28 13:35:04 INFO ContextCleaner: Cleaned accumulator 2262
18/02/28 13:35:04 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 127.0.0.1:60941 in memory (size: 11.2 KB, free: 287.4 MB)
18/02/28 13:35:04 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 127.0.0.1:60941 in memory (size: 19.6 KB, free: 287.4 MB)
18/02/28 13:35:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:35:14 INFO SparkSqlParser: Parsing command: SELECT `month`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`
FROM (SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`dep_time` AS DOUBLE) AS `dep_time`, CAST(`arr_time` AS DOUBLE) AS `arr_time`, CAST(`arr_delay` AS DOUBLE) AS `arr_delay`, CAST(`dep_delay` AS DOUBLE) AS `dep_delay`, CAST(`distance` AS DOUBLE) AS `distance`
FROM (SELECT `month`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`
FROM `spark_flights`) `fvrlvxbssv`) `mpajortxml`
18/02/28 13:35:14 INFO SparkSqlParser: Parsing command: cached_flights
18/02/28 13:35:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:35:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights` AS `zzz83`
WHERE (0 = 1)
18/02/28 13:35:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:35:14 INFO SparkSqlParser: Parsing command: CACHE TABLE `cached_flights`
18/02/28 13:35:14 INFO SparkSqlParser: Parsing command: `cached_flights`
18/02/28 13:35:14 WARN CacheManager: Asked to cache already cached data.
18/02/28 13:35:14 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 13:35:14 INFO DAGScheduler: Registering RDD 316 (sql at <unknown>:0)
18/02/28 13:35:14 INFO DAGScheduler: Got job 52 (sql at <unknown>:0) with 1 output partitions
18/02/28 13:35:14 INFO DAGScheduler: Final stage: ResultStage 98 (sql at <unknown>:0)
18/02/28 13:35:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 97)
18/02/28 13:35:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 97)
18/02/28 13:35:14 INFO DAGScheduler: Submitting ShuffleMapStage 97 (MapPartitionsRDD[316] at sql at <unknown>:0), which has no missing parents
18/02/28 13:35:14 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 24.5 KB, free 282.1 MB)
18/02/28 13:35:14 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 11.2 KB, free 282.1 MB)
18/02/28 13:35:14 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 127.0.0.1:60941 (size: 11.2 KB, free: 287.4 MB)
18/02/28 13:35:14 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1006
18/02/28 13:35:14 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 97 (MapPartitionsRDD[316] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:35:14 INFO TaskSchedulerImpl: Adding task set 97.0 with 4 tasks
18/02/28 13:35:14 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 277, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:35:14 INFO TaskSetManager: Starting task 1.0 in stage 97.0 (TID 278, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:35:14 INFO TaskSetManager: Starting task 2.0 in stage 97.0 (TID 279, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:35:14 INFO TaskSetManager: Starting task 3.0 in stage 97.0 (TID 280, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:35:14 INFO Executor: Running task 2.0 in stage 97.0 (TID 279)
18/02/28 13:35:14 INFO Executor: Running task 3.0 in stage 97.0 (TID 280)
18/02/28 13:35:14 INFO Executor: Running task 0.0 in stage 97.0 (TID 277)
18/02/28 13:35:14 INFO Executor: Running task 1.0 in stage 97.0 (TID 278)
18/02/28 13:35:14 INFO BlockManager: Found block rdd_236_3 locally
18/02/28 13:35:14 INFO BlockManager: Found block rdd_236_2 locally
18/02/28 13:35:14 INFO BlockManager: Found block rdd_236_1 locally
18/02/28 13:35:14 INFO BlockManager: Found block rdd_236_0 locally
18/02/28 13:35:14 INFO Executor: Finished task 3.0 in stage 97.0 (TID 280). 1694 bytes result sent to driver
18/02/28 13:35:14 INFO TaskSetManager: Finished task 3.0 in stage 97.0 (TID 280) in 16 ms on localhost (executor driver) (1/4)
18/02/28 13:35:14 INFO Executor: Finished task 0.0 in stage 97.0 (TID 277). 1694 bytes result sent to driver
18/02/28 13:35:14 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 277) in 21 ms on localhost (executor driver) (2/4)
18/02/28 13:35:14 INFO Executor: Finished task 2.0 in stage 97.0 (TID 279). 1694 bytes result sent to driver
18/02/28 13:35:14 INFO TaskSetManager: Finished task 2.0 in stage 97.0 (TID 279) in 23 ms on localhost (executor driver) (3/4)
18/02/28 13:35:14 INFO Executor: Finished task 1.0 in stage 97.0 (TID 278). 1694 bytes result sent to driver
18/02/28 13:35:14 INFO TaskSetManager: Finished task 1.0 in stage 97.0 (TID 278) in 27 ms on localhost (executor driver) (4/4)
18/02/28 13:35:14 INFO DAGScheduler: ShuffleMapStage 97 (sql at <unknown>:0) finished in 0.027 s
18/02/28 13:35:14 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:35:14 INFO DAGScheduler: running: Set()
18/02/28 13:35:14 INFO DAGScheduler: waiting: Set(ResultStage 98)
18/02/28 13:35:14 INFO DAGScheduler: failed: Set()
18/02/28 13:35:14 INFO DAGScheduler: Submitting ResultStage 98 (MapPartitionsRDD[319] at sql at <unknown>:0), which has no missing parents
18/02/28 13:35:14 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 7.0 KB, free 282.1 MB)
18/02/28 13:35:14 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 3.7 KB, free 282.1 MB)
18/02/28 13:35:14 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool 
18/02/28 13:35:14 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 287.4 MB)
18/02/28 13:35:14 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1006
18/02/28 13:35:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 98 (MapPartitionsRDD[319] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 13:35:14 INFO TaskSchedulerImpl: Adding task set 98.0 with 1 tasks
18/02/28 13:35:14 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 281, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:35:14 INFO Executor: Running task 0.0 in stage 98.0 (TID 281)
18/02/28 13:35:14 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:35:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:35:14 INFO Executor: Finished task 0.0 in stage 98.0 (TID 281). 1495 bytes result sent to driver
18/02/28 13:35:14 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 281) in 11 ms on localhost (executor driver) (1/1)
18/02/28 13:35:14 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool 
18/02/28 13:35:14 INFO DAGScheduler: ResultStage 98 (sql at <unknown>:0) finished in 0.012 s
18/02/28 13:35:14 INFO DAGScheduler: Job 52 finished: sql at <unknown>:0, took 0.053976 s
18/02/28 13:35:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:35:14 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `cached_flights`
18/02/28 13:35:14 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:35:14 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:35:14 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:35:14 INFO DAGScheduler: Registering RDD 322 (collect at utils.scala:211)
18/02/28 13:35:14 INFO DAGScheduler: Got job 53 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:35:14 INFO DAGScheduler: Final stage: ResultStage 100 (collect at utils.scala:211)
18/02/28 13:35:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 99)
18/02/28 13:35:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 99)
18/02/28 13:35:14 INFO DAGScheduler: Submitting ShuffleMapStage 99 (MapPartitionsRDD[322] at collect at utils.scala:211), which has no missing parents
18/02/28 13:35:14 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 24.5 KB, free 282.1 MB)
18/02/28 13:35:14 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 11.2 KB, free 282.1 MB)
18/02/28 13:35:14 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 127.0.0.1:60941 (size: 11.2 KB, free: 287.4 MB)
18/02/28 13:35:14 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1006
18/02/28 13:35:14 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 99 (MapPartitionsRDD[322] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:35:14 INFO TaskSchedulerImpl: Adding task set 99.0 with 4 tasks
18/02/28 13:35:14 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 282, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:35:14 INFO TaskSetManager: Starting task 1.0 in stage 99.0 (TID 283, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:35:14 INFO TaskSetManager: Starting task 2.0 in stage 99.0 (TID 284, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:35:14 INFO TaskSetManager: Starting task 3.0 in stage 99.0 (TID 285, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:35:14 INFO Executor: Running task 1.0 in stage 99.0 (TID 283)
18/02/28 13:35:14 INFO Executor: Running task 0.0 in stage 99.0 (TID 282)
18/02/28 13:35:14 INFO Executor: Running task 3.0 in stage 99.0 (TID 285)
18/02/28 13:35:14 INFO Executor: Running task 2.0 in stage 99.0 (TID 284)
18/02/28 13:35:14 INFO BlockManager: Found block rdd_236_1 locally
18/02/28 13:35:14 INFO BlockManager: Found block rdd_236_0 locally
18/02/28 13:35:14 INFO BlockManager: Found block rdd_236_2 locally
18/02/28 13:35:14 INFO BlockManager: Found block rdd_236_3 locally
18/02/28 13:35:14 INFO Executor: Finished task 2.0 in stage 99.0 (TID 284). 1694 bytes result sent to driver
18/02/28 13:35:14 INFO TaskSetManager: Finished task 2.0 in stage 99.0 (TID 284) in 11 ms on localhost (executor driver) (1/4)
18/02/28 13:35:14 INFO Executor: Finished task 3.0 in stage 99.0 (TID 285). 1737 bytes result sent to driver
18/02/28 13:35:14 INFO TaskSetManager: Finished task 3.0 in stage 99.0 (TID 285) in 13 ms on localhost (executor driver) (2/4)
18/02/28 13:35:14 INFO Executor: Finished task 0.0 in stage 99.0 (TID 282). 1694 bytes result sent to driver
18/02/28 13:35:14 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 282) in 15 ms on localhost (executor driver) (3/4)
18/02/28 13:35:14 INFO Executor: Finished task 1.0 in stage 99.0 (TID 283). 1694 bytes result sent to driver
18/02/28 13:35:14 INFO TaskSetManager: Finished task 1.0 in stage 99.0 (TID 283) in 17 ms on localhost (executor driver) (4/4)
18/02/28 13:35:14 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool 
18/02/28 13:35:14 INFO DAGScheduler: ShuffleMapStage 99 (collect at utils.scala:211) finished in 0.017 s
18/02/28 13:35:14 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:35:14 INFO DAGScheduler: running: Set()
18/02/28 13:35:14 INFO DAGScheduler: waiting: Set(ResultStage 100)
18/02/28 13:35:14 INFO DAGScheduler: failed: Set()
18/02/28 13:35:14 INFO DAGScheduler: Submitting ResultStage 100 (MapPartitionsRDD[325] at collect at utils.scala:211), which has no missing parents
18/02/28 13:35:14 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 7.0 KB, free 282.0 MB)
18/02/28 13:35:14 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 3.7 KB, free 282.0 MB)
18/02/28 13:35:14 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 287.3 MB)
18/02/28 13:35:14 INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1006
18/02/28 13:35:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 100 (MapPartitionsRDD[325] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:35:14 INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks
18/02/28 13:35:14 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 286, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:35:14 INFO Executor: Running task 0.0 in stage 100.0 (TID 286)
18/02/28 13:35:14 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:35:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:35:14 INFO Executor: Finished task 0.0 in stage 100.0 (TID 286). 1495 bytes result sent to driver
18/02/28 13:35:14 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 286) in 3 ms on localhost (executor driver) (1/1)
18/02/28 13:35:14 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool 
18/02/28 13:35:14 INFO DAGScheduler: ResultStage 100 (collect at utils.scala:211) finished in 0.003 s
18/02/28 13:35:14 INFO DAGScheduler: Job 53 finished: collect at utils.scala:211, took 0.025595 s
18/02/28 13:35:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:35:14 INFO SparkSqlParser: Parsing command: SHOW TABLES LIKE"cached_flights"
18/02/28 13:35:14 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:35:14 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:35:14 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:35:14 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:35:14 INFO HiveMetaStore: 0: get_tables: db=default pat=cached_flights
18/02/28 13:35:14 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=cached_flights	
18/02/28 13:35:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:35:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights` AS `zzz84`
WHERE (0 = 1)
18/02/28 13:35:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:35:14 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 13:35:14 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:35:14 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:35:14 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:35:14 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:35:14 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 13:35:14 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 13:37:43 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:37:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
WHERE (NOT(((`arr_delay`) IS NULL)))
18/02/28 13:37:43 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e058fa6b2
18/02/28 13:37:43 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:37:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e058fa6b2` AS `zzz85`
WHERE (0 = 1)
18/02/28 13:37:43 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:37:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e058fa6b2`
18/02/28 13:38:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:38:18 INFO SparkSqlParser: Parsing command: SELECT `month`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`, `sched_dep_time`, `sched_arr_time`
FROM (SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`dep_time` AS DOUBLE) AS `dep_time`, CAST(`arr_time` AS DOUBLE) AS `arr_time`, CAST(`arr_delay` AS DOUBLE) AS `arr_delay`, CAST(`dep_delay` AS DOUBLE) AS `dep_delay`, CAST(`distance` AS DOUBLE) AS `distance`, CAST(`sched_dep_time` AS DOUBLE) AS `sched_dep_time`, CAST(`sched_arr_time` AS DOUBLE) AS `sched_arr_time`
FROM (SELECT `month`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`, `sched_dep_time`, `sched_arr_time`
FROM `spark_flights`) `szjdltusex`) `qkrxxfqsua`
18/02/28 13:38:18 INFO SparkSqlParser: Parsing command: cached_flights
18/02/28 13:38:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:38:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights` AS `zzz86`
WHERE (0 = 1)
18/02/28 13:38:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:38:18 INFO SparkSqlParser: Parsing command: CACHE TABLE `cached_flights`
18/02/28 13:38:18 INFO SparkSqlParser: Parsing command: `cached_flights`
18/02/28 13:38:18 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 13:38:18 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 13:38:18 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dep_time: string, sched_dep_time: string, dep_delay: string, arr_time: string ... 6 more fields>
18/02/28 13:38:18 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 13:38:18 INFO CodeGenerator: Code generated in 9.427213 ms
18/02/28 13:38:18 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 282.5 KB, free 281.8 MB)
18/02/28 13:38:18 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 24.1 KB, free 281.7 MB)
18/02/28 13:38:18 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 127.0.0.1:60941 (size: 24.1 KB, free: 287.3 MB)
18/02/28 13:38:18 INFO SparkContext: Created broadcast 120 from sql at <unknown>:0
18/02/28 13:38:18 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21019222 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 13:38:18 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 13:38:18 INFO DAGScheduler: Registering RDD 331 (sql at <unknown>:0)
18/02/28 13:38:18 INFO DAGScheduler: Got job 54 (sql at <unknown>:0) with 1 output partitions
18/02/28 13:38:18 INFO DAGScheduler: Final stage: ResultStage 102 (sql at <unknown>:0)
18/02/28 13:38:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 101)
18/02/28 13:38:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 101)
18/02/28 13:38:18 INFO DAGScheduler: Submitting ShuffleMapStage 101 (MapPartitionsRDD[331] at sql at <unknown>:0), which has no missing parents
18/02/28 13:38:18 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 26.7 KB, free 281.7 MB)
18/02/28 13:38:18 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 11.7 KB, free 281.7 MB)
18/02/28 13:38:18 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 127.0.0.1:60941 (size: 11.7 KB, free: 287.3 MB)
18/02/28 13:38:18 INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1006
18/02/28 13:38:18 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 101 (MapPartitionsRDD[331] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:38:18 INFO TaskSchedulerImpl: Adding task set 101.0 with 4 tasks
18/02/28 13:38:18 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 287, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:38:18 INFO TaskSetManager: Starting task 1.0 in stage 101.0 (TID 288, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:38:18 INFO TaskSetManager: Starting task 2.0 in stage 101.0 (TID 289, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:38:18 INFO TaskSetManager: Starting task 3.0 in stage 101.0 (TID 290, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:38:18 INFO Executor: Running task 0.0 in stage 101.0 (TID 287)
18/02/28 13:38:18 INFO Executor: Running task 3.0 in stage 101.0 (TID 290)
18/02/28 13:38:18 INFO Executor: Running task 2.0 in stage 101.0 (TID 289)
18/02/28 13:38:18 INFO Executor: Running task 1.0 in stage 101.0 (TID 288)
18/02/28 13:38:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_3.csv, range: 0-2881793, partition values: [empty row]
18/02/28 13:38:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_4.csv, range: 0-2830543, partition values: [empty row]
18/02/28 13:38:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_11.csv, range: 0-2757037, partition values: [empty row]
18/02/28 13:38:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_7.csv, range: 0-2938867, partition values: [empty row]
18/02/28 13:38:18 INFO CodeGenerator: Code generated in 6.242377 ms
18/02/28 13:38:18 INFO ContextCleaner: Cleaned accumulator 3021
18/02/28 13:38:18 INFO ContextCleaner: Cleaned accumulator 3020
18/02/28 13:38:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_1.csv, range: 0-2697256, partition values: [empty row]
18/02/28 13:38:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_6.csv, range: 0-2820227, partition values: [empty row]
18/02/28 13:38:18 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 287.3 MB)
18/02/28 13:38:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_5.csv, range: 0-2880181, partition values: [empty row]
18/02/28 13:38:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_8.csv, range: 0-2932019, partition values: [empty row]
18/02/28 13:38:18 INFO ContextCleaner: Cleaned accumulator 3027
18/02/28 13:38:18 INFO ContextCleaner: Cleaned accumulator 3081
18/02/28 13:38:18 INFO ContextCleaner: Cleaned accumulator 3032
18/02/28 13:38:18 INFO ContextCleaner: Cleaned accumulator 3022
18/02/28 13:38:18 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 127.0.0.1:60941 in memory (size: 11.2 KB, free: 287.3 MB)
18/02/28 13:38:18 INFO ContextCleaner: Cleaned accumulator 3026
18/02/28 13:38:18 INFO ContextCleaner: Cleaned shuffle 45
18/02/28 13:38:18 INFO ContextCleaner: Cleaned accumulator 3030
18/02/28 13:38:18 INFO ContextCleaner: Cleaned accumulator 3025
18/02/28 13:38:18 INFO ContextCleaner: Cleaned accumulator 3024
18/02/28 13:38:18 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 127.0.0.1:60941 in memory (size: 11.2 KB, free: 287.3 MB)
18/02/28 13:38:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_2.csv, range: 0-2487144, partition values: [empty row]
18/02/28 13:38:18 INFO ContextCleaner: Cleaned accumulator 3023
18/02/28 13:38:18 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 287.3 MB)
18/02/28 13:38:18 INFO ContextCleaner: Cleaned accumulator 3148
18/02/28 13:38:18 INFO ContextCleaner: Cleaned accumulator 3031
18/02/28 13:38:18 INFO ContextCleaner: Cleaned accumulator 3028
18/02/28 13:38:18 INFO ContextCleaner: Cleaned accumulator 3029
18/02/28 13:38:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_9.csv, range: 0-2763076, partition values: [empty row]
18/02/28 13:38:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_10.csv, range: 0-2920629, partition values: [empty row]
18/02/28 13:38:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_12.csv, range: 0-2836468, partition values: [empty row]
18/02/28 13:38:19 INFO MemoryStore: Block rdd_328_2 stored as values in memory (estimated size 5.1 MB, free 276.7 MB)
18/02/28 13:38:19 INFO BlockManagerInfo: Added rdd_328_2 in memory on 127.0.0.1:60941 (size: 5.1 MB, free: 282.2 MB)
18/02/28 13:38:19 INFO MemoryStore: Block rdd_328_3 stored as values in memory (estimated size 4.8 MB, free 271.9 MB)
18/02/28 13:38:19 INFO BlockManagerInfo: Added rdd_328_3 in memory on 127.0.0.1:60941 (size: 4.8 MB, free: 277.4 MB)
18/02/28 13:38:19 INFO Executor: Finished task 2.0 in stage 101.0 (TID 289). 2461 bytes result sent to driver
18/02/28 13:38:19 INFO TaskSetManager: Finished task 2.0 in stage 101.0 (TID 289) in 1009 ms on localhost (executor driver) (1/4)
18/02/28 13:38:19 INFO Executor: Finished task 3.0 in stage 101.0 (TID 290). 2461 bytes result sent to driver
18/02/28 13:38:19 INFO TaskSetManager: Finished task 3.0 in stage 101.0 (TID 290) in 1010 ms on localhost (executor driver) (2/4)
18/02/28 13:38:19 INFO MemoryStore: Block rdd_328_0 stored as values in memory (estimated size 5.3 MB, free 266.5 MB)
18/02/28 13:38:19 INFO BlockManagerInfo: Added rdd_328_0 in memory on 127.0.0.1:60941 (size: 5.3 MB, free: 272.1 MB)
18/02/28 13:38:19 INFO Executor: Finished task 0.0 in stage 101.0 (TID 287). 2461 bytes result sent to driver
18/02/28 13:38:19 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 287) in 1077 ms on localhost (executor driver) (3/4)
18/02/28 13:38:19 INFO MemoryStore: Block rdd_328_1 stored as values in memory (estimated size 5.2 MB, free 261.3 MB)
18/02/28 13:38:19 INFO BlockManagerInfo: Added rdd_328_1 in memory on 127.0.0.1:60941 (size: 5.2 MB, free: 266.9 MB)
18/02/28 13:38:19 INFO Executor: Finished task 1.0 in stage 101.0 (TID 288). 2461 bytes result sent to driver
18/02/28 13:38:19 INFO TaskSetManager: Finished task 1.0 in stage 101.0 (TID 288) in 1087 ms on localhost (executor driver) (4/4)
18/02/28 13:38:19 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool 
18/02/28 13:38:19 INFO DAGScheduler: ShuffleMapStage 101 (sql at <unknown>:0) finished in 1.087 s
18/02/28 13:38:19 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:38:19 INFO DAGScheduler: running: Set()
18/02/28 13:38:19 INFO DAGScheduler: waiting: Set(ResultStage 102)
18/02/28 13:38:19 INFO DAGScheduler: failed: Set()
18/02/28 13:38:19 INFO DAGScheduler: Submitting ResultStage 102 (MapPartitionsRDD[334] at sql at <unknown>:0), which has no missing parents
18/02/28 13:38:19 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 7.0 KB, free 261.3 MB)
18/02/28 13:38:19 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 3.7 KB, free 261.3 MB)
18/02/28 13:38:19 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 266.9 MB)
18/02/28 13:38:19 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1006
18/02/28 13:38:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 102 (MapPartitionsRDD[334] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 13:38:19 INFO TaskSchedulerImpl: Adding task set 102.0 with 1 tasks
18/02/28 13:38:19 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 291, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:38:19 INFO Executor: Running task 0.0 in stage 102.0 (TID 291)
18/02/28 13:38:19 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:38:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:38:19 INFO Executor: Finished task 0.0 in stage 102.0 (TID 291). 1495 bytes result sent to driver
18/02/28 13:38:19 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 291) in 3 ms on localhost (executor driver) (1/1)
18/02/28 13:38:19 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool 
18/02/28 13:38:19 INFO DAGScheduler: ResultStage 102 (sql at <unknown>:0) finished in 0.004 s
18/02/28 13:38:19 INFO DAGScheduler: Job 54 finished: sql at <unknown>:0, took 1.097017 s
18/02/28 13:38:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:38:19 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `cached_flights`
18/02/28 13:38:19 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:38:19 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:38:19 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:38:19 INFO DAGScheduler: Registering RDD 337 (collect at utils.scala:211)
18/02/28 13:38:19 INFO DAGScheduler: Got job 55 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:38:19 INFO DAGScheduler: Final stage: ResultStage 104 (collect at utils.scala:211)
18/02/28 13:38:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 103)
18/02/28 13:38:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 103)
18/02/28 13:38:19 INFO DAGScheduler: Submitting ShuffleMapStage 103 (MapPartitionsRDD[337] at collect at utils.scala:211), which has no missing parents
18/02/28 13:38:19 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 26.7 KB, free 261.3 MB)
18/02/28 13:38:19 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 11.7 KB, free 261.3 MB)
18/02/28 13:38:19 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 127.0.0.1:60941 (size: 11.7 KB, free: 266.9 MB)
18/02/28 13:38:19 INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:1006
18/02/28 13:38:19 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 103 (MapPartitionsRDD[337] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:38:19 INFO TaskSchedulerImpl: Adding task set 103.0 with 4 tasks
18/02/28 13:38:19 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 292, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:38:19 INFO TaskSetManager: Starting task 1.0 in stage 103.0 (TID 293, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:38:19 INFO TaskSetManager: Starting task 2.0 in stage 103.0 (TID 294, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:38:19 INFO TaskSetManager: Starting task 3.0 in stage 103.0 (TID 295, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:38:19 INFO Executor: Running task 0.0 in stage 103.0 (TID 292)
18/02/28 13:38:19 INFO Executor: Running task 1.0 in stage 103.0 (TID 293)
18/02/28 13:38:19 INFO Executor: Running task 2.0 in stage 103.0 (TID 294)
18/02/28 13:38:19 INFO Executor: Running task 3.0 in stage 103.0 (TID 295)
18/02/28 13:38:19 INFO BlockManager: Found block rdd_328_1 locally
18/02/28 13:38:19 INFO BlockManager: Found block rdd_328_0 locally
18/02/28 13:38:19 INFO BlockManager: Found block rdd_328_3 locally
18/02/28 13:38:19 INFO BlockManager: Found block rdd_328_2 locally
18/02/28 13:38:19 INFO Executor: Finished task 1.0 in stage 103.0 (TID 293). 1694 bytes result sent to driver
18/02/28 13:38:19 INFO TaskSetManager: Finished task 1.0 in stage 103.0 (TID 293) in 16 ms on localhost (executor driver) (1/4)
18/02/28 13:38:19 INFO Executor: Finished task 0.0 in stage 103.0 (TID 292). 1694 bytes result sent to driver
18/02/28 13:38:19 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 292) in 18 ms on localhost (executor driver) (2/4)
18/02/28 13:38:19 INFO Executor: Finished task 2.0 in stage 103.0 (TID 294). 1737 bytes result sent to driver
18/02/28 13:38:19 INFO TaskSetManager: Finished task 2.0 in stage 103.0 (TID 294) in 19 ms on localhost (executor driver) (3/4)
18/02/28 13:38:19 INFO Executor: Finished task 3.0 in stage 103.0 (TID 295). 1737 bytes result sent to driver
18/02/28 13:38:19 INFO TaskSetManager: Finished task 3.0 in stage 103.0 (TID 295) in 21 ms on localhost (executor driver) (4/4)
18/02/28 13:38:19 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool 
18/02/28 13:38:19 INFO DAGScheduler: ShuffleMapStage 103 (collect at utils.scala:211) finished in 0.022 s
18/02/28 13:38:19 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:38:19 INFO DAGScheduler: running: Set()
18/02/28 13:38:19 INFO DAGScheduler: waiting: Set(ResultStage 104)
18/02/28 13:38:19 INFO DAGScheduler: failed: Set()
18/02/28 13:38:19 INFO DAGScheduler: Submitting ResultStage 104 (MapPartitionsRDD[340] at collect at utils.scala:211), which has no missing parents
18/02/28 13:38:19 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 7.0 KB, free 261.3 MB)
18/02/28 13:38:19 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 3.7 KB, free 261.3 MB)
18/02/28 13:38:19 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 266.9 MB)
18/02/28 13:38:19 INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1006
18/02/28 13:38:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 104 (MapPartitionsRDD[340] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:38:19 INFO TaskSchedulerImpl: Adding task set 104.0 with 1 tasks
18/02/28 13:38:19 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 296, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:38:19 INFO Executor: Running task 0.0 in stage 104.0 (TID 296)
18/02/28 13:38:19 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:38:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:38:19 INFO Executor: Finished task 0.0 in stage 104.0 (TID 296). 1495 bytes result sent to driver
18/02/28 13:38:19 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 296) in 2 ms on localhost (executor driver) (1/1)
18/02/28 13:38:19 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool 
18/02/28 13:38:19 INFO DAGScheduler: ResultStage 104 (collect at utils.scala:211) finished in 0.003 s
18/02/28 13:38:19 INFO DAGScheduler: Job 55 finished: collect at utils.scala:211, took 0.032038 s
18/02/28 13:38:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:38:19 INFO SparkSqlParser: Parsing command: SHOW TABLES LIKE"cached_flights"
18/02/28 13:38:19 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:38:19 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:38:19 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:38:19 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:38:19 INFO HiveMetaStore: 0: get_tables: db=default pat=cached_flights
18/02/28 13:38:19 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=cached_flights	
18/02/28 13:38:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:38:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights` AS `zzz87`
WHERE (0 = 1)
18/02/28 13:38:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:38:19 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 13:38:19 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:38:19 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:38:19 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:38:19 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:38:19 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 13:38:19 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 13:38:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:38:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
WHERE (NOT(((`arr_delay`) IS NULL)))
18/02/28 13:38:31 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e03b1411aa
18/02/28 13:38:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:38:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e03b1411aa` AS `zzz88`
WHERE (0 = 1)
18/02/28 13:38:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:38:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e03b1411aa`
18/02/28 13:38:31 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e01c0224f9
18/02/28 13:38:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:38:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e01c0224f9` AS `zzz89`
WHERE (0 = 1)
18/02/28 13:38:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:38:31 INFO SparkSqlParser: Parsing command: SELECT `month`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`, `sched_dep_time`, `sched_arr_time`, `delayed`, CONCAT("h", CAST(`dephour` AS INT)) AS `dephour`
FROM `sparklyr_tmp_30e01c0224f9`
18/02/28 13:38:31 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:38:31 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:38:31 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e016c21b3c
18/02/28 13:38:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:38:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e016c21b3c` AS `zzz90`
WHERE (0 = 1)
18/02/28 13:38:31 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e06a7c602
18/02/28 13:38:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:38:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e06a7c602` AS `zzz91`
WHERE (0 = 1)
18/02/28 13:38:31 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e02f345f52
18/02/28 13:38:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:38:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e02f345f52` AS `zzz92`
WHERE (0 = 1)
18/02/28 13:39:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:39:05 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e04984212d`
18/02/28 13:39:05 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:39:05 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:39:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:39:05 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e04984212d`
18/02/28 13:39:05 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:39:05 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:39:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:39:05 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e04984212d`
18/02/28 13:39:05 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:39:05 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:39:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:39:05 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e04984212d`
18/02/28 13:39:05 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:39:05 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:39:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:39:05 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e04984212d`
18/02/28 13:39:05 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:39:05 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:39:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:39:05 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e04984212d`
LIMIT 1000
18/02/28 13:39:05 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:39:05 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:39:05 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:39:05 INFO DAGScheduler: Registering RDD 343 (collect at utils.scala:211)
18/02/28 13:39:05 INFO DAGScheduler: Got job 56 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:39:05 INFO DAGScheduler: Final stage: ResultStage 106 (collect at utils.scala:211)
18/02/28 13:39:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 105)
18/02/28 13:39:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 105)
18/02/28 13:39:05 INFO DAGScheduler: Submitting ShuffleMapStage 105 (MapPartitionsRDD[343] at collect at utils.scala:211), which has no missing parents
18/02/28 13:39:05 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 32.1 KB, free 261.2 MB)
18/02/28 13:39:05 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 14.3 KB, free 261.2 MB)
18/02/28 13:39:05 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 127.0.0.1:60941 (size: 14.3 KB, free: 266.8 MB)
18/02/28 13:39:05 INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:1006
18/02/28 13:39:05 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 105 (MapPartitionsRDD[343] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:39:05 INFO TaskSchedulerImpl: Adding task set 105.0 with 4 tasks
18/02/28 13:39:05 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 297, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:39:05 INFO TaskSetManager: Starting task 1.0 in stage 105.0 (TID 298, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:39:05 INFO TaskSetManager: Starting task 2.0 in stage 105.0 (TID 299, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:39:05 INFO TaskSetManager: Starting task 3.0 in stage 105.0 (TID 300, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:39:05 INFO Executor: Running task 0.0 in stage 105.0 (TID 297)
18/02/28 13:39:05 INFO Executor: Running task 1.0 in stage 105.0 (TID 298)
18/02/28 13:39:05 INFO Executor: Running task 2.0 in stage 105.0 (TID 299)
18/02/28 13:39:05 INFO Executor: Running task 3.0 in stage 105.0 (TID 300)
18/02/28 13:39:05 INFO BlockManager: Found block rdd_236_0 locally
18/02/28 13:39:05 INFO BlockManager: Found block rdd_236_2 locally
18/02/28 13:39:05 INFO BlockManager: Found block rdd_236_1 locally
18/02/28 13:39:05 INFO BlockManager: Found block rdd_236_3 locally
18/02/28 13:39:05 INFO ContextCleaner: Cleaned accumulator 3209
18/02/28 13:39:05 INFO BlockManagerInfo: Removed broadcast_124_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 266.8 MB)
18/02/28 13:39:05 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 127.0.0.1:60941 in memory (size: 11.7 KB, free: 266.9 MB)
18/02/28 13:39:05 INFO BlockManagerInfo: Removed broadcast_122_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 266.9 MB)
18/02/28 13:39:05 INFO ContextCleaner: Cleaned accumulator 3270
18/02/28 13:39:05 INFO Executor: Finished task 2.0 in stage 105.0 (TID 299). 2346 bytes result sent to driver
18/02/28 13:39:05 INFO TaskSetManager: Finished task 2.0 in stage 105.0 (TID 299) in 122 ms on localhost (executor driver) (1/4)
18/02/28 13:39:05 INFO Executor: Finished task 1.0 in stage 105.0 (TID 298). 2346 bytes result sent to driver
18/02/28 13:39:05 INFO TaskSetManager: Finished task 1.0 in stage 105.0 (TID 298) in 126 ms on localhost (executor driver) (2/4)
18/02/28 13:39:05 INFO Executor: Finished task 3.0 in stage 105.0 (TID 300). 2346 bytes result sent to driver
18/02/28 13:39:05 INFO TaskSetManager: Finished task 3.0 in stage 105.0 (TID 300) in 132 ms on localhost (executor driver) (3/4)
18/02/28 13:39:05 INFO Executor: Finished task 0.0 in stage 105.0 (TID 297). 2346 bytes result sent to driver
18/02/28 13:39:05 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 297) in 134 ms on localhost (executor driver) (4/4)
18/02/28 13:39:05 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool 
18/02/28 13:39:05 INFO DAGScheduler: ShuffleMapStage 105 (collect at utils.scala:211) finished in 0.135 s
18/02/28 13:39:05 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:39:05 INFO DAGScheduler: running: Set()
18/02/28 13:39:05 INFO DAGScheduler: waiting: Set(ResultStage 106)
18/02/28 13:39:05 INFO DAGScheduler: failed: Set()
18/02/28 13:39:05 INFO DAGScheduler: Submitting ResultStage 106 (MapPartitionsRDD[346] at collect at utils.scala:211), which has no missing parents
18/02/28 13:39:05 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 6.9 KB, free 261.3 MB)
18/02/28 13:39:05 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 3.7 KB, free 261.3 MB)
18/02/28 13:39:05 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 266.9 MB)
18/02/28 13:39:05 INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:1006
18/02/28 13:39:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 106 (MapPartitionsRDD[346] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:39:05 INFO TaskSchedulerImpl: Adding task set 106.0 with 1 tasks
18/02/28 13:39:05 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 301, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:39:05 INFO Executor: Running task 0.0 in stage 106.0 (TID 301)
18/02/28 13:39:05 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:39:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:39:05 INFO Executor: Finished task 0.0 in stage 106.0 (TID 301). 1428 bytes result sent to driver
18/02/28 13:39:05 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 301) in 3 ms on localhost (executor driver) (1/1)
18/02/28 13:39:05 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool 
18/02/28 13:39:05 INFO DAGScheduler: ResultStage 106 (collect at utils.scala:211) finished in 0.003 s
18/02/28 13:39:05 INFO DAGScheduler: Job 56 finished: collect at utils.scala:211, took 0.141419 s
18/02/28 13:39:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:39:17 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e016c21b3c`
18/02/28 13:39:17 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:39:17 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:39:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:39:17 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e016c21b3c`
18/02/28 13:39:17 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:39:17 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:39:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:39:17 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e016c21b3c`
18/02/28 13:39:17 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:39:17 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:39:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:39:17 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e016c21b3c`
18/02/28 13:39:17 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:39:17 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:39:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:39:17 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e016c21b3c`
18/02/28 13:39:17 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:39:17 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:39:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:39:17 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_30e016c21b3c`
LIMIT 1000
18/02/28 13:39:17 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:39:17 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:39:17 INFO CodeGenerator: Code generated in 27.612019 ms
18/02/28 13:39:17 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:39:17 INFO DAGScheduler: Registering RDD 349 (collect at utils.scala:211)
18/02/28 13:39:17 INFO DAGScheduler: Got job 57 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:39:17 INFO DAGScheduler: Final stage: ResultStage 108 (collect at utils.scala:211)
18/02/28 13:39:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 107)
18/02/28 13:39:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 107)
18/02/28 13:39:17 INFO DAGScheduler: Submitting ShuffleMapStage 107 (MapPartitionsRDD[349] at collect at utils.scala:211), which has no missing parents
18/02/28 13:39:17 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 47.6 KB, free 261.2 MB)
18/02/28 13:39:17 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 20.6 KB, free 261.2 MB)
18/02/28 13:39:17 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 127.0.0.1:60941 (size: 20.6 KB, free: 266.8 MB)
18/02/28 13:39:17 INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1006
18/02/28 13:39:17 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 107 (MapPartitionsRDD[349] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:39:17 INFO TaskSchedulerImpl: Adding task set 107.0 with 4 tasks
18/02/28 13:39:17 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 302, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:39:17 INFO TaskSetManager: Starting task 1.0 in stage 107.0 (TID 303, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:39:17 INFO TaskSetManager: Starting task 2.0 in stage 107.0 (TID 304, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:39:17 INFO TaskSetManager: Starting task 3.0 in stage 107.0 (TID 305, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:39:17 INFO Executor: Running task 0.0 in stage 107.0 (TID 302)
18/02/28 13:39:17 INFO Executor: Running task 1.0 in stage 107.0 (TID 303)
18/02/28 13:39:17 INFO Executor: Running task 2.0 in stage 107.0 (TID 304)
18/02/28 13:39:17 INFO Executor: Running task 3.0 in stage 107.0 (TID 305)
18/02/28 13:39:17 INFO BlockManager: Found block rdd_328_0 locally
18/02/28 13:39:17 INFO BlockManager: Found block rdd_328_3 locally
18/02/28 13:39:17 INFO BlockManager: Found block rdd_328_2 locally
18/02/28 13:39:17 INFO BlockManager: Found block rdd_328_1 locally
18/02/28 13:39:17 INFO CodeGenerator: Code generated in 13.051762 ms
18/02/28 13:39:17 INFO CodeGenerator: Code generated in 22.780462 ms
18/02/28 13:39:17 INFO ContextCleaner: Cleaned accumulator 3335
18/02/28 13:39:18 INFO Executor: Finished task 1.0 in stage 107.0 (TID 303). 2408 bytes result sent to driver
18/02/28 13:39:18 INFO TaskSetManager: Finished task 1.0 in stage 107.0 (TID 303) in 691 ms on localhost (executor driver) (1/4)
18/02/28 13:39:18 INFO BlockManagerInfo: Removed broadcast_126_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 266.8 MB)
18/02/28 13:39:18 INFO Executor: Finished task 3.0 in stage 107.0 (TID 305). 2408 bytes result sent to driver
18/02/28 13:39:18 INFO TaskSetManager: Finished task 3.0 in stage 107.0 (TID 305) in 702 ms on localhost (executor driver) (2/4)
18/02/28 13:39:18 INFO Executor: Finished task 0.0 in stage 107.0 (TID 302). 2408 bytes result sent to driver
18/02/28 13:39:18 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 302) in 709 ms on localhost (executor driver) (3/4)
18/02/28 13:39:18 INFO Executor: Finished task 2.0 in stage 107.0 (TID 304). 2408 bytes result sent to driver
18/02/28 13:39:18 INFO TaskSetManager: Finished task 2.0 in stage 107.0 (TID 304) in 711 ms on localhost (executor driver) (4/4)
18/02/28 13:39:18 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool 
18/02/28 13:39:18 INFO DAGScheduler: ShuffleMapStage 107 (collect at utils.scala:211) finished in 0.711 s
18/02/28 13:39:18 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:39:18 INFO DAGScheduler: running: Set()
18/02/28 13:39:18 INFO DAGScheduler: waiting: Set(ResultStage 108)
18/02/28 13:39:18 INFO DAGScheduler: failed: Set()
18/02/28 13:39:18 INFO DAGScheduler: Submitting ResultStage 108 (MapPartitionsRDD[352] at collect at utils.scala:211), which has no missing parents
18/02/28 13:39:18 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 6.9 KB, free 261.2 MB)
18/02/28 13:39:18 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 3.7 KB, free 261.2 MB)
18/02/28 13:39:18 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 266.8 MB)
18/02/28 13:39:18 INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1006
18/02/28 13:39:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 108 (MapPartitionsRDD[352] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:39:18 INFO TaskSchedulerImpl: Adding task set 108.0 with 1 tasks
18/02/28 13:39:18 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 306, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:39:18 INFO Executor: Running task 0.0 in stage 108.0 (TID 306)
18/02/28 13:39:18 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:39:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:39:18 INFO Executor: Finished task 0.0 in stage 108.0 (TID 306). 1471 bytes result sent to driver
18/02/28 13:39:18 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 306) in 4 ms on localhost (executor driver) (1/1)
18/02/28 13:39:18 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool 
18/02/28 13:39:18 INFO DAGScheduler: ResultStage 108 (collect at utils.scala:211) finished in 0.005 s
18/02/28 13:39:18 INFO DAGScheduler: Job 57 finished: collect at utils.scala:211, took 0.723786 s
18/02/28 13:39:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:39:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e016c21b3c`
18/02/28 13:39:48 INFO SparkSqlParser: Parsing command: training
18/02/28 13:39:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:39:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training` AS `zzz93`
WHERE (0 = 1)
18/02/28 13:39:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:39:48 INFO SparkSqlParser: Parsing command: CACHE TABLE `training`
18/02/28 13:39:48 INFO SparkSqlParser: Parsing command: `training`
18/02/28 13:39:48 INFO CodeGenerator: Code generated in 16.614603 ms
18/02/28 13:39:48 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 13:39:48 INFO DAGScheduler: Registering RDD 358 (sql at <unknown>:0)
18/02/28 13:39:48 INFO DAGScheduler: Got job 58 (sql at <unknown>:0) with 1 output partitions
18/02/28 13:39:48 INFO DAGScheduler: Final stage: ResultStage 110 (sql at <unknown>:0)
18/02/28 13:39:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 109)
18/02/28 13:39:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 109)
18/02/28 13:39:48 INFO DAGScheduler: Submitting ShuffleMapStage 109 (MapPartitionsRDD[358] at sql at <unknown>:0), which has no missing parents
18/02/28 13:39:48 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 53.6 KB, free 261.2 MB)
18/02/28 13:39:48 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 22.0 KB, free 261.1 MB)
18/02/28 13:39:48 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 127.0.0.1:60941 (size: 22.0 KB, free: 266.8 MB)
18/02/28 13:39:48 INFO SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:1006
18/02/28 13:39:48 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 109 (MapPartitionsRDD[358] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:39:48 INFO TaskSchedulerImpl: Adding task set 109.0 with 4 tasks
18/02/28 13:39:48 INFO TaskSetManager: Starting task 0.0 in stage 109.0 (TID 307, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:39:48 INFO TaskSetManager: Starting task 1.0 in stage 109.0 (TID 308, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:39:48 INFO TaskSetManager: Starting task 2.0 in stage 109.0 (TID 309, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:39:48 INFO TaskSetManager: Starting task 3.0 in stage 109.0 (TID 310, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:39:48 INFO Executor: Running task 0.0 in stage 109.0 (TID 307)
18/02/28 13:39:48 INFO Executor: Running task 1.0 in stage 109.0 (TID 308)
18/02/28 13:39:48 INFO Executor: Running task 3.0 in stage 109.0 (TID 310)
18/02/28 13:39:48 INFO Executor: Running task 2.0 in stage 109.0 (TID 309)
18/02/28 13:39:48 INFO BlockManager: Found block rdd_328_2 locally
18/02/28 13:39:48 INFO BlockManager: Found block rdd_328_0 locally
18/02/28 13:39:48 INFO BlockManager: Found block rdd_328_3 locally
18/02/28 13:39:48 INFO BlockManager: Found block rdd_328_1 locally
18/02/28 13:39:48 INFO MemoryStore: Block rdd_355_1 stored as values in memory (estimated size 59.4 KB, free 227.1 MB)
18/02/28 13:39:48 INFO BlockManagerInfo: Added rdd_355_1 in memory on 127.0.0.1:60941 (size: 59.4 KB, free: 266.8 MB)
18/02/28 13:39:48 INFO MemoryStore: Block rdd_355_2 stored as values in memory (estimated size 59.8 KB, free 247.0 MB)
18/02/28 13:39:48 INFO BlockManagerInfo: Added rdd_355_2 in memory on 127.0.0.1:60941 (size: 59.8 KB, free: 266.7 MB)
18/02/28 13:39:48 INFO MemoryStore: Block rdd_355_3 stored as values in memory (estimated size 53.4 KB, free 247.0 MB)
18/02/28 13:39:48 INFO BlockManagerInfo: Added rdd_355_3 in memory on 127.0.0.1:60941 (size: 53.4 KB, free: 266.6 MB)
18/02/28 13:39:48 INFO Executor: Finished task 3.0 in stage 109.0 (TID 310). 3056 bytes result sent to driver
18/02/28 13:39:48 INFO TaskSetManager: Finished task 3.0 in stage 109.0 (TID 310) in 361 ms on localhost (executor driver) (1/4)
18/02/28 13:39:48 INFO Executor: Finished task 2.0 in stage 109.0 (TID 309). 3056 bytes result sent to driver
18/02/28 13:39:48 INFO TaskSetManager: Finished task 2.0 in stage 109.0 (TID 309) in 363 ms on localhost (executor driver) (2/4)
18/02/28 13:39:48 INFO Executor: Finished task 1.0 in stage 109.0 (TID 308). 3056 bytes result sent to driver
18/02/28 13:39:48 INFO TaskSetManager: Finished task 1.0 in stage 109.0 (TID 308) in 366 ms on localhost (executor driver) (3/4)
18/02/28 13:39:48 INFO MemoryStore: Block rdd_355_0 stored as values in memory (estimated size 59.6 KB, free 260.9 MB)
18/02/28 13:39:48 INFO BlockManagerInfo: Added rdd_355_0 in memory on 127.0.0.1:60941 (size: 59.6 KB, free: 266.6 MB)
18/02/28 13:39:48 INFO Executor: Finished task 0.0 in stage 109.0 (TID 307). 3056 bytes result sent to driver
18/02/28 13:39:48 INFO TaskSetManager: Finished task 0.0 in stage 109.0 (TID 307) in 379 ms on localhost (executor driver) (4/4)
18/02/28 13:39:48 INFO DAGScheduler: ShuffleMapStage 109 (sql at <unknown>:0) finished in 0.379 s
18/02/28 13:39:48 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:39:48 INFO DAGScheduler: running: Set()
18/02/28 13:39:48 INFO DAGScheduler: waiting: Set(ResultStage 110)
18/02/28 13:39:48 INFO DAGScheduler: failed: Set()
18/02/28 13:39:48 INFO DAGScheduler: Submitting ResultStage 110 (MapPartitionsRDD[361] at sql at <unknown>:0), which has no missing parents
18/02/28 13:39:48 INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 7.0 KB, free 260.9 MB)
18/02/28 13:39:48 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 3.7 KB, free 260.9 MB)
18/02/28 13:39:48 INFO TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool 
18/02/28 13:39:48 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 266.6 MB)
18/02/28 13:39:48 INFO SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:1006
18/02/28 13:39:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 110 (MapPartitionsRDD[361] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 13:39:48 INFO TaskSchedulerImpl: Adding task set 110.0 with 1 tasks
18/02/28 13:39:48 INFO TaskSetManager: Starting task 0.0 in stage 110.0 (TID 311, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:39:48 INFO Executor: Running task 0.0 in stage 110.0 (TID 311)
18/02/28 13:39:48 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:39:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:39:48 INFO Executor: Finished task 0.0 in stage 110.0 (TID 311). 1538 bytes result sent to driver
18/02/28 13:39:48 INFO TaskSetManager: Finished task 0.0 in stage 110.0 (TID 311) in 5 ms on localhost (executor driver) (1/1)
18/02/28 13:39:48 INFO TaskSchedulerImpl: Removed TaskSet 110.0, whose tasks have all completed, from pool 
18/02/28 13:39:48 INFO DAGScheduler: ResultStage 110 (sql at <unknown>:0) finished in 0.005 s
18/02/28 13:39:48 INFO DAGScheduler: Job 58 finished: sql at <unknown>:0, took 0.391701 s
18/02/28 13:39:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:39:48 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `training`
18/02/28 13:39:48 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:39:48 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:39:48 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:39:48 INFO DAGScheduler: Registering RDD 364 (collect at utils.scala:211)
18/02/28 13:39:48 INFO DAGScheduler: Got job 59 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:39:48 INFO DAGScheduler: Final stage: ResultStage 112 (collect at utils.scala:211)
18/02/28 13:39:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 111)
18/02/28 13:39:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 111)
18/02/28 13:39:48 INFO DAGScheduler: Submitting ShuffleMapStage 111 (MapPartitionsRDD[364] at collect at utils.scala:211), which has no missing parents
18/02/28 13:39:48 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 53.6 KB, free 260.8 MB)
18/02/28 13:39:48 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 22.1 KB, free 260.8 MB)
18/02/28 13:39:48 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 127.0.0.1:60941 (size: 22.1 KB, free: 266.6 MB)
18/02/28 13:39:48 INFO SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:1006
18/02/28 13:39:48 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 111 (MapPartitionsRDD[364] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:39:48 INFO TaskSchedulerImpl: Adding task set 111.0 with 4 tasks
18/02/28 13:39:48 INFO TaskSetManager: Starting task 0.0 in stage 111.0 (TID 312, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:39:48 INFO TaskSetManager: Starting task 1.0 in stage 111.0 (TID 313, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:39:48 INFO TaskSetManager: Starting task 2.0 in stage 111.0 (TID 314, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:39:48 INFO TaskSetManager: Starting task 3.0 in stage 111.0 (TID 315, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:39:48 INFO Executor: Running task 0.0 in stage 111.0 (TID 312)
18/02/28 13:39:48 INFO Executor: Running task 1.0 in stage 111.0 (TID 313)
18/02/28 13:39:48 INFO Executor: Running task 3.0 in stage 111.0 (TID 315)
18/02/28 13:39:48 INFO Executor: Running task 2.0 in stage 111.0 (TID 314)
18/02/28 13:39:48 INFO BlockManager: Found block rdd_355_3 locally
18/02/28 13:39:48 INFO BlockManager: Found block rdd_355_2 locally
18/02/28 13:39:48 INFO BlockManager: Found block rdd_355_0 locally
18/02/28 13:39:48 INFO BlockManager: Found block rdd_355_1 locally
18/02/28 13:39:48 INFO Executor: Finished task 1.0 in stage 111.0 (TID 313). 2332 bytes result sent to driver
18/02/28 13:39:48 INFO TaskSetManager: Finished task 1.0 in stage 111.0 (TID 313) in 20 ms on localhost (executor driver) (1/4)
18/02/28 13:39:48 INFO Executor: Finished task 0.0 in stage 111.0 (TID 312). 2289 bytes result sent to driver
18/02/28 13:39:48 INFO TaskSetManager: Finished task 0.0 in stage 111.0 (TID 312) in 23 ms on localhost (executor driver) (2/4)
18/02/28 13:39:48 INFO Executor: Finished task 3.0 in stage 111.0 (TID 315). 2289 bytes result sent to driver
18/02/28 13:39:48 INFO TaskSetManager: Finished task 3.0 in stage 111.0 (TID 315) in 23 ms on localhost (executor driver) (3/4)
18/02/28 13:39:48 INFO Executor: Finished task 2.0 in stage 111.0 (TID 314). 2332 bytes result sent to driver
18/02/28 13:39:48 INFO TaskSetManager: Finished task 2.0 in stage 111.0 (TID 314) in 26 ms on localhost (executor driver) (4/4)
18/02/28 13:39:48 INFO DAGScheduler: ShuffleMapStage 111 (collect at utils.scala:211) finished in 0.027 s
18/02/28 13:39:48 INFO TaskSchedulerImpl: Removed TaskSet 111.0, whose tasks have all completed, from pool 
18/02/28 13:39:48 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:39:48 INFO DAGScheduler: running: Set()
18/02/28 13:39:48 INFO DAGScheduler: waiting: Set(ResultStage 112)
18/02/28 13:39:48 INFO DAGScheduler: failed: Set()
18/02/28 13:39:48 INFO DAGScheduler: Submitting ResultStage 112 (MapPartitionsRDD[367] at collect at utils.scala:211), which has no missing parents
18/02/28 13:39:48 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 7.0 KB, free 260.8 MB)
18/02/28 13:39:48 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 3.7 KB, free 260.8 MB)
18/02/28 13:39:48 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 127.0.0.1:60941 (size: 3.7 KB, free: 266.6 MB)
18/02/28 13:39:48 INFO SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:1006
18/02/28 13:39:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 112 (MapPartitionsRDD[367] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:39:48 INFO TaskSchedulerImpl: Adding task set 112.0 with 1 tasks
18/02/28 13:39:48 INFO TaskSetManager: Starting task 0.0 in stage 112.0 (TID 316, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:39:48 INFO Executor: Running task 0.0 in stage 112.0 (TID 316)
18/02/28 13:39:48 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:39:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:39:48 INFO Executor: Finished task 0.0 in stage 112.0 (TID 316). 1538 bytes result sent to driver
18/02/28 13:39:48 INFO TaskSetManager: Finished task 0.0 in stage 112.0 (TID 316) in 4 ms on localhost (executor driver) (1/1)
18/02/28 13:39:48 INFO TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool 
18/02/28 13:39:48 INFO DAGScheduler: ResultStage 112 (collect at utils.scala:211) finished in 0.004 s
18/02/28 13:39:48 INFO DAGScheduler: Job 59 finished: collect at utils.scala:211, took 0.039701 s
18/02/28 13:39:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:39:48 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 13:39:48 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:39:48 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:39:48 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:39:48 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:39:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 13:39:48 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 13:40:11 INFO ContextCleaner: Cleaned accumulator 3416
18/02/28 13:40:11 INFO ContextCleaner: Cleaned accumulator 3417
18/02/28 13:40:11 INFO ContextCleaner: Cleaned accumulator 3412
18/02/28 13:40:11 INFO ContextCleaner: Cleaned accumulator 3413
18/02/28 13:40:11 INFO ContextCleaner: Cleaned accumulator 3411
18/02/28 13:40:11 INFO BlockManagerInfo: Removed broadcast_132_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 266.6 MB)
18/02/28 13:40:11 INFO BlockManagerInfo: Removed broadcast_130_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 266.6 MB)
18/02/28 13:40:11 INFO ContextCleaner: Cleaned accumulator 3410
18/02/28 13:40:11 INFO ContextCleaner: Cleaned accumulator 3418
18/02/28 13:40:11 INFO ContextCleaner: Cleaned accumulator 3470
18/02/28 13:40:11 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 127.0.0.1:60941 in memory (size: 3.7 KB, free: 266.6 MB)
18/02/28 13:40:11 INFO ContextCleaner: Cleaned accumulator 3420
18/02/28 13:40:11 INFO BlockManagerInfo: Removed broadcast_129_piece0 on 127.0.0.1:60941 in memory (size: 22.0 KB, free: 266.6 MB)
18/02/28 13:40:11 INFO ContextCleaner: Cleaned accumulator 3421
18/02/28 13:40:11 INFO ContextCleaner: Cleaned accumulator 3419
18/02/28 13:40:11 INFO ContextCleaner: Cleaned shuffle 51
18/02/28 13:40:11 INFO BlockManagerInfo: Removed broadcast_131_piece0 on 127.0.0.1:60941 in memory (size: 22.1 KB, free: 266.6 MB)
18/02/28 13:40:11 INFO ContextCleaner: Cleaned accumulator 3414
18/02/28 13:40:11 INFO ContextCleaner: Cleaned accumulator 3409
18/02/28 13:40:11 INFO ContextCleaner: Cleaned accumulator 3415
18/02/28 13:40:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:40:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 13:40:11 INFO SparkContext: Starting job: countByValue at StringIndexer.scala:113
18/02/28 13:40:11 INFO DAGScheduler: Registering RDD 374 (countByValue at StringIndexer.scala:113)
18/02/28 13:40:11 INFO DAGScheduler: Got job 60 (countByValue at StringIndexer.scala:113) with 4 output partitions
18/02/28 13:40:11 INFO DAGScheduler: Final stage: ResultStage 114 (countByValue at StringIndexer.scala:113)
18/02/28 13:40:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 113)
18/02/28 13:40:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 113)
18/02/28 13:40:11 INFO DAGScheduler: Submitting ShuffleMapStage 113 (MapPartitionsRDD[374] at countByValue at StringIndexer.scala:113), which has no missing parents
18/02/28 13:40:11 INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 55.3 KB, free 260.9 MB)
18/02/28 13:40:11 INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 22.9 KB, free 260.9 MB)
18/02/28 13:40:11 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 127.0.0.1:60941 (size: 22.9 KB, free: 266.6 MB)
18/02/28 13:40:11 INFO SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:11 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 113 (MapPartitionsRDD[374] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:11 INFO TaskSchedulerImpl: Adding task set 113.0 with 4 tasks
18/02/28 13:40:11 INFO TaskSetManager: Starting task 0.0 in stage 113.0 (TID 317, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:40:11 INFO TaskSetManager: Starting task 1.0 in stage 113.0 (TID 318, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:40:11 INFO TaskSetManager: Starting task 2.0 in stage 113.0 (TID 319, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:40:11 INFO TaskSetManager: Starting task 3.0 in stage 113.0 (TID 320, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:40:11 INFO Executor: Running task 0.0 in stage 113.0 (TID 317)
18/02/28 13:40:11 INFO Executor: Running task 1.0 in stage 113.0 (TID 318)
18/02/28 13:40:11 INFO Executor: Running task 2.0 in stage 113.0 (TID 319)
18/02/28 13:40:11 INFO BlockManager: Found block rdd_355_2 locally
18/02/28 13:40:11 INFO BlockManager: Found block rdd_355_1 locally
18/02/28 13:40:11 INFO Executor: Running task 3.0 in stage 113.0 (TID 320)
18/02/28 13:40:11 INFO BlockManager: Found block rdd_355_0 locally
18/02/28 13:40:11 INFO BlockManager: Found block rdd_355_3 locally
18/02/28 13:40:11 INFO Executor: Finished task 3.0 in stage 113.0 (TID 320). 2234 bytes result sent to driver
18/02/28 13:40:11 INFO TaskSetManager: Finished task 3.0 in stage 113.0 (TID 320) in 62 ms on localhost (executor driver) (1/4)
18/02/28 13:40:11 INFO Executor: Finished task 2.0 in stage 113.0 (TID 319). 2234 bytes result sent to driver
18/02/28 13:40:11 INFO TaskSetManager: Finished task 2.0 in stage 113.0 (TID 319) in 70 ms on localhost (executor driver) (2/4)
18/02/28 13:40:11 INFO Executor: Finished task 0.0 in stage 113.0 (TID 317). 2277 bytes result sent to driver
18/02/28 13:40:11 INFO TaskSetManager: Finished task 0.0 in stage 113.0 (TID 317) in 72 ms on localhost (executor driver) (3/4)
18/02/28 13:40:11 INFO Executor: Finished task 1.0 in stage 113.0 (TID 318). 2234 bytes result sent to driver
18/02/28 13:40:11 INFO TaskSetManager: Finished task 1.0 in stage 113.0 (TID 318) in 79 ms on localhost (executor driver) (4/4)
18/02/28 13:40:11 INFO TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool 
18/02/28 13:40:11 INFO DAGScheduler: ShuffleMapStage 113 (countByValue at StringIndexer.scala:113) finished in 0.079 s
18/02/28 13:40:11 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:40:11 INFO DAGScheduler: running: Set()
18/02/28 13:40:11 INFO DAGScheduler: waiting: Set(ResultStage 114)
18/02/28 13:40:11 INFO DAGScheduler: failed: Set()
18/02/28 13:40:11 INFO DAGScheduler: Submitting ResultStage 114 (ShuffledRDD[375] at countByValue at StringIndexer.scala:113), which has no missing parents
18/02/28 13:40:11 INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 3.2 KB, free 260.9 MB)
18/02/28 13:40:11 INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 1962.0 B, free 260.9 MB)
18/02/28 13:40:11 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 127.0.0.1:60941 (size: 1962.0 B, free: 266.6 MB)
18/02/28 13:40:11 INFO SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:11 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 114 (ShuffledRDD[375] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:11 INFO TaskSchedulerImpl: Adding task set 114.0 with 4 tasks
18/02/28 13:40:11 INFO TaskSetManager: Starting task 0.0 in stage 114.0 (TID 321, localhost, executor driver, partition 0, ANY, 4621 bytes)
18/02/28 13:40:11 INFO TaskSetManager: Starting task 1.0 in stage 114.0 (TID 322, localhost, executor driver, partition 1, ANY, 4621 bytes)
18/02/28 13:40:11 INFO TaskSetManager: Starting task 2.0 in stage 114.0 (TID 323, localhost, executor driver, partition 2, ANY, 4621 bytes)
18/02/28 13:40:11 INFO TaskSetManager: Starting task 3.0 in stage 114.0 (TID 324, localhost, executor driver, partition 3, ANY, 4621 bytes)
18/02/28 13:40:11 INFO Executor: Running task 0.0 in stage 114.0 (TID 321)
18/02/28 13:40:11 INFO Executor: Running task 1.0 in stage 114.0 (TID 322)
18/02/28 13:40:11 INFO Executor: Running task 2.0 in stage 114.0 (TID 323)
18/02/28 13:40:11 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:40:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:40:11 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:40:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:40:11 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:40:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:40:11 INFO Executor: Finished task 0.0 in stage 114.0 (TID 321). 1196 bytes result sent to driver
18/02/28 13:40:11 INFO Executor: Finished task 1.0 in stage 114.0 (TID 322). 1135 bytes result sent to driver
18/02/28 13:40:11 INFO Executor: Finished task 2.0 in stage 114.0 (TID 323). 1110 bytes result sent to driver
18/02/28 13:40:11 INFO TaskSetManager: Finished task 0.0 in stage 114.0 (TID 321) in 33 ms on localhost (executor driver) (1/4)
18/02/28 13:40:11 INFO TaskSetManager: Finished task 2.0 in stage 114.0 (TID 323) in 42 ms on localhost (executor driver) (2/4)
18/02/28 13:40:11 INFO TaskSetManager: Finished task 1.0 in stage 114.0 (TID 322) in 44 ms on localhost (executor driver) (3/4)
18/02/28 13:40:11 INFO Executor: Running task 3.0 in stage 114.0 (TID 324)
18/02/28 13:40:11 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:40:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:40:11 INFO Executor: Finished task 3.0 in stage 114.0 (TID 324). 1153 bytes result sent to driver
18/02/28 13:40:11 INFO TaskSetManager: Finished task 3.0 in stage 114.0 (TID 324) in 68 ms on localhost (executor driver) (4/4)
18/02/28 13:40:11 INFO TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool 
18/02/28 13:40:11 INFO DAGScheduler: ResultStage 114 (countByValue at StringIndexer.scala:113) finished in 0.069 s
18/02/28 13:40:11 INFO DAGScheduler: Job 60 finished: countByValue at StringIndexer.scala:113, took 0.166312 s
18/02/28 13:40:11 INFO CodeGenerator: Code generated in 7.8422 ms
18/02/28 13:40:11 INFO SparkContext: Starting job: countByValue at StringIndexer.scala:113
18/02/28 13:40:11 INFO DAGScheduler: Registering RDD 382 (countByValue at StringIndexer.scala:113)
18/02/28 13:40:11 INFO DAGScheduler: Got job 61 (countByValue at StringIndexer.scala:113) with 4 output partitions
18/02/28 13:40:11 INFO DAGScheduler: Final stage: ResultStage 116 (countByValue at StringIndexer.scala:113)
18/02/28 13:40:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 115)
18/02/28 13:40:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 115)
18/02/28 13:40:11 INFO DAGScheduler: Submitting ShuffleMapStage 115 (MapPartitionsRDD[382] at countByValue at StringIndexer.scala:113), which has no missing parents
18/02/28 13:40:11 INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 56.1 KB, free 260.9 MB)
18/02/28 13:40:11 INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 23.1 KB, free 260.8 MB)
18/02/28 13:40:11 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 127.0.0.1:60941 (size: 23.1 KB, free: 266.6 MB)
18/02/28 13:40:11 INFO SparkContext: Created broadcast 135 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:11 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 115 (MapPartitionsRDD[382] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:11 INFO TaskSchedulerImpl: Adding task set 115.0 with 4 tasks
18/02/28 13:40:11 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 325, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:40:11 INFO TaskSetManager: Starting task 1.0 in stage 115.0 (TID 326, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:40:11 INFO TaskSetManager: Starting task 2.0 in stage 115.0 (TID 327, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:40:11 INFO TaskSetManager: Starting task 3.0 in stage 115.0 (TID 328, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:40:11 INFO Executor: Running task 0.0 in stage 115.0 (TID 325)
18/02/28 13:40:11 INFO Executor: Running task 1.0 in stage 115.0 (TID 326)
18/02/28 13:40:11 INFO Executor: Running task 2.0 in stage 115.0 (TID 327)
18/02/28 13:40:11 INFO BlockManager: Found block rdd_355_2 locally
18/02/28 13:40:11 INFO BlockManager: Found block rdd_355_1 locally
18/02/28 13:40:11 INFO Executor: Running task 3.0 in stage 115.0 (TID 328)
18/02/28 13:40:11 INFO BlockManager: Found block rdd_355_0 locally
18/02/28 13:40:11 INFO BlockManager: Found block rdd_355_3 locally
18/02/28 13:40:11 INFO Executor: Finished task 2.0 in stage 115.0 (TID 327). 2277 bytes result sent to driver
18/02/28 13:40:11 INFO TaskSetManager: Finished task 2.0 in stage 115.0 (TID 327) in 59 ms on localhost (executor driver) (1/4)
18/02/28 13:40:11 INFO Executor: Finished task 1.0 in stage 115.0 (TID 326). 2234 bytes result sent to driver
18/02/28 13:40:11 INFO TaskSetManager: Finished task 1.0 in stage 115.0 (TID 326) in 62 ms on localhost (executor driver) (2/4)
18/02/28 13:40:11 INFO Executor: Finished task 3.0 in stage 115.0 (TID 328). 2277 bytes result sent to driver
18/02/28 13:40:11 INFO TaskSetManager: Finished task 3.0 in stage 115.0 (TID 328) in 63 ms on localhost (executor driver) (3/4)
18/02/28 13:40:11 INFO Executor: Finished task 0.0 in stage 115.0 (TID 325). 2277 bytes result sent to driver
18/02/28 13:40:11 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 325) in 65 ms on localhost (executor driver) (4/4)
18/02/28 13:40:11 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool 
18/02/28 13:40:11 INFO DAGScheduler: ShuffleMapStage 115 (countByValue at StringIndexer.scala:113) finished in 0.065 s
18/02/28 13:40:11 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:40:11 INFO DAGScheduler: running: Set()
18/02/28 13:40:11 INFO DAGScheduler: waiting: Set(ResultStage 116)
18/02/28 13:40:11 INFO DAGScheduler: failed: Set()
18/02/28 13:40:11 INFO DAGScheduler: Submitting ResultStage 116 (ShuffledRDD[383] at countByValue at StringIndexer.scala:113), which has no missing parents
18/02/28 13:40:11 INFO MemoryStore: Block broadcast_136 stored as values in memory (estimated size 3.2 KB, free 260.8 MB)
18/02/28 13:40:11 INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 1963.0 B, free 260.8 MB)
18/02/28 13:40:11 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 127.0.0.1:60941 (size: 1963.0 B, free: 266.6 MB)
18/02/28 13:40:11 INFO SparkContext: Created broadcast 136 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:11 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 116 (ShuffledRDD[383] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:11 INFO TaskSchedulerImpl: Adding task set 116.0 with 4 tasks
18/02/28 13:40:11 INFO TaskSetManager: Starting task 0.0 in stage 116.0 (TID 329, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:11 INFO TaskSetManager: Starting task 1.0 in stage 116.0 (TID 330, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:11 INFO TaskSetManager: Starting task 2.0 in stage 116.0 (TID 331, localhost, executor driver, partition 2, ANY, 4621 bytes)
18/02/28 13:40:11 INFO TaskSetManager: Starting task 3.0 in stage 116.0 (TID 332, localhost, executor driver, partition 3, ANY, 4621 bytes)
18/02/28 13:40:11 INFO Executor: Running task 0.0 in stage 116.0 (TID 329)
18/02/28 13:40:11 INFO Executor: Running task 1.0 in stage 116.0 (TID 330)
18/02/28 13:40:11 INFO Executor: Running task 2.0 in stage 116.0 (TID 331)
18/02/28 13:40:11 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 13:40:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:40:11 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 13:40:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:40:11 INFO Executor: Finished task 1.0 in stage 116.0 (TID 330). 1005 bytes result sent to driver
18/02/28 13:40:11 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:40:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
18/02/28 13:40:11 INFO Executor: Finished task 0.0 in stage 116.0 (TID 329). 1048 bytes result sent to driver
18/02/28 13:40:11 INFO Executor: Running task 3.0 in stage 116.0 (TID 332)
18/02/28 13:40:11 INFO TaskSetManager: Finished task 1.0 in stage 116.0 (TID 330) in 6 ms on localhost (executor driver) (1/4)
18/02/28 13:40:11 INFO TaskSetManager: Finished task 0.0 in stage 116.0 (TID 329) in 7 ms on localhost (executor driver) (2/4)
18/02/28 13:40:11 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:40:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:40:11 INFO Executor: Finished task 2.0 in stage 116.0 (TID 331). 1197 bytes result sent to driver
18/02/28 13:40:11 INFO TaskSetManager: Finished task 2.0 in stage 116.0 (TID 331) in 11 ms on localhost (executor driver) (3/4)
18/02/28 13:40:11 INFO Executor: Finished task 3.0 in stage 116.0 (TID 332). 1154 bytes result sent to driver
18/02/28 13:40:11 INFO TaskSetManager: Finished task 3.0 in stage 116.0 (TID 332) in 14 ms on localhost (executor driver) (4/4)
18/02/28 13:40:11 INFO TaskSchedulerImpl: Removed TaskSet 116.0, whose tasks have all completed, from pool 
18/02/28 13:40:11 INFO DAGScheduler: ResultStage 116 (countByValue at StringIndexer.scala:113) finished in 0.014 s
18/02/28 13:40:11 INFO DAGScheduler: Job 61 finished: countByValue at StringIndexer.scala:113, took 0.096995 s
18/02/28 13:40:11 INFO CodeGenerator: Code generated in 22.051955 ms
18/02/28 13:40:11 INFO CodeGenerator: Code generated in 18.920365 ms
18/02/28 13:40:11 INFO Instrumentation: LogisticRegression-logistic_regression_30e0295c3a85-1391927450-1: training: numPartitions=4 storageLevel=StorageLevel(disk, memory, deserialized, 1 replicas)
18/02/28 13:40:11 INFO Instrumentation: LogisticRegression-logistic_regression_30e0295c3a85-1391927450-1: {"elasticNetParam":0.0,"fitIntercept":true,"threshold":0.5,"regParam":0.0,"tol":1.0E-6,"maxIter":100}
18/02/28 13:40:11 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:517
18/02/28 13:40:11 INFO DAGScheduler: Got job 62 (treeAggregate at LogisticRegression.scala:517) with 4 output partitions
18/02/28 13:40:11 INFO DAGScheduler: Final stage: ResultStage 117 (treeAggregate at LogisticRegression.scala:517)
18/02/28 13:40:11 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:40:11 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:11 INFO DAGScheduler: Submitting ResultStage 117 (MapPartitionsRDD[393] at treeAggregate at LogisticRegression.scala:517), which has no missing parents
18/02/28 13:40:11 INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 74.0 KB, free 260.8 MB)
18/02/28 13:40:11 INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 29.1 KB, free 260.7 MB)
18/02/28 13:40:11 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 127.0.0.1:60941 (size: 29.1 KB, free: 266.5 MB)
18/02/28 13:40:11 INFO SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:11 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 117 (MapPartitionsRDD[393] at treeAggregate at LogisticRegression.scala:517) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:11 INFO TaskSchedulerImpl: Adding task set 117.0 with 4 tasks
18/02/28 13:40:11 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 333, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:11 INFO TaskSetManager: Starting task 1.0 in stage 117.0 (TID 334, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:11 INFO TaskSetManager: Starting task 2.0 in stage 117.0 (TID 335, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:40:11 INFO TaskSetManager: Starting task 3.0 in stage 117.0 (TID 336, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:11 INFO Executor: Running task 1.0 in stage 117.0 (TID 334)
18/02/28 13:40:11 INFO Executor: Running task 0.0 in stage 117.0 (TID 333)
18/02/28 13:40:11 INFO Executor: Running task 3.0 in stage 117.0 (TID 336)
18/02/28 13:40:11 INFO Executor: Running task 2.0 in stage 117.0 (TID 335)
18/02/28 13:40:11 INFO BlockManager: Found block rdd_355_0 locally
18/02/28 13:40:11 INFO BlockManager: Found block rdd_355_2 locally
18/02/28 13:40:11 INFO BlockManager: Found block rdd_355_3 locally
18/02/28 13:40:11 INFO BlockManager: Found block rdd_355_1 locally
18/02/28 13:40:11 INFO CodeGenerator: Code generated in 9.98999 ms
18/02/28 13:40:12 INFO CodeGenerator: Code generated in 4.836846 ms
18/02/28 13:40:12 INFO MemoryStore: Block rdd_392_3 stored as values in memory (estimated size 78.7 KB, free 260.7 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added rdd_392_3 in memory on 127.0.0.1:60941 (size: 78.7 KB, free: 266.5 MB)
18/02/28 13:40:12 INFO MemoryStore: Block rdd_392_1 stored as values in memory (estimated size 89.5 KB, free 260.6 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added rdd_392_1 in memory on 127.0.0.1:60941 (size: 89.5 KB, free: 266.4 MB)
18/02/28 13:40:12 INFO Executor: Finished task 1.0 in stage 117.0 (TID 334). 3936 bytes result sent to driver
18/02/28 13:40:12 INFO TaskSetManager: Finished task 1.0 in stage 117.0 (TID 334) in 266 ms on localhost (executor driver) (1/4)
18/02/28 13:40:12 INFO Executor: Finished task 3.0 in stage 117.0 (TID 336). 3893 bytes result sent to driver
18/02/28 13:40:12 INFO TaskSetManager: Finished task 3.0 in stage 117.0 (TID 336) in 268 ms on localhost (executor driver) (2/4)
18/02/28 13:40:12 INFO MemoryStore: Block rdd_392_2 stored as values in memory (estimated size 89.9 KB, free 260.5 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added rdd_392_2 in memory on 127.0.0.1:60941 (size: 89.9 KB, free: 266.3 MB)
18/02/28 13:40:12 INFO Executor: Finished task 2.0 in stage 117.0 (TID 335). 3893 bytes result sent to driver
18/02/28 13:40:12 INFO TaskSetManager: Finished task 2.0 in stage 117.0 (TID 335) in 280 ms on localhost (executor driver) (3/4)
18/02/28 13:40:12 INFO MemoryStore: Block rdd_392_0 stored as values in memory (estimated size 89.4 KB, free 260.4 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added rdd_392_0 in memory on 127.0.0.1:60941 (size: 89.4 KB, free: 266.2 MB)
18/02/28 13:40:12 INFO Executor: Finished task 0.0 in stage 117.0 (TID 333). 3893 bytes result sent to driver
18/02/28 13:40:12 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 333) in 295 ms on localhost (executor driver) (4/4)
18/02/28 13:40:12 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool 
18/02/28 13:40:12 INFO DAGScheduler: ResultStage 117 (treeAggregate at LogisticRegression.scala:517) finished in 0.295 s
18/02/28 13:40:12 INFO DAGScheduler: Job 62 finished: treeAggregate at LogisticRegression.scala:517, took 0.300053 s
18/02/28 13:40:12 INFO Instrumentation: LogisticRegression-logistic_regression_30e0295c3a85-1391927450-1: {"numClasses":2}
18/02/28 13:40:12 INFO Instrumentation: LogisticRegression-logistic_regression_30e0295c3a85-1391927450-1: {"numFeatures":5}
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 80.0 B, free 260.4 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 109.0 B, free 260.4 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 127.0.0.1:60941 (size: 109.0 B, free: 266.2 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 138 from broadcast at LogisticRegression.scala:600
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_139 stored as values in memory (estimated size 104.0 B, free 260.4 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 154.0 B, free 260.4 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on 127.0.0.1:60941 (size: 154.0 B, free: 266.2 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 139 from broadcast at LogisticRegression.scala:1879
18/02/28 13:40:12 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:40:12 INFO DAGScheduler: Got job 63 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:40:12 INFO DAGScheduler: Final stage: ResultStage 118 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:40:12 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:40:12 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:12 INFO DAGScheduler: Submitting ResultStage 118 (MapPartitionsRDD[394] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_140 stored as values in memory (estimated size 74.1 KB, free 260.3 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 29.1 KB, free 260.3 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on 127.0.0.1:60941 (size: 29.1 KB, free: 266.2 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:12 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 118 (MapPartitionsRDD[394] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:12 INFO TaskSchedulerImpl: Adding task set 118.0 with 4 tasks
18/02/28 13:40:12 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 337, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 1.0 in stage 118.0 (TID 338, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 2.0 in stage 118.0 (TID 339, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 3.0 in stage 118.0 (TID 340, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO Executor: Running task 1.0 in stage 118.0 (TID 338)
18/02/28 13:40:12 INFO Executor: Running task 0.0 in stage 118.0 (TID 337)
18/02/28 13:40:12 INFO Executor: Running task 3.0 in stage 118.0 (TID 340)
18/02/28 13:40:12 INFO Executor: Running task 2.0 in stage 118.0 (TID 339)
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_0 locally
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_2 locally
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_1 locally
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_3 locally
18/02/28 13:40:12 INFO Executor: Finished task 0.0 in stage 118.0 (TID 337). 3524 bytes result sent to driver
18/02/28 13:40:12 INFO Executor: Finished task 1.0 in stage 118.0 (TID 338). 3524 bytes result sent to driver
18/02/28 13:40:12 INFO Executor: Finished task 3.0 in stage 118.0 (TID 340). 3438 bytes result sent to driver
18/02/28 13:40:12 INFO Executor: Finished task 2.0 in stage 118.0 (TID 339). 3524 bytes result sent to driver
18/02/28 13:40:12 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 337) in 22 ms on localhost (executor driver) (1/4)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 1.0 in stage 118.0 (TID 338) in 23 ms on localhost (executor driver) (2/4)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 3.0 in stage 118.0 (TID 340) in 23 ms on localhost (executor driver) (3/4)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 2.0 in stage 118.0 (TID 339) in 24 ms on localhost (executor driver) (4/4)
18/02/28 13:40:12 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool 
18/02/28 13:40:12 INFO DAGScheduler: ResultStage 118 (treeAggregate at LogisticRegression.scala:1892) finished in 0.024 s
18/02/28 13:40:12 INFO DAGScheduler: Job 63 finished: treeAggregate at LogisticRegression.scala:1892, took 0.027500 s
18/02/28 13:40:12 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
18/02/28 13:40:12 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
18/02/28 13:40:12 INFO TorrentBroadcast: Destroying Broadcast(139) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:40:12 INFO BlockManagerInfo: Removed broadcast_139_piece0 on 127.0.0.1:60941 in memory (size: 154.0 B, free: 266.2 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_141 stored as values in memory (estimated size 104.0 B, free 260.3 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 186.0 B, free 260.3 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on 127.0.0.1:60941 (size: 186.0 B, free: 266.2 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 141 from broadcast at LogisticRegression.scala:1879
18/02/28 13:40:12 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:40:12 INFO DAGScheduler: Got job 64 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:40:12 INFO DAGScheduler: Final stage: ResultStage 119 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:40:12 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:40:12 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:12 INFO DAGScheduler: Submitting ResultStage 119 (MapPartitionsRDD[395] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_142 stored as values in memory (estimated size 74.1 KB, free 260.2 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 29.1 KB, free 260.2 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on 127.0.0.1:60941 (size: 29.1 KB, free: 266.1 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Removed broadcast_137_piece0 on 127.0.0.1:60941 in memory (size: 29.1 KB, free: 266.2 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:12 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 119 (MapPartitionsRDD[395] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:12 INFO TaskSchedulerImpl: Adding task set 119.0 with 4 tasks
18/02/28 13:40:12 INFO BlockManagerInfo: Removed broadcast_135_piece0 on 127.0.0.1:60941 in memory (size: 23.1 KB, free: 266.2 MB)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 341, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 1.0 in stage 119.0 (TID 342, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO BlockManagerInfo: Removed broadcast_136_piece0 on 127.0.0.1:60941 in memory (size: 1963.0 B, free: 266.2 MB)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 2.0 in stage 119.0 (TID 343, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 3.0 in stage 119.0 (TID 344, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO ContextCleaner: Cleaned accumulator 3533
18/02/28 13:40:12 INFO Executor: Running task 0.0 in stage 119.0 (TID 341)
18/02/28 13:40:12 INFO Executor: Running task 1.0 in stage 119.0 (TID 342)
18/02/28 13:40:12 INFO Executor: Running task 3.0 in stage 119.0 (TID 344)
18/02/28 13:40:12 INFO Executor: Running task 2.0 in stage 119.0 (TID 343)
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_2 locally
18/02/28 13:40:12 INFO Executor: Finished task 2.0 in stage 119.0 (TID 343). 3438 bytes result sent to driver
18/02/28 13:40:12 INFO BlockManagerInfo: Removed broadcast_133_piece0 on 127.0.0.1:60941 in memory (size: 22.9 KB, free: 266.2 MB)
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_1 locally
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_0 locally
18/02/28 13:40:12 INFO Executor: Finished task 0.0 in stage 119.0 (TID 341). 3395 bytes result sent to driver
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_3 locally
18/02/28 13:40:12 INFO TaskSetManager: Finished task 2.0 in stage 119.0 (TID 343) in 11 ms on localhost (executor driver) (1/4)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 341) in 11 ms on localhost (executor driver) (2/4)
18/02/28 13:40:12 INFO Executor: Finished task 1.0 in stage 119.0 (TID 342). 3395 bytes result sent to driver
18/02/28 13:40:12 INFO Executor: Finished task 3.0 in stage 119.0 (TID 344). 3481 bytes result sent to driver
18/02/28 13:40:12 INFO ContextCleaner: Cleaned accumulator 3583
18/02/28 13:40:12 INFO TaskSetManager: Finished task 1.0 in stage 119.0 (TID 342) in 12 ms on localhost (executor driver) (3/4)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 3.0 in stage 119.0 (TID 344) in 12 ms on localhost (executor driver) (4/4)
18/02/28 13:40:12 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool 
18/02/28 13:40:12 INFO DAGScheduler: ResultStage 119 (treeAggregate at LogisticRegression.scala:1892) finished in 0.012 s
18/02/28 13:40:12 INFO DAGScheduler: Job 64 finished: treeAggregate at LogisticRegression.scala:1892, took 0.023313 s
18/02/28 13:40:12 INFO TorrentBroadcast: Destroying Broadcast(141) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:40:12 INFO ContextCleaner: Cleaned shuffle 53
18/02/28 13:40:12 INFO ContextCleaner: Cleaned accumulator 3531
18/02/28 13:40:12 INFO ContextCleaner: Cleaned accumulator 3532
18/02/28 13:40:12 INFO LBFGS: Step Size: 1.000
18/02/28 13:40:12 INFO LBFGS: Val and Grad Norm: 0.484291 (rel: 0.116) 0.199553
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_143 stored as values in memory (estimated size 104.0 B, free 260.4 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 186.0 B, free 260.4 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on 127.0.0.1:60941 (size: 186.0 B, free: 266.2 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Removed broadcast_140_piece0 on 127.0.0.1:60941 in memory (size: 29.1 KB, free: 266.2 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 143 from broadcast at LogisticRegression.scala:1879
18/02/28 13:40:12 INFO BlockManagerInfo: Removed broadcast_141_piece0 on 127.0.0.1:60941 in memory (size: 186.0 B, free: 266.2 MB)
18/02/28 13:40:12 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:40:12 INFO BlockManagerInfo: Removed broadcast_134_piece0 on 127.0.0.1:60941 in memory (size: 1962.0 B, free: 266.2 MB)
18/02/28 13:40:12 INFO ContextCleaner: Cleaned accumulator 3582
18/02/28 13:40:12 INFO ContextCleaner: Cleaned accumulator 3584
18/02/28 13:40:12 INFO DAGScheduler: Got job 65 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:40:12 INFO DAGScheduler: Final stage: ResultStage 120 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:40:12 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:40:12 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:12 INFO DAGScheduler: Submitting ResultStage 120 (MapPartitionsRDD[396] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:40:12 INFO ContextCleaner: Cleaned shuffle 54
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_144 stored as values in memory (estimated size 74.1 KB, free 260.5 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 29.1 KB, free 260.5 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on 127.0.0.1:60941 (size: 29.1 KB, free: 266.2 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 144 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:12 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 120 (MapPartitionsRDD[396] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:12 INFO TaskSchedulerImpl: Adding task set 120.0 with 4 tasks
18/02/28 13:40:12 INFO TaskSetManager: Starting task 0.0 in stage 120.0 (TID 345, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 1.0 in stage 120.0 (TID 346, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 2.0 in stage 120.0 (TID 347, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 3.0 in stage 120.0 (TID 348, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO Executor: Running task 0.0 in stage 120.0 (TID 345)
18/02/28 13:40:12 INFO Executor: Running task 2.0 in stage 120.0 (TID 347)
18/02/28 13:40:12 INFO Executor: Running task 3.0 in stage 120.0 (TID 348)
18/02/28 13:40:12 INFO Executor: Running task 1.0 in stage 120.0 (TID 346)
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_3 locally
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_2 locally
18/02/28 13:40:12 INFO Executor: Finished task 2.0 in stage 120.0 (TID 347). 3438 bytes result sent to driver
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_1 locally
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_0 locally
18/02/28 13:40:12 INFO Executor: Finished task 1.0 in stage 120.0 (TID 346). 3438 bytes result sent to driver
18/02/28 13:40:12 INFO Executor: Finished task 3.0 in stage 120.0 (TID 348). 3481 bytes result sent to driver
18/02/28 13:40:12 INFO TaskSetManager: Finished task 2.0 in stage 120.0 (TID 347) in 10 ms on localhost (executor driver) (1/4)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 1.0 in stage 120.0 (TID 346) in 11 ms on localhost (executor driver) (2/4)
18/02/28 13:40:12 INFO Executor: Finished task 0.0 in stage 120.0 (TID 345). 3481 bytes result sent to driver
18/02/28 13:40:12 INFO TaskSetManager: Finished task 3.0 in stage 120.0 (TID 348) in 10 ms on localhost (executor driver) (3/4)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 0.0 in stage 120.0 (TID 345) in 13 ms on localhost (executor driver) (4/4)
18/02/28 13:40:12 INFO TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool 
18/02/28 13:40:12 INFO DAGScheduler: ResultStage 120 (treeAggregate at LogisticRegression.scala:1892) finished in 0.013 s
18/02/28 13:40:12 INFO DAGScheduler: Job 65 finished: treeAggregate at LogisticRegression.scala:1892, took 0.016888 s
18/02/28 13:40:12 INFO TorrentBroadcast: Destroying Broadcast(143) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:40:12 INFO LBFGS: Step Size: 1.000
18/02/28 13:40:12 INFO LBFGS: Val and Grad Norm: 0.369828 (rel: 0.236) 0.0853993
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_145 stored as values in memory (estimated size 104.0 B, free 260.5 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 186.0 B, free 260.5 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Removed broadcast_143_piece0 on 127.0.0.1:60941 in memory (size: 186.0 B, free: 266.2 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on 127.0.0.1:60941 (size: 186.0 B, free: 266.2 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 145 from broadcast at LogisticRegression.scala:1879
18/02/28 13:40:12 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:40:12 INFO DAGScheduler: Got job 66 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:40:12 INFO DAGScheduler: Final stage: ResultStage 121 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:40:12 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:40:12 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:12 INFO DAGScheduler: Submitting ResultStage 121 (MapPartitionsRDD[397] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_146 stored as values in memory (estimated size 74.1 KB, free 260.4 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 29.1 KB, free 260.4 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on 127.0.0.1:60941 (size: 29.1 KB, free: 266.2 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 146 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:12 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 121 (MapPartitionsRDD[397] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:12 INFO TaskSchedulerImpl: Adding task set 121.0 with 4 tasks
18/02/28 13:40:12 INFO TaskSetManager: Starting task 0.0 in stage 121.0 (TID 349, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 1.0 in stage 121.0 (TID 350, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 2.0 in stage 121.0 (TID 351, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 3.0 in stage 121.0 (TID 352, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO Executor: Running task 0.0 in stage 121.0 (TID 349)
18/02/28 13:40:12 INFO Executor: Running task 1.0 in stage 121.0 (TID 350)
18/02/28 13:40:12 INFO Executor: Running task 2.0 in stage 121.0 (TID 351)
18/02/28 13:40:12 INFO Executor: Running task 3.0 in stage 121.0 (TID 352)
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_0 locally
18/02/28 13:40:12 INFO Executor: Finished task 0.0 in stage 121.0 (TID 349). 3481 bytes result sent to driver
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_2 locally
18/02/28 13:40:12 INFO Executor: Finished task 2.0 in stage 121.0 (TID 351). 3395 bytes result sent to driver
18/02/28 13:40:12 INFO TaskSetManager: Finished task 0.0 in stage 121.0 (TID 349) in 9 ms on localhost (executor driver) (1/4)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 2.0 in stage 121.0 (TID 351) in 7 ms on localhost (executor driver) (2/4)
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_1 locally
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_3 locally
18/02/28 13:40:12 INFO Executor: Finished task 1.0 in stage 121.0 (TID 350). 3438 bytes result sent to driver
18/02/28 13:40:12 INFO Executor: Finished task 3.0 in stage 121.0 (TID 352). 3438 bytes result sent to driver
18/02/28 13:40:12 INFO TaskSetManager: Finished task 1.0 in stage 121.0 (TID 350) in 9 ms on localhost (executor driver) (3/4)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 3.0 in stage 121.0 (TID 352) in 9 ms on localhost (executor driver) (4/4)
18/02/28 13:40:12 INFO TaskSchedulerImpl: Removed TaskSet 121.0, whose tasks have all completed, from pool 
18/02/28 13:40:12 INFO DAGScheduler: ResultStage 121 (treeAggregate at LogisticRegression.scala:1892) finished in 0.011 s
18/02/28 13:40:12 INFO DAGScheduler: Job 66 finished: treeAggregate at LogisticRegression.scala:1892, took 0.016341 s
18/02/28 13:40:12 INFO TorrentBroadcast: Destroying Broadcast(145) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:40:12 INFO LBFGS: Step Size: 1.000
18/02/28 13:40:12 INFO LBFGS: Val and Grad Norm: 0.326541 (rel: 0.117) 0.0529131
18/02/28 13:40:12 INFO BlockManagerInfo: Removed broadcast_145_piece0 on 127.0.0.1:60941 in memory (size: 186.0 B, free: 266.2 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_147 stored as values in memory (estimated size 104.0 B, free 260.4 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 186.0 B, free 260.4 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on 127.0.0.1:60941 (size: 186.0 B, free: 266.2 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 147 from broadcast at LogisticRegression.scala:1879
18/02/28 13:40:12 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:40:12 INFO DAGScheduler: Got job 67 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:40:12 INFO DAGScheduler: Final stage: ResultStage 122 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:40:12 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:40:12 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:12 INFO DAGScheduler: Submitting ResultStage 122 (MapPartitionsRDD[398] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_148 stored as values in memory (estimated size 74.1 KB, free 260.3 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 29.1 KB, free 260.3 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on 127.0.0.1:60941 (size: 29.1 KB, free: 266.2 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 148 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:12 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 122 (MapPartitionsRDD[398] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:12 INFO TaskSchedulerImpl: Adding task set 122.0 with 4 tasks
18/02/28 13:40:12 INFO TaskSetManager: Starting task 0.0 in stage 122.0 (TID 353, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 1.0 in stage 122.0 (TID 354, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 2.0 in stage 122.0 (TID 355, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 3.0 in stage 122.0 (TID 356, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO Executor: Running task 1.0 in stage 122.0 (TID 354)
18/02/28 13:40:12 INFO Executor: Running task 3.0 in stage 122.0 (TID 356)
18/02/28 13:40:12 INFO Executor: Running task 2.0 in stage 122.0 (TID 355)
18/02/28 13:40:12 INFO Executor: Running task 0.0 in stage 122.0 (TID 353)
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_2 locally
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_3 locally
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_0 locally
18/02/28 13:40:12 INFO Executor: Finished task 3.0 in stage 122.0 (TID 356). 3481 bytes result sent to driver
18/02/28 13:40:12 INFO Executor: Finished task 0.0 in stage 122.0 (TID 353). 3481 bytes result sent to driver
18/02/28 13:40:12 INFO Executor: Finished task 2.0 in stage 122.0 (TID 355). 3481 bytes result sent to driver
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_1 locally
18/02/28 13:40:12 INFO TaskSetManager: Finished task 3.0 in stage 122.0 (TID 356) in 5 ms on localhost (executor driver) (1/4)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 2.0 in stage 122.0 (TID 355) in 5 ms on localhost (executor driver) (2/4)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 0.0 in stage 122.0 (TID 353) in 6 ms on localhost (executor driver) (3/4)
18/02/28 13:40:12 INFO Executor: Finished task 1.0 in stage 122.0 (TID 354). 3438 bytes result sent to driver
18/02/28 13:40:12 INFO TaskSetManager: Finished task 1.0 in stage 122.0 (TID 354) in 7 ms on localhost (executor driver) (4/4)
18/02/28 13:40:12 INFO TaskSchedulerImpl: Removed TaskSet 122.0, whose tasks have all completed, from pool 
18/02/28 13:40:12 INFO DAGScheduler: ResultStage 122 (treeAggregate at LogisticRegression.scala:1892) finished in 0.007 s
18/02/28 13:40:12 INFO DAGScheduler: Job 67 finished: treeAggregate at LogisticRegression.scala:1892, took 0.010863 s
18/02/28 13:40:12 INFO TorrentBroadcast: Destroying Broadcast(147) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:40:12 INFO LBFGS: Step Size: 1.000
18/02/28 13:40:12 INFO BlockManagerInfo: Removed broadcast_147_piece0 on 127.0.0.1:60941 in memory (size: 186.0 B, free: 266.2 MB)
18/02/28 13:40:12 INFO LBFGS: Val and Grad Norm: 0.291746 (rel: 0.107) 0.0427922
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_149 stored as values in memory (estimated size 104.0 B, free 260.3 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 186.0 B, free 260.3 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on 127.0.0.1:60941 (size: 186.0 B, free: 266.2 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 149 from broadcast at LogisticRegression.scala:1879
18/02/28 13:40:12 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:40:12 INFO DAGScheduler: Got job 68 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:40:12 INFO DAGScheduler: Final stage: ResultStage 123 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:40:12 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:40:12 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:12 INFO DAGScheduler: Submitting ResultStage 123 (MapPartitionsRDD[399] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_150 stored as values in memory (estimated size 74.1 KB, free 260.2 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 29.1 KB, free 260.2 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on 127.0.0.1:60941 (size: 29.1 KB, free: 266.1 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 150 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:12 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 123 (MapPartitionsRDD[399] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:12 INFO TaskSchedulerImpl: Adding task set 123.0 with 4 tasks
18/02/28 13:40:12 INFO TaskSetManager: Starting task 0.0 in stage 123.0 (TID 357, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 1.0 in stage 123.0 (TID 358, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 2.0 in stage 123.0 (TID 359, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 3.0 in stage 123.0 (TID 360, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO Executor: Running task 0.0 in stage 123.0 (TID 357)
18/02/28 13:40:12 INFO Executor: Running task 1.0 in stage 123.0 (TID 358)
18/02/28 13:40:12 INFO Executor: Running task 2.0 in stage 123.0 (TID 359)
18/02/28 13:40:12 INFO Executor: Running task 3.0 in stage 123.0 (TID 360)
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_0 locally
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_1 locally
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_2 locally
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_3 locally
18/02/28 13:40:12 INFO Executor: Finished task 2.0 in stage 123.0 (TID 359). 3481 bytes result sent to driver
18/02/28 13:40:12 INFO Executor: Finished task 3.0 in stage 123.0 (TID 360). 3438 bytes result sent to driver
18/02/28 13:40:12 INFO Executor: Finished task 1.0 in stage 123.0 (TID 358). 3481 bytes result sent to driver
18/02/28 13:40:12 INFO Executor: Finished task 0.0 in stage 123.0 (TID 357). 3481 bytes result sent to driver
18/02/28 13:40:12 INFO TaskSetManager: Finished task 2.0 in stage 123.0 (TID 359) in 5 ms on localhost (executor driver) (1/4)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 3.0 in stage 123.0 (TID 360) in 5 ms on localhost (executor driver) (2/4)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 1.0 in stage 123.0 (TID 358) in 5 ms on localhost (executor driver) (3/4)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 0.0 in stage 123.0 (TID 357) in 5 ms on localhost (executor driver) (4/4)
18/02/28 13:40:12 INFO TaskSchedulerImpl: Removed TaskSet 123.0, whose tasks have all completed, from pool 
18/02/28 13:40:12 INFO DAGScheduler: ResultStage 123 (treeAggregate at LogisticRegression.scala:1892) finished in 0.005 s
18/02/28 13:40:12 INFO DAGScheduler: Job 68 finished: treeAggregate at LogisticRegression.scala:1892, took 0.008590 s
18/02/28 13:40:12 INFO TorrentBroadcast: Destroying Broadcast(149) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:40:12 INFO LBFGS: Step Size: 1.000
18/02/28 13:40:12 INFO LBFGS: Val and Grad Norm: 0.278454 (rel: 0.0456) 0.0130965
18/02/28 13:40:12 INFO BlockManagerInfo: Removed broadcast_149_piece0 on 127.0.0.1:60941 in memory (size: 186.0 B, free: 266.1 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 104.0 B, free 260.2 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 186.0 B, free 260.2 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on 127.0.0.1:60941 (size: 186.0 B, free: 266.1 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 151 from broadcast at LogisticRegression.scala:1879
18/02/28 13:40:12 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:40:12 INFO DAGScheduler: Got job 69 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:40:12 INFO DAGScheduler: Final stage: ResultStage 124 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:40:12 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:40:12 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:12 INFO DAGScheduler: Submitting ResultStage 124 (MapPartitionsRDD[400] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 74.1 KB, free 260.1 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 29.1 KB, free 260.1 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on 127.0.0.1:60941 (size: 29.1 KB, free: 266.1 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 152 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:12 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 124 (MapPartitionsRDD[400] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:12 INFO TaskSchedulerImpl: Adding task set 124.0 with 4 tasks
18/02/28 13:40:12 INFO TaskSetManager: Starting task 0.0 in stage 124.0 (TID 361, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 1.0 in stage 124.0 (TID 362, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 2.0 in stage 124.0 (TID 363, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 3.0 in stage 124.0 (TID 364, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO Executor: Running task 0.0 in stage 124.0 (TID 361)
18/02/28 13:40:12 INFO Executor: Running task 3.0 in stage 124.0 (TID 364)
18/02/28 13:40:12 INFO Executor: Running task 1.0 in stage 124.0 (TID 362)
18/02/28 13:40:12 INFO Executor: Running task 2.0 in stage 124.0 (TID 363)
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_0 locally
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_2 locally
18/02/28 13:40:12 INFO Executor: Finished task 0.0 in stage 124.0 (TID 361). 3438 bytes result sent to driver
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_1 locally
18/02/28 13:40:12 INFO Executor: Finished task 2.0 in stage 124.0 (TID 363). 3395 bytes result sent to driver
18/02/28 13:40:12 INFO Executor: Finished task 1.0 in stage 124.0 (TID 362). 3438 bytes result sent to driver
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_3 locally
18/02/28 13:40:12 INFO TaskSetManager: Finished task 0.0 in stage 124.0 (TID 361) in 5 ms on localhost (executor driver) (1/4)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 1.0 in stage 124.0 (TID 362) in 5 ms on localhost (executor driver) (2/4)
18/02/28 13:40:12 INFO Executor: Finished task 3.0 in stage 124.0 (TID 364). 3395 bytes result sent to driver
18/02/28 13:40:12 INFO TaskSetManager: Finished task 2.0 in stage 124.0 (TID 363) in 6 ms on localhost (executor driver) (3/4)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 3.0 in stage 124.0 (TID 364) in 6 ms on localhost (executor driver) (4/4)
18/02/28 13:40:12 INFO TaskSchedulerImpl: Removed TaskSet 124.0, whose tasks have all completed, from pool 
18/02/28 13:40:12 INFO DAGScheduler: ResultStage 124 (treeAggregate at LogisticRegression.scala:1892) finished in 0.006 s
18/02/28 13:40:12 INFO DAGScheduler: Job 69 finished: treeAggregate at LogisticRegression.scala:1892, took 0.009679 s
18/02/28 13:40:12 INFO TorrentBroadcast: Destroying Broadcast(151) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:40:12 INFO LBFGS: Step Size: 1.000
18/02/28 13:40:12 INFO LBFGS: Val and Grad Norm: 0.275000 (rel: 0.0124) 0.00494595
18/02/28 13:40:12 INFO BlockManagerInfo: Removed broadcast_151_piece0 on 127.0.0.1:60941 in memory (size: 186.0 B, free: 266.1 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_153 stored as values in memory (estimated size 104.0 B, free 260.1 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 186.0 B, free 260.1 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on 127.0.0.1:60941 (size: 186.0 B, free: 266.1 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 153 from broadcast at LogisticRegression.scala:1879
18/02/28 13:40:12 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:40:12 INFO DAGScheduler: Got job 70 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:40:12 INFO DAGScheduler: Final stage: ResultStage 125 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:40:12 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:40:12 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:12 INFO DAGScheduler: Submitting ResultStage 125 (MapPartitionsRDD[401] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_154 stored as values in memory (estimated size 74.1 KB, free 260.0 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 29.1 KB, free 259.9 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on 127.0.0.1:60941 (size: 29.1 KB, free: 266.1 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 154 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:12 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 125 (MapPartitionsRDD[401] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:12 INFO TaskSchedulerImpl: Adding task set 125.0 with 4 tasks
18/02/28 13:40:12 INFO TaskSetManager: Starting task 0.0 in stage 125.0 (TID 365, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 1.0 in stage 125.0 (TID 366, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 2.0 in stage 125.0 (TID 367, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 3.0 in stage 125.0 (TID 368, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO Executor: Running task 0.0 in stage 125.0 (TID 365)
18/02/28 13:40:12 INFO Executor: Running task 2.0 in stage 125.0 (TID 367)
18/02/28 13:40:12 INFO Executor: Running task 3.0 in stage 125.0 (TID 368)
18/02/28 13:40:12 INFO Executor: Running task 1.0 in stage 125.0 (TID 366)
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_3 locally
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_1 locally
18/02/28 13:40:12 INFO Executor: Finished task 3.0 in stage 125.0 (TID 368). 3395 bytes result sent to driver
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_2 locally
18/02/28 13:40:12 INFO Executor: Finished task 1.0 in stage 125.0 (TID 366). 3438 bytes result sent to driver
18/02/28 13:40:12 INFO Executor: Finished task 2.0 in stage 125.0 (TID 367). 3395 bytes result sent to driver
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_0 locally
18/02/28 13:40:12 INFO Executor: Finished task 0.0 in stage 125.0 (TID 365). 3438 bytes result sent to driver
18/02/28 13:40:12 INFO TaskSetManager: Finished task 1.0 in stage 125.0 (TID 366) in 9 ms on localhost (executor driver) (1/4)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 3.0 in stage 125.0 (TID 368) in 9 ms on localhost (executor driver) (2/4)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 2.0 in stage 125.0 (TID 367) in 10 ms on localhost (executor driver) (3/4)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 0.0 in stage 125.0 (TID 365) in 10 ms on localhost (executor driver) (4/4)
18/02/28 13:40:12 INFO TaskSchedulerImpl: Removed TaskSet 125.0, whose tasks have all completed, from pool 
18/02/28 13:40:12 INFO DAGScheduler: ResultStage 125 (treeAggregate at LogisticRegression.scala:1892) finished in 0.010 s
18/02/28 13:40:12 INFO DAGScheduler: Job 70 finished: treeAggregate at LogisticRegression.scala:1892, took 0.014257 s
18/02/28 13:40:12 INFO TorrentBroadcast: Destroying Broadcast(153) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:40:12 INFO LBFGS: Step Size: 1.000
18/02/28 13:40:12 INFO LBFGS: Val and Grad Norm: 0.274401 (rel: 0.00218) 0.00829465
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_155 stored as values in memory (estimated size 104.0 B, free 259.9 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 186.0 B, free 259.9 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on 127.0.0.1:60941 (size: 186.0 B, free: 266.1 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Removed broadcast_153_piece0 on 127.0.0.1:60941 in memory (size: 186.0 B, free: 266.1 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 155 from broadcast at LogisticRegression.scala:1879
18/02/28 13:40:12 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:40:12 INFO DAGScheduler: Got job 71 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:40:12 INFO DAGScheduler: Final stage: ResultStage 126 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:40:12 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:40:12 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:12 INFO DAGScheduler: Submitting ResultStage 126 (MapPartitionsRDD[402] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_156 stored as values in memory (estimated size 74.1 KB, free 259.9 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 29.2 KB, free 259.8 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on 127.0.0.1:60941 (size: 29.2 KB, free: 266.0 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 156 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:12 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 126 (MapPartitionsRDD[402] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:12 INFO TaskSchedulerImpl: Adding task set 126.0 with 4 tasks
18/02/28 13:40:12 INFO TaskSetManager: Starting task 0.0 in stage 126.0 (TID 369, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 1.0 in stage 126.0 (TID 370, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 2.0 in stage 126.0 (TID 371, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 3.0 in stage 126.0 (TID 372, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO Executor: Running task 0.0 in stage 126.0 (TID 369)
18/02/28 13:40:12 INFO Executor: Running task 3.0 in stage 126.0 (TID 372)
18/02/28 13:40:12 INFO Executor: Running task 2.0 in stage 126.0 (TID 371)
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_0 locally
18/02/28 13:40:12 INFO Executor: Finished task 0.0 in stage 126.0 (TID 369). 3438 bytes result sent to driver
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_2 locally
18/02/28 13:40:12 INFO Executor: Finished task 2.0 in stage 126.0 (TID 371). 3438 bytes result sent to driver
18/02/28 13:40:12 INFO Executor: Running task 1.0 in stage 126.0 (TID 370)
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_3 locally
18/02/28 13:40:12 INFO Executor: Finished task 3.0 in stage 126.0 (TID 372). 3395 bytes result sent to driver
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_1 locally
18/02/28 13:40:12 INFO TaskSetManager: Finished task 0.0 in stage 126.0 (TID 369) in 14 ms on localhost (executor driver) (1/4)
18/02/28 13:40:12 INFO Executor: Finished task 1.0 in stage 126.0 (TID 370). 3395 bytes result sent to driver
18/02/28 13:40:12 INFO TaskSetManager: Finished task 2.0 in stage 126.0 (TID 371) in 14 ms on localhost (executor driver) (2/4)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 3.0 in stage 126.0 (TID 372) in 15 ms on localhost (executor driver) (3/4)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 1.0 in stage 126.0 (TID 370) in 15 ms on localhost (executor driver) (4/4)
18/02/28 13:40:12 INFO TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool 
18/02/28 13:40:12 INFO DAGScheduler: ResultStage 126 (treeAggregate at LogisticRegression.scala:1892) finished in 0.016 s
18/02/28 13:40:12 INFO DAGScheduler: Job 71 finished: treeAggregate at LogisticRegression.scala:1892, took 0.020028 s
18/02/28 13:40:12 INFO TorrentBroadcast: Destroying Broadcast(155) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:40:12 INFO LBFGS: Step Size: 1.000
18/02/28 13:40:12 INFO LBFGS: Val and Grad Norm: 0.273935 (rel: 0.00170) 0.00364225
18/02/28 13:40:12 INFO BlockManagerInfo: Removed broadcast_155_piece0 on 127.0.0.1:60941 in memory (size: 186.0 B, free: 266.0 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_157 stored as values in memory (estimated size 104.0 B, free 259.8 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_157_piece0 stored as bytes in memory (estimated size 186.0 B, free 259.8 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on 127.0.0.1:60941 (size: 186.0 B, free: 266.0 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 157 from broadcast at LogisticRegression.scala:1879
18/02/28 13:40:12 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:40:12 INFO DAGScheduler: Got job 72 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:40:12 INFO DAGScheduler: Final stage: ResultStage 127 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:40:12 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:40:12 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:12 INFO DAGScheduler: Submitting ResultStage 127 (MapPartitionsRDD[403] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_158 stored as values in memory (estimated size 74.1 KB, free 259.8 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_158_piece0 stored as bytes in memory (estimated size 29.1 KB, free 259.7 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on 127.0.0.1:60941 (size: 29.1 KB, free: 266.0 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 158 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:12 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 127 (MapPartitionsRDD[403] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:12 INFO TaskSchedulerImpl: Adding task set 127.0 with 4 tasks
18/02/28 13:40:12 INFO TaskSetManager: Starting task 0.0 in stage 127.0 (TID 373, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 1.0 in stage 127.0 (TID 374, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 2.0 in stage 127.0 (TID 375, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 3.0 in stage 127.0 (TID 376, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO Executor: Running task 1.0 in stage 127.0 (TID 374)
18/02/28 13:40:12 INFO Executor: Running task 3.0 in stage 127.0 (TID 376)
18/02/28 13:40:12 INFO Executor: Running task 2.0 in stage 127.0 (TID 375)
18/02/28 13:40:12 INFO Executor: Running task 0.0 in stage 127.0 (TID 373)
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_0 locally
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_1 locally
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_2 locally
18/02/28 13:40:12 INFO Executor: Finished task 0.0 in stage 127.0 (TID 373). 3395 bytes result sent to driver
18/02/28 13:40:12 INFO Executor: Finished task 1.0 in stage 127.0 (TID 374). 3438 bytes result sent to driver
18/02/28 13:40:12 INFO Executor: Finished task 2.0 in stage 127.0 (TID 375). 3438 bytes result sent to driver
18/02/28 13:40:12 INFO TaskSetManager: Finished task 0.0 in stage 127.0 (TID 373) in 5 ms on localhost (executor driver) (1/4)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 1.0 in stage 127.0 (TID 374) in 5 ms on localhost (executor driver) (2/4)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 2.0 in stage 127.0 (TID 375) in 6 ms on localhost (executor driver) (3/4)
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_3 locally
18/02/28 13:40:12 INFO Executor: Finished task 3.0 in stage 127.0 (TID 376). 3438 bytes result sent to driver
18/02/28 13:40:12 INFO TaskSetManager: Finished task 3.0 in stage 127.0 (TID 376) in 8 ms on localhost (executor driver) (4/4)
18/02/28 13:40:12 INFO TaskSchedulerImpl: Removed TaskSet 127.0, whose tasks have all completed, from pool 
18/02/28 13:40:12 INFO DAGScheduler: ResultStage 127 (treeAggregate at LogisticRegression.scala:1892) finished in 0.008 s
18/02/28 13:40:12 INFO DAGScheduler: Job 72 finished: treeAggregate at LogisticRegression.scala:1892, took 0.011483 s
18/02/28 13:40:12 INFO TorrentBroadcast: Destroying Broadcast(157) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:40:12 INFO LBFGS: Step Size: 1.000
18/02/28 13:40:12 INFO LBFGS: Val and Grad Norm: 0.273672 (rel: 0.000960) 0.00332521
18/02/28 13:40:12 INFO BlockManagerInfo: Removed broadcast_157_piece0 on 127.0.0.1:60941 in memory (size: 186.0 B, free: 266.0 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_159 stored as values in memory (estimated size 104.0 B, free 259.7 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_159_piece0 stored as bytes in memory (estimated size 186.0 B, free 259.7 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_159_piece0 in memory on 127.0.0.1:60941 (size: 186.0 B, free: 266.0 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 159 from broadcast at LogisticRegression.scala:1879
18/02/28 13:40:12 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:40:12 INFO DAGScheduler: Got job 73 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:40:12 INFO DAGScheduler: Final stage: ResultStage 128 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:40:12 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:40:12 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:12 INFO DAGScheduler: Submitting ResultStage 128 (MapPartitionsRDD[404] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_160 stored as values in memory (estimated size 74.1 KB, free 259.7 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_160_piece0 stored as bytes in memory (estimated size 29.1 KB, free 259.6 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_160_piece0 in memory on 127.0.0.1:60941 (size: 29.1 KB, free: 266.0 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 160 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:12 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 128 (MapPartitionsRDD[404] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:12 INFO TaskSchedulerImpl: Adding task set 128.0 with 4 tasks
18/02/28 13:40:12 INFO TaskSetManager: Starting task 0.0 in stage 128.0 (TID 377, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 1.0 in stage 128.0 (TID 378, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 2.0 in stage 128.0 (TID 379, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 3.0 in stage 128.0 (TID 380, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO Executor: Running task 0.0 in stage 128.0 (TID 377)
18/02/28 13:40:12 INFO Executor: Running task 2.0 in stage 128.0 (TID 379)
18/02/28 13:40:12 INFO Executor: Running task 3.0 in stage 128.0 (TID 380)
18/02/28 13:40:12 INFO Executor: Running task 1.0 in stage 128.0 (TID 378)
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_1 locally
18/02/28 13:40:12 INFO Executor: Finished task 1.0 in stage 128.0 (TID 378). 3395 bytes result sent to driver
18/02/28 13:40:12 INFO TaskSetManager: Finished task 1.0 in stage 128.0 (TID 378) in 5 ms on localhost (executor driver) (1/4)
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_3 locally
18/02/28 13:40:12 INFO Executor: Finished task 3.0 in stage 128.0 (TID 380). 3481 bytes result sent to driver
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_2 locally
18/02/28 13:40:12 INFO TaskSetManager: Finished task 3.0 in stage 128.0 (TID 380) in 5 ms on localhost (executor driver) (2/4)
18/02/28 13:40:12 INFO Executor: Finished task 2.0 in stage 128.0 (TID 379). 3438 bytes result sent to driver
18/02/28 13:40:12 INFO TaskSetManager: Finished task 2.0 in stage 128.0 (TID 379) in 7 ms on localhost (executor driver) (3/4)
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_0 locally
18/02/28 13:40:12 INFO Executor: Finished task 0.0 in stage 128.0 (TID 377). 3438 bytes result sent to driver
18/02/28 13:40:12 INFO TaskSetManager: Finished task 0.0 in stage 128.0 (TID 377) in 8 ms on localhost (executor driver) (4/4)
18/02/28 13:40:12 INFO TaskSchedulerImpl: Removed TaskSet 128.0, whose tasks have all completed, from pool 
18/02/28 13:40:12 INFO DAGScheduler: ResultStage 128 (treeAggregate at LogisticRegression.scala:1892) finished in 0.008 s
18/02/28 13:40:12 INFO DAGScheduler: Job 73 finished: treeAggregate at LogisticRegression.scala:1892, took 0.012239 s
18/02/28 13:40:12 INFO TorrentBroadcast: Destroying Broadcast(159) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:40:12 INFO LBFGS: Step Size: 1.000
18/02/28 13:40:12 INFO LBFGS: Val and Grad Norm: 0.273062 (rel: 0.00223) 0.00349239
18/02/28 13:40:12 INFO BlockManagerInfo: Removed broadcast_159_piece0 on 127.0.0.1:60941 in memory (size: 186.0 B, free: 266.0 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_161 stored as values in memory (estimated size 104.0 B, free 259.6 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_161_piece0 stored as bytes in memory (estimated size 186.0 B, free 259.6 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_161_piece0 in memory on 127.0.0.1:60941 (size: 186.0 B, free: 266.0 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 161 from broadcast at LogisticRegression.scala:1879
18/02/28 13:40:12 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:40:12 INFO DAGScheduler: Got job 74 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:40:12 INFO DAGScheduler: Final stage: ResultStage 129 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:40:12 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:40:12 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:12 INFO DAGScheduler: Submitting ResultStage 129 (MapPartitionsRDD[405] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_162 stored as values in memory (estimated size 74.1 KB, free 259.6 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_162_piece0 stored as bytes in memory (estimated size 29.2 KB, free 259.5 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_162_piece0 in memory on 127.0.0.1:60941 (size: 29.2 KB, free: 266.0 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 162 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:12 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 129 (MapPartitionsRDD[405] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:12 INFO TaskSchedulerImpl: Adding task set 129.0 with 4 tasks
18/02/28 13:40:12 INFO TaskSetManager: Starting task 0.0 in stage 129.0 (TID 381, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 1.0 in stage 129.0 (TID 382, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 2.0 in stage 129.0 (TID 383, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 3.0 in stage 129.0 (TID 384, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO Executor: Running task 0.0 in stage 129.0 (TID 381)
18/02/28 13:40:12 INFO Executor: Running task 1.0 in stage 129.0 (TID 382)
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_0 locally
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_1 locally
18/02/28 13:40:12 INFO Executor: Finished task 0.0 in stage 129.0 (TID 381). 3395 bytes result sent to driver
18/02/28 13:40:12 INFO Executor: Running task 2.0 in stage 129.0 (TID 383)
18/02/28 13:40:12 INFO Executor: Finished task 1.0 in stage 129.0 (TID 382). 3395 bytes result sent to driver
18/02/28 13:40:12 INFO Executor: Running task 3.0 in stage 129.0 (TID 384)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 0.0 in stage 129.0 (TID 381) in 6 ms on localhost (executor driver) (1/4)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 1.0 in stage 129.0 (TID 382) in 6 ms on localhost (executor driver) (2/4)
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_3 locally
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_2 locally
18/02/28 13:40:12 INFO Executor: Finished task 3.0 in stage 129.0 (TID 384). 3438 bytes result sent to driver
18/02/28 13:40:12 INFO Executor: Finished task 2.0 in stage 129.0 (TID 383). 3395 bytes result sent to driver
18/02/28 13:40:12 INFO TaskSetManager: Finished task 2.0 in stage 129.0 (TID 383) in 9 ms on localhost (executor driver) (3/4)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 3.0 in stage 129.0 (TID 384) in 9 ms on localhost (executor driver) (4/4)
18/02/28 13:40:12 INFO TaskSchedulerImpl: Removed TaskSet 129.0, whose tasks have all completed, from pool 
18/02/28 13:40:12 INFO DAGScheduler: ResultStage 129 (treeAggregate at LogisticRegression.scala:1892) finished in 0.010 s
18/02/28 13:40:12 INFO DAGScheduler: Job 74 finished: treeAggregate at LogisticRegression.scala:1892, took 0.013950 s
18/02/28 13:40:12 INFO TorrentBroadcast: Destroying Broadcast(161) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:40:12 INFO LBFGS: Step Size: 1.000
18/02/28 13:40:12 INFO BlockManagerInfo: Removed broadcast_161_piece0 on 127.0.0.1:60941 in memory (size: 186.0 B, free: 266.0 MB)
18/02/28 13:40:12 INFO LBFGS: Val and Grad Norm: 0.272954 (rel: 0.000395) 0.00113009
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_163 stored as values in memory (estimated size 104.0 B, free 259.5 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_163_piece0 stored as bytes in memory (estimated size 186.0 B, free 259.5 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_163_piece0 in memory on 127.0.0.1:60941 (size: 186.0 B, free: 266.0 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 163 from broadcast at LogisticRegression.scala:1879
18/02/28 13:40:12 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:40:12 INFO DAGScheduler: Got job 75 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:40:12 INFO DAGScheduler: Final stage: ResultStage 130 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:40:12 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:40:12 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:12 INFO DAGScheduler: Submitting ResultStage 130 (MapPartitionsRDD[406] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_164 stored as values in memory (estimated size 74.1 KB, free 259.5 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_164_piece0 stored as bytes in memory (estimated size 29.1 KB, free 259.4 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_164_piece0 in memory on 127.0.0.1:60941 (size: 29.1 KB, free: 265.9 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 164 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:12 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 130 (MapPartitionsRDD[406] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:12 INFO TaskSchedulerImpl: Adding task set 130.0 with 4 tasks
18/02/28 13:40:12 INFO TaskSetManager: Starting task 0.0 in stage 130.0 (TID 385, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 1.0 in stage 130.0 (TID 386, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 2.0 in stage 130.0 (TID 387, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 3.0 in stage 130.0 (TID 388, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO Executor: Running task 0.0 in stage 130.0 (TID 385)
18/02/28 13:40:12 INFO Executor: Running task 3.0 in stage 130.0 (TID 388)
18/02/28 13:40:12 INFO Executor: Running task 2.0 in stage 130.0 (TID 387)
18/02/28 13:40:12 INFO Executor: Running task 1.0 in stage 130.0 (TID 386)
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_3 locally
18/02/28 13:40:12 INFO Executor: Finished task 3.0 in stage 130.0 (TID 388). 3395 bytes result sent to driver
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_0 locally
18/02/28 13:40:12 INFO Executor: Finished task 0.0 in stage 130.0 (TID 385). 3395 bytes result sent to driver
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_1 locally
18/02/28 13:40:12 INFO Executor: Finished task 1.0 in stage 130.0 (TID 386). 3395 bytes result sent to driver
18/02/28 13:40:12 INFO TaskSetManager: Finished task 0.0 in stage 130.0 (TID 385) in 8 ms on localhost (executor driver) (1/4)
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_2 locally
18/02/28 13:40:12 INFO TaskSetManager: Finished task 1.0 in stage 130.0 (TID 386) in 8 ms on localhost (executor driver) (2/4)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 3.0 in stage 130.0 (TID 388) in 8 ms on localhost (executor driver) (3/4)
18/02/28 13:40:12 INFO Executor: Finished task 2.0 in stage 130.0 (TID 387). 3438 bytes result sent to driver
18/02/28 13:40:12 INFO TaskSetManager: Finished task 2.0 in stage 130.0 (TID 387) in 8 ms on localhost (executor driver) (4/4)
18/02/28 13:40:12 INFO TaskSchedulerImpl: Removed TaskSet 130.0, whose tasks have all completed, from pool 
18/02/28 13:40:12 INFO DAGScheduler: ResultStage 130 (treeAggregate at LogisticRegression.scala:1892) finished in 0.010 s
18/02/28 13:40:12 INFO DAGScheduler: Job 75 finished: treeAggregate at LogisticRegression.scala:1892, took 0.012719 s
18/02/28 13:40:12 INFO TorrentBroadcast: Destroying Broadcast(163) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:40:12 INFO LBFGS: Step Size: 1.000
18/02/28 13:40:12 INFO LBFGS: Val and Grad Norm: 0.272948 (rel: 2.33e-05) 0.000245602
18/02/28 13:40:12 INFO BlockManagerInfo: Removed broadcast_163_piece0 on 127.0.0.1:60941 in memory (size: 186.0 B, free: 265.9 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_165 stored as values in memory (estimated size 104.0 B, free 259.4 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_165_piece0 stored as bytes in memory (estimated size 186.0 B, free 259.4 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_165_piece0 in memory on 127.0.0.1:60941 (size: 186.0 B, free: 265.9 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 165 from broadcast at LogisticRegression.scala:1879
18/02/28 13:40:12 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:40:12 INFO DAGScheduler: Got job 76 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:40:12 INFO DAGScheduler: Final stage: ResultStage 131 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:40:12 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:40:12 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:12 INFO DAGScheduler: Submitting ResultStage 131 (MapPartitionsRDD[407] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_166 stored as values in memory (estimated size 74.1 KB, free 259.4 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_166_piece0 stored as bytes in memory (estimated size 29.1 KB, free 259.3 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_166_piece0 in memory on 127.0.0.1:60941 (size: 29.1 KB, free: 265.9 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 166 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:12 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 131 (MapPartitionsRDD[407] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:12 INFO TaskSchedulerImpl: Adding task set 131.0 with 4 tasks
18/02/28 13:40:12 INFO TaskSetManager: Starting task 0.0 in stage 131.0 (TID 389, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 1.0 in stage 131.0 (TID 390, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 2.0 in stage 131.0 (TID 391, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 3.0 in stage 131.0 (TID 392, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO Executor: Running task 1.0 in stage 131.0 (TID 390)
18/02/28 13:40:12 INFO Executor: Running task 2.0 in stage 131.0 (TID 391)
18/02/28 13:40:12 INFO Executor: Running task 0.0 in stage 131.0 (TID 389)
18/02/28 13:40:12 INFO Executor: Running task 3.0 in stage 131.0 (TID 392)
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_0 locally
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_2 locally
18/02/28 13:40:12 INFO Executor: Finished task 2.0 in stage 131.0 (TID 391). 3438 bytes result sent to driver
18/02/28 13:40:12 INFO Executor: Finished task 0.0 in stage 131.0 (TID 389). 3438 bytes result sent to driver
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_3 locally
18/02/28 13:40:12 INFO TaskSetManager: Finished task 2.0 in stage 131.0 (TID 391) in 4 ms on localhost (executor driver) (1/4)
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_1 locally
18/02/28 13:40:12 INFO Executor: Finished task 3.0 in stage 131.0 (TID 392). 3438 bytes result sent to driver
18/02/28 13:40:12 INFO TaskSetManager: Finished task 0.0 in stage 131.0 (TID 389) in 6 ms on localhost (executor driver) (2/4)
18/02/28 13:40:12 INFO Executor: Finished task 1.0 in stage 131.0 (TID 390). 3395 bytes result sent to driver
18/02/28 13:40:12 INFO TaskSetManager: Finished task 3.0 in stage 131.0 (TID 392) in 6 ms on localhost (executor driver) (3/4)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 1.0 in stage 131.0 (TID 390) in 6 ms on localhost (executor driver) (4/4)
18/02/28 13:40:12 INFO TaskSchedulerImpl: Removed TaskSet 131.0, whose tasks have all completed, from pool 
18/02/28 13:40:12 INFO DAGScheduler: ResultStage 131 (treeAggregate at LogisticRegression.scala:1892) finished in 0.007 s
18/02/28 13:40:12 INFO DAGScheduler: Job 76 finished: treeAggregate at LogisticRegression.scala:1892, took 0.009975 s
18/02/28 13:40:12 INFO TorrentBroadcast: Destroying Broadcast(165) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:40:12 INFO LBFGS: Step Size: 1.000
18/02/28 13:40:12 INFO LBFGS: Val and Grad Norm: 0.272947 (rel: 1.08e-06) 3.99333e-05
18/02/28 13:40:12 INFO BlockManagerInfo: Removed broadcast_165_piece0 on 127.0.0.1:60941 in memory (size: 186.0 B, free: 265.9 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_167 stored as values in memory (estimated size 104.0 B, free 259.3 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_167_piece0 stored as bytes in memory (estimated size 186.0 B, free 259.3 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_167_piece0 in memory on 127.0.0.1:60941 (size: 186.0 B, free: 265.9 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 167 from broadcast at LogisticRegression.scala:1879
18/02/28 13:40:12 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:40:12 INFO DAGScheduler: Got job 77 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:40:12 INFO DAGScheduler: Final stage: ResultStage 132 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:40:12 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:40:12 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:12 INFO DAGScheduler: Submitting ResultStage 132 (MapPartitionsRDD[408] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_168 stored as values in memory (estimated size 74.1 KB, free 259.3 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_168_piece0 stored as bytes in memory (estimated size 29.1 KB, free 259.2 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_168_piece0 in memory on 127.0.0.1:60941 (size: 29.1 KB, free: 265.9 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 168 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:12 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 132 (MapPartitionsRDD[408] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:12 INFO TaskSchedulerImpl: Adding task set 132.0 with 4 tasks
18/02/28 13:40:12 INFO TaskSetManager: Starting task 0.0 in stage 132.0 (TID 393, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 1.0 in stage 132.0 (TID 394, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 2.0 in stage 132.0 (TID 395, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:40:12 INFO TaskSetManager: Starting task 3.0 in stage 132.0 (TID 396, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:12 INFO Executor: Running task 2.0 in stage 132.0 (TID 395)
18/02/28 13:40:12 INFO Executor: Running task 3.0 in stage 132.0 (TID 396)
18/02/28 13:40:12 INFO Executor: Running task 0.0 in stage 132.0 (TID 393)
18/02/28 13:40:12 INFO Executor: Running task 1.0 in stage 132.0 (TID 394)
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_0 locally
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_3 locally
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_1 locally
18/02/28 13:40:12 INFO BlockManager: Found block rdd_392_2 locally
18/02/28 13:40:12 INFO Executor: Finished task 1.0 in stage 132.0 (TID 394). 3481 bytes result sent to driver
18/02/28 13:40:12 INFO Executor: Finished task 3.0 in stage 132.0 (TID 396). 3481 bytes result sent to driver
18/02/28 13:40:12 INFO Executor: Finished task 0.0 in stage 132.0 (TID 393). 3481 bytes result sent to driver
18/02/28 13:40:12 INFO Executor: Finished task 2.0 in stage 132.0 (TID 395). 3481 bytes result sent to driver
18/02/28 13:40:12 INFO TaskSetManager: Finished task 1.0 in stage 132.0 (TID 394) in 4 ms on localhost (executor driver) (1/4)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 3.0 in stage 132.0 (TID 396) in 5 ms on localhost (executor driver) (2/4)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 2.0 in stage 132.0 (TID 395) in 5 ms on localhost (executor driver) (3/4)
18/02/28 13:40:12 INFO TaskSetManager: Finished task 0.0 in stage 132.0 (TID 393) in 5 ms on localhost (executor driver) (4/4)
18/02/28 13:40:12 INFO TaskSchedulerImpl: Removed TaskSet 132.0, whose tasks have all completed, from pool 
18/02/28 13:40:12 INFO DAGScheduler: ResultStage 132 (treeAggregate at LogisticRegression.scala:1892) finished in 0.005 s
18/02/28 13:40:12 INFO DAGScheduler: Job 77 finished: treeAggregate at LogisticRegression.scala:1892, took 0.008753 s
18/02/28 13:40:12 INFO TorrentBroadcast: Destroying Broadcast(167) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:40:12 INFO LBFGS: Step Size: 1.000
18/02/28 13:40:12 INFO BlockManagerInfo: Removed broadcast_167_piece0 on 127.0.0.1:60941 in memory (size: 186.0 B, free: 265.9 MB)
18/02/28 13:40:12 INFO LBFGS: Val and Grad Norm: 0.272947 (rel: 4.24e-08) 4.26491e-06
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_169 stored as values in memory (estimated size 104.0 B, free 259.2 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_169_piece0 stored as bytes in memory (estimated size 186.0 B, free 259.2 MB)
18/02/28 13:40:12 INFO BlockManagerInfo: Added broadcast_169_piece0 in memory on 127.0.0.1:60941 (size: 186.0 B, free: 265.9 MB)
18/02/28 13:40:12 INFO SparkContext: Created broadcast 169 from broadcast at LogisticRegression.scala:1879
18/02/28 13:40:12 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:40:12 INFO DAGScheduler: Got job 78 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:40:12 INFO DAGScheduler: Final stage: ResultStage 133 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:40:12 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:40:12 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:12 INFO DAGScheduler: Submitting ResultStage 133 (MapPartitionsRDD[409] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_170 stored as values in memory (estimated size 74.1 KB, free 259.2 MB)
18/02/28 13:40:12 INFO MemoryStore: Block broadcast_170_piece0 stored as bytes in memory (estimated size 29.1 KB, free 259.1 MB)
18/02/28 13:40:13 INFO BlockManagerInfo: Added broadcast_170_piece0 in memory on 127.0.0.1:60941 (size: 29.1 KB, free: 265.8 MB)
18/02/28 13:40:13 INFO SparkContext: Created broadcast 170 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:13 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 133 (MapPartitionsRDD[409] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:13 INFO TaskSchedulerImpl: Adding task set 133.0 with 4 tasks
18/02/28 13:40:13 INFO TaskSetManager: Starting task 0.0 in stage 133.0 (TID 397, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 1.0 in stage 133.0 (TID 398, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 2.0 in stage 133.0 (TID 399, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 3.0 in stage 133.0 (TID 400, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:13 INFO Executor: Running task 0.0 in stage 133.0 (TID 397)
18/02/28 13:40:13 INFO Executor: Running task 3.0 in stage 133.0 (TID 400)
18/02/28 13:40:13 INFO Executor: Running task 2.0 in stage 133.0 (TID 399)
18/02/28 13:40:13 INFO Executor: Running task 1.0 in stage 133.0 (TID 398)
18/02/28 13:40:13 INFO BlockManager: Found block rdd_392_0 locally
18/02/28 13:40:13 INFO BlockManager: Found block rdd_392_1 locally
18/02/28 13:40:13 INFO Executor: Finished task 0.0 in stage 133.0 (TID 397). 3395 bytes result sent to driver
18/02/28 13:40:13 INFO BlockManager: Found block rdd_392_3 locally
18/02/28 13:40:13 INFO Executor: Finished task 1.0 in stage 133.0 (TID 398). 3438 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Finished task 0.0 in stage 133.0 (TID 397) in 5 ms on localhost (executor driver) (1/4)
18/02/28 13:40:13 INFO Executor: Finished task 3.0 in stage 133.0 (TID 400). 3438 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Finished task 3.0 in stage 133.0 (TID 400) in 5 ms on localhost (executor driver) (2/4)
18/02/28 13:40:13 INFO TaskSetManager: Finished task 1.0 in stage 133.0 (TID 398) in 5 ms on localhost (executor driver) (3/4)
18/02/28 13:40:13 INFO BlockManager: Found block rdd_392_2 locally
18/02/28 13:40:13 INFO Executor: Finished task 2.0 in stage 133.0 (TID 399). 3395 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Finished task 2.0 in stage 133.0 (TID 399) in 6 ms on localhost (executor driver) (4/4)
18/02/28 13:40:13 INFO TaskSchedulerImpl: Removed TaskSet 133.0, whose tasks have all completed, from pool 
18/02/28 13:40:13 INFO DAGScheduler: ResultStage 133 (treeAggregate at LogisticRegression.scala:1892) finished in 0.007 s
18/02/28 13:40:13 INFO DAGScheduler: Job 78 finished: treeAggregate at LogisticRegression.scala:1892, took 0.010509 s
18/02/28 13:40:13 INFO TorrentBroadcast: Destroying Broadcast(169) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:40:13 INFO LBFGS: Step Size: 1.000
18/02/28 13:40:13 INFO BlockManagerInfo: Removed broadcast_169_piece0 on 127.0.0.1:60941 in memory (size: 186.0 B, free: 265.8 MB)
18/02/28 13:40:13 INFO LBFGS: Val and Grad Norm: 0.272947 (rel: 6.70e-10) 6.45760e-07
18/02/28 13:40:13 INFO MemoryStore: Block broadcast_171 stored as values in memory (estimated size 104.0 B, free 259.1 MB)
18/02/28 13:40:13 INFO MemoryStore: Block broadcast_171_piece0 stored as bytes in memory (estimated size 186.0 B, free 259.1 MB)
18/02/28 13:40:13 INFO BlockManagerInfo: Added broadcast_171_piece0 in memory on 127.0.0.1:60941 (size: 186.0 B, free: 265.8 MB)
18/02/28 13:40:13 INFO SparkContext: Created broadcast 171 from broadcast at LogisticRegression.scala:1879
18/02/28 13:40:13 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:40:13 INFO DAGScheduler: Got job 79 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:40:13 INFO DAGScheduler: Final stage: ResultStage 134 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:40:13 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:40:13 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:13 INFO DAGScheduler: Submitting ResultStage 134 (MapPartitionsRDD[410] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:40:13 INFO MemoryStore: Block broadcast_172 stored as values in memory (estimated size 74.1 KB, free 259.1 MB)
18/02/28 13:40:13 INFO MemoryStore: Block broadcast_172_piece0 stored as bytes in memory (estimated size 29.1 KB, free 259.1 MB)
18/02/28 13:40:13 INFO BlockManagerInfo: Added broadcast_172_piece0 in memory on 127.0.0.1:60941 (size: 29.1 KB, free: 265.8 MB)
18/02/28 13:40:13 INFO SparkContext: Created broadcast 172 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:13 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 134 (MapPartitionsRDD[410] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:13 INFO TaskSchedulerImpl: Adding task set 134.0 with 4 tasks
18/02/28 13:40:13 INFO BlockManagerInfo: Removed broadcast_164_piece0 on 127.0.0.1:60941 in memory (size: 29.1 KB, free: 265.8 MB)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 0.0 in stage 134.0 (TID 401, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 1.0 in stage 134.0 (TID 402, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 2.0 in stage 134.0 (TID 403, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 3.0 in stage 134.0 (TID 404, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:13 INFO Executor: Running task 1.0 in stage 134.0 (TID 402)
18/02/28 13:40:13 INFO Executor: Running task 0.0 in stage 134.0 (TID 401)
18/02/28 13:40:13 INFO Executor: Running task 2.0 in stage 134.0 (TID 403)
18/02/28 13:40:13 INFO Executor: Running task 3.0 in stage 134.0 (TID 404)
18/02/28 13:40:13 INFO BlockManager: Found block rdd_392_1 locally
18/02/28 13:40:13 INFO BlockManager: Found block rdd_392_0 locally
18/02/28 13:40:13 INFO BlockManager: Found block rdd_392_2 locally
18/02/28 13:40:13 INFO Executor: Finished task 1.0 in stage 134.0 (TID 402). 3438 bytes result sent to driver
18/02/28 13:40:13 INFO Executor: Finished task 0.0 in stage 134.0 (TID 401). 3438 bytes result sent to driver
18/02/28 13:40:13 INFO BlockManagerInfo: Removed broadcast_162_piece0 on 127.0.0.1:60941 in memory (size: 29.2 KB, free: 265.9 MB)
18/02/28 13:40:13 INFO BlockManager: Found block rdd_392_3 locally
18/02/28 13:40:13 INFO Executor: Finished task 2.0 in stage 134.0 (TID 403). 3438 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Finished task 1.0 in stage 134.0 (TID 402) in 4 ms on localhost (executor driver) (1/4)
18/02/28 13:40:13 INFO TaskSetManager: Finished task 0.0 in stage 134.0 (TID 401) in 6 ms on localhost (executor driver) (2/4)
18/02/28 13:40:13 INFO Executor: Finished task 3.0 in stage 134.0 (TID 404). 3438 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Finished task 2.0 in stage 134.0 (TID 403) in 5 ms on localhost (executor driver) (3/4)
18/02/28 13:40:13 INFO TaskSetManager: Finished task 3.0 in stage 134.0 (TID 404) in 5 ms on localhost (executor driver) (4/4)
18/02/28 13:40:13 INFO TaskSchedulerImpl: Removed TaskSet 134.0, whose tasks have all completed, from pool 
18/02/28 13:40:13 INFO DAGScheduler: ResultStage 134 (treeAggregate at LogisticRegression.scala:1892) finished in 0.006 s
18/02/28 13:40:13 INFO BlockManagerInfo: Removed broadcast_168_piece0 on 127.0.0.1:60941 in memory (size: 29.1 KB, free: 265.9 MB)
18/02/28 13:40:13 INFO DAGScheduler: Job 79 finished: treeAggregate at LogisticRegression.scala:1892, took 0.018744 s
18/02/28 13:40:13 INFO TorrentBroadcast: Destroying Broadcast(171) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:40:13 INFO BlockManagerInfo: Removed broadcast_144_piece0 on 127.0.0.1:60941 in memory (size: 29.1 KB, free: 265.9 MB)
18/02/28 13:40:13 INFO BlockManagerInfo: Removed broadcast_171_piece0 on 127.0.0.1:60941 in memory (size: 186.0 B, free: 265.9 MB)
18/02/28 13:40:13 INFO BlockManagerInfo: Removed broadcast_150_piece0 on 127.0.0.1:60941 in memory (size: 29.1 KB, free: 266.0 MB)
18/02/28 13:40:13 INFO BlockManagerInfo: Removed broadcast_158_piece0 on 127.0.0.1:60941 in memory (size: 29.1 KB, free: 266.0 MB)
18/02/28 13:40:13 INFO BlockManagerInfo: Removed broadcast_170_piece0 on 127.0.0.1:60941 in memory (size: 29.1 KB, free: 266.0 MB)
18/02/28 13:40:13 INFO MemoryStore: Block broadcast_173 stored as values in memory (estimated size 104.0 B, free 259.7 MB)
18/02/28 13:40:13 INFO MemoryStore: Block broadcast_173_piece0 stored as bytes in memory (estimated size 186.0 B, free 259.7 MB)
18/02/28 13:40:13 INFO BlockManagerInfo: Added broadcast_173_piece0 in memory on 127.0.0.1:60941 (size: 186.0 B, free: 266.0 MB)
18/02/28 13:40:13 INFO SparkContext: Created broadcast 173 from broadcast at LogisticRegression.scala:1879
18/02/28 13:40:13 INFO BlockManagerInfo: Removed broadcast_160_piece0 on 127.0.0.1:60941 in memory (size: 29.1 KB, free: 266.0 MB)
18/02/28 13:40:13 INFO BlockManagerInfo: Removed broadcast_154_piece0 on 127.0.0.1:60941 in memory (size: 29.1 KB, free: 266.1 MB)
18/02/28 13:40:13 INFO BlockManagerInfo: Removed broadcast_142_piece0 on 127.0.0.1:60941 in memory (size: 29.1 KB, free: 266.1 MB)
18/02/28 13:40:13 INFO BlockManagerInfo: Removed broadcast_146_piece0 on 127.0.0.1:60941 in memory (size: 29.1 KB, free: 266.1 MB)
18/02/28 13:40:13 INFO BlockManagerInfo: Removed broadcast_148_piece0 on 127.0.0.1:60941 in memory (size: 29.1 KB, free: 266.2 MB)
18/02/28 13:40:13 INFO BlockManagerInfo: Removed broadcast_152_piece0 on 127.0.0.1:60941 in memory (size: 29.1 KB, free: 266.2 MB)
18/02/28 13:40:13 INFO BlockManagerInfo: Removed broadcast_156_piece0 on 127.0.0.1:60941 in memory (size: 29.2 KB, free: 266.2 MB)
18/02/28 13:40:13 INFO BlockManagerInfo: Removed broadcast_166_piece0 on 127.0.0.1:60941 in memory (size: 29.1 KB, free: 266.2 MB)
18/02/28 13:40:13 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:40:13 INFO DAGScheduler: Got job 80 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:40:13 INFO DAGScheduler: Final stage: ResultStage 135 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:40:13 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:40:13 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:13 INFO DAGScheduler: Submitting ResultStage 135 (MapPartitionsRDD[411] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:40:13 INFO MemoryStore: Block broadcast_174 stored as values in memory (estimated size 74.1 KB, free 260.5 MB)
18/02/28 13:40:13 INFO MemoryStore: Block broadcast_174_piece0 stored as bytes in memory (estimated size 29.1 KB, free 260.5 MB)
18/02/28 13:40:13 INFO BlockManagerInfo: Added broadcast_174_piece0 in memory on 127.0.0.1:60941 (size: 29.1 KB, free: 266.2 MB)
18/02/28 13:40:13 INFO SparkContext: Created broadcast 174 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:13 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 135 (MapPartitionsRDD[411] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:13 INFO TaskSchedulerImpl: Adding task set 135.0 with 4 tasks
18/02/28 13:40:13 INFO TaskSetManager: Starting task 0.0 in stage 135.0 (TID 405, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 1.0 in stage 135.0 (TID 406, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 2.0 in stage 135.0 (TID 407, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 3.0 in stage 135.0 (TID 408, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:40:13 INFO Executor: Running task 0.0 in stage 135.0 (TID 405)
18/02/28 13:40:13 INFO Executor: Running task 3.0 in stage 135.0 (TID 408)
18/02/28 13:40:13 INFO Executor: Running task 2.0 in stage 135.0 (TID 407)
18/02/28 13:40:13 INFO Executor: Running task 1.0 in stage 135.0 (TID 406)
18/02/28 13:40:13 INFO BlockManager: Found block rdd_392_2 locally
18/02/28 13:40:13 INFO BlockManager: Found block rdd_392_0 locally
18/02/28 13:40:13 INFO Executor: Finished task 0.0 in stage 135.0 (TID 405). 3438 bytes result sent to driver
18/02/28 13:40:13 INFO Executor: Finished task 2.0 in stage 135.0 (TID 407). 3395 bytes result sent to driver
18/02/28 13:40:13 INFO BlockManager: Found block rdd_392_1 locally
18/02/28 13:40:13 INFO TaskSetManager: Finished task 0.0 in stage 135.0 (TID 405) in 6 ms on localhost (executor driver) (1/4)
18/02/28 13:40:13 INFO TaskSetManager: Finished task 2.0 in stage 135.0 (TID 407) in 7 ms on localhost (executor driver) (2/4)
18/02/28 13:40:13 INFO Executor: Finished task 1.0 in stage 135.0 (TID 406). 3438 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Finished task 1.0 in stage 135.0 (TID 406) in 7 ms on localhost (executor driver) (3/4)
18/02/28 13:40:13 INFO BlockManager: Found block rdd_392_3 locally
18/02/28 13:40:13 INFO Executor: Finished task 3.0 in stage 135.0 (TID 408). 3438 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Finished task 3.0 in stage 135.0 (TID 408) in 9 ms on localhost (executor driver) (4/4)
18/02/28 13:40:13 INFO TaskSchedulerImpl: Removed TaskSet 135.0, whose tasks have all completed, from pool 
18/02/28 13:40:13 INFO DAGScheduler: ResultStage 135 (treeAggregate at LogisticRegression.scala:1892) finished in 0.009 s
18/02/28 13:40:13 INFO DAGScheduler: Job 80 finished: treeAggregate at LogisticRegression.scala:1892, took 0.012302 s
18/02/28 13:40:13 INFO TorrentBroadcast: Destroying Broadcast(173) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:40:13 INFO BlockManagerInfo: Removed broadcast_173_piece0 on 127.0.0.1:60941 in memory (size: 186.0 B, free: 266.2 MB)
18/02/28 13:40:13 INFO StrongWolfeLineSearch: Line search t: 0.411229546942526 fval: 0.27294732147242035 rhs: 0.27294732147393314 cdd: -4.630611553576639E-17
18/02/28 13:40:13 INFO LBFGS: Step Size: 0.4112
18/02/28 13:40:13 INFO LBFGS: Val and Grad Norm: 0.272947 (rel: 5.54e-12) 1.75988e-07
18/02/28 13:40:13 INFO LBFGS: Converged because gradient converged
18/02/28 13:40:13 INFO TorrentBroadcast: Destroying Broadcast(138) (from destroy at LogisticRegression.scala:796)
18/02/28 13:40:13 INFO BlockManagerInfo: Removed broadcast_138_piece0 on 127.0.0.1:60941 in memory (size: 109.0 B, free: 266.2 MB)
18/02/28 13:40:13 INFO MapPartitionsRDD: Removing RDD 392 from persistence list
18/02/28 13:40:13 INFO BlockManager: Removing RDD 392
18/02/28 13:40:13 INFO CodeGenerator: Code generated in 19.247945 ms
18/02/28 13:40:13 INFO Instrumentation: LogisticRegression-logistic_regression_30e0295c3a85-1391927450-1: training finished
18/02/28 13:40:13 INFO SparkContext: Starting job: sortByKey at BinaryClassificationMetrics.scala:155
18/02/28 13:40:13 INFO DAGScheduler: Registering RDD 416 (map at LogisticRegression.scala:1398)
18/02/28 13:40:13 INFO DAGScheduler: Got job 81 (sortByKey at BinaryClassificationMetrics.scala:155) with 4 output partitions
18/02/28 13:40:13 INFO DAGScheduler: Final stage: ResultStage 137 (sortByKey at BinaryClassificationMetrics.scala:155)
18/02/28 13:40:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 136)
18/02/28 13:40:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 136)
18/02/28 13:40:13 INFO DAGScheduler: Submitting ShuffleMapStage 136 (MapPartitionsRDD[416] at map at LogisticRegression.scala:1398), which has no missing parents
18/02/28 13:40:13 INFO MemoryStore: Block broadcast_175 stored as values in memory (estimated size 83.2 KB, free 260.7 MB)
18/02/28 13:40:13 INFO MemoryStore: Block broadcast_175_piece0 stored as bytes in memory (estimated size 32.8 KB, free 260.7 MB)
18/02/28 13:40:13 INFO BlockManagerInfo: Added broadcast_175_piece0 in memory on 127.0.0.1:60941 (size: 32.8 KB, free: 266.5 MB)
18/02/28 13:40:13 INFO SparkContext: Created broadcast 175 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:13 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 136 (MapPartitionsRDD[416] at map at LogisticRegression.scala:1398) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:13 INFO TaskSchedulerImpl: Adding task set 136.0 with 4 tasks
18/02/28 13:40:13 INFO TaskSetManager: Starting task 0.0 in stage 136.0 (TID 409, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 1.0 in stage 136.0 (TID 410, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 2.0 in stage 136.0 (TID 411, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 3.0 in stage 136.0 (TID 412, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:40:13 INFO Executor: Running task 0.0 in stage 136.0 (TID 409)
18/02/28 13:40:13 INFO Executor: Running task 1.0 in stage 136.0 (TID 410)
18/02/28 13:40:13 INFO Executor: Running task 2.0 in stage 136.0 (TID 411)
18/02/28 13:40:13 INFO Executor: Running task 3.0 in stage 136.0 (TID 412)
18/02/28 13:40:13 INFO BlockManager: Found block rdd_355_3 locally
18/02/28 13:40:13 INFO BlockManager: Found block rdd_355_0 locally
18/02/28 13:40:13 INFO BlockManager: Found block rdd_355_2 locally
18/02/28 13:40:13 INFO BlockManager: Found block rdd_355_1 locally
18/02/28 13:40:13 INFO CodeGenerator: Code generated in 8.852095 ms
18/02/28 13:40:13 INFO CodeGenerator: Code generated in 6.184195 ms
18/02/28 13:40:13 INFO Executor: Finished task 3.0 in stage 136.0 (TID 412). 2215 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Finished task 3.0 in stage 136.0 (TID 412) in 153 ms on localhost (executor driver) (1/4)
18/02/28 13:40:13 INFO Executor: Finished task 2.0 in stage 136.0 (TID 411). 2172 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Finished task 2.0 in stage 136.0 (TID 411) in 158 ms on localhost (executor driver) (2/4)
18/02/28 13:40:13 INFO Executor: Finished task 1.0 in stage 136.0 (TID 410). 2215 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Finished task 1.0 in stage 136.0 (TID 410) in 162 ms on localhost (executor driver) (3/4)
18/02/28 13:40:13 INFO Executor: Finished task 0.0 in stage 136.0 (TID 409). 2215 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Finished task 0.0 in stage 136.0 (TID 409) in 169 ms on localhost (executor driver) (4/4)
18/02/28 13:40:13 INFO DAGScheduler: ShuffleMapStage 136 (map at LogisticRegression.scala:1398) finished in 0.169 s
18/02/28 13:40:13 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:40:13 INFO DAGScheduler: running: Set()
18/02/28 13:40:13 INFO DAGScheduler: waiting: Set(ResultStage 137)
18/02/28 13:40:13 INFO DAGScheduler: failed: Set()
18/02/28 13:40:13 INFO DAGScheduler: Submitting ResultStage 137 (MapPartitionsRDD[419] at sortByKey at BinaryClassificationMetrics.scala:155), which has no missing parents
18/02/28 13:40:13 INFO MemoryStore: Block broadcast_176 stored as values in memory (estimated size 3.6 KB, free 260.7 MB)
18/02/28 13:40:13 INFO MemoryStore: Block broadcast_176_piece0 stored as bytes in memory (estimated size 2.0 KB, free 260.7 MB)
18/02/28 13:40:13 INFO TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool 
18/02/28 13:40:13 INFO BlockManagerInfo: Added broadcast_176_piece0 in memory on 127.0.0.1:60941 (size: 2.0 KB, free: 266.5 MB)
18/02/28 13:40:13 INFO SparkContext: Created broadcast 176 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:13 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 137 (MapPartitionsRDD[419] at sortByKey at BinaryClassificationMetrics.scala:155) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:13 INFO TaskSchedulerImpl: Adding task set 137.0 with 4 tasks
18/02/28 13:40:13 INFO TaskSetManager: Starting task 0.0 in stage 137.0 (TID 413, localhost, executor driver, partition 0, ANY, 4621 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 1.0 in stage 137.0 (TID 414, localhost, executor driver, partition 1, ANY, 4621 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 2.0 in stage 137.0 (TID 415, localhost, executor driver, partition 2, ANY, 4621 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 3.0 in stage 137.0 (TID 416, localhost, executor driver, partition 3, ANY, 4621 bytes)
18/02/28 13:40:13 INFO Executor: Running task 0.0 in stage 137.0 (TID 413)
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:40:13 INFO Executor: Running task 1.0 in stage 137.0 (TID 414)
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:40:13 INFO Executor: Running task 2.0 in stage 137.0 (TID 415)
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:40:13 INFO Executor: Finished task 1.0 in stage 137.0 (TID 414). 1714 bytes result sent to driver
18/02/28 13:40:13 INFO Executor: Running task 3.0 in stage 137.0 (TID 416)
18/02/28 13:40:13 INFO Executor: Finished task 2.0 in stage 137.0 (TID 415). 1714 bytes result sent to driver
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:40:13 INFO TaskSetManager: Finished task 1.0 in stage 137.0 (TID 414) in 22 ms on localhost (executor driver) (1/4)
18/02/28 13:40:13 INFO TaskSetManager: Finished task 2.0 in stage 137.0 (TID 415) in 22 ms on localhost (executor driver) (2/4)
18/02/28 13:40:13 INFO Executor: Finished task 0.0 in stage 137.0 (TID 413). 1671 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Finished task 0.0 in stage 137.0 (TID 413) in 28 ms on localhost (executor driver) (3/4)
18/02/28 13:40:13 INFO Executor: Finished task 3.0 in stage 137.0 (TID 416). 1671 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Finished task 3.0 in stage 137.0 (TID 416) in 28 ms on localhost (executor driver) (4/4)
18/02/28 13:40:13 INFO DAGScheduler: ResultStage 137 (sortByKey at BinaryClassificationMetrics.scala:155) finished in 0.029 s
18/02/28 13:40:13 INFO DAGScheduler: Job 81 finished: sortByKey at BinaryClassificationMetrics.scala:155, took 0.211828 s
18/02/28 13:40:13 INFO TaskSchedulerImpl: Removed TaskSet 137.0, whose tasks have all completed, from pool 
18/02/28 13:40:13 INFO SparkContext: Starting job: count at BinaryClassificationMetrics.scala:163
18/02/28 13:40:13 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 55 is 169 bytes
18/02/28 13:40:13 INFO DAGScheduler: Registering RDD 417 (combineByKey at BinaryClassificationMetrics.scala:151)
18/02/28 13:40:13 INFO DAGScheduler: Got job 82 (count at BinaryClassificationMetrics.scala:163) with 4 output partitions
18/02/28 13:40:13 INFO DAGScheduler: Final stage: ResultStage 140 (count at BinaryClassificationMetrics.scala:163)
18/02/28 13:40:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 139)
18/02/28 13:40:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 139)
18/02/28 13:40:13 INFO DAGScheduler: Submitting ShuffleMapStage 139 (ShuffledRDD[417] at combineByKey at BinaryClassificationMetrics.scala:151), which has no missing parents
18/02/28 13:40:13 INFO MemoryStore: Block broadcast_177 stored as values in memory (estimated size 3.4 KB, free 260.7 MB)
18/02/28 13:40:13 INFO MemoryStore: Block broadcast_177_piece0 stored as bytes in memory (estimated size 1915.0 B, free 260.7 MB)
18/02/28 13:40:13 INFO BlockManagerInfo: Added broadcast_177_piece0 in memory on 127.0.0.1:60941 (size: 1915.0 B, free: 266.5 MB)
18/02/28 13:40:13 INFO SparkContext: Created broadcast 177 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:13 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 139 (ShuffledRDD[417] at combineByKey at BinaryClassificationMetrics.scala:151) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:13 INFO TaskSchedulerImpl: Adding task set 139.0 with 4 tasks
18/02/28 13:40:13 INFO TaskSetManager: Starting task 0.0 in stage 139.0 (TID 417, localhost, executor driver, partition 0, ANY, 4610 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 1.0 in stage 139.0 (TID 418, localhost, executor driver, partition 1, ANY, 4610 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 2.0 in stage 139.0 (TID 419, localhost, executor driver, partition 2, ANY, 4610 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 3.0 in stage 139.0 (TID 420, localhost, executor driver, partition 3, ANY, 4610 bytes)
18/02/28 13:40:13 INFO Executor: Running task 0.0 in stage 139.0 (TID 417)
18/02/28 13:40:13 INFO Executor: Running task 1.0 in stage 139.0 (TID 418)
18/02/28 13:40:13 INFO Executor: Running task 2.0 in stage 139.0 (TID 419)
18/02/28 13:40:13 INFO Executor: Running task 3.0 in stage 139.0 (TID 420)
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:40:13 INFO Executor: Finished task 1.0 in stage 139.0 (TID 418). 1196 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Finished task 1.0 in stage 139.0 (TID 418) in 82 ms on localhost (executor driver) (1/4)
18/02/28 13:40:13 INFO Executor: Finished task 0.0 in stage 139.0 (TID 417). 1196 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Finished task 0.0 in stage 139.0 (TID 417) in 83 ms on localhost (executor driver) (2/4)
18/02/28 13:40:13 INFO Executor: Finished task 2.0 in stage 139.0 (TID 419). 1239 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Finished task 2.0 in stage 139.0 (TID 419) in 101 ms on localhost (executor driver) (3/4)
18/02/28 13:40:13 INFO Executor: Finished task 3.0 in stage 139.0 (TID 420). 1239 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Finished task 3.0 in stage 139.0 (TID 420) in 111 ms on localhost (executor driver) (4/4)
18/02/28 13:40:13 INFO TaskSchedulerImpl: Removed TaskSet 139.0, whose tasks have all completed, from pool 
18/02/28 13:40:13 INFO DAGScheduler: ShuffleMapStage 139 (combineByKey at BinaryClassificationMetrics.scala:151) finished in 0.111 s
18/02/28 13:40:13 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:40:13 INFO DAGScheduler: running: Set()
18/02/28 13:40:13 INFO DAGScheduler: waiting: Set(ResultStage 140)
18/02/28 13:40:13 INFO DAGScheduler: failed: Set()
18/02/28 13:40:13 INFO DAGScheduler: Submitting ResultStage 140 (ShuffledRDD[420] at sortByKey at BinaryClassificationMetrics.scala:155), which has no missing parents
18/02/28 13:40:13 INFO MemoryStore: Block broadcast_178 stored as values in memory (estimated size 3.1 KB, free 260.7 MB)
18/02/28 13:40:13 INFO MemoryStore: Block broadcast_178_piece0 stored as bytes in memory (estimated size 1868.0 B, free 260.7 MB)
18/02/28 13:40:13 INFO BlockManagerInfo: Added broadcast_178_piece0 in memory on 127.0.0.1:60941 (size: 1868.0 B, free: 266.5 MB)
18/02/28 13:40:13 INFO SparkContext: Created broadcast 178 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:13 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 140 (ShuffledRDD[420] at sortByKey at BinaryClassificationMetrics.scala:155) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:13 INFO TaskSchedulerImpl: Adding task set 140.0 with 4 tasks
18/02/28 13:40:13 INFO TaskSetManager: Starting task 0.0 in stage 140.0 (TID 421, localhost, executor driver, partition 0, ANY, 4621 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 1.0 in stage 140.0 (TID 422, localhost, executor driver, partition 1, ANY, 4621 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 2.0 in stage 140.0 (TID 423, localhost, executor driver, partition 2, ANY, 4621 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 3.0 in stage 140.0 (TID 424, localhost, executor driver, partition 3, ANY, 4621 bytes)
18/02/28 13:40:13 INFO Executor: Running task 0.0 in stage 140.0 (TID 421)
18/02/28 13:40:13 INFO Executor: Running task 2.0 in stage 140.0 (TID 423)
18/02/28 13:40:13 INFO Executor: Running task 3.0 in stage 140.0 (TID 424)
18/02/28 13:40:13 INFO Executor: Running task 1.0 in stage 140.0 (TID 422)
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:40:13 INFO Executor: Finished task 1.0 in stage 140.0 (TID 422). 1047 bytes result sent to driver
18/02/28 13:40:13 INFO Executor: Finished task 3.0 in stage 140.0 (TID 424). 1090 bytes result sent to driver
18/02/28 13:40:13 INFO Executor: Finished task 2.0 in stage 140.0 (TID 423). 1004 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Finished task 1.0 in stage 140.0 (TID 422) in 24 ms on localhost (executor driver) (1/4)
18/02/28 13:40:13 INFO TaskSetManager: Finished task 3.0 in stage 140.0 (TID 424) in 25 ms on localhost (executor driver) (2/4)
18/02/28 13:40:13 INFO TaskSetManager: Finished task 2.0 in stage 140.0 (TID 423) in 25 ms on localhost (executor driver) (3/4)
18/02/28 13:40:13 INFO Executor: Finished task 0.0 in stage 140.0 (TID 421). 1090 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Finished task 0.0 in stage 140.0 (TID 421) in 26 ms on localhost (executor driver) (4/4)
18/02/28 13:40:13 INFO DAGScheduler: ResultStage 140 (count at BinaryClassificationMetrics.scala:163) finished in 0.026 s
18/02/28 13:40:13 INFO DAGScheduler: Job 82 finished: count at BinaryClassificationMetrics.scala:163, took 0.153675 s
18/02/28 13:40:13 INFO TaskSchedulerImpl: Removed TaskSet 140.0, whose tasks have all completed, from pool 
18/02/28 13:40:13 INFO SparkContext: Starting job: collect at BinaryClassificationMetrics.scala:192
18/02/28 13:40:13 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 55 is 169 bytes
18/02/28 13:40:13 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 56 is 172 bytes
18/02/28 13:40:13 INFO DAGScheduler: Got job 83 (collect at BinaryClassificationMetrics.scala:192) with 4 output partitions
18/02/28 13:40:13 INFO DAGScheduler: Final stage: ResultStage 143 (collect at BinaryClassificationMetrics.scala:192)
18/02/28 13:40:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 142)
18/02/28 13:40:13 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:13 INFO DAGScheduler: Submitting ResultStage 143 (MapPartitionsRDD[423] at mapPartitions at BinaryClassificationMetrics.scala:188), which has no missing parents
18/02/28 13:40:13 INFO MemoryStore: Block broadcast_179 stored as values in memory (estimated size 4.2 KB, free 260.7 MB)
18/02/28 13:40:13 INFO MemoryStore: Block broadcast_179_piece0 stored as bytes in memory (estimated size 2.3 KB, free 260.7 MB)
18/02/28 13:40:13 INFO BlockManagerInfo: Added broadcast_179_piece0 in memory on 127.0.0.1:60941 (size: 2.3 KB, free: 266.5 MB)
18/02/28 13:40:13 INFO SparkContext: Created broadcast 179 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:13 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 143 (MapPartitionsRDD[423] at mapPartitions at BinaryClassificationMetrics.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:13 INFO TaskSchedulerImpl: Adding task set 143.0 with 4 tasks
18/02/28 13:40:13 INFO TaskSetManager: Starting task 0.0 in stage 143.0 (TID 425, localhost, executor driver, partition 0, ANY, 4621 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 1.0 in stage 143.0 (TID 426, localhost, executor driver, partition 1, ANY, 4621 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 2.0 in stage 143.0 (TID 427, localhost, executor driver, partition 2, ANY, 4621 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 3.0 in stage 143.0 (TID 428, localhost, executor driver, partition 3, ANY, 4621 bytes)
18/02/28 13:40:13 INFO Executor: Running task 0.0 in stage 143.0 (TID 425)
18/02/28 13:40:13 INFO Executor: Running task 1.0 in stage 143.0 (TID 426)
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:40:13 INFO Executor: Running task 2.0 in stage 143.0 (TID 427)
18/02/28 13:40:13 INFO Executor: Running task 3.0 in stage 143.0 (TID 428)
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:40:13 INFO Executor: Finished task 1.0 in stage 143.0 (TID 426). 1260 bytes result sent to driver
18/02/28 13:40:13 INFO Executor: Finished task 2.0 in stage 143.0 (TID 427). 1217 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Finished task 1.0 in stage 143.0 (TID 426) in 15 ms on localhost (executor driver) (1/4)
18/02/28 13:40:13 INFO Executor: Finished task 0.0 in stage 143.0 (TID 425). 1174 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Finished task 2.0 in stage 143.0 (TID 427) in 18 ms on localhost (executor driver) (2/4)
18/02/28 13:40:13 INFO TaskSetManager: Finished task 0.0 in stage 143.0 (TID 425) in 19 ms on localhost (executor driver) (3/4)
18/02/28 13:40:13 INFO Executor: Finished task 3.0 in stage 143.0 (TID 428). 1174 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Finished task 3.0 in stage 143.0 (TID 428) in 20 ms on localhost (executor driver) (4/4)
18/02/28 13:40:13 INFO TaskSchedulerImpl: Removed TaskSet 143.0, whose tasks have all completed, from pool 
18/02/28 13:40:13 INFO DAGScheduler: ResultStage 143 (collect at BinaryClassificationMetrics.scala:192) finished in 0.021 s
18/02/28 13:40:13 INFO DAGScheduler: Job 83 finished: collect at BinaryClassificationMetrics.scala:192, took 0.025883 s
18/02/28 13:40:13 INFO BinaryClassificationMetrics: Total counts: {numPos: 749, numNeg: 2412}
18/02/28 13:40:13 INFO SparkContext: Starting job: collect at SlidingRDD.scala:81
18/02/28 13:40:13 INFO DAGScheduler: Got job 84 (collect at SlidingRDD.scala:81) with 6 output partitions
18/02/28 13:40:13 INFO DAGScheduler: Final stage: ResultStage 146 (collect at SlidingRDD.scala:81)
18/02/28 13:40:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 145)
18/02/28 13:40:13 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:13 INFO DAGScheduler: Submitting ResultStage 146 (MapPartitionsRDD[431] at mapPartitions at SlidingRDD.scala:78), which has no missing parents
18/02/28 13:40:13 INFO MemoryStore: Block broadcast_180 stored as values in memory (estimated size 6.3 KB, free 260.7 MB)
18/02/28 13:40:13 INFO MemoryStore: Block broadcast_180_piece0 stored as bytes in memory (estimated size 3.3 KB, free 260.6 MB)
18/02/28 13:40:13 INFO BlockManagerInfo: Added broadcast_180_piece0 in memory on 127.0.0.1:60941 (size: 3.3 KB, free: 266.5 MB)
18/02/28 13:40:13 INFO SparkContext: Created broadcast 180 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:13 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 146 (MapPartitionsRDD[431] at mapPartitions at SlidingRDD.scala:78) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
18/02/28 13:40:13 INFO TaskSchedulerImpl: Adding task set 146.0 with 6 tasks
18/02/28 13:40:13 INFO TaskSetManager: Starting task 0.0 in stage 146.0 (TID 429, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 5.0 in stage 146.0 (TID 430, localhost, executor driver, partition 5, PROCESS_LOCAL, 5058 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 1.0 in stage 146.0 (TID 431, localhost, executor driver, partition 1, ANY, 4730 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 2.0 in stage 146.0 (TID 432, localhost, executor driver, partition 2, ANY, 4730 bytes)
18/02/28 13:40:13 INFO Executor: Running task 5.0 in stage 146.0 (TID 430)
18/02/28 13:40:13 INFO Executor: Running task 1.0 in stage 146.0 (TID 431)
18/02/28 13:40:13 INFO Executor: Running task 2.0 in stage 146.0 (TID 432)
18/02/28 13:40:13 INFO Executor: Running task 0.0 in stage 146.0 (TID 429)
18/02/28 13:40:13 INFO Executor: Finished task 0.0 in stage 146.0 (TID 429). 856 bytes result sent to driver
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:40:13 INFO Executor: Finished task 5.0 in stage 146.0 (TID 430). 856 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Starting task 3.0 in stage 146.0 (TID 433, localhost, executor driver, partition 3, ANY, 4730 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 4.0 in stage 146.0 (TID 434, localhost, executor driver, partition 4, ANY, 4730 bytes)
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:40:13 INFO Executor: Running task 3.0 in stage 146.0 (TID 433)
18/02/28 13:40:13 INFO TaskSetManager: Finished task 0.0 in stage 146.0 (TID 429) in 11 ms on localhost (executor driver) (1/6)
18/02/28 13:40:13 INFO TaskSetManager: Finished task 5.0 in stage 146.0 (TID 430) in 10 ms on localhost (executor driver) (2/6)
18/02/28 13:40:13 INFO Executor: Running task 4.0 in stage 146.0 (TID 434)
18/02/28 13:40:13 INFO MemoryStore: Block rdd_424_0 stored as values in memory (estimated size 2.5 KB, free 260.6 MB)
18/02/28 13:40:13 INFO BlockManagerInfo: Added rdd_424_0 in memory on 127.0.0.1:60941 (size: 2.5 KB, free: 266.5 MB)
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:40:13 INFO MemoryStore: Block rdd_424_1 stored as values in memory (estimated size 2.1 KB, free 260.6 MB)
18/02/28 13:40:13 INFO MemoryStore: Block rdd_424_2 stored as values in memory (estimated size 2.2 KB, free 260.6 MB)
18/02/28 13:40:13 INFO BlockManagerInfo: Added rdd_424_1 in memory on 127.0.0.1:60941 (size: 2.1 KB, free: 266.5 MB)
18/02/28 13:40:13 INFO BlockManagerInfo: Added rdd_424_2 in memory on 127.0.0.1:60941 (size: 2.2 KB, free: 266.5 MB)
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:40:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
18/02/28 13:40:13 INFO Executor: Finished task 1.0 in stage 146.0 (TID 431). 1983 bytes result sent to driver
18/02/28 13:40:13 INFO Executor: Finished task 2.0 in stage 146.0 (TID 432). 1940 bytes result sent to driver
18/02/28 13:40:13 INFO Executor: Finished task 3.0 in stage 146.0 (TID 433). 1940 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Finished task 1.0 in stage 146.0 (TID 431) in 24 ms on localhost (executor driver) (3/6)
18/02/28 13:40:13 INFO TaskSetManager: Finished task 2.0 in stage 146.0 (TID 432) in 25 ms on localhost (executor driver) (4/6)
18/02/28 13:40:13 INFO TaskSetManager: Finished task 3.0 in stage 146.0 (TID 433) in 18 ms on localhost (executor driver) (5/6)
18/02/28 13:40:13 INFO MemoryStore: Block rdd_424_3 stored as values in memory (estimated size 1952.0 B, free 260.6 MB)
18/02/28 13:40:13 INFO BlockManagerInfo: Added rdd_424_3 in memory on 127.0.0.1:60941 (size: 1952.0 B, free: 266.5 MB)
18/02/28 13:40:13 INFO Executor: Finished task 4.0 in stage 146.0 (TID 434). 1940 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Finished task 4.0 in stage 146.0 (TID 434) in 21 ms on localhost (executor driver) (6/6)
18/02/28 13:40:13 INFO DAGScheduler: ResultStage 146 (collect at SlidingRDD.scala:81) finished in 0.031 s
18/02/28 13:40:13 INFO DAGScheduler: Job 84 finished: collect at SlidingRDD.scala:81, took 0.036931 s
18/02/28 13:40:13 INFO SparkContext: Starting job: aggregate at AreaUnderCurve.scala:45
18/02/28 13:40:13 INFO DAGScheduler: Got job 85 (aggregate at AreaUnderCurve.scala:45) with 5 output partitions
18/02/28 13:40:13 INFO DAGScheduler: Final stage: ResultStage 149 (aggregate at AreaUnderCurve.scala:45)
18/02/28 13:40:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 148)
18/02/28 13:40:13 INFO TaskSchedulerImpl: Removed TaskSet 146.0, whose tasks have all completed, from pool 
18/02/28 13:40:13 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:13 INFO DAGScheduler: Submitting ResultStage 149 (SlidingRDD[430] at RDD at SlidingRDD.scala:50), which has no missing parents
18/02/28 13:40:13 INFO MemoryStore: Block broadcast_181 stored as values in memory (estimated size 6.5 KB, free 260.6 MB)
18/02/28 13:40:13 INFO MemoryStore: Block broadcast_181_piece0 stored as bytes in memory (estimated size 3.4 KB, free 260.6 MB)
18/02/28 13:40:13 INFO BlockManagerInfo: Added broadcast_181_piece0 in memory on 127.0.0.1:60941 (size: 3.4 KB, free: 266.5 MB)
18/02/28 13:40:13 INFO SparkContext: Created broadcast 181 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:13 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 149 (SlidingRDD[430] at RDD at SlidingRDD.scala:50) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/02/28 13:40:13 INFO TaskSchedulerImpl: Adding task set 149.0 with 5 tasks
18/02/28 13:40:13 INFO TaskSetManager: Starting task 1.0 in stage 149.0 (TID 435, localhost, executor driver, partition 1, PROCESS_LOCAL, 5269 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 2.0 in stage 149.0 (TID 436, localhost, executor driver, partition 2, PROCESS_LOCAL, 5269 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 3.0 in stage 149.0 (TID 437, localhost, executor driver, partition 3, PROCESS_LOCAL, 5269 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 4.0 in stage 149.0 (TID 438, localhost, executor driver, partition 4, PROCESS_LOCAL, 5269 bytes)
18/02/28 13:40:13 INFO Executor: Running task 1.0 in stage 149.0 (TID 435)
18/02/28 13:40:13 INFO Executor: Running task 4.0 in stage 149.0 (TID 438)
18/02/28 13:40:13 INFO Executor: Running task 3.0 in stage 149.0 (TID 437)
18/02/28 13:40:13 INFO BlockManager: Found block rdd_424_2 locally
18/02/28 13:40:13 INFO BlockManager: Found block rdd_424_0 locally
18/02/28 13:40:13 INFO Executor: Running task 2.0 in stage 149.0 (TID 436)
18/02/28 13:40:13 INFO BlockManager: Found block rdd_424_3 locally
18/02/28 13:40:13 INFO BlockManager: Found block rdd_424_1 locally
18/02/28 13:40:13 INFO Executor: Finished task 4.0 in stage 149.0 (TID 438). 748 bytes result sent to driver
18/02/28 13:40:13 INFO Executor: Finished task 3.0 in stage 149.0 (TID 437). 748 bytes result sent to driver
18/02/28 13:40:13 INFO Executor: Finished task 1.0 in stage 149.0 (TID 435). 791 bytes result sent to driver
18/02/28 13:40:13 INFO Executor: Finished task 2.0 in stage 149.0 (TID 436). 748 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Starting task 0.0 in stage 149.0 (TID 439, localhost, executor driver, partition 0, PROCESS_LOCAL, 5475 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Finished task 4.0 in stage 149.0 (TID 438) in 9 ms on localhost (executor driver) (1/5)
18/02/28 13:40:13 INFO Executor: Running task 0.0 in stage 149.0 (TID 439)
18/02/28 13:40:13 INFO TaskSetManager: Finished task 3.0 in stage 149.0 (TID 437) in 10 ms on localhost (executor driver) (2/5)
18/02/28 13:40:13 INFO TaskSetManager: Finished task 1.0 in stage 149.0 (TID 435) in 13 ms on localhost (executor driver) (3/5)
18/02/28 13:40:13 INFO TaskSetManager: Finished task 2.0 in stage 149.0 (TID 436) in 10 ms on localhost (executor driver) (4/5)
18/02/28 13:40:13 INFO Executor: Finished task 0.0 in stage 149.0 (TID 439). 619 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Finished task 0.0 in stage 149.0 (TID 439) in 3 ms on localhost (executor driver) (5/5)
18/02/28 13:40:13 INFO TaskSchedulerImpl: Removed TaskSet 149.0, whose tasks have all completed, from pool 
18/02/28 13:40:13 INFO DAGScheduler: ResultStage 149 (aggregate at AreaUnderCurve.scala:45) finished in 0.015 s
18/02/28 13:40:13 INFO DAGScheduler: Job 85 finished: aggregate at AreaUnderCurve.scala:45, took 0.019924 s
18/02/28 13:40:13 INFO CodeGenerator: Code generated in 6.525176 ms
18/02/28 13:40:13 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:40:13 INFO DAGScheduler: Got job 86 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:40:13 INFO DAGScheduler: Final stage: ResultStage 152 (collect at utils.scala:211)
18/02/28 13:40:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 151)
18/02/28 13:40:13 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:13 INFO DAGScheduler: Submitting ResultStage 152 (MapPartitionsRDD[435] at collect at utils.scala:211), which has no missing parents
18/02/28 13:40:13 INFO MemoryStore: Block broadcast_182 stored as values in memory (estimated size 10.4 KB, free 260.6 MB)
18/02/28 13:40:13 INFO MemoryStore: Block broadcast_182_piece0 stored as bytes in memory (estimated size 4.9 KB, free 260.6 MB)
18/02/28 13:40:13 INFO BlockManagerInfo: Added broadcast_182_piece0 in memory on 127.0.0.1:60941 (size: 4.9 KB, free: 266.5 MB)
18/02/28 13:40:13 INFO SparkContext: Created broadcast 182 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:13 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 152 (MapPartitionsRDD[435] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:13 INFO TaskSchedulerImpl: Adding task set 152.0 with 4 tasks
18/02/28 13:40:13 INFO TaskSetManager: Starting task 0.0 in stage 152.0 (TID 440, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 1.0 in stage 152.0 (TID 441, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 2.0 in stage 152.0 (TID 442, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 3.0 in stage 152.0 (TID 443, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:13 INFO Executor: Running task 0.0 in stage 152.0 (TID 440)
18/02/28 13:40:13 INFO Executor: Running task 1.0 in stage 152.0 (TID 441)
18/02/28 13:40:13 INFO Executor: Running task 2.0 in stage 152.0 (TID 442)
18/02/28 13:40:13 INFO BlockManager: Found block rdd_424_1 locally
18/02/28 13:40:13 INFO BlockManager: Found block rdd_424_2 locally
18/02/28 13:40:13 INFO Executor: Running task 3.0 in stage 152.0 (TID 443)
18/02/28 13:40:13 INFO BlockManager: Found block rdd_424_3 locally
18/02/28 13:40:13 INFO BlockManager: Found block rdd_424_0 locally
18/02/28 13:40:13 INFO Executor: Finished task 0.0 in stage 152.0 (TID 440). 1609 bytes result sent to driver
18/02/28 13:40:13 INFO Executor: Finished task 2.0 in stage 152.0 (TID 442). 1597 bytes result sent to driver
18/02/28 13:40:13 INFO Executor: Finished task 1.0 in stage 152.0 (TID 441). 1598 bytes result sent to driver
18/02/28 13:40:13 INFO Executor: Finished task 3.0 in stage 152.0 (TID 443). 1508 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Finished task 0.0 in stage 152.0 (TID 440) in 12 ms on localhost (executor driver) (1/4)
18/02/28 13:40:13 INFO TaskSetManager: Finished task 2.0 in stage 152.0 (TID 442) in 13 ms on localhost (executor driver) (2/4)
18/02/28 13:40:13 INFO TaskSetManager: Finished task 1.0 in stage 152.0 (TID 441) in 13 ms on localhost (executor driver) (3/4)
18/02/28 13:40:13 INFO TaskSetManager: Finished task 3.0 in stage 152.0 (TID 443) in 14 ms on localhost (executor driver) (4/4)
18/02/28 13:40:13 INFO DAGScheduler: ResultStage 152 (collect at utils.scala:211) finished in 0.014 s
18/02/28 13:40:13 INFO DAGScheduler: Job 86 finished: collect at utils.scala:211, took 0.017899 s
18/02/28 13:40:13 INFO TaskSchedulerImpl: Removed TaskSet 152.0, whose tasks have all completed, from pool 
18/02/28 13:40:13 INFO CodeGenerator: Code generated in 4.765265 ms
18/02/28 13:40:13 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:40:13 INFO DAGScheduler: Got job 87 (collect at utils.scala:211) with 5 output partitions
18/02/28 13:40:13 INFO DAGScheduler: Final stage: ResultStage 155 (collect at utils.scala:211)
18/02/28 13:40:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 154)
18/02/28 13:40:13 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:13 INFO DAGScheduler: Submitting ResultStage 155 (MapPartitionsRDD[441] at collect at utils.scala:211), which has no missing parents
18/02/28 13:40:13 INFO MemoryStore: Block broadcast_183 stored as values in memory (estimated size 11.1 KB, free 260.6 MB)
18/02/28 13:40:13 INFO MemoryStore: Block broadcast_183_piece0 stored as bytes in memory (estimated size 5.3 KB, free 260.6 MB)
18/02/28 13:40:13 INFO BlockManagerInfo: Added broadcast_183_piece0 in memory on 127.0.0.1:60941 (size: 5.3 KB, free: 266.5 MB)
18/02/28 13:40:13 INFO SparkContext: Created broadcast 183 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:13 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 155 (MapPartitionsRDD[441] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/02/28 13:40:13 INFO TaskSchedulerImpl: Adding task set 155.0 with 5 tasks
18/02/28 13:40:13 INFO TaskSetManager: Starting task 1.0 in stage 155.0 (TID 444, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 2.0 in stage 155.0 (TID 445, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 3.0 in stage 155.0 (TID 446, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 4.0 in stage 155.0 (TID 447, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:40:13 INFO Executor: Running task 1.0 in stage 155.0 (TID 444)
18/02/28 13:40:13 INFO Executor: Running task 2.0 in stage 155.0 (TID 445)
18/02/28 13:40:13 INFO Executor: Running task 3.0 in stage 155.0 (TID 446)
18/02/28 13:40:13 INFO BlockManager: Found block rdd_424_0 locally
18/02/28 13:40:13 INFO Executor: Finished task 1.0 in stage 155.0 (TID 444). 1451 bytes result sent to driver
18/02/28 13:40:13 INFO BlockManager: Found block rdd_424_2 locally
18/02/28 13:40:13 INFO BlockManager: Found block rdd_424_1 locally
18/02/28 13:40:13 INFO Executor: Finished task 3.0 in stage 155.0 (TID 446). 1560 bytes result sent to driver
18/02/28 13:40:13 INFO Executor: Running task 4.0 in stage 155.0 (TID 447)
18/02/28 13:40:13 INFO Executor: Finished task 2.0 in stage 155.0 (TID 445). 1499 bytes result sent to driver
18/02/28 13:40:13 INFO BlockManager: Found block rdd_424_3 locally
18/02/28 13:40:13 INFO TaskSetManager: Starting task 0.0 in stage 155.0 (TID 448, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 13:40:13 INFO Executor: Finished task 4.0 in stage 155.0 (TID 447). 1513 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Finished task 1.0 in stage 155.0 (TID 444) in 7 ms on localhost (executor driver) (1/5)
18/02/28 13:40:13 INFO TaskSetManager: Finished task 3.0 in stage 155.0 (TID 446) in 8 ms on localhost (executor driver) (2/5)
18/02/28 13:40:13 INFO TaskSetManager: Finished task 2.0 in stage 155.0 (TID 445) in 8 ms on localhost (executor driver) (3/5)
18/02/28 13:40:13 INFO Executor: Running task 0.0 in stage 155.0 (TID 448)
18/02/28 13:40:13 INFO TaskSetManager: Finished task 4.0 in stage 155.0 (TID 447) in 8 ms on localhost (executor driver) (4/5)
18/02/28 13:40:13 INFO Executor: Finished task 0.0 in stage 155.0 (TID 448). 1043 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Finished task 0.0 in stage 155.0 (TID 448) in 6 ms on localhost (executor driver) (5/5)
18/02/28 13:40:13 INFO DAGScheduler: ResultStage 155 (collect at utils.scala:211) finished in 0.011 s
18/02/28 13:40:13 INFO DAGScheduler: Job 87 finished: collect at utils.scala:211, took 0.014486 s
18/02/28 13:40:13 INFO TaskSchedulerImpl: Removed TaskSet 155.0, whose tasks have all completed, from pool 
18/02/28 13:40:13 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:40:13 INFO DAGScheduler: Got job 88 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:40:13 INFO DAGScheduler: Final stage: ResultStage 158 (collect at utils.scala:211)
18/02/28 13:40:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 157)
18/02/28 13:40:13 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:13 INFO DAGScheduler: Submitting ResultStage 158 (MapPartitionsRDD[445] at collect at utils.scala:211), which has no missing parents
18/02/28 13:40:13 INFO MemoryStore: Block broadcast_184 stored as values in memory (estimated size 10.3 KB, free 260.6 MB)
18/02/28 13:40:13 INFO MemoryStore: Block broadcast_184_piece0 stored as bytes in memory (estimated size 4.9 KB, free 260.6 MB)
18/02/28 13:40:13 INFO BlockManagerInfo: Added broadcast_184_piece0 in memory on 127.0.0.1:60941 (size: 4.9 KB, free: 266.5 MB)
18/02/28 13:40:13 INFO SparkContext: Created broadcast 184 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:13 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 158 (MapPartitionsRDD[445] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:13 INFO TaskSchedulerImpl: Adding task set 158.0 with 4 tasks
18/02/28 13:40:13 INFO TaskSetManager: Starting task 0.0 in stage 158.0 (TID 449, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 1.0 in stage 158.0 (TID 450, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 2.0 in stage 158.0 (TID 451, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:13 INFO TaskSetManager: Starting task 3.0 in stage 158.0 (TID 452, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:13 INFO Executor: Running task 0.0 in stage 158.0 (TID 449)
18/02/28 13:40:13 INFO Executor: Running task 2.0 in stage 158.0 (TID 451)
18/02/28 13:40:13 INFO Executor: Running task 3.0 in stage 158.0 (TID 452)
18/02/28 13:40:13 INFO BlockManager: Found block rdd_424_3 locally
18/02/28 13:40:13 INFO Executor: Finished task 3.0 in stage 158.0 (TID 452). 1510 bytes result sent to driver
18/02/28 13:40:13 INFO Executor: Running task 1.0 in stage 158.0 (TID 450)
18/02/28 13:40:13 INFO BlockManager: Found block rdd_424_0 locally
18/02/28 13:40:13 INFO BlockManager: Found block rdd_424_1 locally
18/02/28 13:40:13 INFO Executor: Finished task 1.0 in stage 158.0 (TID 450). 1446 bytes result sent to driver
18/02/28 13:40:13 INFO Executor: Finished task 0.0 in stage 158.0 (TID 449). 1389 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Finished task 3.0 in stage 158.0 (TID 452) in 5 ms on localhost (executor driver) (1/4)
18/02/28 13:40:13 INFO TaskSetManager: Finished task 1.0 in stage 158.0 (TID 450) in 6 ms on localhost (executor driver) (2/4)
18/02/28 13:40:13 INFO TaskSetManager: Finished task 0.0 in stage 158.0 (TID 449) in 6 ms on localhost (executor driver) (3/4)
18/02/28 13:40:13 INFO BlockManager: Found block rdd_424_2 locally
18/02/28 13:40:13 INFO Executor: Finished task 2.0 in stage 158.0 (TID 451). 1608 bytes result sent to driver
18/02/28 13:40:13 INFO TaskSetManager: Finished task 2.0 in stage 158.0 (TID 451) in 8 ms on localhost (executor driver) (4/4)
18/02/28 13:40:13 INFO TaskSchedulerImpl: Removed TaskSet 158.0, whose tasks have all completed, from pool 
18/02/28 13:40:13 INFO DAGScheduler: ResultStage 158 (collect at utils.scala:211) finished in 0.009 s
18/02/28 13:40:13 INFO DAGScheduler: Job 88 finished: collect at utils.scala:211, took 0.012690 s
18/02/28 13:40:13 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e0774a3431
18/02/28 13:40:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:40:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0774a3431` AS `zzz94`
WHERE (0 = 1)
18/02/28 13:40:14 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:40:14 INFO DAGScheduler: Got job 89 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:40:14 INFO DAGScheduler: Final stage: ResultStage 161 (collect at utils.scala:211)
18/02/28 13:40:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 160)
18/02/28 13:40:14 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:14 INFO DAGScheduler: Submitting ResultStage 161 (MapPartitionsRDD[449] at collect at utils.scala:211), which has no missing parents
18/02/28 13:40:14 INFO MemoryStore: Block broadcast_185 stored as values in memory (estimated size 10.3 KB, free 260.6 MB)
18/02/28 13:40:14 INFO MemoryStore: Block broadcast_185_piece0 stored as bytes in memory (estimated size 4.9 KB, free 260.6 MB)
18/02/28 13:40:14 INFO BlockManagerInfo: Added broadcast_185_piece0 in memory on 127.0.0.1:60941 (size: 4.9 KB, free: 266.5 MB)
18/02/28 13:40:14 INFO SparkContext: Created broadcast 185 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 161 (MapPartitionsRDD[449] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:14 INFO TaskSchedulerImpl: Adding task set 161.0 with 4 tasks
18/02/28 13:40:14 INFO TaskSetManager: Starting task 0.0 in stage 161.0 (TID 453, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 1.0 in stage 161.0 (TID 454, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 2.0 in stage 161.0 (TID 455, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 3.0 in stage 161.0 (TID 456, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:14 INFO Executor: Running task 0.0 in stage 161.0 (TID 453)
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_0 locally
18/02/28 13:40:14 INFO Executor: Finished task 0.0 in stage 161.0 (TID 453). 1628 bytes result sent to driver
18/02/28 13:40:14 INFO Executor: Running task 1.0 in stage 161.0 (TID 454)
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_1 locally
18/02/28 13:40:14 INFO Executor: Finished task 1.0 in stage 161.0 (TID 454). 1604 bytes result sent to driver
18/02/28 13:40:14 INFO Executor: Running task 2.0 in stage 161.0 (TID 455)
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_2 locally
18/02/28 13:40:14 INFO Executor: Finished task 2.0 in stage 161.0 (TID 455). 1604 bytes result sent to driver
18/02/28 13:40:14 INFO Executor: Running task 3.0 in stage 161.0 (TID 456)
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_3 locally
18/02/28 13:40:14 INFO Executor: Finished task 3.0 in stage 161.0 (TID 456). 1553 bytes result sent to driver
18/02/28 13:40:14 INFO BlockManagerInfo: Removed broadcast_177_piece0 on 127.0.0.1:60941 in memory (size: 1915.0 B, free: 266.5 MB)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 0.0 in stage 161.0 (TID 453) in 10 ms on localhost (executor driver) (1/4)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 1.0 in stage 161.0 (TID 454) in 10 ms on localhost (executor driver) (2/4)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 2.0 in stage 161.0 (TID 455) in 11 ms on localhost (executor driver) (3/4)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 3.0 in stage 161.0 (TID 456) in 13 ms on localhost (executor driver) (4/4)
18/02/28 13:40:14 INFO DAGScheduler: ResultStage 161 (collect at utils.scala:211) finished in 0.014 s
18/02/28 13:40:14 INFO DAGScheduler: Job 89 finished: collect at utils.scala:211, took 0.024949 s
18/02/28 13:40:14 INFO TaskSchedulerImpl: Removed TaskSet 161.0, whose tasks have all completed, from pool 
18/02/28 13:40:14 INFO BlockManagerInfo: Removed broadcast_181_piece0 on 127.0.0.1:60941 in memory (size: 3.4 KB, free: 266.5 MB)
18/02/28 13:40:14 INFO BlockManagerInfo: Removed broadcast_175_piece0 on 127.0.0.1:60941 in memory (size: 32.8 KB, free: 266.5 MB)
18/02/28 13:40:14 INFO BlockManagerInfo: Removed broadcast_179_piece0 on 127.0.0.1:60941 in memory (size: 2.3 KB, free: 266.5 MB)
18/02/28 13:40:14 INFO BlockManagerInfo: Removed broadcast_174_piece0 on 127.0.0.1:60941 in memory (size: 29.1 KB, free: 266.6 MB)
18/02/28 13:40:14 INFO BlockManagerInfo: Removed broadcast_184_piece0 on 127.0.0.1:60941 in memory (size: 4.9 KB, free: 266.6 MB)
18/02/28 13:40:14 INFO BlockManagerInfo: Removed broadcast_183_piece0 on 127.0.0.1:60941 in memory (size: 5.3 KB, free: 266.6 MB)
18/02/28 13:40:14 INFO BlockManagerInfo: Removed broadcast_178_piece0 on 127.0.0.1:60941 in memory (size: 1868.0 B, free: 266.6 MB)
18/02/28 13:40:14 INFO BlockManagerInfo: Removed broadcast_172_piece0 on 127.0.0.1:60941 in memory (size: 29.1 KB, free: 266.6 MB)
18/02/28 13:40:14 INFO BlockManagerInfo: Removed broadcast_182_piece0 on 127.0.0.1:60941 in memory (size: 4.9 KB, free: 266.6 MB)
18/02/28 13:40:14 INFO BlockManagerInfo: Removed broadcast_180_piece0 on 127.0.0.1:60941 in memory (size: 3.3 KB, free: 266.6 MB)
18/02/28 13:40:14 INFO BlockManagerInfo: Removed broadcast_176_piece0 on 127.0.0.1:60941 in memory (size: 2.0 KB, free: 266.6 MB)
18/02/28 13:40:14 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:40:14 INFO DAGScheduler: Got job 90 (collect at utils.scala:211) with 6 output partitions
18/02/28 13:40:14 INFO DAGScheduler: Final stage: ResultStage 164 (collect at utils.scala:211)
18/02/28 13:40:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 163)
18/02/28 13:40:14 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:14 INFO DAGScheduler: Submitting ResultStage 164 (MapPartitionsRDD[456] at collect at utils.scala:211), which has no missing parents
18/02/28 13:40:14 INFO MemoryStore: Block broadcast_186 stored as values in memory (estimated size 11.2 KB, free 261.0 MB)
18/02/28 13:40:14 INFO MemoryStore: Block broadcast_186_piece0 stored as bytes in memory (estimated size 5.4 KB, free 261.0 MB)
18/02/28 13:40:14 INFO BlockManagerInfo: Added broadcast_186_piece0 in memory on 127.0.0.1:60941 (size: 5.4 KB, free: 266.6 MB)
18/02/28 13:40:14 INFO SparkContext: Created broadcast 186 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:14 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 164 (MapPartitionsRDD[456] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
18/02/28 13:40:14 INFO TaskSchedulerImpl: Adding task set 164.0 with 6 tasks
18/02/28 13:40:14 INFO TaskSetManager: Starting task 1.0 in stage 164.0 (TID 457, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 2.0 in stage 164.0 (TID 458, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 3.0 in stage 164.0 (TID 459, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 4.0 in stage 164.0 (TID 460, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:40:14 INFO Executor: Running task 1.0 in stage 164.0 (TID 457)
18/02/28 13:40:14 INFO Executor: Running task 2.0 in stage 164.0 (TID 458)
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_0 locally
18/02/28 13:40:14 INFO Executor: Finished task 1.0 in stage 164.0 (TID 457). 1398 bytes result sent to driver
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_1 locally
18/02/28 13:40:14 INFO Executor: Running task 3.0 in stage 164.0 (TID 459)
18/02/28 13:40:14 INFO Executor: Finished task 2.0 in stage 164.0 (TID 458). 1400 bytes result sent to driver
18/02/28 13:40:14 INFO Executor: Running task 4.0 in stage 164.0 (TID 460)
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_2 locally
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_3 locally
18/02/28 13:40:14 INFO Executor: Finished task 4.0 in stage 164.0 (TID 460). 1458 bytes result sent to driver
18/02/28 13:40:14 INFO Executor: Finished task 3.0 in stage 164.0 (TID 459). 1541 bytes result sent to driver
18/02/28 13:40:14 INFO TaskSetManager: Starting task 0.0 in stage 164.0 (TID 461, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 13:40:14 INFO Executor: Running task 0.0 in stage 164.0 (TID 461)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 5.0 in stage 164.0 (TID 462, localhost, executor driver, partition 5, PROCESS_LOCAL, 5058 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 2.0 in stage 164.0 (TID 458) in 6 ms on localhost (executor driver) (1/6)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 4.0 in stage 164.0 (TID 460) in 7 ms on localhost (executor driver) (2/6)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 3.0 in stage 164.0 (TID 459) in 7 ms on localhost (executor driver) (3/6)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 1.0 in stage 164.0 (TID 457) in 7 ms on localhost (executor driver) (4/6)
18/02/28 13:40:14 INFO Executor: Running task 5.0 in stage 164.0 (TID 462)
18/02/28 13:40:14 INFO Executor: Finished task 5.0 in stage 164.0 (TID 462). 1007 bytes result sent to driver
18/02/28 13:40:14 INFO Executor: Finished task 0.0 in stage 164.0 (TID 461). 1042 bytes result sent to driver
18/02/28 13:40:14 INFO TaskSetManager: Finished task 5.0 in stage 164.0 (TID 462) in 4 ms on localhost (executor driver) (5/6)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 0.0 in stage 164.0 (TID 461) in 4 ms on localhost (executor driver) (6/6)
18/02/28 13:40:14 INFO TaskSchedulerImpl: Removed TaskSet 164.0, whose tasks have all completed, from pool 
18/02/28 13:40:14 INFO DAGScheduler: ResultStage 164 (collect at utils.scala:211) finished in 0.010 s
18/02/28 13:40:14 INFO DAGScheduler: Job 90 finished: collect at utils.scala:211, took 0.014145 s
18/02/28 13:40:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:40:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 13:40:14 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e05b612970
18/02/28 13:40:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:40:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e05b612970` AS `zzz95`
WHERE (0 = 1)
18/02/28 13:40:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:40:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e05b612970`
18/02/28 13:40:14 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:40:14 INFO DAGScheduler: Got job 91 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:40:14 INFO DAGScheduler: Final stage: ResultStage 167 (collect at utils.scala:211)
18/02/28 13:40:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 166)
18/02/28 13:40:14 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:14 INFO DAGScheduler: Submitting ResultStage 167 (MapPartitionsRDD[459] at collect at utils.scala:211), which has no missing parents
18/02/28 13:40:14 INFO MemoryStore: Block broadcast_187 stored as values in memory (estimated size 10.4 KB, free 260.9 MB)
18/02/28 13:40:14 INFO MemoryStore: Block broadcast_187_piece0 stored as bytes in memory (estimated size 4.9 KB, free 260.9 MB)
18/02/28 13:40:14 INFO BlockManagerInfo: Added broadcast_187_piece0 in memory on 127.0.0.1:60941 (size: 4.9 KB, free: 266.6 MB)
18/02/28 13:40:14 INFO SparkContext: Created broadcast 187 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 167 (MapPartitionsRDD[459] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:14 INFO TaskSchedulerImpl: Adding task set 167.0 with 4 tasks
18/02/28 13:40:14 INFO TaskSetManager: Starting task 0.0 in stage 167.0 (TID 463, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 1.0 in stage 167.0 (TID 464, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 2.0 in stage 167.0 (TID 465, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 3.0 in stage 167.0 (TID 466, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:14 INFO Executor: Running task 0.0 in stage 167.0 (TID 463)
18/02/28 13:40:14 INFO Executor: Running task 1.0 in stage 167.0 (TID 464)
18/02/28 13:40:14 INFO Executor: Running task 2.0 in stage 167.0 (TID 465)
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_0 locally
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_2 locally
18/02/28 13:40:14 INFO Executor: Finished task 2.0 in stage 167.0 (TID 465). 1554 bytes result sent to driver
18/02/28 13:40:14 INFO Executor: Running task 3.0 in stage 167.0 (TID 466)
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_1 locally
18/02/28 13:40:14 INFO Executor: Finished task 1.0 in stage 167.0 (TID 464). 1598 bytes result sent to driver
18/02/28 13:40:14 INFO Executor: Finished task 0.0 in stage 167.0 (TID 463). 1652 bytes result sent to driver
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_3 locally
18/02/28 13:40:14 INFO TaskSetManager: Finished task 2.0 in stage 167.0 (TID 465) in 5 ms on localhost (executor driver) (1/4)
18/02/28 13:40:14 INFO Executor: Finished task 3.0 in stage 167.0 (TID 466). 1508 bytes result sent to driver
18/02/28 13:40:14 INFO TaskSetManager: Finished task 0.0 in stage 167.0 (TID 463) in 6 ms on localhost (executor driver) (2/4)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 1.0 in stage 167.0 (TID 464) in 5 ms on localhost (executor driver) (3/4)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 3.0 in stage 167.0 (TID 466) in 6 ms on localhost (executor driver) (4/4)
18/02/28 13:40:14 INFO TaskSchedulerImpl: Removed TaskSet 167.0, whose tasks have all completed, from pool 
18/02/28 13:40:14 INFO DAGScheduler: ResultStage 167 (collect at utils.scala:211) finished in 0.009 s
18/02/28 13:40:14 INFO DAGScheduler: Job 91 finished: collect at utils.scala:211, took 0.013560 s
18/02/28 13:40:14 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:40:14 INFO DAGScheduler: Got job 92 (collect at utils.scala:211) with 5 output partitions
18/02/28 13:40:14 INFO DAGScheduler: Final stage: ResultStage 170 (collect at utils.scala:211)
18/02/28 13:40:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 169)
18/02/28 13:40:14 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:14 INFO DAGScheduler: Submitting ResultStage 170 (MapPartitionsRDD[462] at collect at utils.scala:211), which has no missing parents
18/02/28 13:40:14 INFO MemoryStore: Block broadcast_188 stored as values in memory (estimated size 11.1 KB, free 260.9 MB)
18/02/28 13:40:14 INFO MemoryStore: Block broadcast_188_piece0 stored as bytes in memory (estimated size 5.3 KB, free 260.9 MB)
18/02/28 13:40:14 INFO BlockManagerInfo: Added broadcast_188_piece0 in memory on 127.0.0.1:60941 (size: 5.3 KB, free: 266.6 MB)
18/02/28 13:40:14 INFO SparkContext: Created broadcast 188 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:14 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 170 (MapPartitionsRDD[462] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/02/28 13:40:14 INFO TaskSchedulerImpl: Adding task set 170.0 with 5 tasks
18/02/28 13:40:14 INFO TaskSetManager: Starting task 1.0 in stage 170.0 (TID 467, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 2.0 in stage 170.0 (TID 468, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 3.0 in stage 170.0 (TID 469, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 4.0 in stage 170.0 (TID 470, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:40:14 INFO Executor: Running task 2.0 in stage 170.0 (TID 468)
18/02/28 13:40:14 INFO Executor: Running task 3.0 in stage 170.0 (TID 469)
18/02/28 13:40:14 INFO Executor: Running task 4.0 in stage 170.0 (TID 470)
18/02/28 13:40:14 INFO Executor: Running task 1.0 in stage 170.0 (TID 467)
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_2 locally
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_3 locally
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_0 locally
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_1 locally
18/02/28 13:40:14 INFO Executor: Finished task 4.0 in stage 170.0 (TID 470). 1513 bytes result sent to driver
18/02/28 13:40:14 INFO Executor: Finished task 1.0 in stage 170.0 (TID 467). 1451 bytes result sent to driver
18/02/28 13:40:14 INFO Executor: Finished task 2.0 in stage 170.0 (TID 468). 1499 bytes result sent to driver
18/02/28 13:40:14 INFO Executor: Finished task 3.0 in stage 170.0 (TID 469). 1603 bytes result sent to driver
18/02/28 13:40:14 INFO TaskSetManager: Starting task 0.0 in stage 170.0 (TID 471, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 13:40:14 INFO Executor: Running task 0.0 in stage 170.0 (TID 471)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 1.0 in stage 170.0 (TID 467) in 2 ms on localhost (executor driver) (1/5)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 3.0 in stage 170.0 (TID 469) in 3 ms on localhost (executor driver) (2/5)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 4.0 in stage 170.0 (TID 470) in 3 ms on localhost (executor driver) (3/5)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 2.0 in stage 170.0 (TID 468) in 3 ms on localhost (executor driver) (4/5)
18/02/28 13:40:14 INFO Executor: Finished task 0.0 in stage 170.0 (TID 471). 1000 bytes result sent to driver
18/02/28 13:40:14 INFO TaskSetManager: Finished task 0.0 in stage 170.0 (TID 471) in 3 ms on localhost (executor driver) (5/5)
18/02/28 13:40:14 INFO TaskSchedulerImpl: Removed TaskSet 170.0, whose tasks have all completed, from pool 
18/02/28 13:40:14 INFO DAGScheduler: ResultStage 170 (collect at utils.scala:211) finished in 0.005 s
18/02/28 13:40:14 INFO DAGScheduler: Job 92 finished: collect at utils.scala:211, took 0.008420 s
18/02/28 13:40:14 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:40:14 INFO DAGScheduler: Got job 93 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:40:14 INFO DAGScheduler: Final stage: ResultStage 173 (collect at utils.scala:211)
18/02/28 13:40:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 172)
18/02/28 13:40:14 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:14 INFO DAGScheduler: Submitting ResultStage 173 (MapPartitionsRDD[465] at collect at utils.scala:211), which has no missing parents
18/02/28 13:40:14 INFO MemoryStore: Block broadcast_189 stored as values in memory (estimated size 10.3 KB, free 260.9 MB)
18/02/28 13:40:14 INFO MemoryStore: Block broadcast_189_piece0 stored as bytes in memory (estimated size 4.9 KB, free 260.9 MB)
18/02/28 13:40:14 INFO BlockManagerInfo: Added broadcast_189_piece0 in memory on 127.0.0.1:60941 (size: 4.9 KB, free: 266.6 MB)
18/02/28 13:40:14 INFO SparkContext: Created broadcast 189 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 173 (MapPartitionsRDD[465] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:14 INFO TaskSchedulerImpl: Adding task set 173.0 with 4 tasks
18/02/28 13:40:14 INFO TaskSetManager: Starting task 0.0 in stage 173.0 (TID 472, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 1.0 in stage 173.0 (TID 473, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 2.0 in stage 173.0 (TID 474, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 3.0 in stage 173.0 (TID 475, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:14 INFO Executor: Running task 0.0 in stage 173.0 (TID 472)
18/02/28 13:40:14 INFO Executor: Running task 3.0 in stage 173.0 (TID 475)
18/02/28 13:40:14 INFO Executor: Running task 2.0 in stage 173.0 (TID 474)
18/02/28 13:40:14 INFO Executor: Running task 1.0 in stage 173.0 (TID 473)
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_1 locally
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_3 locally
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_0 locally
18/02/28 13:40:14 INFO Executor: Finished task 0.0 in stage 173.0 (TID 472). 1346 bytes result sent to driver
18/02/28 13:40:14 INFO Executor: Finished task 3.0 in stage 173.0 (TID 475). 1553 bytes result sent to driver
18/02/28 13:40:14 INFO Executor: Finished task 1.0 in stage 173.0 (TID 473). 1446 bytes result sent to driver
18/02/28 13:40:14 INFO TaskSetManager: Finished task 0.0 in stage 173.0 (TID 472) in 3 ms on localhost (executor driver) (1/4)
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_2 locally
18/02/28 13:40:14 INFO TaskSetManager: Finished task 3.0 in stage 173.0 (TID 475) in 4 ms on localhost (executor driver) (2/4)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 1.0 in stage 173.0 (TID 473) in 4 ms on localhost (executor driver) (3/4)
18/02/28 13:40:14 INFO Executor: Finished task 2.0 in stage 173.0 (TID 474). 1608 bytes result sent to driver
18/02/28 13:40:14 INFO TaskSetManager: Finished task 2.0 in stage 173.0 (TID 474) in 4 ms on localhost (executor driver) (4/4)
18/02/28 13:40:14 INFO TaskSchedulerImpl: Removed TaskSet 173.0, whose tasks have all completed, from pool 
18/02/28 13:40:14 INFO DAGScheduler: ResultStage 173 (collect at utils.scala:211) finished in 0.004 s
18/02/28 13:40:14 INFO DAGScheduler: Job 93 finished: collect at utils.scala:211, took 0.008313 s
18/02/28 13:40:14 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e0160b7ed4
18/02/28 13:40:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:40:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0160b7ed4` AS `zzz96`
WHERE (0 = 1)
18/02/28 13:40:14 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:40:14 INFO DAGScheduler: Got job 94 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:40:14 INFO DAGScheduler: Final stage: ResultStage 176 (collect at utils.scala:211)
18/02/28 13:40:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 175)
18/02/28 13:40:14 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:14 INFO DAGScheduler: Submitting ResultStage 176 (MapPartitionsRDD[468] at collect at utils.scala:211), which has no missing parents
18/02/28 13:40:14 INFO MemoryStore: Block broadcast_190 stored as values in memory (estimated size 10.3 KB, free 260.9 MB)
18/02/28 13:40:14 INFO MemoryStore: Block broadcast_190_piece0 stored as bytes in memory (estimated size 4.9 KB, free 260.9 MB)
18/02/28 13:40:14 INFO BlockManagerInfo: Added broadcast_190_piece0 in memory on 127.0.0.1:60941 (size: 4.9 KB, free: 266.6 MB)
18/02/28 13:40:14 INFO SparkContext: Created broadcast 190 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 176 (MapPartitionsRDD[468] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:14 INFO TaskSchedulerImpl: Adding task set 176.0 with 4 tasks
18/02/28 13:40:14 INFO TaskSetManager: Starting task 0.0 in stage 176.0 (TID 476, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 1.0 in stage 176.0 (TID 477, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 2.0 in stage 176.0 (TID 478, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 3.0 in stage 176.0 (TID 479, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:14 INFO Executor: Running task 0.0 in stage 176.0 (TID 476)
18/02/28 13:40:14 INFO Executor: Running task 1.0 in stage 176.0 (TID 477)
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_1 locally
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_0 locally
18/02/28 13:40:14 INFO Executor: Finished task 1.0 in stage 176.0 (TID 477). 1561 bytes result sent to driver
18/02/28 13:40:14 INFO Executor: Running task 2.0 in stage 176.0 (TID 478)
18/02/28 13:40:14 INFO Executor: Finished task 0.0 in stage 176.0 (TID 476). 1585 bytes result sent to driver
18/02/28 13:40:14 INFO TaskSetManager: Finished task 1.0 in stage 176.0 (TID 477) in 3 ms on localhost (executor driver) (1/4)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 0.0 in stage 176.0 (TID 476) in 4 ms on localhost (executor driver) (2/4)
18/02/28 13:40:14 INFO Executor: Running task 3.0 in stage 176.0 (TID 479)
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_2 locally
18/02/28 13:40:14 INFO Executor: Finished task 2.0 in stage 176.0 (TID 478). 1561 bytes result sent to driver
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_3 locally
18/02/28 13:40:14 INFO TaskSetManager: Finished task 2.0 in stage 176.0 (TID 478) in 5 ms on localhost (executor driver) (3/4)
18/02/28 13:40:14 INFO Executor: Finished task 3.0 in stage 176.0 (TID 479). 1467 bytes result sent to driver
18/02/28 13:40:14 INFO TaskSetManager: Finished task 3.0 in stage 176.0 (TID 479) in 6 ms on localhost (executor driver) (4/4)
18/02/28 13:40:14 INFO TaskSchedulerImpl: Removed TaskSet 176.0, whose tasks have all completed, from pool 
18/02/28 13:40:14 INFO DAGScheduler: ResultStage 176 (collect at utils.scala:211) finished in 0.006 s
18/02/28 13:40:14 INFO DAGScheduler: Job 94 finished: collect at utils.scala:211, took 0.010795 s
18/02/28 13:40:14 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:40:14 INFO DAGScheduler: Got job 95 (collect at utils.scala:211) with 6 output partitions
18/02/28 13:40:14 INFO DAGScheduler: Final stage: ResultStage 179 (collect at utils.scala:211)
18/02/28 13:40:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 178)
18/02/28 13:40:14 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:14 INFO DAGScheduler: Submitting ResultStage 179 (MapPartitionsRDD[471] at collect at utils.scala:211), which has no missing parents
18/02/28 13:40:14 INFO MemoryStore: Block broadcast_191 stored as values in memory (estimated size 11.2 KB, free 260.9 MB)
18/02/28 13:40:14 INFO MemoryStore: Block broadcast_191_piece0 stored as bytes in memory (estimated size 5.4 KB, free 260.9 MB)
18/02/28 13:40:14 INFO BlockManagerInfo: Added broadcast_191_piece0 in memory on 127.0.0.1:60941 (size: 5.4 KB, free: 266.6 MB)
18/02/28 13:40:14 INFO SparkContext: Created broadcast 191 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:14 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 179 (MapPartitionsRDD[471] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
18/02/28 13:40:14 INFO TaskSchedulerImpl: Adding task set 179.0 with 6 tasks
18/02/28 13:40:14 INFO TaskSetManager: Starting task 1.0 in stage 179.0 (TID 480, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 2.0 in stage 179.0 (TID 481, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 3.0 in stage 179.0 (TID 482, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 4.0 in stage 179.0 (TID 483, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:40:14 INFO Executor: Running task 1.0 in stage 179.0 (TID 480)
18/02/28 13:40:14 INFO Executor: Running task 4.0 in stage 179.0 (TID 483)
18/02/28 13:40:14 INFO Executor: Running task 3.0 in stage 179.0 (TID 482)
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_3 locally
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_2 locally
18/02/28 13:40:14 INFO Executor: Running task 2.0 in stage 179.0 (TID 481)
18/02/28 13:40:14 INFO Executor: Finished task 3.0 in stage 179.0 (TID 482). 1627 bytes result sent to driver
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_1 locally
18/02/28 13:40:14 INFO TaskSetManager: Starting task 0.0 in stage 179.0 (TID 484, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 13:40:14 INFO Executor: Finished task 2.0 in stage 179.0 (TID 481). 1400 bytes result sent to driver
18/02/28 13:40:14 INFO Executor: Finished task 4.0 in stage 179.0 (TID 483). 1544 bytes result sent to driver
18/02/28 13:40:14 INFO TaskSetManager: Starting task 5.0 in stage 179.0 (TID 485, localhost, executor driver, partition 5, PROCESS_LOCAL, 5058 bytes)
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_0 locally
18/02/28 13:40:14 INFO TaskSetManager: Finished task 3.0 in stage 179.0 (TID 482) in 5 ms on localhost (executor driver) (1/6)
18/02/28 13:40:14 INFO Executor: Finished task 1.0 in stage 179.0 (TID 480). 1441 bytes result sent to driver
18/02/28 13:40:14 INFO Executor: Running task 0.0 in stage 179.0 (TID 484)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 2.0 in stage 179.0 (TID 481) in 6 ms on localhost (executor driver) (2/6)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 4.0 in stage 179.0 (TID 483) in 6 ms on localhost (executor driver) (3/6)
18/02/28 13:40:14 INFO Executor: Running task 5.0 in stage 179.0 (TID 485)
18/02/28 13:40:14 INFO Executor: Finished task 0.0 in stage 179.0 (TID 484). 999 bytes result sent to driver
18/02/28 13:40:14 INFO Executor: Finished task 5.0 in stage 179.0 (TID 485). 1007 bytes result sent to driver
18/02/28 13:40:14 INFO TaskSetManager: Finished task 1.0 in stage 179.0 (TID 480) in 8 ms on localhost (executor driver) (4/6)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 0.0 in stage 179.0 (TID 484) in 5 ms on localhost (executor driver) (5/6)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 5.0 in stage 179.0 (TID 485) in 4 ms on localhost (executor driver) (6/6)
18/02/28 13:40:14 INFO TaskSchedulerImpl: Removed TaskSet 179.0, whose tasks have all completed, from pool 
18/02/28 13:40:14 INFO DAGScheduler: ResultStage 179 (collect at utils.scala:211) finished in 0.009 s
18/02/28 13:40:14 INFO DAGScheduler: Job 95 finished: collect at utils.scala:211, took 0.013230 s
18/02/28 13:40:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:40:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 13:40:14 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:40:14 INFO DAGScheduler: Got job 96 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:40:14 INFO DAGScheduler: Final stage: ResultStage 182 (collect at utils.scala:211)
18/02/28 13:40:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 181)
18/02/28 13:40:14 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:14 INFO DAGScheduler: Submitting ResultStage 182 (MapPartitionsRDD[474] at collect at utils.scala:211), which has no missing parents
18/02/28 13:40:14 INFO MemoryStore: Block broadcast_192 stored as values in memory (estimated size 10.4 KB, free 260.9 MB)
18/02/28 13:40:14 INFO MemoryStore: Block broadcast_192_piece0 stored as bytes in memory (estimated size 4.9 KB, free 260.9 MB)
18/02/28 13:40:14 INFO BlockManagerInfo: Added broadcast_192_piece0 in memory on 127.0.0.1:60941 (size: 4.9 KB, free: 266.6 MB)
18/02/28 13:40:14 INFO SparkContext: Created broadcast 192 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 182 (MapPartitionsRDD[474] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:14 INFO TaskSchedulerImpl: Adding task set 182.0 with 4 tasks
18/02/28 13:40:14 INFO TaskSetManager: Starting task 0.0 in stage 182.0 (TID 486, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 1.0 in stage 182.0 (TID 487, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 2.0 in stage 182.0 (TID 488, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 3.0 in stage 182.0 (TID 489, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:14 INFO Executor: Running task 0.0 in stage 182.0 (TID 486)
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_0 locally
18/02/28 13:40:14 INFO Executor: Finished task 0.0 in stage 182.0 (TID 486). 1609 bytes result sent to driver
18/02/28 13:40:14 INFO Executor: Running task 1.0 in stage 182.0 (TID 487)
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_1 locally
18/02/28 13:40:14 INFO Executor: Finished task 1.0 in stage 182.0 (TID 487). 1598 bytes result sent to driver
18/02/28 13:40:14 INFO Executor: Running task 2.0 in stage 182.0 (TID 488)
18/02/28 13:40:14 INFO Executor: Running task 3.0 in stage 182.0 (TID 489)
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_2 locally
18/02/28 13:40:14 INFO Executor: Finished task 2.0 in stage 182.0 (TID 488). 1597 bytes result sent to driver
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_3 locally
18/02/28 13:40:14 INFO TaskSetManager: Finished task 0.0 in stage 182.0 (TID 486) in 7 ms on localhost (executor driver) (1/4)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 2.0 in stage 182.0 (TID 488) in 8 ms on localhost (executor driver) (2/4)
18/02/28 13:40:14 INFO Executor: Finished task 3.0 in stage 182.0 (TID 489). 1508 bytes result sent to driver
18/02/28 13:40:14 INFO TaskSetManager: Finished task 1.0 in stage 182.0 (TID 487) in 8 ms on localhost (executor driver) (3/4)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 3.0 in stage 182.0 (TID 489) in 9 ms on localhost (executor driver) (4/4)
18/02/28 13:40:14 INFO TaskSchedulerImpl: Removed TaskSet 182.0, whose tasks have all completed, from pool 
18/02/28 13:40:14 INFO DAGScheduler: ResultStage 182 (collect at utils.scala:211) finished in 0.009 s
18/02/28 13:40:14 INFO DAGScheduler: Job 96 finished: collect at utils.scala:211, took 0.012810 s
18/02/28 13:40:14 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:40:14 INFO DAGScheduler: Got job 97 (collect at utils.scala:211) with 5 output partitions
18/02/28 13:40:14 INFO DAGScheduler: Final stage: ResultStage 185 (collect at utils.scala:211)
18/02/28 13:40:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 184)
18/02/28 13:40:14 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:14 INFO DAGScheduler: Submitting ResultStage 185 (MapPartitionsRDD[477] at collect at utils.scala:211), which has no missing parents
18/02/28 13:40:14 INFO MemoryStore: Block broadcast_193 stored as values in memory (estimated size 11.1 KB, free 260.9 MB)
18/02/28 13:40:14 INFO MemoryStore: Block broadcast_193_piece0 stored as bytes in memory (estimated size 5.3 KB, free 260.8 MB)
18/02/28 13:40:14 INFO BlockManagerInfo: Added broadcast_193_piece0 in memory on 127.0.0.1:60941 (size: 5.3 KB, free: 266.6 MB)
18/02/28 13:40:14 INFO SparkContext: Created broadcast 193 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:14 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 185 (MapPartitionsRDD[477] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/02/28 13:40:14 INFO TaskSchedulerImpl: Adding task set 185.0 with 5 tasks
18/02/28 13:40:14 INFO TaskSetManager: Starting task 1.0 in stage 185.0 (TID 490, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 2.0 in stage 185.0 (TID 491, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 3.0 in stage 185.0 (TID 492, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 4.0 in stage 185.0 (TID 493, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:40:14 INFO Executor: Running task 1.0 in stage 185.0 (TID 490)
18/02/28 13:40:14 INFO Executor: Running task 2.0 in stage 185.0 (TID 491)
18/02/28 13:40:14 INFO Executor: Running task 3.0 in stage 185.0 (TID 492)
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_0 locally
18/02/28 13:40:14 INFO Executor: Finished task 1.0 in stage 185.0 (TID 490). 1408 bytes result sent to driver
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_2 locally
18/02/28 13:40:14 INFO Executor: Finished task 3.0 in stage 185.0 (TID 492). 1603 bytes result sent to driver
18/02/28 13:40:14 INFO Executor: Running task 4.0 in stage 185.0 (TID 493)
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_3 locally
18/02/28 13:40:14 INFO Executor: Finished task 4.0 in stage 185.0 (TID 493). 1470 bytes result sent to driver
18/02/28 13:40:14 INFO TaskSetManager: Starting task 0.0 in stage 185.0 (TID 494, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_1 locally
18/02/28 13:40:14 INFO Executor: Finished task 2.0 in stage 185.0 (TID 491). 1456 bytes result sent to driver
18/02/28 13:40:14 INFO TaskSetManager: Finished task 1.0 in stage 185.0 (TID 490) in 9 ms on localhost (executor driver) (1/5)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 3.0 in stage 185.0 (TID 492) in 9 ms on localhost (executor driver) (2/5)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 4.0 in stage 185.0 (TID 493) in 9 ms on localhost (executor driver) (3/5)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 2.0 in stage 185.0 (TID 491) in 10 ms on localhost (executor driver) (4/5)
18/02/28 13:40:14 INFO Executor: Running task 0.0 in stage 185.0 (TID 494)
18/02/28 13:40:14 INFO Executor: Finished task 0.0 in stage 185.0 (TID 494). 1043 bytes result sent to driver
18/02/28 13:40:14 INFO TaskSetManager: Finished task 0.0 in stage 185.0 (TID 494) in 6 ms on localhost (executor driver) (5/5)
18/02/28 13:40:14 INFO DAGScheduler: ResultStage 185 (collect at utils.scala:211) finished in 0.013 s
18/02/28 13:40:14 INFO DAGScheduler: Job 97 finished: collect at utils.scala:211, took 0.016805 s
18/02/28 13:40:14 INFO TaskSchedulerImpl: Removed TaskSet 185.0, whose tasks have all completed, from pool 
18/02/28 13:40:14 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:40:14 INFO DAGScheduler: Got job 98 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:40:14 INFO DAGScheduler: Final stage: ResultStage 188 (collect at utils.scala:211)
18/02/28 13:40:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 187)
18/02/28 13:40:14 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:14 INFO DAGScheduler: Submitting ResultStage 188 (MapPartitionsRDD[480] at collect at utils.scala:211), which has no missing parents
18/02/28 13:40:14 INFO MemoryStore: Block broadcast_194 stored as values in memory (estimated size 10.3 KB, free 260.8 MB)
18/02/28 13:40:14 INFO MemoryStore: Block broadcast_194_piece0 stored as bytes in memory (estimated size 4.9 KB, free 260.8 MB)
18/02/28 13:40:14 INFO BlockManagerInfo: Added broadcast_194_piece0 in memory on 127.0.0.1:60941 (size: 4.9 KB, free: 266.6 MB)
18/02/28 13:40:14 INFO SparkContext: Created broadcast 194 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 188 (MapPartitionsRDD[480] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:14 INFO TaskSchedulerImpl: Adding task set 188.0 with 4 tasks
18/02/28 13:40:14 INFO TaskSetManager: Starting task 0.0 in stage 188.0 (TID 495, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 1.0 in stage 188.0 (TID 496, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 2.0 in stage 188.0 (TID 497, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 3.0 in stage 188.0 (TID 498, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:14 INFO Executor: Running task 1.0 in stage 188.0 (TID 496)
18/02/28 13:40:14 INFO Executor: Running task 3.0 in stage 188.0 (TID 498)
18/02/28 13:40:14 INFO Executor: Running task 0.0 in stage 188.0 (TID 495)
18/02/28 13:40:14 INFO Executor: Running task 2.0 in stage 188.0 (TID 497)
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_1 locally
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_0 locally
18/02/28 13:40:14 INFO Executor: Finished task 1.0 in stage 188.0 (TID 496). 1446 bytes result sent to driver
18/02/28 13:40:14 INFO Executor: Finished task 0.0 in stage 188.0 (TID 495). 1346 bytes result sent to driver
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_3 locally
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_2 locally
18/02/28 13:40:14 INFO TaskSetManager: Finished task 1.0 in stage 188.0 (TID 496) in 4 ms on localhost (executor driver) (1/4)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 0.0 in stage 188.0 (TID 495) in 5 ms on localhost (executor driver) (2/4)
18/02/28 13:40:14 INFO Executor: Finished task 3.0 in stage 188.0 (TID 498). 1553 bytes result sent to driver
18/02/28 13:40:14 INFO Executor: Finished task 2.0 in stage 188.0 (TID 497). 1565 bytes result sent to driver
18/02/28 13:40:14 INFO TaskSetManager: Finished task 3.0 in stage 188.0 (TID 498) in 5 ms on localhost (executor driver) (3/4)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 2.0 in stage 188.0 (TID 497) in 5 ms on localhost (executor driver) (4/4)
18/02/28 13:40:14 INFO TaskSchedulerImpl: Removed TaskSet 188.0, whose tasks have all completed, from pool 
18/02/28 13:40:14 INFO DAGScheduler: ResultStage 188 (collect at utils.scala:211) finished in 0.005 s
18/02/28 13:40:14 INFO DAGScheduler: Job 98 finished: collect at utils.scala:211, took 0.008458 s
18/02/28 13:40:14 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e0b7f59b4
18/02/28 13:40:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:40:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0b7f59b4` AS `zzz97`
WHERE (0 = 1)
18/02/28 13:40:14 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:40:14 INFO DAGScheduler: Got job 99 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:40:14 INFO DAGScheduler: Final stage: ResultStage 191 (collect at utils.scala:211)
18/02/28 13:40:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 190)
18/02/28 13:40:14 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:14 INFO DAGScheduler: Submitting ResultStage 191 (MapPartitionsRDD[483] at collect at utils.scala:211), which has no missing parents
18/02/28 13:40:14 INFO MemoryStore: Block broadcast_195 stored as values in memory (estimated size 10.3 KB, free 260.8 MB)
18/02/28 13:40:14 INFO MemoryStore: Block broadcast_195_piece0 stored as bytes in memory (estimated size 4.9 KB, free 260.8 MB)
18/02/28 13:40:14 INFO BlockManagerInfo: Added broadcast_195_piece0 in memory on 127.0.0.1:60941 (size: 4.9 KB, free: 266.6 MB)
18/02/28 13:40:14 INFO SparkContext: Created broadcast 195 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 191 (MapPartitionsRDD[483] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:40:14 INFO TaskSchedulerImpl: Adding task set 191.0 with 4 tasks
18/02/28 13:40:14 INFO TaskSetManager: Starting task 0.0 in stage 191.0 (TID 499, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 1.0 in stage 191.0 (TID 500, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 2.0 in stage 191.0 (TID 501, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 3.0 in stage 191.0 (TID 502, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:40:14 INFO Executor: Running task 1.0 in stage 191.0 (TID 500)
18/02/28 13:40:14 INFO Executor: Running task 2.0 in stage 191.0 (TID 501)
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_1 locally
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_2 locally
18/02/28 13:40:14 INFO Executor: Finished task 1.0 in stage 191.0 (TID 500). 1561 bytes result sent to driver
18/02/28 13:40:14 INFO Executor: Running task 3.0 in stage 191.0 (TID 502)
18/02/28 13:40:14 INFO Executor: Finished task 2.0 in stage 191.0 (TID 501). 1604 bytes result sent to driver
18/02/28 13:40:14 INFO Executor: Running task 0.0 in stage 191.0 (TID 499)
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_3 locally
18/02/28 13:40:14 INFO TaskSetManager: Finished task 1.0 in stage 191.0 (TID 500) in 4 ms on localhost (executor driver) (1/4)
18/02/28 13:40:14 INFO Executor: Finished task 3.0 in stage 191.0 (TID 502). 1467 bytes result sent to driver
18/02/28 13:40:14 INFO TaskSetManager: Finished task 2.0 in stage 191.0 (TID 501) in 4 ms on localhost (executor driver) (2/4)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 3.0 in stage 191.0 (TID 502) in 4 ms on localhost (executor driver) (3/4)
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_0 locally
18/02/28 13:40:14 INFO Executor: Finished task 0.0 in stage 191.0 (TID 499). 1628 bytes result sent to driver
18/02/28 13:40:14 INFO TaskSetManager: Finished task 0.0 in stage 191.0 (TID 499) in 6 ms on localhost (executor driver) (4/4)
18/02/28 13:40:14 INFO TaskSchedulerImpl: Removed TaskSet 191.0, whose tasks have all completed, from pool 
18/02/28 13:40:14 INFO DAGScheduler: ResultStage 191 (collect at utils.scala:211) finished in 0.006 s
18/02/28 13:40:14 INFO DAGScheduler: Job 99 finished: collect at utils.scala:211, took 0.009699 s
18/02/28 13:40:14 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:40:14 INFO DAGScheduler: Got job 100 (collect at utils.scala:211) with 6 output partitions
18/02/28 13:40:14 INFO DAGScheduler: Final stage: ResultStage 194 (collect at utils.scala:211)
18/02/28 13:40:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 193)
18/02/28 13:40:14 INFO DAGScheduler: Missing parents: List()
18/02/28 13:40:14 INFO DAGScheduler: Submitting ResultStage 194 (MapPartitionsRDD[486] at collect at utils.scala:211), which has no missing parents
18/02/28 13:40:14 INFO MemoryStore: Block broadcast_196 stored as values in memory (estimated size 11.2 KB, free 260.8 MB)
18/02/28 13:40:14 INFO MemoryStore: Block broadcast_196_piece0 stored as bytes in memory (estimated size 5.4 KB, free 260.8 MB)
18/02/28 13:40:14 INFO BlockManagerInfo: Added broadcast_196_piece0 in memory on 127.0.0.1:60941 (size: 5.4 KB, free: 266.5 MB)
18/02/28 13:40:14 INFO SparkContext: Created broadcast 196 from broadcast at DAGScheduler.scala:1006
18/02/28 13:40:14 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 194 (MapPartitionsRDD[486] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
18/02/28 13:40:14 INFO TaskSchedulerImpl: Adding task set 194.0 with 6 tasks
18/02/28 13:40:14 INFO TaskSetManager: Starting task 1.0 in stage 194.0 (TID 503, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 2.0 in stage 194.0 (TID 504, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 3.0 in stage 194.0 (TID 505, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:40:14 INFO TaskSetManager: Starting task 4.0 in stage 194.0 (TID 506, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:40:14 INFO Executor: Running task 1.0 in stage 194.0 (TID 503)
18/02/28 13:40:14 INFO Executor: Running task 3.0 in stage 194.0 (TID 505)
18/02/28 13:40:14 INFO Executor: Running task 4.0 in stage 194.0 (TID 506)
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_3 locally
18/02/28 13:40:14 INFO Executor: Finished task 4.0 in stage 194.0 (TID 506). 1458 bytes result sent to driver
18/02/28 13:40:14 INFO TaskSetManager: Starting task 0.0 in stage 194.0 (TID 507, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_0 locally
18/02/28 13:40:14 INFO Executor: Running task 2.0 in stage 194.0 (TID 504)
18/02/28 13:40:14 INFO Executor: Finished task 1.0 in stage 194.0 (TID 503). 1398 bytes result sent to driver
18/02/28 13:40:14 INFO Executor: Running task 0.0 in stage 194.0 (TID 507)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 4.0 in stage 194.0 (TID 506) in 6 ms on localhost (executor driver) (1/6)
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_2 locally
18/02/28 13:40:14 INFO Executor: Finished task 3.0 in stage 194.0 (TID 505). 1584 bytes result sent to driver
18/02/28 13:40:14 INFO TaskSetManager: Starting task 5.0 in stage 194.0 (TID 508, localhost, executor driver, partition 5, PROCESS_LOCAL, 5058 bytes)
18/02/28 13:40:14 INFO BlockManager: Found block rdd_424_1 locally
18/02/28 13:40:14 INFO Executor: Finished task 2.0 in stage 194.0 (TID 504). 1443 bytes result sent to driver
18/02/28 13:40:14 INFO Executor: Finished task 0.0 in stage 194.0 (TID 507). 999 bytes result sent to driver
18/02/28 13:40:14 INFO Executor: Running task 5.0 in stage 194.0 (TID 508)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 1.0 in stage 194.0 (TID 503) in 9 ms on localhost (executor driver) (2/6)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 3.0 in stage 194.0 (TID 505) in 9 ms on localhost (executor driver) (3/6)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 2.0 in stage 194.0 (TID 504) in 9 ms on localhost (executor driver) (4/6)
18/02/28 13:40:14 INFO Executor: Finished task 5.0 in stage 194.0 (TID 508). 1050 bytes result sent to driver
18/02/28 13:40:14 INFO TaskSetManager: Finished task 0.0 in stage 194.0 (TID 507) in 8 ms on localhost (executor driver) (5/6)
18/02/28 13:40:14 INFO TaskSetManager: Finished task 5.0 in stage 194.0 (TID 508) in 4 ms on localhost (executor driver) (6/6)
18/02/28 13:40:14 INFO DAGScheduler: ResultStage 194 (collect at utils.scala:211) finished in 0.011 s
18/02/28 13:40:14 INFO DAGScheduler: Job 100 finished: collect at utils.scala:211, took 0.015243 s
18/02/28 13:40:14 INFO TaskSchedulerImpl: Removed TaskSet 194.0, whose tasks have all completed, from pool 
18/02/28 13:40:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:40:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 13:40:14 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e0164875bf
18/02/28 13:40:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:40:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0164875bf` AS `zzz98`
WHERE (0 = 1)
18/02/28 13:40:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:40:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0164875bf`
18/02/28 13:41:43 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:41:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e06a7c602`
18/02/28 13:41:44 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e0d1f4768
18/02/28 13:41:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:41:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0d1f4768` AS `zzz99`
WHERE (0 = 1)
18/02/28 13:41:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:41:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0d1f4768`
18/02/28 13:41:44 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e065b62d27
18/02/28 13:41:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:41:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e065b62d27` AS `zzz100`
WHERE (0 = 1)
18/02/28 13:42:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:42:00 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e065b62d27`
LIMIT 6
18/02/28 13:42:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:42:00 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e065b62d27`
LIMIT 6
18/02/28 13:42:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:42:00 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e065b62d27`
LIMIT 6
18/02/28 13:42:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:42:00 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e065b62d27`
LIMIT 6
18/02/28 13:42:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:42:00 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e065b62d27`
LIMIT 6
18/02/28 13:42:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:42:00 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e065b62d27`
LIMIT 6
18/02/28 13:42:00 INFO BlockManagerInfo: Removed broadcast_188_piece0 on 127.0.0.1:60941 in memory (size: 5.3 KB, free: 266.6 MB)
18/02/28 13:42:00 INFO BlockManagerInfo: Removed broadcast_193_piece0 on 127.0.0.1:60941 in memory (size: 5.3 KB, free: 266.6 MB)
18/02/28 13:42:00 INFO BlockManagerInfo: Removed broadcast_192_piece0 on 127.0.0.1:60941 in memory (size: 4.9 KB, free: 266.6 MB)
18/02/28 13:42:00 INFO BlockManagerInfo: Removed broadcast_185_piece0 on 127.0.0.1:60941 in memory (size: 4.9 KB, free: 266.6 MB)
18/02/28 13:42:00 INFO CodeGenerator: Code generated in 60.852508 ms
18/02/28 13:42:00 INFO BlockManagerInfo: Removed broadcast_191_piece0 on 127.0.0.1:60941 in memory (size: 5.4 KB, free: 266.6 MB)
18/02/28 13:42:00 INFO BlockManagerInfo: Removed broadcast_195_piece0 on 127.0.0.1:60941 in memory (size: 4.9 KB, free: 266.6 MB)
18/02/28 13:42:00 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:42:00 INFO BlockManagerInfo: Removed broadcast_196_piece0 on 127.0.0.1:60941 in memory (size: 5.4 KB, free: 266.6 MB)
18/02/28 13:42:00 INFO DAGScheduler: Got job 101 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:42:00 INFO DAGScheduler: Final stage: ResultStage 195 (collect at utils.scala:211)
18/02/28 13:42:00 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:42:00 INFO DAGScheduler: Missing parents: List()
18/02/28 13:42:00 INFO DAGScheduler: Submitting ResultStage 195 (MapPartitionsRDD[489] at collect at utils.scala:211), which has no missing parents
18/02/28 13:42:00 INFO BlockManagerInfo: Removed broadcast_194_piece0 on 127.0.0.1:60941 in memory (size: 4.9 KB, free: 266.6 MB)
18/02/28 13:42:00 INFO BlockManagerInfo: Removed broadcast_187_piece0 on 127.0.0.1:60941 in memory (size: 4.9 KB, free: 266.6 MB)
18/02/28 13:42:00 INFO BlockManagerInfo: Removed broadcast_189_piece0 on 127.0.0.1:60941 in memory (size: 4.9 KB, free: 266.6 MB)
18/02/28 13:42:00 INFO MemoryStore: Block broadcast_197 stored as values in memory (estimated size 159.2 KB, free 260.8 MB)
18/02/28 13:42:00 INFO BlockManagerInfo: Removed broadcast_186_piece0 on 127.0.0.1:60941 in memory (size: 5.4 KB, free: 266.6 MB)
18/02/28 13:42:00 INFO MemoryStore: Block broadcast_197_piece0 stored as bytes in memory (estimated size 44.5 KB, free 260.8 MB)
18/02/28 13:42:00 INFO BlockManagerInfo: Added broadcast_197_piece0 in memory on 127.0.0.1:60941 (size: 44.5 KB, free: 266.6 MB)
18/02/28 13:42:00 INFO BlockManagerInfo: Removed broadcast_190_piece0 on 127.0.0.1:60941 in memory (size: 4.9 KB, free: 266.6 MB)
18/02/28 13:42:00 INFO SparkContext: Created broadcast 197 from broadcast at DAGScheduler.scala:1006
18/02/28 13:42:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 195 (MapPartitionsRDD[489] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:42:00 INFO TaskSchedulerImpl: Adding task set 195.0 with 1 tasks
18/02/28 13:42:00 INFO TaskSetManager: Starting task 0.0 in stage 195.0 (TID 509, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:42:00 INFO Executor: Running task 0.0 in stage 195.0 (TID 509)
18/02/28 13:42:00 INFO BlockManager: Found block rdd_328_0 locally
18/02/28 13:42:00 INFO Executor: Finished task 0.0 in stage 195.0 (TID 509). 2409 bytes result sent to driver
18/02/28 13:42:00 INFO TaskSetManager: Finished task 0.0 in stage 195.0 (TID 509) in 298 ms on localhost (executor driver) (1/1)
18/02/28 13:42:00 INFO DAGScheduler: ResultStage 195 (collect at utils.scala:211) finished in 0.298 s
18/02/28 13:42:00 INFO DAGScheduler: Job 101 finished: collect at utils.scala:211, took 0.302819 s
18/02/28 13:42:00 INFO CodeGenerator: Code generated in 6.898597 ms
18/02/28 13:42:00 INFO TaskSchedulerImpl: Removed TaskSet 195.0, whose tasks have all completed, from pool 
18/02/28 13:43:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:43:32 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_30e065b62d27`
GROUP BY `delayed`, `prediction`
18/02/28 13:43:32 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:43:32 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:43:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:43:32 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_30e065b62d27`
GROUP BY `delayed`, `prediction`
18/02/28 13:43:32 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:43:32 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:43:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:43:32 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_30e065b62d27`
GROUP BY `delayed`, `prediction`
18/02/28 13:43:32 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:43:32 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:43:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:43:32 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_30e065b62d27`
GROUP BY `delayed`, `prediction`
18/02/28 13:43:32 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:43:32 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:43:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:43:32 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_30e065b62d27`
GROUP BY `delayed`, `prediction`
18/02/28 13:43:32 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:43:32 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:43:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:43:32 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_30e065b62d27`
GROUP BY `delayed`, `prediction`
LIMIT 1000
18/02/28 13:43:32 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:43:32 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:43:32 INFO CodeGenerator: Code generated in 13.509811 ms
18/02/28 13:43:32 INFO CodeGenerator: Code generated in 30.783454 ms
18/02/28 13:43:32 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:43:32 INFO DAGScheduler: Registering RDD 492 (collect at utils.scala:211)
18/02/28 13:43:32 INFO DAGScheduler: Got job 102 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:43:32 INFO DAGScheduler: Final stage: ResultStage 197 (collect at utils.scala:211)
18/02/28 13:43:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 196)
18/02/28 13:43:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 196)
18/02/28 13:43:32 INFO DAGScheduler: Submitting ShuffleMapStage 196 (MapPartitionsRDD[492] at collect at utils.scala:211), which has no missing parents
18/02/28 13:43:32 INFO MemoryStore: Block broadcast_198 stored as values in memory (estimated size 79.1 KB, free 260.7 MB)
18/02/28 13:43:32 INFO MemoryStore: Block broadcast_198_piece0 stored as bytes in memory (estimated size 32.3 KB, free 260.7 MB)
18/02/28 13:43:32 INFO BlockManagerInfo: Added broadcast_198_piece0 in memory on 127.0.0.1:60941 (size: 32.3 KB, free: 266.5 MB)
18/02/28 13:43:32 INFO SparkContext: Created broadcast 198 from broadcast at DAGScheduler.scala:1006
18/02/28 13:43:32 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 196 (MapPartitionsRDD[492] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:43:32 INFO TaskSchedulerImpl: Adding task set 196.0 with 4 tasks
18/02/28 13:43:32 INFO TaskSetManager: Starting task 0.0 in stage 196.0 (TID 510, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:43:32 INFO TaskSetManager: Starting task 1.0 in stage 196.0 (TID 511, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:43:32 INFO TaskSetManager: Starting task 2.0 in stage 196.0 (TID 512, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:43:32 INFO TaskSetManager: Starting task 3.0 in stage 196.0 (TID 513, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:43:32 INFO Executor: Running task 0.0 in stage 196.0 (TID 510)
18/02/28 13:43:32 INFO Executor: Running task 1.0 in stage 196.0 (TID 511)
18/02/28 13:43:32 INFO Executor: Running task 3.0 in stage 196.0 (TID 513)
18/02/28 13:43:32 INFO Executor: Running task 2.0 in stage 196.0 (TID 512)
18/02/28 13:43:32 INFO BlockManager: Found block rdd_328_1 locally
18/02/28 13:43:32 INFO BlockManager: Found block rdd_328_2 locally
18/02/28 13:43:32 INFO BlockManager: Found block rdd_328_0 locally
18/02/28 13:43:32 INFO BlockManager: Found block rdd_328_3 locally
18/02/28 13:43:32 INFO CodeGenerator: Code generated in 6.858398 ms
18/02/28 13:43:33 INFO BlockManagerInfo: Removed broadcast_197_piece0 on 127.0.0.1:60941 in memory (size: 44.5 KB, free: 266.6 MB)
18/02/28 13:43:33 INFO ContextCleaner: Cleaned accumulator 4668
18/02/28 13:43:33 INFO Executor: Finished task 1.0 in stage 196.0 (TID 511). 2454 bytes result sent to driver
18/02/28 13:43:33 INFO TaskSetManager: Finished task 1.0 in stage 196.0 (TID 511) in 694 ms on localhost (executor driver) (1/4)
18/02/28 13:43:33 INFO Executor: Finished task 3.0 in stage 196.0 (TID 513). 2411 bytes result sent to driver
18/02/28 13:43:33 INFO TaskSetManager: Finished task 3.0 in stage 196.0 (TID 513) in 697 ms on localhost (executor driver) (2/4)
18/02/28 13:43:33 INFO Executor: Finished task 0.0 in stage 196.0 (TID 510). 2411 bytes result sent to driver
18/02/28 13:43:33 INFO TaskSetManager: Finished task 0.0 in stage 196.0 (TID 510) in 706 ms on localhost (executor driver) (3/4)
18/02/28 13:43:33 INFO Executor: Finished task 2.0 in stage 196.0 (TID 512). 2454 bytes result sent to driver
18/02/28 13:43:33 INFO TaskSetManager: Finished task 2.0 in stage 196.0 (TID 512) in 710 ms on localhost (executor driver) (4/4)
18/02/28 13:43:33 INFO DAGScheduler: ShuffleMapStage 196 (collect at utils.scala:211) finished in 0.710 s
18/02/28 13:43:33 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:43:33 INFO DAGScheduler: running: Set()
18/02/28 13:43:33 INFO DAGScheduler: waiting: Set(ResultStage 197)
18/02/28 13:43:33 INFO DAGScheduler: failed: Set()
18/02/28 13:43:33 INFO DAGScheduler: Submitting ResultStage 197 (MapPartitionsRDD[495] at collect at utils.scala:211), which has no missing parents
18/02/28 13:43:33 INFO MemoryStore: Block broadcast_199 stored as values in memory (estimated size 38.1 KB, free 260.8 MB)
18/02/28 13:43:33 INFO MemoryStore: Block broadcast_199_piece0 stored as bytes in memory (estimated size 17.9 KB, free 260.8 MB)
18/02/28 13:43:33 INFO TaskSchedulerImpl: Removed TaskSet 196.0, whose tasks have all completed, from pool 
18/02/28 13:43:33 INFO BlockManagerInfo: Added broadcast_199_piece0 in memory on 127.0.0.1:60941 (size: 17.9 KB, free: 266.6 MB)
18/02/28 13:43:33 INFO SparkContext: Created broadcast 199 from broadcast at DAGScheduler.scala:1006
18/02/28 13:43:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 197 (MapPartitionsRDD[495] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:43:33 INFO TaskSchedulerImpl: Adding task set 197.0 with 1 tasks
18/02/28 13:43:33 INFO TaskSetManager: Starting task 0.0 in stage 197.0 (TID 514, localhost, executor driver, partition 0, PROCESS_LOCAL, 4726 bytes)
18/02/28 13:43:33 INFO Executor: Running task 0.0 in stage 197.0 (TID 514)
18/02/28 13:43:33 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 13:43:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:43:33 INFO Executor: Finished task 0.0 in stage 197.0 (TID 514). 2577 bytes result sent to driver
18/02/28 13:43:33 INFO TaskSetManager: Finished task 0.0 in stage 197.0 (TID 514) in 7 ms on localhost (executor driver) (1/1)
18/02/28 13:43:33 INFO DAGScheduler: ResultStage 197 (collect at utils.scala:211) finished in 0.007 s
18/02/28 13:43:33 INFO DAGScheduler: Job 102 finished: collect at utils.scala:211, took 0.726370 s
18/02/28 13:43:33 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:43:33 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 57 is 158 bytes
18/02/28 13:43:33 INFO DAGScheduler: Got job 103 (collect at utils.scala:211) with 3 output partitions
18/02/28 13:43:33 INFO DAGScheduler: Final stage: ResultStage 199 (collect at utils.scala:211)
18/02/28 13:43:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 198)
18/02/28 13:43:33 INFO DAGScheduler: Missing parents: List()
18/02/28 13:43:33 INFO DAGScheduler: Submitting ResultStage 199 (MapPartitionsRDD[495] at collect at utils.scala:211), which has no missing parents
18/02/28 13:43:33 INFO MemoryStore: Block broadcast_200 stored as values in memory (estimated size 38.1 KB, free 260.8 MB)
18/02/28 13:43:33 INFO MemoryStore: Block broadcast_200_piece0 stored as bytes in memory (estimated size 17.9 KB, free 260.8 MB)
18/02/28 13:43:33 INFO TaskSchedulerImpl: Removed TaskSet 197.0, whose tasks have all completed, from pool 
18/02/28 13:43:33 INFO BlockManagerInfo: Added broadcast_200_piece0 in memory on 127.0.0.1:60941 (size: 17.9 KB, free: 266.5 MB)
18/02/28 13:43:33 INFO SparkContext: Created broadcast 200 from broadcast at DAGScheduler.scala:1006
18/02/28 13:43:33 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 199 (MapPartitionsRDD[495] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(1, 2, 3))
18/02/28 13:43:33 INFO TaskSchedulerImpl: Adding task set 199.0 with 3 tasks
18/02/28 13:43:33 INFO TaskSetManager: Starting task 2.0 in stage 199.0 (TID 515, localhost, executor driver, partition 3, PROCESS_LOCAL, 4726 bytes)
18/02/28 13:43:33 INFO TaskSetManager: Starting task 0.0 in stage 199.0 (TID 516, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 13:43:33 INFO TaskSetManager: Starting task 1.0 in stage 199.0 (TID 517, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 13:43:33 INFO Executor: Running task 2.0 in stage 199.0 (TID 515)
18/02/28 13:43:33 INFO Executor: Running task 0.0 in stage 199.0 (TID 516)
18/02/28 13:43:33 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:43:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:43:33 INFO Executor: Running task 1.0 in stage 199.0 (TID 517)
18/02/28 13:43:33 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:43:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:43:33 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 13:43:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:43:33 INFO Executor: Finished task 1.0 in stage 199.0 (TID 517). 2666 bytes result sent to driver
18/02/28 13:43:33 INFO Executor: Finished task 0.0 in stage 199.0 (TID 516). 2597 bytes result sent to driver
18/02/28 13:43:33 INFO Executor: Finished task 2.0 in stage 199.0 (TID 515). 2577 bytes result sent to driver
18/02/28 13:43:33 INFO TaskSetManager: Finished task 1.0 in stage 199.0 (TID 517) in 14 ms on localhost (executor driver) (1/3)
18/02/28 13:43:33 INFO TaskSetManager: Finished task 0.0 in stage 199.0 (TID 516) in 16 ms on localhost (executor driver) (2/3)
18/02/28 13:43:33 INFO TaskSetManager: Finished task 2.0 in stage 199.0 (TID 515) in 16 ms on localhost (executor driver) (3/3)
18/02/28 13:43:33 INFO TaskSchedulerImpl: Removed TaskSet 199.0, whose tasks have all completed, from pool 
18/02/28 13:43:33 INFO DAGScheduler: ResultStage 199 (collect at utils.scala:211) finished in 0.016 s
18/02/28 13:43:33 INFO DAGScheduler: Job 103 finished: collect at utils.scala:211, took 0.020501 s
18/02/28 13:45:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:45:12 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_30e065b62d27`
GROUP BY `delayed`, `prediction`
18/02/28 13:45:12 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:45:12 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:45:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:45:17 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_30e065b62d27`
GROUP BY `delayed`, `prediction`
18/02/28 13:45:17 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:45:17 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:45:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:45:17 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_30e065b62d27`
GROUP BY `delayed`, `prediction`
18/02/28 13:45:17 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:45:17 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:45:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:45:17 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_30e065b62d27`
GROUP BY `delayed`, `prediction`
18/02/28 13:45:17 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:45:17 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:45:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:45:17 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_30e065b62d27`
GROUP BY `delayed`, `prediction`
18/02/28 13:45:17 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:45:17 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:45:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:45:17 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_30e065b62d27`
GROUP BY `delayed`, `prediction`
18/02/28 13:45:17 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:45:17 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:45:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:45:18 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_30e065b62d27`
GROUP BY `delayed`, `prediction`
LIMIT 1000
18/02/28 13:45:18 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:45:18 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:45:18 INFO ContextCleaner: Cleaned accumulator 4758
18/02/28 13:45:18 INFO BlockManagerInfo: Removed broadcast_200_piece0 on 127.0.0.1:60941 in memory (size: 17.9 KB, free: 266.6 MB)
18/02/28 13:45:18 INFO BlockManagerInfo: Removed broadcast_199_piece0 on 127.0.0.1:60941 in memory (size: 17.9 KB, free: 266.6 MB)
18/02/28 13:45:18 INFO BlockManagerInfo: Removed broadcast_198_piece0 on 127.0.0.1:60941 in memory (size: 32.3 KB, free: 266.6 MB)
18/02/28 13:45:18 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:45:18 INFO DAGScheduler: Registering RDD 498 (collect at utils.scala:211)
18/02/28 13:45:18 INFO DAGScheduler: Got job 104 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:45:18 INFO DAGScheduler: Final stage: ResultStage 201 (collect at utils.scala:211)
18/02/28 13:45:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 200)
18/02/28 13:45:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 200)
18/02/28 13:45:18 INFO DAGScheduler: Submitting ShuffleMapStage 200 (MapPartitionsRDD[498] at collect at utils.scala:211), which has no missing parents
18/02/28 13:45:18 INFO MemoryStore: Block broadcast_201 stored as values in memory (estimated size 79.1 KB, free 260.9 MB)
18/02/28 13:45:18 INFO MemoryStore: Block broadcast_201_piece0 stored as bytes in memory (estimated size 32.2 KB, free 260.9 MB)
18/02/28 13:45:18 INFO BlockManagerInfo: Added broadcast_201_piece0 in memory on 127.0.0.1:60941 (size: 32.2 KB, free: 266.6 MB)
18/02/28 13:45:18 INFO SparkContext: Created broadcast 201 from broadcast at DAGScheduler.scala:1006
18/02/28 13:45:18 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 200 (MapPartitionsRDD[498] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:45:18 INFO TaskSchedulerImpl: Adding task set 200.0 with 4 tasks
18/02/28 13:45:18 INFO TaskSetManager: Starting task 0.0 in stage 200.0 (TID 518, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:45:18 INFO TaskSetManager: Starting task 1.0 in stage 200.0 (TID 519, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:45:18 INFO TaskSetManager: Starting task 2.0 in stage 200.0 (TID 520, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:45:18 INFO TaskSetManager: Starting task 3.0 in stage 200.0 (TID 521, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:45:18 INFO Executor: Running task 1.0 in stage 200.0 (TID 519)
18/02/28 13:45:18 INFO Executor: Running task 0.0 in stage 200.0 (TID 518)
18/02/28 13:45:18 INFO Executor: Running task 2.0 in stage 200.0 (TID 520)
18/02/28 13:45:18 INFO Executor: Running task 3.0 in stage 200.0 (TID 521)
18/02/28 13:45:18 INFO BlockManager: Found block rdd_328_0 locally
18/02/28 13:45:18 INFO BlockManager: Found block rdd_328_2 locally
18/02/28 13:45:18 INFO BlockManager: Found block rdd_328_3 locally
18/02/28 13:45:18 INFO BlockManager: Found block rdd_328_1 locally
18/02/28 13:45:18 INFO Executor: Finished task 2.0 in stage 200.0 (TID 520). 2368 bytes result sent to driver
18/02/28 13:45:18 INFO TaskSetManager: Finished task 2.0 in stage 200.0 (TID 520) in 345 ms on localhost (executor driver) (1/4)
18/02/28 13:45:18 INFO Executor: Finished task 3.0 in stage 200.0 (TID 521). 2411 bytes result sent to driver
18/02/28 13:45:18 INFO TaskSetManager: Finished task 3.0 in stage 200.0 (TID 521) in 439 ms on localhost (executor driver) (2/4)
18/02/28 13:45:18 INFO Executor: Finished task 0.0 in stage 200.0 (TID 518). 2411 bytes result sent to driver
18/02/28 13:45:18 INFO TaskSetManager: Finished task 0.0 in stage 200.0 (TID 518) in 442 ms on localhost (executor driver) (3/4)
18/02/28 13:45:18 INFO Executor: Finished task 1.0 in stage 200.0 (TID 519). 2411 bytes result sent to driver
18/02/28 13:45:18 INFO TaskSetManager: Finished task 1.0 in stage 200.0 (TID 519) in 448 ms on localhost (executor driver) (4/4)
18/02/28 13:45:18 INFO DAGScheduler: ShuffleMapStage 200 (collect at utils.scala:211) finished in 0.448 s
18/02/28 13:45:18 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:45:18 INFO DAGScheduler: running: Set()
18/02/28 13:45:18 INFO DAGScheduler: waiting: Set(ResultStage 201)
18/02/28 13:45:18 INFO DAGScheduler: failed: Set()
18/02/28 13:45:18 INFO DAGScheduler: Submitting ResultStage 201 (MapPartitionsRDD[501] at collect at utils.scala:211), which has no missing parents
18/02/28 13:45:18 INFO TaskSchedulerImpl: Removed TaskSet 200.0, whose tasks have all completed, from pool 
18/02/28 13:45:18 INFO MemoryStore: Block broadcast_202 stored as values in memory (estimated size 38.1 KB, free 260.8 MB)
18/02/28 13:45:18 INFO MemoryStore: Block broadcast_202_piece0 stored as bytes in memory (estimated size 17.9 KB, free 260.8 MB)
18/02/28 13:45:18 INFO BlockManagerInfo: Added broadcast_202_piece0 in memory on 127.0.0.1:60941 (size: 17.9 KB, free: 266.6 MB)
18/02/28 13:45:18 INFO SparkContext: Created broadcast 202 from broadcast at DAGScheduler.scala:1006
18/02/28 13:45:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 201 (MapPartitionsRDD[501] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:45:18 INFO TaskSchedulerImpl: Adding task set 201.0 with 1 tasks
18/02/28 13:45:18 INFO TaskSetManager: Starting task 0.0 in stage 201.0 (TID 522, localhost, executor driver, partition 0, PROCESS_LOCAL, 4726 bytes)
18/02/28 13:45:18 INFO Executor: Running task 0.0 in stage 201.0 (TID 522)
18/02/28 13:45:18 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 13:45:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:45:18 INFO Executor: Finished task 0.0 in stage 201.0 (TID 522). 2577 bytes result sent to driver
18/02/28 13:45:18 INFO TaskSetManager: Finished task 0.0 in stage 201.0 (TID 522) in 4 ms on localhost (executor driver) (1/1)
18/02/28 13:45:18 INFO TaskSchedulerImpl: Removed TaskSet 201.0, whose tasks have all completed, from pool 
18/02/28 13:45:18 INFO DAGScheduler: ResultStage 201 (collect at utils.scala:211) finished in 0.004 s
18/02/28 13:45:18 INFO DAGScheduler: Job 104 finished: collect at utils.scala:211, took 0.461298 s
18/02/28 13:45:18 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:45:18 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 58 is 158 bytes
18/02/28 13:45:18 INFO DAGScheduler: Got job 105 (collect at utils.scala:211) with 3 output partitions
18/02/28 13:45:18 INFO DAGScheduler: Final stage: ResultStage 203 (collect at utils.scala:211)
18/02/28 13:45:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 202)
18/02/28 13:45:18 INFO DAGScheduler: Missing parents: List()
18/02/28 13:45:18 INFO DAGScheduler: Submitting ResultStage 203 (MapPartitionsRDD[501] at collect at utils.scala:211), which has no missing parents
18/02/28 13:45:18 INFO MemoryStore: Block broadcast_203 stored as values in memory (estimated size 38.1 KB, free 260.8 MB)
18/02/28 13:45:18 INFO MemoryStore: Block broadcast_203_piece0 stored as bytes in memory (estimated size 17.9 KB, free 260.8 MB)
18/02/28 13:45:18 INFO BlockManagerInfo: Added broadcast_203_piece0 in memory on 127.0.0.1:60941 (size: 17.9 KB, free: 266.5 MB)
18/02/28 13:45:18 INFO SparkContext: Created broadcast 203 from broadcast at DAGScheduler.scala:1006
18/02/28 13:45:18 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 203 (MapPartitionsRDD[501] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(1, 2, 3))
18/02/28 13:45:18 INFO TaskSchedulerImpl: Adding task set 203.0 with 3 tasks
18/02/28 13:45:18 INFO TaskSetManager: Starting task 2.0 in stage 203.0 (TID 523, localhost, executor driver, partition 3, PROCESS_LOCAL, 4726 bytes)
18/02/28 13:45:18 INFO TaskSetManager: Starting task 0.0 in stage 203.0 (TID 524, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 13:45:18 INFO TaskSetManager: Starting task 1.0 in stage 203.0 (TID 525, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 13:45:18 INFO Executor: Running task 2.0 in stage 203.0 (TID 523)
18/02/28 13:45:18 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 13:45:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:45:18 INFO Executor: Finished task 2.0 in stage 203.0 (TID 523). 2620 bytes result sent to driver
18/02/28 13:45:18 INFO Executor: Running task 0.0 in stage 203.0 (TID 524)
18/02/28 13:45:18 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:45:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:45:18 INFO Executor: Finished task 0.0 in stage 203.0 (TID 524). 2597 bytes result sent to driver
18/02/28 13:45:18 INFO Executor: Running task 1.0 in stage 203.0 (TID 525)
18/02/28 13:45:18 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:45:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:45:18 INFO Executor: Finished task 1.0 in stage 203.0 (TID 525). 2623 bytes result sent to driver
18/02/28 13:45:18 INFO TaskSetManager: Finished task 2.0 in stage 203.0 (TID 523) in 18 ms on localhost (executor driver) (1/3)
18/02/28 13:45:18 INFO TaskSetManager: Finished task 1.0 in stage 203.0 (TID 525) in 17 ms on localhost (executor driver) (2/3)
18/02/28 13:45:18 INFO TaskSetManager: Finished task 0.0 in stage 203.0 (TID 524) in 17 ms on localhost (executor driver) (3/3)
18/02/28 13:45:18 INFO DAGScheduler: ResultStage 203 (collect at utils.scala:211) finished in 0.019 s
18/02/28 13:45:18 INFO DAGScheduler: Job 105 finished: collect at utils.scala:211, took 0.023015 s
18/02/28 13:45:18 INFO TaskSchedulerImpl: Removed TaskSet 203.0, whose tasks have all completed, from pool 
18/02/28 13:45:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:45:34 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_30e065b62d27`
GROUP BY `delayed`, `prediction`
18/02/28 13:45:34 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:45:34 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:45:34 INFO CodeGenerator: Code generated in 6.551269 ms
18/02/28 13:45:34 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
18/02/28 13:45:34 INFO CodeGenerator: Code generated in 8.931433 ms
18/02/28 13:45:34 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
18/02/28 13:45:34 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
18/02/28 13:45:34 INFO CodeGenerator: Code generated in 13.374406 ms
18/02/28 13:45:34 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
18/02/28 13:45:34 INFO CodeGenerator: Code generated in 26.463545 ms
18/02/28 13:45:34 INFO CodeGenerator: Code generated in 9.64513 ms
18/02/28 13:45:34 INFO SparkContext: Starting job: pivot at <unknown>:0
18/02/28 13:45:34 INFO DAGScheduler: Registering RDD 504 (pivot at <unknown>:0)
18/02/28 13:45:34 INFO DAGScheduler: Registering RDD 507 (pivot at <unknown>:0)
18/02/28 13:45:34 INFO DAGScheduler: Got job 106 (pivot at <unknown>:0) with 4 output partitions
18/02/28 13:45:34 INFO DAGScheduler: Final stage: ResultStage 206 (pivot at <unknown>:0)
18/02/28 13:45:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 205)
18/02/28 13:45:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 205)
18/02/28 13:45:34 INFO DAGScheduler: Submitting ShuffleMapStage 204 (MapPartitionsRDD[504] at pivot at <unknown>:0), which has no missing parents
18/02/28 13:45:34 INFO MemoryStore: Block broadcast_204 stored as values in memory (estimated size 73.5 KB, free 260.7 MB)
18/02/28 13:45:34 INFO MemoryStore: Block broadcast_204_piece0 stored as bytes in memory (estimated size 29.9 KB, free 260.7 MB)
18/02/28 13:45:34 INFO BlockManagerInfo: Added broadcast_204_piece0 in memory on 127.0.0.1:60941 (size: 29.9 KB, free: 266.5 MB)
18/02/28 13:45:34 INFO SparkContext: Created broadcast 204 from broadcast at DAGScheduler.scala:1006
18/02/28 13:45:34 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 204 (MapPartitionsRDD[504] at pivot at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:45:34 INFO TaskSchedulerImpl: Adding task set 204.0 with 4 tasks
18/02/28 13:45:34 INFO TaskSetManager: Starting task 0.0 in stage 204.0 (TID 526, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:45:34 INFO TaskSetManager: Starting task 1.0 in stage 204.0 (TID 527, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:45:34 INFO TaskSetManager: Starting task 2.0 in stage 204.0 (TID 528, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:45:34 INFO TaskSetManager: Starting task 3.0 in stage 204.0 (TID 529, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:45:34 INFO Executor: Running task 0.0 in stage 204.0 (TID 526)
18/02/28 13:45:34 INFO Executor: Running task 1.0 in stage 204.0 (TID 527)
18/02/28 13:45:34 INFO Executor: Running task 3.0 in stage 204.0 (TID 529)
18/02/28 13:45:34 INFO Executor: Running task 2.0 in stage 204.0 (TID 528)
18/02/28 13:45:34 INFO BlockManager: Found block rdd_328_3 locally
18/02/28 13:45:34 INFO BlockManager: Found block rdd_328_0 locally
18/02/28 13:45:34 INFO BlockManager: Found block rdd_328_2 locally
18/02/28 13:45:34 INFO BlockManager: Found block rdd_328_1 locally
18/02/28 13:45:34 INFO BlockManagerInfo: Removed broadcast_203_piece0 on 127.0.0.1:60941 in memory (size: 17.9 KB, free: 266.5 MB)
18/02/28 13:45:34 INFO ContextCleaner: Cleaned accumulator 4849
18/02/28 13:45:34 INFO ContextCleaner: Cleaned accumulator 4854
18/02/28 13:45:34 INFO ContextCleaner: Cleaned accumulator 4856
18/02/28 13:45:34 INFO ContextCleaner: Cleaned accumulator 4848
18/02/28 13:45:34 INFO BlockManagerInfo: Removed broadcast_201_piece0 on 127.0.0.1:60941 in memory (size: 32.2 KB, free: 266.6 MB)
18/02/28 13:45:34 INFO ContextCleaner: Cleaned accumulator 4858
18/02/28 13:45:34 INFO BlockManagerInfo: Removed broadcast_202_piece0 on 127.0.0.1:60941 in memory (size: 17.9 KB, free: 266.6 MB)
18/02/28 13:45:34 INFO ContextCleaner: Cleaned accumulator 4850
18/02/28 13:45:34 INFO Executor: Finished task 2.0 in stage 204.0 (TID 528). 2411 bytes result sent to driver
18/02/28 13:45:34 INFO TaskSetManager: Finished task 2.0 in stage 204.0 (TID 528) in 453 ms on localhost (executor driver) (1/4)
18/02/28 13:45:34 INFO Executor: Finished task 3.0 in stage 204.0 (TID 529). 2411 bytes result sent to driver
18/02/28 13:45:34 INFO TaskSetManager: Finished task 3.0 in stage 204.0 (TID 529) in 458 ms on localhost (executor driver) (2/4)
18/02/28 13:45:34 INFO Executor: Finished task 1.0 in stage 204.0 (TID 527). 2411 bytes result sent to driver
18/02/28 13:45:34 INFO TaskSetManager: Finished task 1.0 in stage 204.0 (TID 527) in 460 ms on localhost (executor driver) (3/4)
18/02/28 13:45:34 INFO Executor: Finished task 0.0 in stage 204.0 (TID 526). 2411 bytes result sent to driver
18/02/28 13:45:34 INFO TaskSetManager: Finished task 0.0 in stage 204.0 (TID 526) in 479 ms on localhost (executor driver) (4/4)
18/02/28 13:45:34 INFO TaskSchedulerImpl: Removed TaskSet 204.0, whose tasks have all completed, from pool 
18/02/28 13:45:34 INFO DAGScheduler: ShuffleMapStage 204 (pivot at <unknown>:0) finished in 0.479 s
18/02/28 13:45:34 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:45:34 INFO DAGScheduler: running: Set()
18/02/28 13:45:34 INFO DAGScheduler: waiting: Set(ShuffleMapStage 205, ResultStage 206)
18/02/28 13:45:34 INFO DAGScheduler: failed: Set()
18/02/28 13:45:34 INFO DAGScheduler: Submitting ShuffleMapStage 205 (MapPartitionsRDD[507] at pivot at <unknown>:0), which has no missing parents
18/02/28 13:45:34 INFO MemoryStore: Block broadcast_205 stored as values in memory (estimated size 41.5 KB, free 260.8 MB)
18/02/28 13:45:34 INFO MemoryStore: Block broadcast_205_piece0 stored as bytes in memory (estimated size 18.1 KB, free 260.8 MB)
18/02/28 13:45:34 INFO BlockManagerInfo: Added broadcast_205_piece0 in memory on 127.0.0.1:60941 (size: 18.1 KB, free: 266.6 MB)
18/02/28 13:45:34 INFO SparkContext: Created broadcast 205 from broadcast at DAGScheduler.scala:1006
18/02/28 13:45:34 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 205 (MapPartitionsRDD[507] at pivot at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:45:34 INFO TaskSchedulerImpl: Adding task set 205.0 with 4 tasks
18/02/28 13:45:34 INFO TaskSetManager: Starting task 0.0 in stage 205.0 (TID 530, localhost, executor driver, partition 0, PROCESS_LOCAL, 4715 bytes)
18/02/28 13:45:34 INFO TaskSetManager: Starting task 3.0 in stage 205.0 (TID 531, localhost, executor driver, partition 3, PROCESS_LOCAL, 4715 bytes)
18/02/28 13:45:34 INFO TaskSetManager: Starting task 1.0 in stage 205.0 (TID 532, localhost, executor driver, partition 1, ANY, 4715 bytes)
18/02/28 13:45:34 INFO TaskSetManager: Starting task 2.0 in stage 205.0 (TID 533, localhost, executor driver, partition 2, ANY, 4715 bytes)
18/02/28 13:45:34 INFO Executor: Running task 0.0 in stage 205.0 (TID 530)
18/02/28 13:45:34 INFO Executor: Running task 3.0 in stage 205.0 (TID 531)
18/02/28 13:45:34 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 13:45:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:45:34 INFO Executor: Running task 2.0 in stage 205.0 (TID 533)
18/02/28 13:45:34 INFO Executor: Running task 1.0 in stage 205.0 (TID 532)
18/02/28 13:45:34 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:45:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:45:34 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 13:45:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:45:34 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:45:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:45:34 INFO Executor: Finished task 0.0 in stage 205.0 (TID 530). 3040 bytes result sent to driver
18/02/28 13:45:34 INFO TaskSetManager: Finished task 0.0 in stage 205.0 (TID 530) in 21 ms on localhost (executor driver) (1/4)
18/02/28 13:45:34 INFO Executor: Finished task 3.0 in stage 205.0 (TID 531). 3083 bytes result sent to driver
18/02/28 13:45:34 INFO TaskSetManager: Finished task 3.0 in stage 205.0 (TID 531) in 25 ms on localhost (executor driver) (2/4)
18/02/28 13:45:34 INFO Executor: Finished task 1.0 in stage 205.0 (TID 532). 3212 bytes result sent to driver
18/02/28 13:45:34 INFO TaskSetManager: Finished task 1.0 in stage 205.0 (TID 532) in 35 ms on localhost (executor driver) (3/4)
18/02/28 13:45:34 INFO Executor: Finished task 2.0 in stage 205.0 (TID 533). 3169 bytes result sent to driver
18/02/28 13:45:34 INFO TaskSetManager: Finished task 2.0 in stage 205.0 (TID 533) in 40 ms on localhost (executor driver) (4/4)
18/02/28 13:45:34 INFO TaskSchedulerImpl: Removed TaskSet 205.0, whose tasks have all completed, from pool 
18/02/28 13:45:34 INFO DAGScheduler: ShuffleMapStage 205 (pivot at <unknown>:0) finished in 0.040 s
18/02/28 13:45:34 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:45:34 INFO DAGScheduler: running: Set()
18/02/28 13:45:34 INFO DAGScheduler: waiting: Set(ResultStage 206)
18/02/28 13:45:34 INFO DAGScheduler: failed: Set()
18/02/28 13:45:34 INFO DAGScheduler: Submitting ResultStage 206 (MapPartitionsRDD[512] at pivot at <unknown>:0), which has no missing parents
18/02/28 13:45:34 INFO MemoryStore: Block broadcast_206 stored as values in memory (estimated size 38.5 KB, free 260.8 MB)
18/02/28 13:45:34 INFO MemoryStore: Block broadcast_206_piece0 stored as bytes in memory (estimated size 17.5 KB, free 260.8 MB)
18/02/28 13:45:34 INFO BlockManagerInfo: Added broadcast_206_piece0 in memory on 127.0.0.1:60941 (size: 17.5 KB, free: 266.5 MB)
18/02/28 13:45:34 INFO SparkContext: Created broadcast 206 from broadcast at DAGScheduler.scala:1006
18/02/28 13:45:34 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 206 (MapPartitionsRDD[512] at pivot at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:45:34 INFO TaskSchedulerImpl: Adding task set 206.0 with 4 tasks
18/02/28 13:45:34 INFO TaskSetManager: Starting task 0.0 in stage 206.0 (TID 534, localhost, executor driver, partition 0, PROCESS_LOCAL, 4726 bytes)
18/02/28 13:45:34 INFO TaskSetManager: Starting task 3.0 in stage 206.0 (TID 535, localhost, executor driver, partition 3, PROCESS_LOCAL, 4726 bytes)
18/02/28 13:45:34 INFO TaskSetManager: Starting task 1.0 in stage 206.0 (TID 536, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 13:45:34 INFO TaskSetManager: Starting task 2.0 in stage 206.0 (TID 537, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 13:45:34 INFO Executor: Running task 0.0 in stage 206.0 (TID 534)
18/02/28 13:45:34 INFO Executor: Running task 3.0 in stage 206.0 (TID 535)
18/02/28 13:45:34 INFO Executor: Running task 1.0 in stage 206.0 (TID 536)
18/02/28 13:45:34 INFO Executor: Running task 2.0 in stage 206.0 (TID 537)
18/02/28 13:45:34 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 13:45:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:45:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 13:45:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:45:34 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 13:45:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:45:34 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 4 blocks
18/02/28 13:45:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:45:34 INFO Executor: Finished task 0.0 in stage 206.0 (TID 534). 3682 bytes result sent to driver
18/02/28 13:45:34 INFO Executor: Finished task 1.0 in stage 206.0 (TID 536). 3876 bytes result sent to driver
18/02/28 13:45:34 INFO Executor: Finished task 3.0 in stage 206.0 (TID 535). 3682 bytes result sent to driver
18/02/28 13:45:34 INFO TaskSetManager: Finished task 0.0 in stage 206.0 (TID 534) in 13 ms on localhost (executor driver) (1/4)
18/02/28 13:45:34 INFO TaskSetManager: Finished task 1.0 in stage 206.0 (TID 536) in 14 ms on localhost (executor driver) (2/4)
18/02/28 13:45:34 INFO Executor: Finished task 2.0 in stage 206.0 (TID 537). 3833 bytes result sent to driver
18/02/28 13:45:34 INFO TaskSetManager: Finished task 3.0 in stage 206.0 (TID 535) in 14 ms on localhost (executor driver) (3/4)
18/02/28 13:45:34 INFO TaskSetManager: Finished task 2.0 in stage 206.0 (TID 537) in 13 ms on localhost (executor driver) (4/4)
18/02/28 13:45:34 INFO TaskSchedulerImpl: Removed TaskSet 206.0, whose tasks have all completed, from pool 
18/02/28 13:45:34 INFO DAGScheduler: ResultStage 206 (pivot at <unknown>:0) finished in 0.015 s
18/02/28 13:45:34 INFO DAGScheduler: Job 106 finished: pivot at <unknown>:0, took 0.545512 s
18/02/28 13:45:34 INFO SparkContext: Starting job: pivot at <unknown>:0
18/02/28 13:45:34 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 59 is 158 bytes
18/02/28 13:45:34 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 60 is 161 bytes
18/02/28 13:45:34 INFO DAGScheduler: Registering RDD 513 (pivot at <unknown>:0)
18/02/28 13:45:34 INFO DAGScheduler: Got job 107 (pivot at <unknown>:0) with 1 output partitions
18/02/28 13:45:34 INFO DAGScheduler: Final stage: ResultStage 210 (pivot at <unknown>:0)
18/02/28 13:45:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 209)
18/02/28 13:45:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 209)
18/02/28 13:45:34 INFO DAGScheduler: Submitting ShuffleMapStage 209 (MapPartitionsRDD[513] at pivot at <unknown>:0), which has no missing parents
18/02/28 13:45:34 INFO MemoryStore: Block broadcast_207 stored as values in memory (estimated size 39.1 KB, free 260.7 MB)
18/02/28 13:45:34 INFO MemoryStore: Block broadcast_207_piece0 stored as bytes in memory (estimated size 17.8 KB, free 260.7 MB)
18/02/28 13:45:34 INFO BlockManagerInfo: Added broadcast_207_piece0 in memory on 127.0.0.1:60941 (size: 17.8 KB, free: 266.5 MB)
18/02/28 13:45:34 INFO SparkContext: Created broadcast 207 from broadcast at DAGScheduler.scala:1006
18/02/28 13:45:34 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 209 (MapPartitionsRDD[513] at pivot at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:45:34 INFO TaskSchedulerImpl: Adding task set 209.0 with 4 tasks
18/02/28 13:45:34 INFO TaskSetManager: Starting task 0.0 in stage 209.0 (TID 538, localhost, executor driver, partition 0, PROCESS_LOCAL, 4715 bytes)
18/02/28 13:45:34 INFO TaskSetManager: Starting task 3.0 in stage 209.0 (TID 539, localhost, executor driver, partition 3, PROCESS_LOCAL, 4715 bytes)
18/02/28 13:45:34 INFO TaskSetManager: Starting task 1.0 in stage 209.0 (TID 540, localhost, executor driver, partition 1, ANY, 4715 bytes)
18/02/28 13:45:34 INFO TaskSetManager: Starting task 2.0 in stage 209.0 (TID 541, localhost, executor driver, partition 2, ANY, 4715 bytes)
18/02/28 13:45:34 INFO Executor: Running task 0.0 in stage 209.0 (TID 538)
18/02/28 13:45:34 INFO Executor: Running task 3.0 in stage 209.0 (TID 539)
18/02/28 13:45:34 INFO Executor: Running task 1.0 in stage 209.0 (TID 540)
18/02/28 13:45:34 INFO Executor: Running task 2.0 in stage 209.0 (TID 541)
18/02/28 13:45:34 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 13:45:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:45:34 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 13:45:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:45:34 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 4 blocks
18/02/28 13:45:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:45:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 13:45:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:45:34 INFO Executor: Finished task 3.0 in stage 209.0 (TID 539). 3563 bytes result sent to driver
18/02/28 13:45:34 INFO TaskSetManager: Finished task 3.0 in stage 209.0 (TID 539) in 13 ms on localhost (executor driver) (1/4)
18/02/28 13:45:34 INFO Executor: Finished task 0.0 in stage 209.0 (TID 538). 3606 bytes result sent to driver
18/02/28 13:45:34 INFO TaskSetManager: Finished task 0.0 in stage 209.0 (TID 538) in 14 ms on localhost (executor driver) (2/4)
18/02/28 13:45:34 INFO Executor: Finished task 1.0 in stage 209.0 (TID 540). 3735 bytes result sent to driver
18/02/28 13:45:34 INFO TaskSetManager: Finished task 1.0 in stage 209.0 (TID 540) in 18 ms on localhost (executor driver) (3/4)
18/02/28 13:45:34 INFO Executor: Finished task 2.0 in stage 209.0 (TID 541). 3735 bytes result sent to driver
18/02/28 13:45:34 INFO TaskSetManager: Finished task 2.0 in stage 209.0 (TID 541) in 20 ms on localhost (executor driver) (4/4)
18/02/28 13:45:34 INFO TaskSchedulerImpl: Removed TaskSet 209.0, whose tasks have all completed, from pool 
18/02/28 13:45:34 INFO DAGScheduler: ShuffleMapStage 209 (pivot at <unknown>:0) finished in 0.021 s
18/02/28 13:45:34 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:45:34 INFO DAGScheduler: running: Set()
18/02/28 13:45:34 INFO DAGScheduler: waiting: Set(ResultStage 210)
18/02/28 13:45:34 INFO DAGScheduler: failed: Set()
18/02/28 13:45:34 INFO DAGScheduler: Submitting ResultStage 210 (MapPartitionsRDD[518] at pivot at <unknown>:0), which has no missing parents
18/02/28 13:45:34 INFO MemoryStore: Block broadcast_208 stored as values in memory (estimated size 37.5 KB, free 260.7 MB)
18/02/28 13:45:34 INFO MemoryStore: Block broadcast_208_piece0 stored as bytes in memory (estimated size 17.1 KB, free 260.7 MB)
18/02/28 13:45:34 INFO BlockManagerInfo: Added broadcast_208_piece0 in memory on 127.0.0.1:60941 (size: 17.1 KB, free: 266.5 MB)
18/02/28 13:45:34 INFO SparkContext: Created broadcast 208 from broadcast at DAGScheduler.scala:1006
18/02/28 13:45:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 210 (MapPartitionsRDD[518] at pivot at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 13:45:34 INFO TaskSchedulerImpl: Adding task set 210.0 with 1 tasks
18/02/28 13:45:34 INFO TaskSetManager: Starting task 0.0 in stage 210.0 (TID 542, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:45:34 INFO Executor: Running task 0.0 in stage 210.0 (TID 542)
18/02/28 13:45:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 13:45:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:45:34 INFO CodeGenerator: Code generated in 2.87277 ms
18/02/28 13:45:34 INFO Executor: Finished task 0.0 in stage 210.0 (TID 542). 3952 bytes result sent to driver
18/02/28 13:45:34 INFO TaskSetManager: Finished task 0.0 in stage 210.0 (TID 542) in 10 ms on localhost (executor driver) (1/1)
18/02/28 13:45:34 INFO TaskSchedulerImpl: Removed TaskSet 210.0, whose tasks have all completed, from pool 
18/02/28 13:45:34 INFO DAGScheduler: ResultStage 210 (pivot at <unknown>:0) finished in 0.010 s
18/02/28 13:45:34 INFO DAGScheduler: Job 107 finished: pivot at <unknown>:0, took 0.041033 s
18/02/28 13:45:34 INFO SparkContext: Starting job: pivot at <unknown>:0
18/02/28 13:45:34 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 59 is 158 bytes
18/02/28 13:45:34 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 60 is 161 bytes
18/02/28 13:45:34 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 61 is 163 bytes
18/02/28 13:45:34 INFO DAGScheduler: Got job 108 (pivot at <unknown>:0) with 2 output partitions
18/02/28 13:45:34 INFO DAGScheduler: Final stage: ResultStage 214 (pivot at <unknown>:0)
18/02/28 13:45:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 213)
18/02/28 13:45:34 INFO DAGScheduler: Missing parents: List()
18/02/28 13:45:34 INFO DAGScheduler: Submitting ResultStage 214 (MapPartitionsRDD[518] at pivot at <unknown>:0), which has no missing parents
18/02/28 13:45:34 INFO MemoryStore: Block broadcast_209 stored as values in memory (estimated size 37.5 KB, free 260.6 MB)
18/02/28 13:45:34 INFO MemoryStore: Block broadcast_209_piece0 stored as bytes in memory (estimated size 17.1 KB, free 260.6 MB)
18/02/28 13:45:34 INFO BlockManagerInfo: Added broadcast_209_piece0 in memory on 127.0.0.1:60941 (size: 17.1 KB, free: 266.5 MB)
18/02/28 13:45:34 INFO SparkContext: Created broadcast 209 from broadcast at DAGScheduler.scala:1006
18/02/28 13:45:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 214 (MapPartitionsRDD[518] at pivot at <unknown>:0) (first 15 tasks are for partitions Vector(1, 2))
18/02/28 13:45:34 INFO TaskSchedulerImpl: Adding task set 214.0 with 2 tasks
18/02/28 13:45:34 INFO TaskSetManager: Starting task 1.0 in stage 214.0 (TID 543, localhost, executor driver, partition 2, PROCESS_LOCAL, 4726 bytes)
18/02/28 13:45:34 INFO TaskSetManager: Starting task 0.0 in stage 214.0 (TID 544, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 13:45:34 INFO Executor: Running task 0.0 in stage 214.0 (TID 544)
18/02/28 13:45:34 INFO Executor: Running task 1.0 in stage 214.0 (TID 543)
18/02/28 13:45:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 13:45:34 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 13:45:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:45:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:45:34 INFO Executor: Finished task 1.0 in stage 214.0 (TID 543). 3872 bytes result sent to driver
18/02/28 13:45:34 INFO TaskSetManager: Finished task 1.0 in stage 214.0 (TID 543) in 4 ms on localhost (executor driver) (1/2)
18/02/28 13:45:34 INFO Executor: Finished task 0.0 in stage 214.0 (TID 544). 3952 bytes result sent to driver
18/02/28 13:45:34 INFO TaskSetManager: Finished task 0.0 in stage 214.0 (TID 544) in 5 ms on localhost (executor driver) (2/2)
18/02/28 13:45:34 INFO TaskSchedulerImpl: Removed TaskSet 214.0, whose tasks have all completed, from pool 
18/02/28 13:45:34 INFO DAGScheduler: ResultStage 214 (pivot at <unknown>:0) finished in 0.005 s
18/02/28 13:45:34 INFO DAGScheduler: Job 108 finished: pivot at <unknown>:0, took 0.009549 s
18/02/28 13:45:34 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e0dce78a8
18/02/28 13:45:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:45:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0dce78a8` AS `zzz101`
WHERE (0 = 1)
18/02/28 13:45:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:45:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0dce78a8`
18/02/28 13:45:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:45:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0dce78a8`
18/02/28 13:45:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:45:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0dce78a8`
18/02/28 13:45:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:45:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0dce78a8`
18/02/28 13:45:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:45:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0dce78a8`
18/02/28 13:45:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:45:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0dce78a8`
LIMIT 1000
18/02/28 13:45:35 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
18/02/28 13:45:35 INFO CodeGenerator: Code generated in 27.755181 ms
18/02/28 13:45:35 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
18/02/28 13:45:35 INFO ContextCleaner: Cleaned accumulator 5034
18/02/28 13:45:35 INFO BlockManagerInfo: Removed broadcast_205_piece0 on 127.0.0.1:60941 in memory (size: 18.1 KB, free: 266.5 MB)
18/02/28 13:45:35 INFO BlockManagerInfo: Removed broadcast_207_piece0 on 127.0.0.1:60941 in memory (size: 17.8 KB, free: 266.5 MB)
18/02/28 13:45:35 INFO ContextCleaner: Cleaned shuffle 61
18/02/28 13:45:35 INFO BlockManagerInfo: Removed broadcast_209_piece0 on 127.0.0.1:60941 in memory (size: 17.1 KB, free: 266.5 MB)
18/02/28 13:45:35 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:45:35 INFO DAGScheduler: Registering RDD 521 (collect at utils.scala:211)
18/02/28 13:45:35 INFO DAGScheduler: Registering RDD 525 (collect at utils.scala:211)
18/02/28 13:45:35 INFO DAGScheduler: Got job 109 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:45:35 INFO DAGScheduler: Final stage: ResultStage 217 (collect at utils.scala:211)
18/02/28 13:45:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 216)
18/02/28 13:45:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 216)
18/02/28 13:45:35 INFO DAGScheduler: Submitting ShuffleMapStage 215 (MapPartitionsRDD[521] at collect at utils.scala:211), which has no missing parents
18/02/28 13:45:35 INFO MemoryStore: Block broadcast_210 stored as values in memory (estimated size 73.3 KB, free 260.7 MB)
18/02/28 13:45:35 INFO BlockManagerInfo: Removed broadcast_206_piece0 on 127.0.0.1:60941 in memory (size: 17.5 KB, free: 266.6 MB)
18/02/28 13:45:35 INFO ContextCleaner: Cleaned accumulator 5033
18/02/28 13:45:35 INFO BlockManagerInfo: Removed broadcast_208_piece0 on 127.0.0.1:60941 in memory (size: 17.1 KB, free: 266.6 MB)
18/02/28 13:45:35 INFO MemoryStore: Block broadcast_210_piece0 stored as bytes in memory (estimated size 29.9 KB, free 260.7 MB)
18/02/28 13:45:35 INFO BlockManagerInfo: Added broadcast_210_piece0 in memory on 127.0.0.1:60941 (size: 29.9 KB, free: 266.5 MB)
18/02/28 13:45:35 INFO SparkContext: Created broadcast 210 from broadcast at DAGScheduler.scala:1006
18/02/28 13:45:35 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 215 (MapPartitionsRDD[521] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:45:35 INFO TaskSchedulerImpl: Adding task set 215.0 with 4 tasks
18/02/28 13:45:35 INFO TaskSetManager: Starting task 0.0 in stage 215.0 (TID 545, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:45:35 INFO TaskSetManager: Starting task 1.0 in stage 215.0 (TID 546, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:45:35 INFO TaskSetManager: Starting task 2.0 in stage 215.0 (TID 547, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:45:35 INFO TaskSetManager: Starting task 3.0 in stage 215.0 (TID 548, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:45:35 INFO Executor: Running task 0.0 in stage 215.0 (TID 545)
18/02/28 13:45:35 INFO Executor: Running task 2.0 in stage 215.0 (TID 547)
18/02/28 13:45:35 INFO Executor: Running task 3.0 in stage 215.0 (TID 548)
18/02/28 13:45:35 INFO BlockManager: Found block rdd_328_0 locally
18/02/28 13:45:35 INFO Executor: Running task 1.0 in stage 215.0 (TID 546)
18/02/28 13:45:35 INFO BlockManager: Found block rdd_328_1 locally
18/02/28 13:45:35 INFO BlockManager: Found block rdd_328_2 locally
18/02/28 13:45:35 INFO BlockManager: Found block rdd_328_3 locally
18/02/28 13:45:35 INFO Executor: Finished task 3.0 in stage 215.0 (TID 548). 2411 bytes result sent to driver
18/02/28 13:45:35 INFO TaskSetManager: Finished task 3.0 in stage 215.0 (TID 548) in 477 ms on localhost (executor driver) (1/4)
18/02/28 13:45:35 INFO Executor: Finished task 2.0 in stage 215.0 (TID 547). 2411 bytes result sent to driver
18/02/28 13:45:35 INFO TaskSetManager: Finished task 2.0 in stage 215.0 (TID 547) in 495 ms on localhost (executor driver) (2/4)
18/02/28 13:45:35 INFO Executor: Finished task 1.0 in stage 215.0 (TID 546). 2411 bytes result sent to driver
18/02/28 13:45:35 INFO TaskSetManager: Finished task 1.0 in stage 215.0 (TID 546) in 496 ms on localhost (executor driver) (3/4)
18/02/28 13:45:35 INFO Executor: Finished task 0.0 in stage 215.0 (TID 545). 2411 bytes result sent to driver
18/02/28 13:45:35 INFO TaskSetManager: Finished task 0.0 in stage 215.0 (TID 545) in 498 ms on localhost (executor driver) (4/4)
18/02/28 13:45:35 INFO TaskSchedulerImpl: Removed TaskSet 215.0, whose tasks have all completed, from pool 
18/02/28 13:45:35 INFO DAGScheduler: ShuffleMapStage 215 (collect at utils.scala:211) finished in 0.499 s
18/02/28 13:45:35 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:45:35 INFO DAGScheduler: running: Set()
18/02/28 13:45:35 INFO DAGScheduler: waiting: Set(ShuffleMapStage 216, ResultStage 217)
18/02/28 13:45:35 INFO DAGScheduler: failed: Set()
18/02/28 13:45:35 INFO DAGScheduler: Submitting ShuffleMapStage 216 (MapPartitionsRDD[525] at collect at utils.scala:211), which has no missing parents
18/02/28 13:45:35 INFO MemoryStore: Block broadcast_211 stored as values in memory (estimated size 58.4 KB, free 260.7 MB)
18/02/28 13:45:35 INFO MemoryStore: Block broadcast_211_piece0 stored as bytes in memory (estimated size 23.0 KB, free 260.7 MB)
18/02/28 13:45:35 INFO BlockManagerInfo: Added broadcast_211_piece0 in memory on 127.0.0.1:60941 (size: 23.0 KB, free: 266.5 MB)
18/02/28 13:45:35 INFO SparkContext: Created broadcast 211 from broadcast at DAGScheduler.scala:1006
18/02/28 13:45:35 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 216 (MapPartitionsRDD[525] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:45:35 INFO TaskSchedulerImpl: Adding task set 216.0 with 4 tasks
18/02/28 13:45:35 INFO TaskSetManager: Starting task 0.0 in stage 216.0 (TID 549, localhost, executor driver, partition 0, PROCESS_LOCAL, 4715 bytes)
18/02/28 13:45:35 INFO TaskSetManager: Starting task 3.0 in stage 216.0 (TID 550, localhost, executor driver, partition 3, PROCESS_LOCAL, 4715 bytes)
18/02/28 13:45:35 INFO TaskSetManager: Starting task 1.0 in stage 216.0 (TID 551, localhost, executor driver, partition 1, ANY, 4715 bytes)
18/02/28 13:45:35 INFO TaskSetManager: Starting task 2.0 in stage 216.0 (TID 552, localhost, executor driver, partition 2, ANY, 4715 bytes)
18/02/28 13:45:35 INFO Executor: Running task 0.0 in stage 216.0 (TID 549)
18/02/28 13:45:35 INFO Executor: Running task 3.0 in stage 216.0 (TID 550)
18/02/28 13:45:35 INFO Executor: Running task 1.0 in stage 216.0 (TID 551)
18/02/28 13:45:35 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 13:45:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:45:35 INFO Executor: Running task 2.0 in stage 216.0 (TID 552)
18/02/28 13:45:35 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 13:45:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:45:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:45:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:45:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:45:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:45:35 INFO CodeGenerator: Code generated in 3.692252 ms
18/02/28 13:45:35 INFO Executor: Finished task 0.0 in stage 216.0 (TID 549). 3726 bytes result sent to driver
18/02/28 13:45:35 INFO TaskSetManager: Finished task 0.0 in stage 216.0 (TID 549) in 39 ms on localhost (executor driver) (1/4)
18/02/28 13:45:35 INFO Executor: Finished task 3.0 in stage 216.0 (TID 550). 3726 bytes result sent to driver
18/02/28 13:45:35 INFO TaskSetManager: Finished task 3.0 in stage 216.0 (TID 550) in 42 ms on localhost (executor driver) (2/4)
18/02/28 13:45:35 INFO CodeGenerator: Code generated in 5.493419 ms
18/02/28 13:45:35 INFO CodeGenerator: Code generated in 5.73073 ms
18/02/28 13:45:35 INFO Executor: Finished task 1.0 in stage 216.0 (TID 551). 3855 bytes result sent to driver
18/02/28 13:45:35 INFO TaskSetManager: Finished task 1.0 in stage 216.0 (TID 551) in 75 ms on localhost (executor driver) (3/4)
18/02/28 13:45:35 INFO Executor: Finished task 2.0 in stage 216.0 (TID 552). 3941 bytes result sent to driver
18/02/28 13:45:35 INFO TaskSetManager: Finished task 2.0 in stage 216.0 (TID 552) in 88 ms on localhost (executor driver) (4/4)
18/02/28 13:45:35 INFO TaskSchedulerImpl: Removed TaskSet 216.0, whose tasks have all completed, from pool 
18/02/28 13:45:35 INFO DAGScheduler: ShuffleMapStage 216 (collect at utils.scala:211) finished in 0.088 s
18/02/28 13:45:35 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:45:35 INFO DAGScheduler: running: Set()
18/02/28 13:45:35 INFO DAGScheduler: waiting: Set(ResultStage 217)
18/02/28 13:45:35 INFO DAGScheduler: failed: Set()
18/02/28 13:45:35 INFO DAGScheduler: Submitting ResultStage 217 (MapPartitionsRDD[528] at collect at utils.scala:211), which has no missing parents
18/02/28 13:45:35 INFO MemoryStore: Block broadcast_212 stored as values in memory (estimated size 37.0 KB, free 260.7 MB)
18/02/28 13:45:35 INFO MemoryStore: Block broadcast_212_piece0 stored as bytes in memory (estimated size 16.8 KB, free 260.7 MB)
18/02/28 13:45:35 INFO BlockManagerInfo: Added broadcast_212_piece0 in memory on 127.0.0.1:60941 (size: 16.8 KB, free: 266.5 MB)
18/02/28 13:45:35 INFO SparkContext: Created broadcast 212 from broadcast at DAGScheduler.scala:1006
18/02/28 13:45:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 217 (MapPartitionsRDD[528] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:45:35 INFO TaskSchedulerImpl: Adding task set 217.0 with 1 tasks
18/02/28 13:45:35 INFO TaskSetManager: Starting task 0.0 in stage 217.0 (TID 553, localhost, executor driver, partition 0, PROCESS_LOCAL, 4726 bytes)
18/02/28 13:45:35 INFO Executor: Running task 0.0 in stage 217.0 (TID 553)
18/02/28 13:45:35 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 13:45:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:45:35 INFO Executor: Finished task 0.0 in stage 217.0 (TID 553). 3954 bytes result sent to driver
18/02/28 13:45:35 INFO TaskSetManager: Finished task 0.0 in stage 217.0 (TID 553) in 5 ms on localhost (executor driver) (1/1)
18/02/28 13:45:35 INFO TaskSchedulerImpl: Removed TaskSet 217.0, whose tasks have all completed, from pool 
18/02/28 13:45:35 INFO DAGScheduler: ResultStage 217 (collect at utils.scala:211) finished in 0.005 s
18/02/28 13:45:35 INFO DAGScheduler: Job 109 finished: collect at utils.scala:211, took 0.605800 s
18/02/28 13:45:35 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:45:35 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 62 is 158 bytes
18/02/28 13:45:35 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 63 is 161 bytes
18/02/28 13:45:35 INFO DAGScheduler: Got job 110 (collect at utils.scala:211) with 3 output partitions
18/02/28 13:45:35 INFO DAGScheduler: Final stage: ResultStage 220 (collect at utils.scala:211)
18/02/28 13:45:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 219)
18/02/28 13:45:35 INFO DAGScheduler: Missing parents: List()
18/02/28 13:45:35 INFO DAGScheduler: Submitting ResultStage 220 (MapPartitionsRDD[528] at collect at utils.scala:211), which has no missing parents
18/02/28 13:45:35 INFO MemoryStore: Block broadcast_213 stored as values in memory (estimated size 37.0 KB, free 260.6 MB)
18/02/28 13:45:35 INFO MemoryStore: Block broadcast_213_piece0 stored as bytes in memory (estimated size 16.8 KB, free 260.6 MB)
18/02/28 13:45:35 INFO BlockManagerInfo: Added broadcast_213_piece0 in memory on 127.0.0.1:60941 (size: 16.8 KB, free: 266.5 MB)
18/02/28 13:45:35 INFO SparkContext: Created broadcast 213 from broadcast at DAGScheduler.scala:1006
18/02/28 13:45:35 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 220 (MapPartitionsRDD[528] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(1, 2, 3))
18/02/28 13:45:35 INFO TaskSchedulerImpl: Adding task set 220.0 with 3 tasks
18/02/28 13:45:35 INFO TaskSetManager: Starting task 2.0 in stage 220.0 (TID 554, localhost, executor driver, partition 3, PROCESS_LOCAL, 4726 bytes)
18/02/28 13:45:35 INFO TaskSetManager: Starting task 0.0 in stage 220.0 (TID 555, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 13:45:35 INFO TaskSetManager: Starting task 1.0 in stage 220.0 (TID 556, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 13:45:35 INFO Executor: Running task 2.0 in stage 220.0 (TID 554)
18/02/28 13:45:35 INFO Executor: Running task 0.0 in stage 220.0 (TID 555)
18/02/28 13:45:35 INFO Executor: Running task 1.0 in stage 220.0 (TID 556)
18/02/28 13:45:35 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 4 blocks
18/02/28 13:45:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:45:35 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 13:45:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:45:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 13:45:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:45:35 INFO Executor: Finished task 2.0 in stage 220.0 (TID 554). 3997 bytes result sent to driver
18/02/28 13:45:35 INFO TaskSetManager: Finished task 2.0 in stage 220.0 (TID 554) in 4 ms on localhost (executor driver) (1/3)
18/02/28 13:45:35 INFO CodeGenerator: Code generated in 4.277949 ms
18/02/28 13:45:35 INFO CodeGenerator: Code generated in 5.221903 ms
18/02/28 13:45:35 INFO Executor: Finished task 1.0 in stage 220.0 (TID 556). 4059 bytes result sent to driver
18/02/28 13:45:35 INFO Executor: Finished task 0.0 in stage 220.0 (TID 555). 4100 bytes result sent to driver
18/02/28 13:45:35 INFO TaskSetManager: Finished task 0.0 in stage 220.0 (TID 555) in 25 ms on localhost (executor driver) (2/3)
18/02/28 13:45:35 INFO TaskSetManager: Finished task 1.0 in stage 220.0 (TID 556) in 26 ms on localhost (executor driver) (3/3)
18/02/28 13:45:35 INFO TaskSchedulerImpl: Removed TaskSet 220.0, whose tasks have all completed, from pool 
18/02/28 13:45:35 INFO DAGScheduler: ResultStage 220 (collect at utils.scala:211) finished in 0.027 s
18/02/28 13:45:35 INFO DAGScheduler: Job 110 finished: collect at utils.scala:211, took 0.032284 s
18/02/28 13:45:35 INFO CodeGenerator: Code generated in 5.324515 ms
18/02/28 13:45:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:45:47 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_30e065b62d27`
GROUP BY `delayed`, `prediction`
18/02/28 13:45:47 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:45:47 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:45:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:45:47 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_30e065b62d27`
GROUP BY `delayed`, `prediction`
18/02/28 13:45:47 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:45:47 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:45:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:45:47 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_30e065b62d27`
GROUP BY `delayed`, `prediction`
18/02/28 13:45:47 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:45:47 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:45:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:45:47 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_30e065b62d27`
GROUP BY `delayed`, `prediction`
18/02/28 13:45:47 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:45:47 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:45:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:45:47 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_30e065b62d27`
GROUP BY `delayed`, `prediction`
18/02/28 13:45:47 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:45:47 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:45:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:45:47 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_30e065b62d27`
GROUP BY `delayed`, `prediction`
LIMIT 1000
18/02/28 13:45:47 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:45:47 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:45:47 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:45:47 INFO DAGScheduler: Registering RDD 531 (collect at utils.scala:211)
18/02/28 13:45:47 INFO DAGScheduler: Got job 111 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:45:47 INFO DAGScheduler: Final stage: ResultStage 222 (collect at utils.scala:211)
18/02/28 13:45:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 221)
18/02/28 13:45:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 221)
18/02/28 13:45:47 INFO DAGScheduler: Submitting ShuffleMapStage 221 (MapPartitionsRDD[531] at collect at utils.scala:211), which has no missing parents
18/02/28 13:45:47 INFO MemoryStore: Block broadcast_214 stored as values in memory (estimated size 79.1 KB, free 260.5 MB)
18/02/28 13:45:47 INFO MemoryStore: Block broadcast_214_piece0 stored as bytes in memory (estimated size 32.3 KB, free 260.5 MB)
18/02/28 13:45:47 INFO BlockManagerInfo: Added broadcast_214_piece0 in memory on 127.0.0.1:60941 (size: 32.3 KB, free: 266.5 MB)
18/02/28 13:45:47 INFO SparkContext: Created broadcast 214 from broadcast at DAGScheduler.scala:1006
18/02/28 13:45:47 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 221 (MapPartitionsRDD[531] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:45:47 INFO TaskSchedulerImpl: Adding task set 221.0 with 4 tasks
18/02/28 13:45:47 INFO TaskSetManager: Starting task 0.0 in stage 221.0 (TID 557, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:45:47 INFO TaskSetManager: Starting task 1.0 in stage 221.0 (TID 558, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:45:47 INFO TaskSetManager: Starting task 2.0 in stage 221.0 (TID 559, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:45:47 INFO TaskSetManager: Starting task 3.0 in stage 221.0 (TID 560, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:45:47 INFO Executor: Running task 0.0 in stage 221.0 (TID 557)
18/02/28 13:45:47 INFO Executor: Running task 1.0 in stage 221.0 (TID 558)
18/02/28 13:45:47 INFO BlockManager: Found block rdd_328_0 locally
18/02/28 13:45:47 INFO BlockManager: Found block rdd_328_1 locally
18/02/28 13:45:47 INFO Executor: Running task 2.0 in stage 221.0 (TID 559)
18/02/28 13:45:47 INFO BlockManager: Found block rdd_328_2 locally
18/02/28 13:45:47 INFO Executor: Running task 3.0 in stage 221.0 (TID 560)
18/02/28 13:45:47 INFO BlockManager: Found block rdd_328_3 locally
18/02/28 13:45:48 INFO BlockManagerInfo: Removed broadcast_211_piece0 on 127.0.0.1:60941 in memory (size: 23.0 KB, free: 266.5 MB)
18/02/28 13:45:48 INFO ContextCleaner: Cleaned accumulator 5165
18/02/28 13:45:48 INFO BlockManagerInfo: Removed broadcast_212_piece0 on 127.0.0.1:60941 in memory (size: 16.8 KB, free: 266.5 MB)
18/02/28 13:45:48 INFO BlockManagerInfo: Removed broadcast_213_piece0 on 127.0.0.1:60941 in memory (size: 16.8 KB, free: 266.5 MB)
18/02/28 13:45:48 INFO Executor: Finished task 2.0 in stage 221.0 (TID 559). 2411 bytes result sent to driver
18/02/28 13:45:48 INFO TaskSetManager: Finished task 2.0 in stage 221.0 (TID 559) in 218 ms on localhost (executor driver) (1/4)
18/02/28 13:45:48 INFO Executor: Finished task 1.0 in stage 221.0 (TID 558). 2411 bytes result sent to driver
18/02/28 13:45:48 INFO TaskSetManager: Finished task 1.0 in stage 221.0 (TID 558) in 220 ms on localhost (executor driver) (2/4)
18/02/28 13:45:48 INFO Executor: Finished task 3.0 in stage 221.0 (TID 560). 2454 bytes result sent to driver
18/02/28 13:45:48 INFO TaskSetManager: Finished task 3.0 in stage 221.0 (TID 560) in 227 ms on localhost (executor driver) (3/4)
18/02/28 13:45:48 INFO Executor: Finished task 0.0 in stage 221.0 (TID 557). 2411 bytes result sent to driver
18/02/28 13:45:48 INFO TaskSetManager: Finished task 0.0 in stage 221.0 (TID 557) in 250 ms on localhost (executor driver) (4/4)
18/02/28 13:45:48 INFO DAGScheduler: ShuffleMapStage 221 (collect at utils.scala:211) finished in 0.250 s
18/02/28 13:45:48 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:45:48 INFO DAGScheduler: running: Set()
18/02/28 13:45:48 INFO DAGScheduler: waiting: Set(ResultStage 222)
18/02/28 13:45:48 INFO DAGScheduler: failed: Set()
18/02/28 13:45:48 INFO TaskSchedulerImpl: Removed TaskSet 221.0, whose tasks have all completed, from pool 
18/02/28 13:45:48 INFO DAGScheduler: Submitting ResultStage 222 (MapPartitionsRDD[534] at collect at utils.scala:211), which has no missing parents
18/02/28 13:45:48 INFO MemoryStore: Block broadcast_215 stored as values in memory (estimated size 38.1 KB, free 260.6 MB)
18/02/28 13:45:48 INFO MemoryStore: Block broadcast_215_piece0 stored as bytes in memory (estimated size 17.9 KB, free 260.6 MB)
18/02/28 13:45:48 INFO BlockManagerInfo: Added broadcast_215_piece0 in memory on 127.0.0.1:60941 (size: 17.9 KB, free: 266.5 MB)
18/02/28 13:45:48 INFO SparkContext: Created broadcast 215 from broadcast at DAGScheduler.scala:1006
18/02/28 13:45:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 222 (MapPartitionsRDD[534] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:45:48 INFO TaskSchedulerImpl: Adding task set 222.0 with 1 tasks
18/02/28 13:45:48 INFO TaskSetManager: Starting task 0.0 in stage 222.0 (TID 561, localhost, executor driver, partition 0, PROCESS_LOCAL, 4726 bytes)
18/02/28 13:45:48 INFO Executor: Running task 0.0 in stage 222.0 (TID 561)
18/02/28 13:45:48 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 13:45:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:45:48 INFO Executor: Finished task 0.0 in stage 222.0 (TID 561). 2577 bytes result sent to driver
18/02/28 13:45:48 INFO TaskSetManager: Finished task 0.0 in stage 222.0 (TID 561) in 5 ms on localhost (executor driver) (1/1)
18/02/28 13:45:48 INFO TaskSchedulerImpl: Removed TaskSet 222.0, whose tasks have all completed, from pool 
18/02/28 13:45:48 INFO DAGScheduler: ResultStage 222 (collect at utils.scala:211) finished in 0.005 s
18/02/28 13:45:48 INFO DAGScheduler: Job 111 finished: collect at utils.scala:211, took 0.266079 s
18/02/28 13:45:48 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:45:48 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 64 is 158 bytes
18/02/28 13:45:48 INFO DAGScheduler: Got job 112 (collect at utils.scala:211) with 3 output partitions
18/02/28 13:45:48 INFO DAGScheduler: Final stage: ResultStage 224 (collect at utils.scala:211)
18/02/28 13:45:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 223)
18/02/28 13:45:48 INFO DAGScheduler: Missing parents: List()
18/02/28 13:45:48 INFO DAGScheduler: Submitting ResultStage 224 (MapPartitionsRDD[534] at collect at utils.scala:211), which has no missing parents
18/02/28 13:45:48 INFO MemoryStore: Block broadcast_216 stored as values in memory (estimated size 38.1 KB, free 260.6 MB)
18/02/28 13:45:48 INFO MemoryStore: Block broadcast_216_piece0 stored as bytes in memory (estimated size 17.9 KB, free 260.6 MB)
18/02/28 13:45:48 INFO BlockManagerInfo: Added broadcast_216_piece0 in memory on 127.0.0.1:60941 (size: 17.9 KB, free: 266.5 MB)
18/02/28 13:45:48 INFO SparkContext: Created broadcast 216 from broadcast at DAGScheduler.scala:1006
18/02/28 13:45:48 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 224 (MapPartitionsRDD[534] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(1, 2, 3))
18/02/28 13:45:48 INFO TaskSchedulerImpl: Adding task set 224.0 with 3 tasks
18/02/28 13:45:48 INFO TaskSetManager: Starting task 2.0 in stage 224.0 (TID 562, localhost, executor driver, partition 3, PROCESS_LOCAL, 4726 bytes)
18/02/28 13:45:48 INFO TaskSetManager: Starting task 0.0 in stage 224.0 (TID 563, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 13:45:48 INFO TaskSetManager: Starting task 1.0 in stage 224.0 (TID 564, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 13:45:48 INFO Executor: Running task 2.0 in stage 224.0 (TID 562)
18/02/28 13:45:48 INFO Executor: Running task 0.0 in stage 224.0 (TID 563)
18/02/28 13:45:48 INFO Executor: Running task 1.0 in stage 224.0 (TID 564)
18/02/28 13:45:48 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 13:45:48 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:45:48 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:45:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:45:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:45:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:45:48 INFO Executor: Finished task 2.0 in stage 224.0 (TID 562). 2577 bytes result sent to driver
18/02/28 13:45:48 INFO Executor: Finished task 1.0 in stage 224.0 (TID 564). 2623 bytes result sent to driver
18/02/28 13:45:48 INFO TaskSetManager: Finished task 2.0 in stage 224.0 (TID 562) in 5 ms on localhost (executor driver) (1/3)
18/02/28 13:45:48 INFO TaskSetManager: Finished task 1.0 in stage 224.0 (TID 564) in 5 ms on localhost (executor driver) (2/3)
18/02/28 13:45:48 INFO Executor: Finished task 0.0 in stage 224.0 (TID 563). 2597 bytes result sent to driver
18/02/28 13:45:48 INFO TaskSetManager: Finished task 0.0 in stage 224.0 (TID 563) in 6 ms on localhost (executor driver) (3/3)
18/02/28 13:45:48 INFO TaskSchedulerImpl: Removed TaskSet 224.0, whose tasks have all completed, from pool 
18/02/28 13:45:48 INFO DAGScheduler: ResultStage 224 (collect at utils.scala:211) finished in 0.007 s
18/02/28 13:45:48 INFO DAGScheduler: Job 112 finished: collect at utils.scala:211, took 0.011899 s
18/02/28 13:46:28 INFO SparkContext: Invoking stop() from shutdown hook
18/02/28 13:46:28 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
18/02/28 13:46:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/02/28 13:46:28 INFO MemoryStore: MemoryStore cleared
18/02/28 13:46:28 INFO BlockManager: BlockManager stopped
18/02/28 13:46:28 INFO BlockManagerMaster: BlockManagerMaster stopped
18/02/28 13:46:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/02/28 13:46:28 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-270041d1-4711-4c11-beb7-662a8c46d069\userFiles-acafcda6-52e6-4d03-8ea3-6b371ffbc1ad
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-270041d1-4711-4c11-beb7-662a8c46d069\userFiles-acafcda6-52e6-4d03-8ea3-6b371ffbc1ad
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1937)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1936)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 13:46:28 INFO SparkContext: Successfully stopped SparkContext
18/02/28 13:46:28 INFO ShutdownHookManager: Shutdown hook called
18/02/28 13:46:28 INFO ShutdownHookManager: Deleting directory C:\Users\JC\AppData\Local\Temp\spark-270041d1-4711-4c11-beb7-662a8c46d069
18/02/28 13:46:28 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-270041d1-4711-4c11-beb7-662a8c46d069
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-270041d1-4711-4c11-beb7-662a8c46d069
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 13:46:28 INFO ShutdownHookManager: Deleting directory C:\Users\JC\AppData\Local\Temp\spark-270041d1-4711-4c11-beb7-662a8c46d069\userFiles-acafcda6-52e6-4d03-8ea3-6b371ffbc1ad
18/02/28 13:46:28 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-270041d1-4711-4c11-beb7-662a8c46d069\userFiles-acafcda6-52e6-4d03-8ea3-6b371ffbc1ad
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-270041d1-4711-4c11-beb7-662a8c46d069\userFiles-acafcda6-52e6-4d03-8ea3-6b371ffbc1ad
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 13:47:50 INFO SparkContext: Running Spark version 2.2.0
18/02/28 13:47:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/02/28 13:47:50 INFO SparkContext: Submitted application: sparklyr
18/02/28 13:47:50 INFO SecurityManager: Changing view acls to: JC
18/02/28 13:47:50 INFO SecurityManager: Changing modify acls to: JC
18/02/28 13:47:50 INFO SecurityManager: Changing view acls groups to: 
18/02/28 13:47:50 INFO SecurityManager: Changing modify acls groups to: 
18/02/28 13:47:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(JC); groups with view permissions: Set(); users  with modify permissions: Set(JC); groups with modify permissions: Set()
18/02/28 13:47:51 INFO Utils: Successfully started service 'sparkDriver' on port 61143.
18/02/28 13:47:51 INFO SparkEnv: Registering MapOutputTracker
18/02/28 13:47:51 INFO SparkEnv: Registering BlockManagerMaster
18/02/28 13:47:51 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/02/28 13:47:51 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/02/28 13:47:51 INFO DiskBlockManager: Created local directory at C:\Users\JC\AppData\Local\Temp\blockmgr-f4c39716-96c0-4e8f-bf43-3fc7bbab51ef
18/02/28 13:47:51 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/02/28 13:47:51 INFO SparkEnv: Registering OutputCommitCoordinator
18/02/28 13:47:51 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/02/28 13:47:51 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
18/02/28 13:47:51 INFO SparkContext: Added JAR file:/C:/Users/JC/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:61143/jars/sparklyr-2.2-2.11.jar with timestamp 1519854471597
18/02/28 13:47:51 INFO Executor: Starting executor ID driver on host localhost
18/02/28 13:47:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61164.
18/02/28 13:47:51 INFO NettyBlockTransferService: Server created on 127.0.0.1:61164
18/02/28 13:47:51 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/02/28 13:47:51 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 61164, None)
18/02/28 13:47:51 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:61164 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 61164, None)
18/02/28 13:47:51 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 61164, None)
18/02/28 13:47:51 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 61164, None)
18/02/28 13:47:52 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/02/28 13:47:52 INFO SharedState: loading hive config file: file:/C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
18/02/28 13:47:52 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:\Users\JC\AppData\Local\spark\spark-2.2.0-bin-hadoop2.7\tmp\hive') to the value of spark.sql.warehouse.dir ('C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive').
18/02/28 13:47:52 INFO SharedState: Warehouse path is 'C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive'.
18/02/28 13:47:53 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
18/02/28 13:47:54 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
18/02/28 13:47:54 INFO ObjectStore: ObjectStore, initialize called
18/02/28 13:47:54 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
18/02/28 13:47:54 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
18/02/28 13:47:56 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
18/02/28 13:47:57 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 13:47:57 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 13:47:58 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 13:47:58 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 13:47:58 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
18/02/28 13:47:58 INFO ObjectStore: Initialized ObjectStore
18/02/28 13:47:58 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
18/02/28 13:47:59 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
18/02/28 13:47:59 INFO HiveMetaStore: Added admin role in metastore
18/02/28 13:47:59 INFO HiveMetaStore: Added public role in metastore
18/02/28 13:47:59 INFO HiveMetaStore: No user is added in admin role, since config is empty
18/02/28 13:47:59 INFO HiveMetaStore: 0: get_all_databases
18/02/28 13:47:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_all_databases	
18/02/28 13:47:59 INFO HiveMetaStore: 0: get_functions: db=default pat=*
18/02/28 13:47:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
18/02/28 13:47:59 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 13:47:59 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/Temp/e21bb53f-8ba2-4330-a6a6-2d0bea1e65fc_resources
18/02/28 13:47:59 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/e21bb53f-8ba2-4330-a6a6-2d0bea1e65fc
18/02/28 13:47:59 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/e21bb53f-8ba2-4330-a6a6-2d0bea1e65fc
18/02/28 13:47:59 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/e21bb53f-8ba2-4330-a6a6-2d0bea1e65fc/_tmp_space.db
18/02/28 13:47:59 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive
18/02/28 13:47:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:47:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:47:59 INFO HiveMetaStore: 0: get_database: global_temp
18/02/28 13:47:59 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: global_temp	
18/02/28 13:47:59 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
18/02/28 13:48:00 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/Temp/f3ff8009-50e2-4e51-8a4f-745da24308c5_resources
18/02/28 13:48:00 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/f3ff8009-50e2-4e51-8a4f-745da24308c5
18/02/28 13:48:00 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/f3ff8009-50e2-4e51-8a4f-745da24308c5
18/02/28 13:48:00 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/f3ff8009-50e2-4e51-8a4f-745da24308c5/_tmp_space.db
18/02/28 13:48:00 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive
18/02/28 13:48:00 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
18/02/28 13:48:00 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 13:48:02 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:48:02 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:48:02 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:48:02 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:48:02 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 13:48:02 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 13:48:03 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 13:48:03 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
18/02/28 13:48:03 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
18/02/28 13:48:03 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:48:03 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:03 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55), which has no missing parents
18/02/28 13:48:03 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
18/02/28 13:48:03 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
18/02/28 13:48:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:61164 (size: 3.4 KB, free: 366.3 MB)
18/02/28 13:48:03 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0))
18/02/28 13:48:03 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/02/28 13:48:03 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 13:48:03 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/02/28 13:48:03 INFO Executor: Fetching spark://127.0.0.1:61143/jars/sparklyr-2.2-2.11.jar with timestamp 1519854471597
18/02/28 13:48:03 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:61143 after 27 ms (0 ms spent in bootstraps)
18/02/28 13:48:03 INFO Utils: Fetching spark://127.0.0.1:61143/jars/sparklyr-2.2-2.11.jar to C:\Users\JC\AppData\Local\Temp\spark-b809cd80-489a-49cf-bdaa-44d24bceeb26\userFiles-33f96b26-e344-4cc0-9504-08e309e9d1d5\fetchFileTemp4323126838214745172.tmp
18/02/28 13:48:03 INFO Executor: Adding file:/C:/Users/JC/AppData/Local/Temp/spark-b809cd80-489a-49cf-bdaa-44d24bceeb26/userFiles-33f96b26-e344-4cc0-9504-08e309e9d1d5/sparklyr-2.2-2.11.jar to class loader
18/02/28 13:48:04 INFO CodeGenerator: Code generated in 389.752036 ms
18/02/28 13:48:04 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
18/02/28 13:48:04 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 966 ms on localhost (executor driver) (1/1)
18/02/28 13:48:04 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/02/28 13:48:04 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.992 s
18/02/28 13:48:04 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 1.204998 s
18/02/28 13:48:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:04 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 13:48:04 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:48:04 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:48:04 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:48:04 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:48:04 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 13:48:04 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 13:48:04 INFO SparkSqlParser: Parsing command: spark_flights
18/02/28 13:48:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_flights` AS `zzz1`
WHERE (0 = 1)
18/02/28 13:48:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_flights`
18/02/28 13:48:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:05 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_flights`
18/02/28 13:48:05 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:48:05 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:48:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:05 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_flights`
LIMIT 10
18/02/28 13:48:05 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:48:05 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:48:05 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 13:48:05 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 13:48:05 INFO FileSourceStrategy: Output Data Schema: struct<>
18/02/28 13:48:05 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 13:48:05 INFO CodeGenerator: Code generated in 23.871811 ms
18/02/28 13:48:05 INFO CodeGenerator: Code generated in 13.346549 ms
18/02/28 13:48:05 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 282.5 KB, free 366.0 MB)
18/02/28 13:48:05 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 24.1 KB, free 366.0 MB)
18/02/28 13:48:05 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:61164 (size: 24.1 KB, free: 366.3 MB)
18/02/28 13:48:05 INFO SparkContext: Created broadcast 1 from collect at utils.scala:211
18/02/28 13:48:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21019222 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 13:48:06 INFO ContextCleaner: Cleaned accumulator 0
18/02/28 13:48:06 INFO ContextCleaner: Cleaned accumulator 49
18/02/28 13:48:06 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:48:06 INFO DAGScheduler: Registering RDD 7 (collect at utils.scala:211)
18/02/28 13:48:06 INFO DAGScheduler: Got job 1 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:48:06 INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:211)
18/02/28 13:48:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
18/02/28 13:48:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
18/02/28 13:48:06 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:06 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:61164 in memory (size: 3.4 KB, free: 366.3 MB)
18/02/28 13:48:06 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 14.2 KB, free 366.0 MB)
18/02/28 13:48:06 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 8.0 KB, free 366.0 MB)
18/02/28 13:48:06 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:61164 (size: 8.0 KB, free: 366.3 MB)
18/02/28 13:48:06 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:06 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:06 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks
18/02/28 13:48:06 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:06 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:06 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:48:06 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:06 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
18/02/28 13:48:06 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
18/02/28 13:48:06 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
18/02/28 13:48:06 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
18/02/28 13:48:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_3.csv, range: 0-2881793, partition values: [empty row]
18/02/28 13:48:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_11.csv, range: 0-2757037, partition values: [empty row]
18/02/28 13:48:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_7.csv, range: 0-2938867, partition values: [empty row]
18/02/28 13:48:06 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_4.csv, range: 0-2830543, partition values: [empty row]
18/02/28 13:48:06 INFO CodeGenerator: Code generated in 6.641539 ms
18/02/28 13:48:07 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_6.csv, range: 0-2820227, partition values: [empty row]
18/02/28 13:48:07 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_8.csv, range: 0-2932019, partition values: [empty row]
18/02/28 13:48:07 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_1.csv, range: 0-2697256, partition values: [empty row]
18/02/28 13:48:07 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_5.csv, range: 0-2880181, partition values: [empty row]
18/02/28 13:48:07 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_9.csv, range: 0-2763076, partition values: [empty row]
18/02/28 13:48:07 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_2.csv, range: 0-2487144, partition values: [empty row]
18/02/28 13:48:07 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_10.csv, range: 0-2920629, partition values: [empty row]
18/02/28 13:48:07 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_12.csv, range: 0-2836468, partition values: [empty row]
18/02/28 13:48:07 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1628 bytes result sent to driver
18/02/28 13:48:07 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 1628 bytes result sent to driver
18/02/28 13:48:07 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1246 ms on localhost (executor driver) (1/4)
18/02/28 13:48:07 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 1244 ms on localhost (executor driver) (2/4)
18/02/28 13:48:07 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1628 bytes result sent to driver
18/02/28 13:48:07 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1257 ms on localhost (executor driver) (3/4)
18/02/28 13:48:07 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1585 bytes result sent to driver
18/02/28 13:48:07 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1259 ms on localhost (executor driver) (4/4)
18/02/28 13:48:07 INFO DAGScheduler: ShuffleMapStage 1 (collect at utils.scala:211) finished in 1.264 s
18/02/28 13:48:07 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:48:07 INFO DAGScheduler: running: Set()
18/02/28 13:48:07 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/02/28 13:48:07 INFO DAGScheduler: waiting: Set(ResultStage 2)
18/02/28 13:48:07 INFO DAGScheduler: failed: Set()
18/02/28 13:48:07 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[10] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:07 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.9 KB, free 366.0 MB)
18/02/28 13:48:07 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.0 MB)
18/02/28 13:48:07 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:61164 (size: 3.7 KB, free: 366.3 MB)
18/02/28 13:48:07 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:48:07 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
18/02/28 13:48:07 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:48:07 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
18/02/28 13:48:07 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
18/02/28 13:48:07 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1514 bytes result sent to driver
18/02/28 13:48:07 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 60 ms on localhost (executor driver) (1/1)
18/02/28 13:48:07 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/02/28 13:48:07 INFO DAGScheduler: ResultStage 2 (collect at utils.scala:211) finished in 0.061 s
18/02/28 13:48:07 INFO DAGScheduler: Job 1 finished: collect at utils.scala:211, took 1.419811 s
18/02/28 13:48:07 INFO CodeGenerator: Code generated in 8.75724 ms
18/02/28 13:48:07 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:07 INFO SparkSqlParser: Parsing command: SELECT `month`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`, `sched_dep_time`, `sched_arr_time`
FROM (SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`dep_time` AS DOUBLE) AS `dep_time`, CAST(`arr_time` AS DOUBLE) AS `arr_time`, CAST(`arr_delay` AS DOUBLE) AS `arr_delay`, CAST(`dep_delay` AS DOUBLE) AS `dep_delay`, CAST(`distance` AS DOUBLE) AS `distance`, CAST(`sched_dep_time` AS DOUBLE) AS `sched_dep_time`, CAST(`sched_arr_time` AS DOUBLE) AS `sched_arr_time`
FROM (SELECT `month`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`, `sched_dep_time`, `sched_arr_time`
FROM `spark_flights`) `zibmghssnm`) `tdatpbjxcw`
18/02/28 13:48:07 INFO SparkSqlParser: Parsing command: cached_flights
18/02/28 13:48:07 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:07 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights` AS `zzz2`
WHERE (0 = 1)
18/02/28 13:48:07 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:07 INFO SparkSqlParser: Parsing command: CACHE TABLE `cached_flights`
18/02/28 13:48:08 INFO SparkSqlParser: Parsing command: `cached_flights`
18/02/28 13:48:08 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 13:48:08 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 13:48:08 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dep_time: string, sched_dep_time: string, dep_delay: string, arr_time: string ... 6 more fields>
18/02/28 13:48:08 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 13:48:08 INFO CodeGenerator: Code generated in 24.05905 ms
18/02/28 13:48:08 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 282.5 KB, free 365.7 MB)
18/02/28 13:48:08 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.7 MB)
18/02/28 13:48:08 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:61164 (size: 24.1 KB, free: 366.2 MB)
18/02/28 13:48:08 INFO SparkContext: Created broadcast 4 from sql at <unknown>:0
18/02/28 13:48:08 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21019222 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 13:48:08 INFO CodeGenerator: Code generated in 15.069436 ms
18/02/28 13:48:08 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 13:48:08 INFO DAGScheduler: Registering RDD 16 (sql at <unknown>:0)
18/02/28 13:48:08 INFO DAGScheduler: Got job 2 (sql at <unknown>:0) with 1 output partitions
18/02/28 13:48:08 INFO DAGScheduler: Final stage: ResultStage 4 (sql at <unknown>:0)
18/02/28 13:48:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
18/02/28 13:48:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
18/02/28 13:48:08 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[16] at sql at <unknown>:0), which has no missing parents
18/02/28 13:48:08 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 26.7 KB, free 365.6 MB)
18/02/28 13:48:08 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 11.7 KB, free 365.6 MB)
18/02/28 13:48:08 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:61164 (size: 11.7 KB, free: 366.2 MB)
18/02/28 13:48:08 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:08 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[16] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:08 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks
18/02/28 13:48:08 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:08 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:08 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 8, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:48:08 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 9, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:08 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)
18/02/28 13:48:08 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)
18/02/28 13:48:08 INFO Executor: Running task 2.0 in stage 3.0 (TID 8)
18/02/28 13:48:08 INFO Executor: Running task 3.0 in stage 3.0 (TID 9)
18/02/28 13:48:08 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_4.csv, range: 0-2830543, partition values: [empty row]
18/02/28 13:48:08 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_11.csv, range: 0-2757037, partition values: [empty row]
18/02/28 13:48:08 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_7.csv, range: 0-2938867, partition values: [empty row]
18/02/28 13:48:08 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_3.csv, range: 0-2881793, partition values: [empty row]
18/02/28 13:48:08 INFO CodeGenerator: Code generated in 33.666097 ms
18/02/28 13:48:08 INFO ContextCleaner: Cleaned accumulator 119
18/02/28 13:48:08 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:61164 in memory (size: 3.7 KB, free: 366.2 MB)
18/02/28 13:48:08 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:61164 in memory (size: 8.0 KB, free: 366.2 MB)
18/02/28 13:48:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_1.csv, range: 0-2697256, partition values: [empty row]
18/02/28 13:48:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_6.csv, range: 0-2820227, partition values: [empty row]
18/02/28 13:48:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_5.csv, range: 0-2880181, partition values: [empty row]
18/02/28 13:48:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_8.csv, range: 0-2932019, partition values: [empty row]
18/02/28 13:48:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_2.csv, range: 0-2487144, partition values: [empty row]
18/02/28 13:48:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_9.csv, range: 0-2763076, partition values: [empty row]
18/02/28 13:48:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_12.csv, range: 0-2836468, partition values: [empty row]
18/02/28 13:48:09 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_10.csv, range: 0-2920629, partition values: [empty row]
18/02/28 13:48:09 INFO MemoryStore: Block rdd_13_3 stored as values in memory (estimated size 4.8 MB, free 360.9 MB)
18/02/28 13:48:09 INFO BlockManagerInfo: Added rdd_13_3 in memory on 127.0.0.1:61164 (size: 4.8 MB, free: 361.4 MB)
18/02/28 13:48:09 INFO CodeGenerator: Code generated in 11.553845 ms
18/02/28 13:48:10 INFO CodeGenerator: Code generated in 97.460489 ms
18/02/28 13:48:10 INFO MemoryStore: Block rdd_13_1 stored as values in memory (estimated size 5.2 MB, free 355.6 MB)
18/02/28 13:48:10 INFO BlockManagerInfo: Added rdd_13_1 in memory on 127.0.0.1:61164 (size: 5.2 MB, free: 356.2 MB)
18/02/28 13:48:10 INFO MemoryStore: Block rdd_13_2 stored as values in memory (estimated size 5.1 MB, free 350.5 MB)
18/02/28 13:48:10 INFO BlockManagerInfo: Added rdd_13_2 in memory on 127.0.0.1:61164 (size: 5.1 MB, free: 351.1 MB)
18/02/28 13:48:10 INFO Executor: Finished task 3.0 in stage 3.0 (TID 9). 2504 bytes result sent to driver
18/02/28 13:48:10 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 9) in 1916 ms on localhost (executor driver) (1/4)
18/02/28 13:48:10 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 2547 bytes result sent to driver
18/02/28 13:48:10 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 1922 ms on localhost (executor driver) (2/4)
18/02/28 13:48:10 INFO MemoryStore: Block rdd_13_0 stored as values in memory (estimated size 5.3 MB, free 345.2 MB)
18/02/28 13:48:10 INFO BlockManagerInfo: Added rdd_13_0 in memory on 127.0.0.1:61164 (size: 5.3 MB, free: 345.8 MB)
18/02/28 13:48:10 INFO Executor: Finished task 2.0 in stage 3.0 (TID 8). 2461 bytes result sent to driver
18/02/28 13:48:10 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 8) in 1932 ms on localhost (executor driver) (3/4)
18/02/28 13:48:10 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 2547 bytes result sent to driver
18/02/28 13:48:10 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 1946 ms on localhost (executor driver) (4/4)
18/02/28 13:48:10 INFO DAGScheduler: ShuffleMapStage 3 (sql at <unknown>:0) finished in 1.948 s
18/02/28 13:48:10 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:48:10 INFO DAGScheduler: running: Set()
18/02/28 13:48:10 INFO DAGScheduler: waiting: Set(ResultStage 4)
18/02/28 13:48:10 INFO DAGScheduler: failed: Set()
18/02/28 13:48:10 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[19] at sql at <unknown>:0), which has no missing parents
18/02/28 13:48:10 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/02/28 13:48:10 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.0 KB, free 345.2 MB)
18/02/28 13:48:10 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.7 KB, free 345.2 MB)
18/02/28 13:48:10 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:61164 (size: 3.7 KB, free: 345.8 MB)
18/02/28 13:48:10 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 13:48:10 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
18/02/28 13:48:10 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 10, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:48:10 INFO Executor: Running task 0.0 in stage 4.0 (TID 10)
18/02/28 13:48:10 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:48:10 INFO Executor: Finished task 0.0 in stage 4.0 (TID 10). 1581 bytes result sent to driver
18/02/28 13:48:10 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 10) in 9 ms on localhost (executor driver) (1/1)
18/02/28 13:48:10 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/02/28 13:48:10 INFO DAGScheduler: ResultStage 4 (sql at <unknown>:0) finished in 0.010 s
18/02/28 13:48:10 INFO DAGScheduler: Job 2 finished: sql at <unknown>:0, took 2.000176 s
18/02/28 13:48:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:10 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `cached_flights`
18/02/28 13:48:10 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:48:10 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:48:10 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:48:10 INFO DAGScheduler: Registering RDD 22 (collect at utils.scala:211)
18/02/28 13:48:10 INFO DAGScheduler: Got job 3 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:48:10 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:211)
18/02/28 13:48:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
18/02/28 13:48:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
18/02/28 13:48:10 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[22] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:10 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 26.7 KB, free 345.2 MB)
18/02/28 13:48:10 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.7 KB, free 345.2 MB)
18/02/28 13:48:10 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:61164 (size: 11.7 KB, free: 345.8 MB)
18/02/28 13:48:10 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:10 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[22] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:10 INFO TaskSchedulerImpl: Adding task set 5.0 with 4 tasks
18/02/28 13:48:10 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:10 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 12, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:10 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 13, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:48:10 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 14, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:10 INFO Executor: Running task 0.0 in stage 5.0 (TID 11)
18/02/28 13:48:10 INFO Executor: Running task 1.0 in stage 5.0 (TID 12)
18/02/28 13:48:10 INFO Executor: Running task 2.0 in stage 5.0 (TID 13)
18/02/28 13:48:10 INFO Executor: Running task 3.0 in stage 5.0 (TID 14)
18/02/28 13:48:10 INFO BlockManager: Found block rdd_13_2 locally
18/02/28 13:48:10 INFO BlockManager: Found block rdd_13_3 locally
18/02/28 13:48:10 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 13:48:10 INFO BlockManager: Found block rdd_13_1 locally
18/02/28 13:48:10 INFO Executor: Finished task 1.0 in stage 5.0 (TID 12). 1737 bytes result sent to driver
18/02/28 13:48:10 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 12) in 51 ms on localhost (executor driver) (1/4)
18/02/28 13:48:10 INFO Executor: Finished task 0.0 in stage 5.0 (TID 11). 1694 bytes result sent to driver
18/02/28 13:48:10 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 11) in 63 ms on localhost (executor driver) (2/4)
18/02/28 13:48:10 INFO Executor: Finished task 2.0 in stage 5.0 (TID 13). 1780 bytes result sent to driver
18/02/28 13:48:10 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 13) in 64 ms on localhost (executor driver) (3/4)
18/02/28 13:48:10 INFO Executor: Finished task 3.0 in stage 5.0 (TID 14). 1737 bytes result sent to driver
18/02/28 13:48:10 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 14) in 70 ms on localhost (executor driver) (4/4)
18/02/28 13:48:10 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/02/28 13:48:10 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:211) finished in 0.075 s
18/02/28 13:48:10 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:48:10 INFO DAGScheduler: running: Set()
18/02/28 13:48:10 INFO DAGScheduler: waiting: Set(ResultStage 6)
18/02/28 13:48:10 INFO DAGScheduler: failed: Set()
18/02/28 13:48:10 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:10 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.0 KB, free 345.1 MB)
18/02/28 13:48:10 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.7 KB, free 345.1 MB)
18/02/28 13:48:10 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:61164 (size: 3.7 KB, free: 345.8 MB)
18/02/28 13:48:10 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:48:10 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
18/02/28 13:48:10 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 15, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:48:10 INFO Executor: Running task 0.0 in stage 6.0 (TID 15)
18/02/28 13:48:10 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:48:10 INFO Executor: Finished task 0.0 in stage 6.0 (TID 15). 1495 bytes result sent to driver
18/02/28 13:48:10 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 15) in 8 ms on localhost (executor driver) (1/1)
18/02/28 13:48:10 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
18/02/28 13:48:10 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:211) finished in 0.009 s
18/02/28 13:48:10 INFO DAGScheduler: Job 3 finished: collect at utils.scala:211, took 0.124457 s
18/02/28 13:48:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:10 INFO SparkSqlParser: Parsing command: SHOW TABLES LIKE"cached_flights"
18/02/28 13:48:10 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:48:10 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:48:10 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:48:10 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:48:10 INFO HiveMetaStore: 0: get_tables: db=default pat=cached_flights
18/02/28 13:48:10 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=cached_flights	
18/02/28 13:48:10 INFO CodeGenerator: Code generated in 13.461855 ms
18/02/28 13:48:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:10 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights` AS `zzz3`
WHERE (0 = 1)
18/02/28 13:48:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:10 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `cached_flights`
18/02/28 13:48:10 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:48:10 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:48:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:10 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `cached_flights`
LIMIT 10
18/02/28 13:48:10 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:48:10 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:48:10 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:48:10 INFO DAGScheduler: Registering RDD 28 (collect at utils.scala:211)
18/02/28 13:48:10 INFO DAGScheduler: Got job 4 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:48:10 INFO DAGScheduler: Final stage: ResultStage 8 (collect at utils.scala:211)
18/02/28 13:48:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
18/02/28 13:48:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
18/02/28 13:48:10 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[28] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:10 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 26.7 KB, free 345.1 MB)
18/02/28 13:48:10 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 11.7 KB, free 345.1 MB)
18/02/28 13:48:10 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:61164 (size: 11.7 KB, free: 345.7 MB)
18/02/28 13:48:10 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:10 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[28] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:10 INFO TaskSchedulerImpl: Adding task set 7.0 with 4 tasks
18/02/28 13:48:10 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:10 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 17, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:10 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 18, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:48:10 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 19, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:10 INFO Executor: Running task 0.0 in stage 7.0 (TID 16)
18/02/28 13:48:10 INFO Executor: Running task 1.0 in stage 7.0 (TID 17)
18/02/28 13:48:10 INFO Executor: Running task 2.0 in stage 7.0 (TID 18)
18/02/28 13:48:10 INFO Executor: Running task 3.0 in stage 7.0 (TID 19)
18/02/28 13:48:10 INFO BlockManager: Found block rdd_13_2 locally
18/02/28 13:48:10 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 13:48:10 INFO BlockManager: Found block rdd_13_1 locally
18/02/28 13:48:10 INFO BlockManager: Found block rdd_13_3 locally
18/02/28 13:48:10 INFO Executor: Finished task 0.0 in stage 7.0 (TID 16). 1737 bytes result sent to driver
18/02/28 13:48:10 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 16) in 67 ms on localhost (executor driver) (1/4)
18/02/28 13:48:10 INFO Executor: Finished task 3.0 in stage 7.0 (TID 19). 1737 bytes result sent to driver
18/02/28 13:48:10 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 19) in 74 ms on localhost (executor driver) (2/4)
18/02/28 13:48:10 INFO Executor: Finished task 2.0 in stage 7.0 (TID 18). 1737 bytes result sent to driver
18/02/28 13:48:10 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 18) in 91 ms on localhost (executor driver) (3/4)
18/02/28 13:48:10 INFO Executor: Finished task 1.0 in stage 7.0 (TID 17). 1780 bytes result sent to driver
18/02/28 13:48:10 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 17) in 95 ms on localhost (executor driver) (4/4)
18/02/28 13:48:10 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
18/02/28 13:48:10 INFO DAGScheduler: ShuffleMapStage 7 (collect at utils.scala:211) finished in 0.098 s
18/02/28 13:48:10 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:48:10 INFO DAGScheduler: running: Set()
18/02/28 13:48:10 INFO DAGScheduler: waiting: Set(ResultStage 8)
18/02/28 13:48:10 INFO DAGScheduler: failed: Set()
18/02/28 13:48:10 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[31] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:10 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 6.9 KB, free 345.1 MB)
18/02/28 13:48:10 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.7 KB, free 345.1 MB)
18/02/28 13:48:10 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:61164 (size: 3.7 KB, free: 345.7 MB)
18/02/28 13:48:10 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[31] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:48:10 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
18/02/28 13:48:10 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 20, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:48:10 INFO Executor: Running task 0.0 in stage 8.0 (TID 20)
18/02/28 13:48:10 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:48:10 INFO Executor: Finished task 0.0 in stage 8.0 (TID 20). 1514 bytes result sent to driver
18/02/28 13:48:10 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 20) in 8 ms on localhost (executor driver) (1/1)
18/02/28 13:48:10 INFO DAGScheduler: ResultStage 8 (collect at utils.scala:211) finished in 0.010 s
18/02/28 13:48:10 INFO DAGScheduler: Job 4 finished: collect at utils.scala:211, took 0.128344 s
18/02/28 13:48:10 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
18/02/28 13:48:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
LIMIT 6
18/02/28 13:48:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
LIMIT 6
18/02/28 13:48:11 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:48:11 INFO DAGScheduler: Got job 5 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:48:11 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:211)
18/02/28 13:48:11 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:48:11 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:11 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[33] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:11 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 22.8 KB, free 345.1 MB)
18/02/28 13:48:11 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 10.3 KB, free 345.1 MB)
18/02/28 13:48:11 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:61164 (size: 10.3 KB, free: 345.7 MB)
18/02/28 13:48:11 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[33] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:48:11 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
18/02/28 13:48:11 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:11 INFO Executor: Running task 0.0 in stage 9.0 (TID 21)
18/02/28 13:48:11 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 13:48:11 INFO CodeGenerator: Code generated in 73.977967 ms
18/02/28 13:48:11 INFO Executor: 1 block locks were not released by TID = 21:
[rdd_13_0]
18/02/28 13:48:11 INFO Executor: Finished task 0.0 in stage 9.0 (TID 21). 1474 bytes result sent to driver
18/02/28 13:48:11 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 21) in 118 ms on localhost (executor driver) (1/1)
18/02/28 13:48:11 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
18/02/28 13:48:11 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:211) finished in 0.119 s
18/02/28 13:48:11 INFO DAGScheduler: Job 5 finished: collect at utils.scala:211, took 0.133582 s
18/02/28 13:48:11 INFO CodeGenerator: Code generated in 14.08105 ms
18/02/28 13:48:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:11 INFO SparkSqlParser: Parsing command: SELECT `month`, count(*) AS `n()`
FROM `cached_flights`
GROUP BY `month`
18/02/28 13:48:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:48:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:48:11 INFO CodeGenerator: Code generated in 39.845004 ms
18/02/28 13:48:11 INFO CodeGenerator: Code generated in 57.122879 ms
18/02/28 13:48:11 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:48:11 INFO DAGScheduler: Registering RDD 36 (collect at utils.scala:211)
18/02/28 13:48:11 INFO DAGScheduler: Got job 6 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:48:11 INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:211)
18/02/28 13:48:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
18/02/28 13:48:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
18/02/28 13:48:11 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[36] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:11 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 37.3 KB, free 345.0 MB)
18/02/28 13:48:11 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 16.6 KB, free 345.0 MB)
18/02/28 13:48:11 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:61164 (size: 16.6 KB, free: 345.7 MB)
18/02/28 13:48:11 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:11 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[36] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:11 INFO TaskSchedulerImpl: Adding task set 10.0 with 4 tasks
18/02/28 13:48:11 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:11 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:11 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:48:11 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:11 INFO Executor: Running task 0.0 in stage 10.0 (TID 22)
18/02/28 13:48:11 INFO Executor: Running task 1.0 in stage 10.0 (TID 23)
18/02/28 13:48:11 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 13:48:11 INFO BlockManager: Found block rdd_13_1 locally
18/02/28 13:48:11 INFO Executor: Running task 3.0 in stage 10.0 (TID 25)
18/02/28 13:48:11 INFO Executor: Running task 2.0 in stage 10.0 (TID 24)
18/02/28 13:48:11 INFO BlockManager: Found block rdd_13_2 locally
18/02/28 13:48:11 INFO BlockManager: Found block rdd_13_3 locally
18/02/28 13:48:11 INFO CodeGenerator: Code generated in 27.209683 ms
18/02/28 13:48:11 INFO CodeGenerator: Code generated in 8.812249 ms
18/02/28 13:48:11 INFO CodeGenerator: Code generated in 18.621698 ms
18/02/28 13:48:11 INFO CodeGenerator: Code generated in 9.947675 ms
18/02/28 13:48:12 INFO CodeGenerator: Code generated in 25.113022 ms
18/02/28 13:48:12 INFO CodeGenerator: Code generated in 15.767265 ms
18/02/28 13:48:12 INFO ContextCleaner: Cleaned accumulator 124
18/02/28 13:48:12 INFO ContextCleaner: Cleaned accumulator 126
18/02/28 13:48:12 INFO ContextCleaner: Cleaned accumulator 128
18/02/28 13:48:12 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:61164 in memory (size: 3.7 KB, free: 345.7 MB)
18/02/28 13:48:12 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:61164 in memory (size: 3.7 KB, free: 345.7 MB)
18/02/28 13:48:12 INFO ContextCleaner: Cleaned accumulator 121
18/02/28 13:48:12 INFO ContextCleaner: Cleaned shuffle 1
18/02/28 13:48:12 INFO ContextCleaner: Cleaned accumulator 327
18/02/28 13:48:12 INFO ContextCleaner: Cleaned accumulator 122
18/02/28 13:48:12 INFO ContextCleaner: Cleaned accumulator 125
18/02/28 13:48:12 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:61164 in memory (size: 11.7 KB, free: 345.7 MB)
18/02/28 13:48:12 INFO ContextCleaner: Cleaned accumulator 120
18/02/28 13:48:12 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:61164 in memory (size: 11.7 KB, free: 345.7 MB)
18/02/28 13:48:12 INFO ContextCleaner: Cleaned accumulator 241
18/02/28 13:48:12 INFO ContextCleaner: Cleaned accumulator 130
18/02/28 13:48:12 INFO ContextCleaner: Cleaned accumulator 123
18/02/28 13:48:12 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:61164 in memory (size: 11.7 KB, free: 345.8 MB)
18/02/28 13:48:12 INFO ContextCleaner: Cleaned accumulator 180
18/02/28 13:48:12 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:61164 in memory (size: 10.3 KB, free: 345.8 MB)
18/02/28 13:48:12 INFO ContextCleaner: Cleaned accumulator 131
18/02/28 13:48:12 INFO ContextCleaner: Cleaned accumulator 127
18/02/28 13:48:12 INFO ContextCleaner: Cleaned accumulator 129
18/02/28 13:48:12 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:61164 in memory (size: 3.7 KB, free: 345.8 MB)
18/02/28 13:48:12 INFO Executor: Finished task 3.0 in stage 10.0 (TID 25). 2054 bytes result sent to driver
18/02/28 13:48:12 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 494 ms on localhost (executor driver) (1/4)
18/02/28 13:48:12 INFO Executor: Finished task 1.0 in stage 10.0 (TID 23). 2011 bytes result sent to driver
18/02/28 13:48:12 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 514 ms on localhost (executor driver) (2/4)
18/02/28 13:48:12 INFO Executor: Finished task 0.0 in stage 10.0 (TID 22). 2054 bytes result sent to driver
18/02/28 13:48:12 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 531 ms on localhost (executor driver) (3/4)
18/02/28 13:48:12 INFO Executor: Finished task 2.0 in stage 10.0 (TID 24). 2011 bytes result sent to driver
18/02/28 13:48:12 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 542 ms on localhost (executor driver) (4/4)
18/02/28 13:48:12 INFO DAGScheduler: ShuffleMapStage 10 (collect at utils.scala:211) finished in 0.544 s
18/02/28 13:48:12 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:48:12 INFO DAGScheduler: running: Set()
18/02/28 13:48:12 INFO DAGScheduler: waiting: Set(ResultStage 11)
18/02/28 13:48:12 INFO DAGScheduler: failed: Set()
18/02/28 13:48:12 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[39] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:12 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 17.6 KB, free 345.2 MB)
18/02/28 13:48:12 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 8.2 KB, free 345.2 MB)
18/02/28 13:48:12 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
18/02/28 13:48:12 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:61164 (size: 8.2 KB, free: 345.8 MB)
18/02/28 13:48:12 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:12 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 11 (MapPartitionsRDD[39] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:12 INFO TaskSchedulerImpl: Adding task set 11.0 with 4 tasks
18/02/28 13:48:12 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 26, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:48:12 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 27, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 13:48:12 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 28, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 13:48:12 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 29, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 13:48:12 INFO Executor: Running task 0.0 in stage 11.0 (TID 26)
18/02/28 13:48:12 INFO Executor: Running task 1.0 in stage 11.0 (TID 27)
18/02/28 13:48:12 INFO Executor: Running task 2.0 in stage 11.0 (TID 28)
18/02/28 13:48:12 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 13:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:48:12 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 13:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:48:12 INFO Executor: Running task 3.0 in stage 11.0 (TID 29)
18/02/28 13:48:12 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:48:12 INFO Executor: Finished task 3.0 in stage 11.0 (TID 29). 2297 bytes result sent to driver
18/02/28 13:48:12 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 13:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:48:12 INFO Executor: Finished task 2.0 in stage 11.0 (TID 28). 2281 bytes result sent to driver
18/02/28 13:48:12 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 29) in 36 ms on localhost (executor driver) (1/4)
18/02/28 13:48:12 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 28) in 37 ms on localhost (executor driver) (2/4)
18/02/28 13:48:12 INFO Executor: Finished task 1.0 in stage 11.0 (TID 27). 2220 bytes result sent to driver
18/02/28 13:48:12 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 27) in 39 ms on localhost (executor driver) (3/4)
18/02/28 13:48:12 INFO Executor: Finished task 0.0 in stage 11.0 (TID 26). 2281 bytes result sent to driver
18/02/28 13:48:12 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 26) in 44 ms on localhost (executor driver) (4/4)
18/02/28 13:48:12 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
18/02/28 13:48:12 INFO DAGScheduler: ResultStage 11 (collect at utils.scala:211) finished in 0.045 s
18/02/28 13:48:12 INFO DAGScheduler: Job 6 finished: collect at utils.scala:211, took 0.614797 s
18/02/28 13:48:12 INFO CodeGenerator: Code generated in 9.241736 ms
18/02/28 13:48:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:13 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
WHERE (NOT(((`arr_delay`) IS NULL)))
18/02/28 13:48:14 INFO SparkSqlParser: Parsing command: sparklyr_tmp_292877436f08
18/02/28 13:48:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_292877436f08` AS `zzz4`
WHERE (0 = 1)
18/02/28 13:48:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_292877436f08`
18/02/28 13:48:14 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29285ee8217e
18/02/28 13:48:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29285ee8217e` AS `zzz5`
WHERE (0 = 1)
18/02/28 13:48:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:14 INFO SparkSqlParser: Parsing command: SELECT `month`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`, `sched_dep_time`, `sched_arr_time`, `delayed`, CONCAT("h", CAST(`dephour` AS INT)) AS `dephour`
FROM `sparklyr_tmp_29285ee8217e`
18/02/28 13:48:14 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:48:14 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:48:14 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29284d916c37
18/02/28 13:48:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29284d916c37` AS `zzz6`
WHERE (0 = 1)
18/02/28 13:48:14 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29284f4e3fe0
18/02/28 13:48:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29284f4e3fe0` AS `zzz7`
WHERE (0 = 1)
18/02/28 13:48:14 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29284dd8319d
18/02/28 13:48:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29284dd8319d` AS `zzz8`
WHERE (0 = 1)
18/02/28 13:48:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:14 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_29284d916c37`
18/02/28 13:48:14 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:48:14 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:48:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:14 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_29284d916c37`
LIMIT 10
18/02/28 13:48:14 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:48:14 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:48:15 INFO CodeGenerator: Code generated in 45.340185 ms
18/02/28 13:48:15 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:48:15 INFO DAGScheduler: Registering RDD 42 (collect at utils.scala:211)
18/02/28 13:48:15 INFO DAGScheduler: Got job 7 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:48:15 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:211)
18/02/28 13:48:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
18/02/28 13:48:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
18/02/28 13:48:15 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[42] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:15 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 47.6 KB, free 345.1 MB)
18/02/28 13:48:15 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 20.7 KB, free 345.1 MB)
18/02/28 13:48:15 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:61164 (size: 20.7 KB, free: 345.7 MB)
18/02/28 13:48:15 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:15 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[42] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:15 INFO TaskSchedulerImpl: Adding task set 12.0 with 4 tasks
18/02/28 13:48:15 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:15 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 31, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:15 INFO TaskSetManager: Starting task 2.0 in stage 12.0 (TID 32, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:48:15 INFO TaskSetManager: Starting task 3.0 in stage 12.0 (TID 33, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:15 INFO Executor: Running task 0.0 in stage 12.0 (TID 30)
18/02/28 13:48:15 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 13:48:15 INFO Executor: Running task 1.0 in stage 12.0 (TID 31)
18/02/28 13:48:15 INFO Executor: Running task 2.0 in stage 12.0 (TID 32)
18/02/28 13:48:15 INFO BlockManager: Found block rdd_13_1 locally
18/02/28 13:48:15 INFO Executor: Running task 3.0 in stage 12.0 (TID 33)
18/02/28 13:48:15 INFO BlockManager: Found block rdd_13_3 locally
18/02/28 13:48:15 INFO BlockManager: Found block rdd_13_2 locally
18/02/28 13:48:15 INFO CodeGenerator: Code generated in 88.691611 ms
18/02/28 13:48:15 INFO CodeGenerator: Code generated in 19.619956 ms
18/02/28 13:48:15 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:61164 in memory (size: 8.2 KB, free: 345.8 MB)
18/02/28 13:48:15 INFO ContextCleaner: Cleaned accumulator 388
18/02/28 13:48:15 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:61164 in memory (size: 16.6 KB, free: 345.8 MB)
18/02/28 13:48:16 INFO Executor: Finished task 3.0 in stage 12.0 (TID 33). 2451 bytes result sent to driver
18/02/28 13:48:16 INFO TaskSetManager: Finished task 3.0 in stage 12.0 (TID 33) in 1062 ms on localhost (executor driver) (1/4)
18/02/28 13:48:16 INFO Executor: Finished task 0.0 in stage 12.0 (TID 30). 2408 bytes result sent to driver
18/02/28 13:48:16 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 30) in 1090 ms on localhost (executor driver) (2/4)
18/02/28 13:48:16 INFO Executor: Finished task 1.0 in stage 12.0 (TID 31). 2408 bytes result sent to driver
18/02/28 13:48:16 INFO Executor: Finished task 2.0 in stage 12.0 (TID 32). 2408 bytes result sent to driver
18/02/28 13:48:16 INFO TaskSetManager: Finished task 2.0 in stage 12.0 (TID 32) in 1098 ms on localhost (executor driver) (3/4)
18/02/28 13:48:16 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 31) in 1099 ms on localhost (executor driver) (4/4)
18/02/28 13:48:16 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
18/02/28 13:48:16 INFO DAGScheduler: ShuffleMapStage 12 (collect at utils.scala:211) finished in 1.102 s
18/02/28 13:48:16 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:48:16 INFO DAGScheduler: running: Set()
18/02/28 13:48:16 INFO DAGScheduler: waiting: Set(ResultStage 13)
18/02/28 13:48:16 INFO DAGScheduler: failed: Set()
18/02/28 13:48:16 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[45] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:16 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 6.9 KB, free 345.2 MB)
18/02/28 13:48:16 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 345.2 MB)
18/02/28 13:48:16 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:61164 (size: 3.7 KB, free: 345.8 MB)
18/02/28 13:48:16 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[45] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:48:16 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
18/02/28 13:48:16 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 34, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:48:16 INFO Executor: Running task 0.0 in stage 13.0 (TID 34)
18/02/28 13:48:16 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:48:16 INFO Executor: Finished task 0.0 in stage 13.0 (TID 34). 1514 bytes result sent to driver
18/02/28 13:48:16 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 34) in 12 ms on localhost (executor driver) (1/1)
18/02/28 13:48:16 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:211) finished in 0.012 s
18/02/28 13:48:16 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
18/02/28 13:48:16 INFO DAGScheduler: Job 7 finished: collect at utils.scala:211, took 1.129159 s
18/02/28 13:48:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29284d916c37`
18/02/28 13:48:16 INFO SparkSqlParser: Parsing command: training
18/02/28 13:48:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training` AS `zzz9`
WHERE (0 = 1)
18/02/28 13:48:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:16 INFO SparkSqlParser: Parsing command: CACHE TABLE `training`
18/02/28 13:48:16 INFO SparkSqlParser: Parsing command: `training`
18/02/28 13:48:16 INFO CodeGenerator: Code generated in 38.375296 ms
18/02/28 13:48:16 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 13:48:16 INFO DAGScheduler: Registering RDD 51 (sql at <unknown>:0)
18/02/28 13:48:16 INFO DAGScheduler: Got job 8 (sql at <unknown>:0) with 1 output partitions
18/02/28 13:48:16 INFO DAGScheduler: Final stage: ResultStage 15 (sql at <unknown>:0)
18/02/28 13:48:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
18/02/28 13:48:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)
18/02/28 13:48:16 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[51] at sql at <unknown>:0), which has no missing parents
18/02/28 13:48:16 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 53.6 KB, free 345.1 MB)
18/02/28 13:48:16 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 22.0 KB, free 345.1 MB)
18/02/28 13:48:16 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:61164 (size: 22.0 KB, free: 345.7 MB)
18/02/28 13:48:16 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:16 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[51] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:16 INFO TaskSchedulerImpl: Adding task set 14.0 with 4 tasks
18/02/28 13:48:16 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:16 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 36, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:16 INFO TaskSetManager: Starting task 2.0 in stage 14.0 (TID 37, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:48:16 INFO TaskSetManager: Starting task 3.0 in stage 14.0 (TID 38, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:16 INFO Executor: Running task 0.0 in stage 14.0 (TID 35)
18/02/28 13:48:16 INFO Executor: Running task 1.0 in stage 14.0 (TID 36)
18/02/28 13:48:16 INFO Executor: Running task 2.0 in stage 14.0 (TID 37)
18/02/28 13:48:16 INFO Executor: Running task 3.0 in stage 14.0 (TID 38)
18/02/28 13:48:16 INFO BlockManager: Found block rdd_13_2 locally
18/02/28 13:48:16 INFO BlockManager: Found block rdd_13_3 locally
18/02/28 13:48:16 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 13:48:16 INFO BlockManager: Found block rdd_13_1 locally
18/02/28 13:48:17 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:61164 in memory (size: 3.7 KB, free: 345.7 MB)
18/02/28 13:48:17 INFO ContextCleaner: Cleaned accumulator 462
18/02/28 13:48:17 INFO MemoryStore: Block rdd_48_2 stored as values in memory (estimated size 58.0 KB, free 311.0 MB)
18/02/28 13:48:17 INFO BlockManagerInfo: Added rdd_48_2 in memory on 127.0.0.1:61164 (size: 58.0 KB, free: 345.7 MB)
18/02/28 13:48:17 INFO MemoryStore: Block rdd_48_3 stored as values in memory (estimated size 56.4 KB, free 321.0 MB)
18/02/28 13:48:17 INFO BlockManagerInfo: Added rdd_48_3 in memory on 127.0.0.1:61164 (size: 56.4 KB, free: 345.6 MB)
18/02/28 13:48:17 INFO MemoryStore: Block rdd_48_1 stored as values in memory (estimated size 64.6 KB, free 330.9 MB)
18/02/28 13:48:17 INFO BlockManagerInfo: Added rdd_48_1 in memory on 127.0.0.1:61164 (size: 64.6 KB, free: 345.6 MB)
18/02/28 13:48:17 INFO MemoryStore: Block rdd_48_0 stored as values in memory (estimated size 63.8 KB, free 344.9 MB)
18/02/28 13:48:17 INFO BlockManagerInfo: Added rdd_48_0 in memory on 127.0.0.1:61164 (size: 63.8 KB, free: 345.5 MB)
18/02/28 13:48:17 INFO Executor: Finished task 0.0 in stage 14.0 (TID 35). 3099 bytes result sent to driver
18/02/28 13:48:17 INFO Executor: Finished task 3.0 in stage 14.0 (TID 38). 3099 bytes result sent to driver
18/02/28 13:48:17 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 35) in 727 ms on localhost (executor driver) (1/4)
18/02/28 13:48:17 INFO TaskSetManager: Finished task 3.0 in stage 14.0 (TID 38) in 729 ms on localhost (executor driver) (2/4)
18/02/28 13:48:17 INFO Executor: Finished task 2.0 in stage 14.0 (TID 37). 3099 bytes result sent to driver
18/02/28 13:48:17 INFO TaskSetManager: Finished task 2.0 in stage 14.0 (TID 37) in 731 ms on localhost (executor driver) (3/4)
18/02/28 13:48:17 INFO Executor: Finished task 1.0 in stage 14.0 (TID 36). 3142 bytes result sent to driver
18/02/28 13:48:17 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 36) in 738 ms on localhost (executor driver) (4/4)
18/02/28 13:48:17 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
18/02/28 13:48:17 INFO DAGScheduler: ShuffleMapStage 14 (sql at <unknown>:0) finished in 0.739 s
18/02/28 13:48:17 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:48:17 INFO DAGScheduler: running: Set()
18/02/28 13:48:17 INFO DAGScheduler: waiting: Set(ResultStage 15)
18/02/28 13:48:17 INFO DAGScheduler: failed: Set()
18/02/28 13:48:17 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[54] at sql at <unknown>:0), which has no missing parents
18/02/28 13:48:17 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 344.9 MB)
18/02/28 13:48:17 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KB, free 344.8 MB)
18/02/28 13:48:17 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:61164 (size: 3.7 KB, free: 345.5 MB)
18/02/28 13:48:17 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[54] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 13:48:17 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
18/02/28 13:48:17 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 39, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:48:17 INFO Executor: Running task 0.0 in stage 15.0 (TID 39)
18/02/28 13:48:17 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:48:17 INFO Executor: Finished task 0.0 in stage 15.0 (TID 39). 1538 bytes result sent to driver
18/02/28 13:48:17 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 39) in 13 ms on localhost (executor driver) (1/1)
18/02/28 13:48:17 INFO DAGScheduler: ResultStage 15 (sql at <unknown>:0) finished in 0.013 s
18/02/28 13:48:17 INFO DAGScheduler: Job 8 finished: sql at <unknown>:0, took 0.770085 s
18/02/28 13:48:17 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
18/02/28 13:48:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:17 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `training`
18/02/28 13:48:17 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:48:17 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:48:17 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:48:17 INFO DAGScheduler: Registering RDD 57 (collect at utils.scala:211)
18/02/28 13:48:17 INFO DAGScheduler: Got job 9 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:48:17 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:211)
18/02/28 13:48:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
18/02/28 13:48:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)
18/02/28 13:48:17 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[57] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:17 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 53.6 KB, free 344.8 MB)
18/02/28 13:48:17 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 22.1 KB, free 344.8 MB)
18/02/28 13:48:17 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:61164 (size: 22.1 KB, free: 345.5 MB)
18/02/28 13:48:17 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:17 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[57] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:17 INFO TaskSchedulerImpl: Adding task set 16.0 with 4 tasks
18/02/28 13:48:17 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 40, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:17 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 41, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:17 INFO TaskSetManager: Starting task 2.0 in stage 16.0 (TID 42, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:48:17 INFO TaskSetManager: Starting task 3.0 in stage 16.0 (TID 43, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:17 INFO Executor: Running task 0.0 in stage 16.0 (TID 40)
18/02/28 13:48:17 INFO BlockManager: Found block rdd_48_0 locally
18/02/28 13:48:17 INFO Executor: Running task 1.0 in stage 16.0 (TID 41)
18/02/28 13:48:17 INFO Executor: Running task 2.0 in stage 16.0 (TID 42)
18/02/28 13:48:17 INFO BlockManager: Found block rdd_48_2 locally
18/02/28 13:48:17 INFO BlockManager: Found block rdd_48_1 locally
18/02/28 13:48:17 INFO Executor: Running task 3.0 in stage 16.0 (TID 43)
18/02/28 13:48:17 INFO BlockManager: Found block rdd_48_3 locally
18/02/28 13:48:17 INFO Executor: Finished task 2.0 in stage 16.0 (TID 42). 2289 bytes result sent to driver
18/02/28 13:48:17 INFO TaskSetManager: Finished task 2.0 in stage 16.0 (TID 42) in 48 ms on localhost (executor driver) (1/4)
18/02/28 13:48:17 INFO Executor: Finished task 1.0 in stage 16.0 (TID 41). 2289 bytes result sent to driver
18/02/28 13:48:17 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 41) in 59 ms on localhost (executor driver) (2/4)
18/02/28 13:48:17 INFO Executor: Finished task 0.0 in stage 16.0 (TID 40). 2289 bytes result sent to driver
18/02/28 13:48:17 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 40) in 65 ms on localhost (executor driver) (3/4)
18/02/28 13:48:17 INFO Executor: Finished task 3.0 in stage 16.0 (TID 43). 2289 bytes result sent to driver
18/02/28 13:48:17 INFO TaskSetManager: Finished task 3.0 in stage 16.0 (TID 43) in 71 ms on localhost (executor driver) (4/4)
18/02/28 13:48:17 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
18/02/28 13:48:17 INFO DAGScheduler: ShuffleMapStage 16 (collect at utils.scala:211) finished in 0.074 s
18/02/28 13:48:17 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:48:17 INFO DAGScheduler: running: Set()
18/02/28 13:48:17 INFO DAGScheduler: waiting: Set(ResultStage 17)
18/02/28 13:48:17 INFO DAGScheduler: failed: Set()
18/02/28 13:48:17 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[60] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:17 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 7.0 KB, free 344.8 MB)
18/02/28 13:48:17 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 3.7 KB, free 344.8 MB)
18/02/28 13:48:17 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:61164 (size: 3.7 KB, free: 345.5 MB)
18/02/28 13:48:17 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[60] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:48:17 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
18/02/28 13:48:17 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 44, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 13:48:17 INFO Executor: Running task 0.0 in stage 17.0 (TID 44)
18/02/28 13:48:17 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:48:17 INFO Executor: Finished task 0.0 in stage 17.0 (TID 44). 1495 bytes result sent to driver
18/02/28 13:48:17 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 44) in 8 ms on localhost (executor driver) (1/1)
18/02/28 13:48:17 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
18/02/28 13:48:17 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:211) finished in 0.008 s
18/02/28 13:48:17 INFO DAGScheduler: Job 9 finished: collect at utils.scala:211, took 0.100996 s
18/02/28 13:48:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 13:48:17 INFO CodeGenerator: Code generated in 5.283964 ms
18/02/28 13:48:17 INFO SparkContext: Starting job: countByValue at StringIndexer.scala:113
18/02/28 13:48:18 INFO DAGScheduler: Registering RDD 67 (countByValue at StringIndexer.scala:113)
18/02/28 13:48:18 INFO DAGScheduler: Got job 10 (countByValue at StringIndexer.scala:113) with 4 output partitions
18/02/28 13:48:18 INFO DAGScheduler: Final stage: ResultStage 19 (countByValue at StringIndexer.scala:113)
18/02/28 13:48:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
18/02/28 13:48:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 18)
18/02/28 13:48:18 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[67] at countByValue at StringIndexer.scala:113), which has no missing parents
18/02/28 13:48:18 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 55.3 KB, free 344.7 MB)
18/02/28 13:48:18 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 22.9 KB, free 344.7 MB)
18/02/28 13:48:18 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:61164 (size: 22.9 KB, free: 345.5 MB)
18/02/28 13:48:18 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:18 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[67] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:18 INFO TaskSchedulerImpl: Adding task set 18.0 with 4 tasks
18/02/28 13:48:18 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 45, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:18 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 46, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:18 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 47, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:48:18 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 48, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:18 INFO Executor: Running task 0.0 in stage 18.0 (TID 45)
18/02/28 13:48:18 INFO Executor: Running task 1.0 in stage 18.0 (TID 46)
18/02/28 13:48:18 INFO Executor: Running task 2.0 in stage 18.0 (TID 47)
18/02/28 13:48:18 INFO BlockManager: Found block rdd_48_1 locally
18/02/28 13:48:18 INFO BlockManager: Found block rdd_48_2 locally
18/02/28 13:48:18 INFO BlockManager: Found block rdd_48_0 locally
18/02/28 13:48:18 INFO Executor: Running task 3.0 in stage 18.0 (TID 48)
18/02/28 13:48:18 INFO BlockManager: Found block rdd_48_3 locally
18/02/28 13:48:18 INFO CodeGenerator: Code generated in 36.517711 ms
18/02/28 13:48:18 INFO CodeGenerator: Code generated in 9.881383 ms
18/02/28 13:48:18 INFO Executor: Finished task 1.0 in stage 18.0 (TID 46). 2277 bytes result sent to driver
18/02/28 13:48:18 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 46) in 255 ms on localhost (executor driver) (1/4)
18/02/28 13:48:18 INFO Executor: Finished task 3.0 in stage 18.0 (TID 48). 2277 bytes result sent to driver
18/02/28 13:48:18 INFO Executor: Finished task 2.0 in stage 18.0 (TID 47). 2277 bytes result sent to driver
18/02/28 13:48:18 INFO TaskSetManager: Finished task 3.0 in stage 18.0 (TID 48) in 268 ms on localhost (executor driver) (2/4)
18/02/28 13:48:18 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 47) in 271 ms on localhost (executor driver) (3/4)
18/02/28 13:48:18 INFO Executor: Finished task 0.0 in stage 18.0 (TID 45). 2320 bytes result sent to driver
18/02/28 13:48:18 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 45) in 278 ms on localhost (executor driver) (4/4)
18/02/28 13:48:18 INFO DAGScheduler: ShuffleMapStage 18 (countByValue at StringIndexer.scala:113) finished in 0.279 s
18/02/28 13:48:18 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:48:18 INFO DAGScheduler: running: Set()
18/02/28 13:48:18 INFO DAGScheduler: waiting: Set(ResultStage 19)
18/02/28 13:48:18 INFO DAGScheduler: failed: Set()
18/02/28 13:48:18 INFO DAGScheduler: Submitting ResultStage 19 (ShuffledRDD[68] at countByValue at StringIndexer.scala:113), which has no missing parents
18/02/28 13:48:18 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 3.2 KB, free 344.7 MB)
18/02/28 13:48:18 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 1963.0 B, free 344.7 MB)
18/02/28 13:48:18 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
18/02/28 13:48:18 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:61164 (size: 1963.0 B, free: 345.5 MB)
18/02/28 13:48:18 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:18 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 19 (ShuffledRDD[68] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:18 INFO TaskSchedulerImpl: Adding task set 19.0 with 4 tasks
18/02/28 13:48:18 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 49, localhost, executor driver, partition 0, ANY, 4621 bytes)
18/02/28 13:48:18 INFO TaskSetManager: Starting task 1.0 in stage 19.0 (TID 50, localhost, executor driver, partition 1, ANY, 4621 bytes)
18/02/28 13:48:18 INFO TaskSetManager: Starting task 2.0 in stage 19.0 (TID 51, localhost, executor driver, partition 2, ANY, 4621 bytes)
18/02/28 13:48:18 INFO TaskSetManager: Starting task 3.0 in stage 19.0 (TID 52, localhost, executor driver, partition 3, ANY, 4621 bytes)
18/02/28 13:48:18 INFO Executor: Running task 0.0 in stage 19.0 (TID 49)
18/02/28 13:48:18 INFO Executor: Running task 1.0 in stage 19.0 (TID 50)
18/02/28 13:48:18 INFO Executor: Running task 2.0 in stage 19.0 (TID 51)
18/02/28 13:48:18 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:48:18 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:48:18 INFO Executor: Running task 3.0 in stage 19.0 (TID 52)
18/02/28 13:48:18 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
18/02/28 13:48:18 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:48:18 INFO Executor: Finished task 0.0 in stage 19.0 (TID 49). 1196 bytes result sent to driver
18/02/28 13:48:18 INFO Executor: Finished task 1.0 in stage 19.0 (TID 50). 1221 bytes result sent to driver
18/02/28 13:48:18 INFO Executor: Finished task 2.0 in stage 19.0 (TID 51). 1239 bytes result sent to driver
18/02/28 13:48:18 INFO Executor: Finished task 3.0 in stage 19.0 (TID 52). 1196 bytes result sent to driver
18/02/28 13:48:18 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 49) in 91 ms on localhost (executor driver) (1/4)
18/02/28 13:48:18 INFO TaskSetManager: Finished task 1.0 in stage 19.0 (TID 50) in 92 ms on localhost (executor driver) (2/4)
18/02/28 13:48:18 INFO TaskSetManager: Finished task 3.0 in stage 19.0 (TID 52) in 92 ms on localhost (executor driver) (3/4)
18/02/28 13:48:18 INFO TaskSetManager: Finished task 2.0 in stage 19.0 (TID 51) in 93 ms on localhost (executor driver) (4/4)
18/02/28 13:48:18 INFO DAGScheduler: ResultStage 19 (countByValue at StringIndexer.scala:113) finished in 0.096 s
18/02/28 13:48:18 INFO DAGScheduler: Job 10 finished: countByValue at StringIndexer.scala:113, took 0.571096 s
18/02/28 13:48:18 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
18/02/28 13:48:18 INFO ContextCleaner: Cleaned accumulator 586
18/02/28 13:48:18 INFO ContextCleaner: Cleaned accumulator 523
18/02/28 13:48:18 INFO CodeGenerator: Code generated in 9.830606 ms
18/02/28 13:48:18 INFO SparkContext: Starting job: countByValue at StringIndexer.scala:113
18/02/28 13:48:18 INFO DAGScheduler: Registering RDD 75 (countByValue at StringIndexer.scala:113)
18/02/28 13:48:18 INFO DAGScheduler: Got job 11 (countByValue at StringIndexer.scala:113) with 4 output partitions
18/02/28 13:48:18 INFO DAGScheduler: Final stage: ResultStage 21 (countByValue at StringIndexer.scala:113)
18/02/28 13:48:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
18/02/28 13:48:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
18/02/28 13:48:18 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[75] at countByValue at StringIndexer.scala:113), which has no missing parents
18/02/28 13:48:18 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 56.1 KB, free 344.6 MB)
18/02/28 13:48:18 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 23.1 KB, free 344.6 MB)
18/02/28 13:48:18 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:61164 (size: 23.1 KB, free: 345.4 MB)
18/02/28 13:48:18 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:18 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[75] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:18 INFO TaskSchedulerImpl: Adding task set 20.0 with 4 tasks
18/02/28 13:48:18 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:61164 in memory (size: 22.9 KB, free: 345.5 MB)
18/02/28 13:48:18 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:18 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 54, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:18 INFO TaskSetManager: Starting task 2.0 in stage 20.0 (TID 55, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:48:18 INFO TaskSetManager: Starting task 3.0 in stage 20.0 (TID 56, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:18 INFO Executor: Running task 0.0 in stage 20.0 (TID 53)
18/02/28 13:48:18 INFO Executor: Running task 1.0 in stage 20.0 (TID 54)
18/02/28 13:48:18 INFO Executor: Running task 2.0 in stage 20.0 (TID 55)
18/02/28 13:48:18 INFO Executor: Running task 3.0 in stage 20.0 (TID 56)
18/02/28 13:48:18 INFO BlockManager: Found block rdd_48_1 locally
18/02/28 13:48:18 INFO ContextCleaner: Cleaned accumulator 585
18/02/28 13:48:18 INFO ContextCleaner: Cleaned accumulator 584
18/02/28 13:48:18 INFO BlockManager: Found block rdd_48_0 locally
18/02/28 13:48:18 INFO ContextCleaner: Cleaned shuffle 8
18/02/28 13:48:18 INFO BlockManager: Found block rdd_48_2 locally
18/02/28 13:48:18 INFO BlockManager: Found block rdd_48_3 locally
18/02/28 13:48:18 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:61164 in memory (size: 1963.0 B, free: 345.5 MB)
18/02/28 13:48:19 INFO Executor: Finished task 0.0 in stage 20.0 (TID 53). 2234 bytes result sent to driver
18/02/28 13:48:19 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 53) in 105 ms on localhost (executor driver) (1/4)
18/02/28 13:48:19 INFO Executor: Finished task 1.0 in stage 20.0 (TID 54). 2320 bytes result sent to driver
18/02/28 13:48:19 INFO Executor: Finished task 2.0 in stage 20.0 (TID 55). 2320 bytes result sent to driver
18/02/28 13:48:19 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 54) in 116 ms on localhost (executor driver) (2/4)
18/02/28 13:48:19 INFO TaskSetManager: Finished task 2.0 in stage 20.0 (TID 55) in 116 ms on localhost (executor driver) (3/4)
18/02/28 13:48:19 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:61164 in memory (size: 22.1 KB, free: 345.5 MB)
18/02/28 13:48:19 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:61164 in memory (size: 3.7 KB, free: 345.5 MB)
18/02/28 13:48:19 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:61164 in memory (size: 3.7 KB, free: 345.5 MB)
18/02/28 13:48:19 INFO Executor: Finished task 3.0 in stage 20.0 (TID 56). 2320 bytes result sent to driver
18/02/28 13:48:19 INFO TaskSetManager: Finished task 3.0 in stage 20.0 (TID 56) in 137 ms on localhost (executor driver) (4/4)
18/02/28 13:48:19 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
18/02/28 13:48:19 INFO DAGScheduler: ShuffleMapStage 20 (countByValue at StringIndexer.scala:113) finished in 0.141 s
18/02/28 13:48:19 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:48:19 INFO DAGScheduler: running: Set()
18/02/28 13:48:19 INFO DAGScheduler: waiting: Set(ResultStage 21)
18/02/28 13:48:19 INFO DAGScheduler: failed: Set()
18/02/28 13:48:19 INFO DAGScheduler: Submitting ResultStage 21 (ShuffledRDD[76] at countByValue at StringIndexer.scala:113), which has no missing parents
18/02/28 13:48:19 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 3.2 KB, free 344.8 MB)
18/02/28 13:48:19 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 1963.0 B, free 344.8 MB)
18/02/28 13:48:19 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:61164 (size: 1963.0 B, free: 345.5 MB)
18/02/28 13:48:19 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:19 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 21 (ShuffledRDD[76] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:19 INFO TaskSchedulerImpl: Adding task set 21.0 with 4 tasks
18/02/28 13:48:19 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 57, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:19 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 58, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:19 INFO TaskSetManager: Starting task 2.0 in stage 21.0 (TID 59, localhost, executor driver, partition 2, ANY, 4621 bytes)
18/02/28 13:48:19 INFO TaskSetManager: Starting task 3.0 in stage 21.0 (TID 60, localhost, executor driver, partition 3, ANY, 4621 bytes)
18/02/28 13:48:19 INFO Executor: Running task 0.0 in stage 21.0 (TID 57)
18/02/28 13:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 13:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:48:19 INFO Executor: Running task 1.0 in stage 21.0 (TID 58)
18/02/28 13:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 13:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:48:19 INFO Executor: Running task 2.0 in stage 21.0 (TID 59)
18/02/28 13:48:19 INFO Executor: Running task 3.0 in stage 21.0 (TID 60)
18/02/28 13:48:19 INFO Executor: Finished task 0.0 in stage 21.0 (TID 57). 1005 bytes result sent to driver
18/02/28 13:48:19 INFO Executor: Finished task 1.0 in stage 21.0 (TID 58). 1048 bytes result sent to driver
18/02/28 13:48:19 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:48:19 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:48:19 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 57) in 14 ms on localhost (executor driver) (1/4)
18/02/28 13:48:19 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 58) in 13 ms on localhost (executor driver) (2/4)
18/02/28 13:48:19 INFO Executor: Finished task 2.0 in stage 21.0 (TID 59). 1154 bytes result sent to driver
18/02/28 13:48:19 INFO Executor: Finished task 3.0 in stage 21.0 (TID 60). 1154 bytes result sent to driver
18/02/28 13:48:19 INFO TaskSetManager: Finished task 2.0 in stage 21.0 (TID 59) in 22 ms on localhost (executor driver) (3/4)
18/02/28 13:48:19 INFO TaskSetManager: Finished task 3.0 in stage 21.0 (TID 60) in 21 ms on localhost (executor driver) (4/4)
18/02/28 13:48:19 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
18/02/28 13:48:19 INFO DAGScheduler: ResultStage 21 (countByValue at StringIndexer.scala:113) finished in 0.024 s
18/02/28 13:48:19 INFO DAGScheduler: Job 11 finished: countByValue at StringIndexer.scala:113, took 0.200153 s
18/02/28 13:48:19 INFO CodeGenerator: Code generated in 27.060526 ms
18/02/28 13:48:19 INFO CodeGenerator: Code generated in 23.035757 ms
18/02/28 13:48:19 INFO Instrumentation: LogisticRegression-logistic_regression_29281b016def-70802161-1: training: numPartitions=4 storageLevel=StorageLevel(disk, memory, deserialized, 1 replicas)
18/02/28 13:48:19 INFO Instrumentation: LogisticRegression-logistic_regression_29281b016def-70802161-1: {"elasticNetParam":0.0,"fitIntercept":true,"threshold":0.5,"regParam":0.0,"tol":1.0E-6,"maxIter":100}
18/02/28 13:48:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:517
18/02/28 13:48:19 INFO DAGScheduler: Got job 12 (treeAggregate at LogisticRegression.scala:517) with 4 output partitions
18/02/28 13:48:19 INFO DAGScheduler: Final stage: ResultStage 22 (treeAggregate at LogisticRegression.scala:517)
18/02/28 13:48:19 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:48:19 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:19 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[86] at treeAggregate at LogisticRegression.scala:517), which has no missing parents
18/02/28 13:48:19 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 74.0 KB, free 344.7 MB)
18/02/28 13:48:19 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.7 MB)
18/02/28 13:48:19 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:61164 (size: 29.1 KB, free: 345.5 MB)
18/02/28 13:48:19 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:19 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 22 (MapPartitionsRDD[86] at treeAggregate at LogisticRegression.scala:517) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:19 INFO TaskSchedulerImpl: Adding task set 22.0 with 4 tasks
18/02/28 13:48:19 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:19 INFO TaskSetManager: Starting task 1.0 in stage 22.0 (TID 62, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:19 INFO TaskSetManager: Starting task 2.0 in stage 22.0 (TID 63, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:48:19 INFO TaskSetManager: Starting task 3.0 in stage 22.0 (TID 64, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:19 INFO Executor: Running task 0.0 in stage 22.0 (TID 61)
18/02/28 13:48:19 INFO Executor: Running task 1.0 in stage 22.0 (TID 62)
18/02/28 13:48:19 INFO Executor: Running task 2.0 in stage 22.0 (TID 63)
18/02/28 13:48:19 INFO Executor: Running task 3.0 in stage 22.0 (TID 64)
18/02/28 13:48:19 INFO BlockManager: Found block rdd_48_0 locally
18/02/28 13:48:19 INFO BlockManager: Found block rdd_48_2 locally
18/02/28 13:48:19 INFO BlockManager: Found block rdd_48_1 locally
18/02/28 13:48:19 INFO BlockManager: Found block rdd_48_3 locally
18/02/28 13:48:19 INFO CodeGenerator: Code generated in 20.375968 ms
18/02/28 13:48:19 INFO CodeGenerator: Code generated in 8.214916 ms
18/02/28 13:48:19 INFO MemoryStore: Block rdd_85_2 stored as values in memory (estimated size 78.7 KB, free 344.6 MB)
18/02/28 13:48:19 INFO BlockManagerInfo: Added rdd_85_2 in memory on 127.0.0.1:61164 (size: 78.7 KB, free: 345.4 MB)
18/02/28 13:48:19 INFO MemoryStore: Block rdd_85_1 stored as values in memory (estimated size 89.4 KB, free 344.5 MB)
18/02/28 13:48:19 INFO BlockManagerInfo: Added rdd_85_1 in memory on 127.0.0.1:61164 (size: 89.4 KB, free: 345.3 MB)
18/02/28 13:48:19 INFO MemoryStore: Block rdd_85_0 stored as values in memory (estimated size 90.0 KB, free 344.4 MB)
18/02/28 13:48:19 INFO BlockManagerInfo: Added rdd_85_0 in memory on 127.0.0.1:61164 (size: 90.0 KB, free: 345.2 MB)
18/02/28 13:48:19 INFO MemoryStore: Block rdd_85_3 stored as values in memory (estimated size 78.7 KB, free 344.3 MB)
18/02/28 13:48:19 INFO BlockManagerInfo: Added rdd_85_3 in memory on 127.0.0.1:61164 (size: 78.7 KB, free: 345.1 MB)
18/02/28 13:48:19 INFO Executor: Finished task 2.0 in stage 22.0 (TID 63). 3936 bytes result sent to driver
18/02/28 13:48:19 INFO Executor: Finished task 0.0 in stage 22.0 (TID 61). 3936 bytes result sent to driver
18/02/28 13:48:19 INFO TaskSetManager: Finished task 2.0 in stage 22.0 (TID 63) in 237 ms on localhost (executor driver) (1/4)
18/02/28 13:48:19 INFO Executor: Finished task 3.0 in stage 22.0 (TID 64). 3893 bytes result sent to driver
18/02/28 13:48:19 INFO Executor: Finished task 1.0 in stage 22.0 (TID 62). 3893 bytes result sent to driver
18/02/28 13:48:19 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 61) in 239 ms on localhost (executor driver) (2/4)
18/02/28 13:48:19 INFO TaskSetManager: Finished task 1.0 in stage 22.0 (TID 62) in 240 ms on localhost (executor driver) (3/4)
18/02/28 13:48:19 INFO TaskSetManager: Finished task 3.0 in stage 22.0 (TID 64) in 240 ms on localhost (executor driver) (4/4)
18/02/28 13:48:19 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
18/02/28 13:48:19 INFO DAGScheduler: ResultStage 22 (treeAggregate at LogisticRegression.scala:517) finished in 0.242 s
18/02/28 13:48:19 INFO DAGScheduler: Job 12 finished: treeAggregate at LogisticRegression.scala:517, took 0.250415 s
18/02/28 13:48:19 INFO Instrumentation: LogisticRegression-logistic_regression_29281b016def-70802161-1: {"numClasses":2}
18/02/28 13:48:19 INFO Instrumentation: LogisticRegression-logistic_regression_29281b016def-70802161-1: {"numFeatures":5}
18/02/28 13:48:19 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 80.0 B, free 344.3 MB)
18/02/28 13:48:19 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 109.0 B, free 344.3 MB)
18/02/28 13:48:19 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:61164 (size: 109.0 B, free: 345.1 MB)
18/02/28 13:48:19 INFO SparkContext: Created broadcast 25 from broadcast at LogisticRegression.scala:600
18/02/28 13:48:19 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 104.0 B, free 344.3 MB)
18/02/28 13:48:19 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 154.0 B, free 344.3 MB)
18/02/28 13:48:19 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:61164 (size: 154.0 B, free: 345.1 MB)
18/02/28 13:48:19 INFO SparkContext: Created broadcast 26 from broadcast at LogisticRegression.scala:1879
18/02/28 13:48:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:48:19 INFO DAGScheduler: Got job 13 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:48:19 INFO DAGScheduler: Final stage: ResultStage 23 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:48:19 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:48:19 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:19 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[87] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:48:19 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 74.1 KB, free 344.3 MB)
18/02/28 13:48:19 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 29.2 KB, free 344.2 MB)
18/02/28 13:48:19 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:61164 (size: 29.2 KB, free: 345.1 MB)
18/02/28 13:48:19 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:19 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 23 (MapPartitionsRDD[87] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:19 INFO TaskSchedulerImpl: Adding task set 23.0 with 4 tasks
18/02/28 13:48:19 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 65, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:19 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 66, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:19 INFO TaskSetManager: Starting task 2.0 in stage 23.0 (TID 67, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:48:19 INFO TaskSetManager: Starting task 3.0 in stage 23.0 (TID 68, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:19 INFO Executor: Running task 1.0 in stage 23.0 (TID 66)
18/02/28 13:48:19 INFO Executor: Running task 3.0 in stage 23.0 (TID 68)
18/02/28 13:48:19 INFO Executor: Running task 2.0 in stage 23.0 (TID 67)
18/02/28 13:48:19 INFO Executor: Running task 0.0 in stage 23.0 (TID 65)
18/02/28 13:48:19 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 13:48:19 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 13:48:19 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 13:48:19 INFO ContextCleaner: Cleaned shuffle 9
18/02/28 13:48:19 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 13:48:19 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:61164 in memory (size: 1963.0 B, free: 345.1 MB)
18/02/28 13:48:19 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:61164 in memory (size: 23.1 KB, free: 345.1 MB)
18/02/28 13:48:19 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:61164 in memory (size: 29.1 KB, free: 345.2 MB)
18/02/28 13:48:19 INFO ContextCleaner: Cleaned accumulator 637
18/02/28 13:48:19 INFO ContextCleaner: Cleaned accumulator 636
18/02/28 13:48:19 INFO ContextCleaner: Cleaned accumulator 635
18/02/28 13:48:19 INFO Executor: Finished task 0.0 in stage 23.0 (TID 65). 3481 bytes result sent to driver
18/02/28 13:48:19 INFO Executor: Finished task 2.0 in stage 23.0 (TID 67). 3524 bytes result sent to driver
18/02/28 13:48:19 INFO Executor: Finished task 3.0 in stage 23.0 (TID 68). 3524 bytes result sent to driver
18/02/28 13:48:19 INFO Executor: Finished task 1.0 in stage 23.0 (TID 66). 3481 bytes result sent to driver
18/02/28 13:48:19 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 65) in 40 ms on localhost (executor driver) (1/4)
18/02/28 13:48:19 INFO TaskSetManager: Finished task 3.0 in stage 23.0 (TID 68) in 40 ms on localhost (executor driver) (2/4)
18/02/28 13:48:19 INFO TaskSetManager: Finished task 2.0 in stage 23.0 (TID 67) in 40 ms on localhost (executor driver) (3/4)
18/02/28 13:48:19 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 66) in 41 ms on localhost (executor driver) (4/4)
18/02/28 13:48:19 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
18/02/28 13:48:19 INFO DAGScheduler: ResultStage 23 (treeAggregate at LogisticRegression.scala:1892) finished in 0.041 s
18/02/28 13:48:19 INFO DAGScheduler: Job 13 finished: treeAggregate at LogisticRegression.scala:1892, took 0.047127 s
18/02/28 13:48:19 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
18/02/28 13:48:19 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
18/02/28 13:48:19 INFO TorrentBroadcast: Destroying Broadcast(26) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:48:19 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:61164 in memory (size: 154.0 B, free: 345.2 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 104.0 B, free 344.4 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.4 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:61164 (size: 186.0 B, free: 345.2 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 28 from broadcast at LogisticRegression.scala:1879
18/02/28 13:48:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:48:20 INFO DAGScheduler: Got job 14 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:48:20 INFO DAGScheduler: Final stage: ResultStage 24 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:48:20 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:48:20 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:20 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[88] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 74.1 KB, free 344.4 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 29.2 KB, free 344.3 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:61164 (size: 29.2 KB, free: 345.1 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 24 (MapPartitionsRDD[88] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:20 INFO TaskSchedulerImpl: Adding task set 24.0 with 4 tasks
18/02/28 13:48:20 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 69, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 70, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 71, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 3.0 in stage 24.0 (TID 72, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO Executor: Running task 0.0 in stage 24.0 (TID 69)
18/02/28 13:48:20 INFO Executor: Running task 1.0 in stage 24.0 (TID 70)
18/02/28 13:48:20 INFO Executor: Running task 2.0 in stage 24.0 (TID 71)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 13:48:20 INFO Executor: Running task 3.0 in stage 24.0 (TID 72)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 13:48:20 INFO Executor: Finished task 1.0 in stage 24.0 (TID 70). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO Executor: Finished task 2.0 in stage 24.0 (TID 71). 3481 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 70) in 10 ms on localhost (executor driver) (1/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 71) in 10 ms on localhost (executor driver) (2/4)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 13:48:20 INFO Executor: Finished task 3.0 in stage 24.0 (TID 72). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO Executor: Finished task 0.0 in stage 24.0 (TID 69). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 69) in 15 ms on localhost (executor driver) (3/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 3.0 in stage 24.0 (TID 72) in 16 ms on localhost (executor driver) (4/4)
18/02/28 13:48:20 INFO DAGScheduler: ResultStage 24 (treeAggregate at LogisticRegression.scala:1892) finished in 0.016 s
18/02/28 13:48:20 INFO DAGScheduler: Job 14 finished: treeAggregate at LogisticRegression.scala:1892, took 0.023039 s
18/02/28 13:48:20 INFO TorrentBroadcast: Destroying Broadcast(28) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:48:20 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:61164 in memory (size: 186.0 B, free: 345.1 MB)
18/02/28 13:48:20 INFO LBFGS: Step Size: 1.000
18/02/28 13:48:20 INFO LBFGS: Val and Grad Norm: 0.484863 (rel: 0.123) 0.207175
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 104.0 B, free 344.3 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.3 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:61164 (size: 186.0 B, free: 345.1 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 30 from broadcast at LogisticRegression.scala:1879
18/02/28 13:48:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:48:20 INFO DAGScheduler: Got job 15 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:48:20 INFO DAGScheduler: Final stage: ResultStage 25 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:48:20 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:48:20 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:20 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[89] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 74.1 KB, free 344.3 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 29.2 KB, free 344.2 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:61164 (size: 29.2 KB, free: 345.1 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 25 (MapPartitionsRDD[89] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:20 INFO TaskSchedulerImpl: Adding task set 25.0 with 4 tasks
18/02/28 13:48:20 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 73, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 1.0 in stage 25.0 (TID 74, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 2.0 in stage 25.0 (TID 75, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 3.0 in stage 25.0 (TID 76, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO Executor: Running task 0.0 in stage 25.0 (TID 73)
18/02/28 13:48:20 INFO Executor: Running task 1.0 in stage 25.0 (TID 74)
18/02/28 13:48:20 INFO Executor: Running task 2.0 in stage 25.0 (TID 75)
18/02/28 13:48:20 INFO Executor: Running task 3.0 in stage 25.0 (TID 76)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 13:48:20 INFO Executor: Finished task 1.0 in stage 25.0 (TID 74). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 13:48:20 INFO TaskSetManager: Finished task 1.0 in stage 25.0 (TID 74) in 12 ms on localhost (executor driver) (1/4)
18/02/28 13:48:20 INFO Executor: Finished task 0.0 in stage 25.0 (TID 73). 3481 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 73) in 13 ms on localhost (executor driver) (2/4)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 13:48:20 INFO Executor: Finished task 3.0 in stage 25.0 (TID 76). 3524 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 3.0 in stage 25.0 (TID 76) in 14 ms on localhost (executor driver) (3/4)
18/02/28 13:48:20 INFO Executor: Finished task 2.0 in stage 25.0 (TID 75). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 2.0 in stage 25.0 (TID 75) in 15 ms on localhost (executor driver) (4/4)
18/02/28 13:48:20 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
18/02/28 13:48:20 INFO DAGScheduler: ResultStage 25 (treeAggregate at LogisticRegression.scala:1892) finished in 0.016 s
18/02/28 13:48:20 INFO DAGScheduler: Job 15 finished: treeAggregate at LogisticRegression.scala:1892, took 0.023247 s
18/02/28 13:48:20 INFO TorrentBroadcast: Destroying Broadcast(30) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:48:20 INFO LBFGS: Step Size: 1.000
18/02/28 13:48:20 INFO LBFGS: Val and Grad Norm: 0.363007 (rel: 0.251) 0.0818939
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:61164 in memory (size: 186.0 B, free: 345.1 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 104.0 B, free 344.2 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.2 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:61164 (size: 186.0 B, free: 345.1 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 32 from broadcast at LogisticRegression.scala:1879
18/02/28 13:48:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:48:20 INFO DAGScheduler: Got job 16 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:48:20 INFO DAGScheduler: Final stage: ResultStage 26 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:48:20 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:48:20 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:20 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[90] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 74.1 KB, free 344.2 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 29.2 KB, free 344.1 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:61164 (size: 29.2 KB, free: 345.1 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 26 (MapPartitionsRDD[90] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:20 INFO TaskSchedulerImpl: Adding task set 26.0 with 4 tasks
18/02/28 13:48:20 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 77, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 1.0 in stage 26.0 (TID 78, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 2.0 in stage 26.0 (TID 79, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 3.0 in stage 26.0 (TID 80, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO Executor: Running task 0.0 in stage 26.0 (TID 77)
18/02/28 13:48:20 INFO Executor: Running task 2.0 in stage 26.0 (TID 79)
18/02/28 13:48:20 INFO Executor: Running task 3.0 in stage 26.0 (TID 80)
18/02/28 13:48:20 INFO Executor: Running task 1.0 in stage 26.0 (TID 78)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 13:48:20 INFO Executor: Finished task 1.0 in stage 26.0 (TID 78). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 13:48:20 INFO TaskSetManager: Finished task 1.0 in stage 26.0 (TID 78) in 8 ms on localhost (executor driver) (1/4)
18/02/28 13:48:20 INFO Executor: Finished task 3.0 in stage 26.0 (TID 80). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO Executor: Finished task 0.0 in stage 26.0 (TID 77). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 3.0 in stage 26.0 (TID 80) in 8 ms on localhost (executor driver) (2/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 77) in 9 ms on localhost (executor driver) (3/4)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 13:48:20 INFO Executor: Finished task 2.0 in stage 26.0 (TID 79). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 2.0 in stage 26.0 (TID 79) in 9 ms on localhost (executor driver) (4/4)
18/02/28 13:48:20 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
18/02/28 13:48:20 INFO DAGScheduler: ResultStage 26 (treeAggregate at LogisticRegression.scala:1892) finished in 0.011 s
18/02/28 13:48:20 INFO DAGScheduler: Job 16 finished: treeAggregate at LogisticRegression.scala:1892, took 0.016448 s
18/02/28 13:48:20 INFO TorrentBroadcast: Destroying Broadcast(32) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:48:20 INFO LBFGS: Step Size: 1.000
18/02/28 13:48:20 INFO LBFGS: Val and Grad Norm: 0.325989 (rel: 0.102) 0.0476394
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:61164 in memory (size: 186.0 B, free: 345.1 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 104.0 B, free 344.1 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.1 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:61164 (size: 186.0 B, free: 345.1 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 34 from broadcast at LogisticRegression.scala:1879
18/02/28 13:48:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:48:20 INFO DAGScheduler: Got job 17 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:48:20 INFO DAGScheduler: Final stage: ResultStage 27 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:48:20 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:48:20 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:20 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[91] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 74.1 KB, free 344.1 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 29.2 KB, free 344.0 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:61164 (size: 29.2 KB, free: 345.0 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 27 (MapPartitionsRDD[91] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:20 INFO TaskSchedulerImpl: Adding task set 27.0 with 4 tasks
18/02/28 13:48:20 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 81, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 82, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 2.0 in stage 27.0 (TID 83, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 3.0 in stage 27.0 (TID 84, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO Executor: Running task 2.0 in stage 27.0 (TID 83)
18/02/28 13:48:20 INFO Executor: Running task 0.0 in stage 27.0 (TID 81)
18/02/28 13:48:20 INFO Executor: Running task 3.0 in stage 27.0 (TID 84)
18/02/28 13:48:20 INFO Executor: Running task 1.0 in stage 27.0 (TID 82)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 13:48:20 INFO Executor: Finished task 1.0 in stage 27.0 (TID 82). 3481 bytes result sent to driver
18/02/28 13:48:20 INFO Executor: Finished task 2.0 in stage 27.0 (TID 83). 3481 bytes result sent to driver
18/02/28 13:48:20 INFO Executor: Finished task 0.0 in stage 27.0 (TID 81). 3481 bytes result sent to driver
18/02/28 13:48:20 INFO Executor: Finished task 3.0 in stage 27.0 (TID 84). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 2.0 in stage 27.0 (TID 83) in 7 ms on localhost (executor driver) (1/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 3.0 in stage 27.0 (TID 84) in 7 ms on localhost (executor driver) (2/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 82) in 7 ms on localhost (executor driver) (3/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 81) in 7 ms on localhost (executor driver) (4/4)
18/02/28 13:48:20 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
18/02/28 13:48:20 INFO DAGScheduler: ResultStage 27 (treeAggregate at LogisticRegression.scala:1892) finished in 0.007 s
18/02/28 13:48:20 INFO DAGScheduler: Job 17 finished: treeAggregate at LogisticRegression.scala:1892, took 0.013505 s
18/02/28 13:48:20 INFO TorrentBroadcast: Destroying Broadcast(34) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:48:20 INFO LBFGS: Step Size: 1.000
18/02/28 13:48:20 INFO LBFGS: Val and Grad Norm: 0.299770 (rel: 0.0804) 0.0386357
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:61164 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 104.0 B, free 344.0 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.0 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:61164 (size: 186.0 B, free: 345.0 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 36 from broadcast at LogisticRegression.scala:1879
18/02/28 13:48:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:48:20 INFO DAGScheduler: Got job 18 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:48:20 INFO DAGScheduler: Final stage: ResultStage 28 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:48:20 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:48:20 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:20 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[92] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 74.1 KB, free 344.0 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 29.2 KB, free 343.9 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:61164 (size: 29.2 KB, free: 345.0 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 28 (MapPartitionsRDD[92] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:20 INFO TaskSchedulerImpl: Adding task set 28.0 with 4 tasks
18/02/28 13:48:20 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 85, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 1.0 in stage 28.0 (TID 86, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 2.0 in stage 28.0 (TID 87, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 3.0 in stage 28.0 (TID 88, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO Executor: Running task 0.0 in stage 28.0 (TID 85)
18/02/28 13:48:20 INFO Executor: Running task 1.0 in stage 28.0 (TID 86)
18/02/28 13:48:20 INFO Executor: Running task 2.0 in stage 28.0 (TID 87)
18/02/28 13:48:20 INFO Executor: Running task 3.0 in stage 28.0 (TID 88)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 13:48:20 INFO Executor: Finished task 2.0 in stage 28.0 (TID 87). 3395 bytes result sent to driver
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 13:48:20 INFO Executor: Finished task 0.0 in stage 28.0 (TID 85). 3395 bytes result sent to driver
18/02/28 13:48:20 INFO Executor: Finished task 1.0 in stage 28.0 (TID 86). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 13:48:20 INFO TaskSetManager: Finished task 2.0 in stage 28.0 (TID 87) in 7 ms on localhost (executor driver) (1/4)
18/02/28 13:48:20 INFO Executor: Finished task 3.0 in stage 28.0 (TID 88). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 1.0 in stage 28.0 (TID 86) in 8 ms on localhost (executor driver) (2/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 85) in 9 ms on localhost (executor driver) (3/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 3.0 in stage 28.0 (TID 88) in 9 ms on localhost (executor driver) (4/4)
18/02/28 13:48:20 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
18/02/28 13:48:20 INFO DAGScheduler: ResultStage 28 (treeAggregate at LogisticRegression.scala:1892) finished in 0.010 s
18/02/28 13:48:20 INFO DAGScheduler: Job 18 finished: treeAggregate at LogisticRegression.scala:1892, took 0.015720 s
18/02/28 13:48:20 INFO TorrentBroadcast: Destroying Broadcast(36) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:48:20 INFO LBFGS: Step Size: 1.000
18/02/28 13:48:20 INFO LBFGS: Val and Grad Norm: 0.290164 (rel: 0.0320) 0.0113809
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:61164 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 104.0 B, free 343.9 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.9 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:61164 (size: 186.0 B, free: 345.0 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 38 from broadcast at LogisticRegression.scala:1879
18/02/28 13:48:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:48:20 INFO DAGScheduler: Got job 19 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:48:20 INFO DAGScheduler: Final stage: ResultStage 29 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:48:20 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:48:20 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:20 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[93] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 74.1 KB, free 343.9 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 29.2 KB, free 343.8 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:61164 (size: 29.2 KB, free: 345.0 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 29 (MapPartitionsRDD[93] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:20 INFO TaskSchedulerImpl: Adding task set 29.0 with 4 tasks
18/02/28 13:48:20 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 89, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 90, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 2.0 in stage 29.0 (TID 91, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 3.0 in stage 29.0 (TID 92, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO Executor: Running task 0.0 in stage 29.0 (TID 89)
18/02/28 13:48:20 INFO Executor: Running task 1.0 in stage 29.0 (TID 90)
18/02/28 13:48:20 INFO Executor: Running task 2.0 in stage 29.0 (TID 91)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 13:48:20 INFO Executor: Running task 3.0 in stage 29.0 (TID 92)
18/02/28 13:48:20 INFO Executor: Finished task 0.0 in stage 29.0 (TID 89). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 13:48:20 INFO Executor: Finished task 1.0 in stage 29.0 (TID 90). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO Executor: Finished task 2.0 in stage 29.0 (TID 91). 3395 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 89) in 10 ms on localhost (executor driver) (1/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 90) in 10 ms on localhost (executor driver) (2/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 2.0 in stage 29.0 (TID 91) in 9 ms on localhost (executor driver) (3/4)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 13:48:20 INFO Executor: Finished task 3.0 in stage 29.0 (TID 92). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 3.0 in stage 29.0 (TID 92) in 11 ms on localhost (executor driver) (4/4)
18/02/28 13:48:20 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
18/02/28 13:48:20 INFO DAGScheduler: ResultStage 29 (treeAggregate at LogisticRegression.scala:1892) finished in 0.012 s
18/02/28 13:48:20 INFO DAGScheduler: Job 19 finished: treeAggregate at LogisticRegression.scala:1892, took 0.020043 s
18/02/28 13:48:20 INFO TorrentBroadcast: Destroying Broadcast(38) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:48:20 INFO LBFGS: Step Size: 1.000
18/02/28 13:48:20 INFO LBFGS: Val and Grad Norm: 0.287957 (rel: 0.00761) 0.00478609
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:61164 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 104.0 B, free 343.8 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.8 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:61164 (size: 186.0 B, free: 345.0 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 40 from broadcast at LogisticRegression.scala:1879
18/02/28 13:48:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:48:20 INFO DAGScheduler: Got job 20 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:48:20 INFO DAGScheduler: Final stage: ResultStage 30 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:48:20 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:48:20 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:20 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[94] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 74.1 KB, free 343.8 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 29.2 KB, free 343.7 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:61164 (size: 29.2 KB, free: 345.0 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 30 (MapPartitionsRDD[94] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:20 INFO TaskSchedulerImpl: Adding task set 30.0 with 4 tasks
18/02/28 13:48:20 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 93, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 94, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 2.0 in stage 30.0 (TID 95, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 3.0 in stage 30.0 (TID 96, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO Executor: Running task 0.0 in stage 30.0 (TID 93)
18/02/28 13:48:20 INFO Executor: Running task 3.0 in stage 30.0 (TID 96)
18/02/28 13:48:20 INFO Executor: Running task 2.0 in stage 30.0 (TID 95)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 13:48:20 INFO Executor: Finished task 3.0 in stage 30.0 (TID 96). 3481 bytes result sent to driver
18/02/28 13:48:20 INFO Executor: Finished task 2.0 in stage 30.0 (TID 95). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO Executor: Running task 1.0 in stage 30.0 (TID 94)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 13:48:20 INFO Executor: Finished task 0.0 in stage 30.0 (TID 93). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 2.0 in stage 30.0 (TID 95) in 8 ms on localhost (executor driver) (1/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 3.0 in stage 30.0 (TID 96) in 8 ms on localhost (executor driver) (2/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 93) in 9 ms on localhost (executor driver) (3/4)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 13:48:20 INFO Executor: Finished task 1.0 in stage 30.0 (TID 94). 3395 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 94) in 12 ms on localhost (executor driver) (4/4)
18/02/28 13:48:20 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
18/02/28 13:48:20 INFO DAGScheduler: ResultStage 30 (treeAggregate at LogisticRegression.scala:1892) finished in 0.012 s
18/02/28 13:48:20 INFO DAGScheduler: Job 20 finished: treeAggregate at LogisticRegression.scala:1892, took 0.017127 s
18/02/28 13:48:20 INFO TorrentBroadcast: Destroying Broadcast(40) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:48:20 INFO LBFGS: Step Size: 1.000
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:61164 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 13:48:20 INFO LBFGS: Val and Grad Norm: 0.287456 (rel: 0.00174) 0.00733903
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 104.0 B, free 343.7 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.7 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:61164 (size: 186.0 B, free: 345.0 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 42 from broadcast at LogisticRegression.scala:1879
18/02/28 13:48:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:48:20 INFO DAGScheduler: Got job 21 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:48:20 INFO DAGScheduler: Final stage: ResultStage 31 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:48:20 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:48:20 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:20 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[95] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 74.1 KB, free 343.7 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 29.2 KB, free 343.6 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:61164 (size: 29.2 KB, free: 344.9 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 31 (MapPartitionsRDD[95] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:20 INFO TaskSchedulerImpl: Adding task set 31.0 with 4 tasks
18/02/28 13:48:20 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 97, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 1.0 in stage 31.0 (TID 98, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 2.0 in stage 31.0 (TID 99, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 3.0 in stage 31.0 (TID 100, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO Executor: Running task 0.0 in stage 31.0 (TID 97)
18/02/28 13:48:20 INFO Executor: Running task 2.0 in stage 31.0 (TID 99)
18/02/28 13:48:20 INFO Executor: Running task 3.0 in stage 31.0 (TID 100)
18/02/28 13:48:20 INFO Executor: Running task 1.0 in stage 31.0 (TID 98)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 13:48:20 INFO Executor: Finished task 1.0 in stage 31.0 (TID 98). 3395 bytes result sent to driver
18/02/28 13:48:20 INFO Executor: Finished task 3.0 in stage 31.0 (TID 100). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 1.0 in stage 31.0 (TID 98) in 6 ms on localhost (executor driver) (1/4)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 13:48:20 INFO TaskSetManager: Finished task 3.0 in stage 31.0 (TID 100) in 7 ms on localhost (executor driver) (2/4)
18/02/28 13:48:20 INFO Executor: Finished task 0.0 in stage 31.0 (TID 97). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 13:48:20 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 97) in 9 ms on localhost (executor driver) (3/4)
18/02/28 13:48:20 INFO Executor: Finished task 2.0 in stage 31.0 (TID 99). 3481 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 2.0 in stage 31.0 (TID 99) in 8 ms on localhost (executor driver) (4/4)
18/02/28 13:48:20 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
18/02/28 13:48:20 INFO DAGScheduler: ResultStage 31 (treeAggregate at LogisticRegression.scala:1892) finished in 0.010 s
18/02/28 13:48:20 INFO DAGScheduler: Job 21 finished: treeAggregate at LogisticRegression.scala:1892, took 0.014593 s
18/02/28 13:48:20 INFO TorrentBroadcast: Destroying Broadcast(42) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:48:20 INFO LBFGS: Step Size: 1.000
18/02/28 13:48:20 INFO LBFGS: Val and Grad Norm: 0.287030 (rel: 0.00148) 0.00343552
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:61164 in memory (size: 186.0 B, free: 344.9 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 104.0 B, free 343.6 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.6 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:61164 (size: 186.0 B, free: 344.9 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 44 from broadcast at LogisticRegression.scala:1879
18/02/28 13:48:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:48:20 INFO DAGScheduler: Got job 22 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:48:20 INFO DAGScheduler: Final stage: ResultStage 32 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:48:20 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:48:20 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:20 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[96] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 74.1 KB, free 343.6 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 29.2 KB, free 343.5 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:61164 (size: 29.2 KB, free: 344.9 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 32 (MapPartitionsRDD[96] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:20 INFO TaskSchedulerImpl: Adding task set 32.0 with 4 tasks
18/02/28 13:48:20 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 101, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 102, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 2.0 in stage 32.0 (TID 103, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 3.0 in stage 32.0 (TID 104, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO Executor: Running task 0.0 in stage 32.0 (TID 101)
18/02/28 13:48:20 INFO Executor: Running task 3.0 in stage 32.0 (TID 104)
18/02/28 13:48:20 INFO Executor: Running task 2.0 in stage 32.0 (TID 103)
18/02/28 13:48:20 INFO Executor: Running task 1.0 in stage 32.0 (TID 102)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 13:48:20 INFO Executor: Finished task 1.0 in stage 32.0 (TID 102). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 13:48:20 INFO Executor: Finished task 2.0 in stage 32.0 (TID 103). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 13:48:20 INFO Executor: Finished task 0.0 in stage 32.0 (TID 101). 3481 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 102) in 13 ms on localhost (executor driver) (1/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 2.0 in stage 32.0 (TID 103) in 14 ms on localhost (executor driver) (2/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 101) in 14 ms on localhost (executor driver) (3/4)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 13:48:20 INFO Executor: Finished task 3.0 in stage 32.0 (TID 104). 3481 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 3.0 in stage 32.0 (TID 104) in 22 ms on localhost (executor driver) (4/4)
18/02/28 13:48:20 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
18/02/28 13:48:20 INFO DAGScheduler: ResultStage 32 (treeAggregate at LogisticRegression.scala:1892) finished in 0.022 s
18/02/28 13:48:20 INFO DAGScheduler: Job 22 finished: treeAggregate at LogisticRegression.scala:1892, took 0.028020 s
18/02/28 13:48:20 INFO TorrentBroadcast: Destroying Broadcast(44) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:48:20 INFO LBFGS: Step Size: 1.000
18/02/28 13:48:20 INFO LBFGS: Val and Grad Norm: 0.286656 (rel: 0.00130) 0.00324468
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:61164 in memory (size: 186.0 B, free: 344.9 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 104.0 B, free 343.5 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.5 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:61164 (size: 186.0 B, free: 344.9 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 46 from broadcast at LogisticRegression.scala:1879
18/02/28 13:48:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:48:20 INFO DAGScheduler: Got job 23 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:48:20 INFO DAGScheduler: Final stage: ResultStage 33 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:48:20 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:48:20 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:20 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[97] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 74.1 KB, free 343.4 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 29.2 KB, free 343.4 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:61164 (size: 29.2 KB, free: 344.9 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 33 (MapPartitionsRDD[97] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:20 INFO TaskSchedulerImpl: Adding task set 33.0 with 4 tasks
18/02/28 13:48:20 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 105, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 1.0 in stage 33.0 (TID 106, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 2.0 in stage 33.0 (TID 107, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 3.0 in stage 33.0 (TID 108, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO Executor: Running task 2.0 in stage 33.0 (TID 107)
18/02/28 13:48:20 INFO Executor: Running task 1.0 in stage 33.0 (TID 106)
18/02/28 13:48:20 INFO Executor: Running task 3.0 in stage 33.0 (TID 108)
18/02/28 13:48:20 INFO Executor: Running task 0.0 in stage 33.0 (TID 105)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 13:48:20 INFO Executor: Finished task 1.0 in stage 33.0 (TID 106). 3481 bytes result sent to driver
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 13:48:20 INFO Executor: Finished task 2.0 in stage 33.0 (TID 107). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO Executor: Finished task 3.0 in stage 33.0 (TID 108). 3481 bytes result sent to driver
18/02/28 13:48:20 INFO Executor: Finished task 0.0 in stage 33.0 (TID 105). 3481 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 1.0 in stage 33.0 (TID 106) in 9 ms on localhost (executor driver) (1/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 2.0 in stage 33.0 (TID 107) in 10 ms on localhost (executor driver) (2/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 105) in 10 ms on localhost (executor driver) (3/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 3.0 in stage 33.0 (TID 108) in 9 ms on localhost (executor driver) (4/4)
18/02/28 13:48:20 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
18/02/28 13:48:20 INFO DAGScheduler: ResultStage 33 (treeAggregate at LogisticRegression.scala:1892) finished in 0.011 s
18/02/28 13:48:20 INFO DAGScheduler: Job 23 finished: treeAggregate at LogisticRegression.scala:1892, took 0.015915 s
18/02/28 13:48:20 INFO TorrentBroadcast: Destroying Broadcast(46) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:48:20 INFO LBFGS: Step Size: 1.000
18/02/28 13:48:20 INFO LBFGS: Val and Grad Norm: 0.286204 (rel: 0.00158) 0.00283187
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:61164 in memory (size: 186.0 B, free: 344.9 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 104.0 B, free 343.4 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.4 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:61164 (size: 186.0 B, free: 344.9 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 48 from broadcast at LogisticRegression.scala:1879
18/02/28 13:48:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:48:20 INFO DAGScheduler: Got job 24 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:48:20 INFO DAGScheduler: Final stage: ResultStage 34 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:48:20 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:48:20 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:20 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[98] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 74.1 KB, free 343.3 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:61164 in memory (size: 29.2 KB, free: 344.9 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 29.2 KB, free 343.4 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:61164 (size: 29.2 KB, free: 344.9 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 34 (MapPartitionsRDD[98] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:61164 in memory (size: 29.2 KB, free: 344.9 MB)
18/02/28 13:48:20 INFO TaskSchedulerImpl: Adding task set 34.0 with 4 tasks
18/02/28 13:48:20 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 109, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 1.0 in stage 34.0 (TID 110, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 2.0 in stage 34.0 (TID 111, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 3.0 in stage 34.0 (TID 112, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:61164 in memory (size: 29.2 KB, free: 344.9 MB)
18/02/28 13:48:20 INFO Executor: Running task 0.0 in stage 34.0 (TID 109)
18/02/28 13:48:20 INFO Executor: Running task 2.0 in stage 34.0 (TID 111)
18/02/28 13:48:20 INFO Executor: Running task 3.0 in stage 34.0 (TID 112)
18/02/28 13:48:20 INFO Executor: Running task 1.0 in stage 34.0 (TID 110)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 13:48:20 INFO Executor: Finished task 1.0 in stage 34.0 (TID 110). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 13:48:20 INFO Executor: Finished task 0.0 in stage 34.0 (TID 109). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO Executor: Finished task 3.0 in stage 34.0 (TID 112). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 13:48:20 INFO TaskSetManager: Finished task 1.0 in stage 34.0 (TID 110) in 7 ms on localhost (executor driver) (1/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 109) in 8 ms on localhost (executor driver) (2/4)
18/02/28 13:48:20 INFO Executor: Finished task 2.0 in stage 34.0 (TID 111). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 3.0 in stage 34.0 (TID 112) in 7 ms on localhost (executor driver) (3/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 2.0 in stage 34.0 (TID 111) in 8 ms on localhost (executor driver) (4/4)
18/02/28 13:48:20 INFO DAGScheduler: ResultStage 34 (treeAggregate at LogisticRegression.scala:1892) finished in 0.009 s
18/02/28 13:48:20 INFO DAGScheduler: Job 24 finished: treeAggregate at LogisticRegression.scala:1892, took 0.029950 s
18/02/28 13:48:20 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
18/02/28 13:48:20 INFO TorrentBroadcast: Destroying Broadcast(48) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:61164 in memory (size: 29.2 KB, free: 345.0 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:61164 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:61164 in memory (size: 29.2 KB, free: 345.0 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 104.0 B, free 343.8 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:61164 in memory (size: 29.2 KB, free: 345.0 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.0 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:61164 in memory (size: 29.2 KB, free: 345.0 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:61164 (size: 186.0 B, free: 345.0 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 50 from broadcast at LogisticRegression.scala:1879
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:61164 in memory (size: 29.2 KB, free: 345.1 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:61164 in memory (size: 29.2 KB, free: 345.1 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:61164 in memory (size: 29.2 KB, free: 345.1 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:61164 in memory (size: 29.2 KB, free: 345.2 MB)
18/02/28 13:48:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:48:20 INFO DAGScheduler: Got job 25 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:48:20 INFO DAGScheduler: Final stage: ResultStage 35 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:48:20 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:48:20 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:20 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[99] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 74.1 KB, free 344.4 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 29.2 KB, free 344.3 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:61164 (size: 29.2 KB, free: 345.1 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 35 (MapPartitionsRDD[99] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:20 INFO TaskSchedulerImpl: Adding task set 35.0 with 4 tasks
18/02/28 13:48:20 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 113, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 1.0 in stage 35.0 (TID 114, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 2.0 in stage 35.0 (TID 115, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 3.0 in stage 35.0 (TID 116, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO Executor: Running task 1.0 in stage 35.0 (TID 114)
18/02/28 13:48:20 INFO Executor: Running task 3.0 in stage 35.0 (TID 116)
18/02/28 13:48:20 INFO Executor: Running task 2.0 in stage 35.0 (TID 115)
18/02/28 13:48:20 INFO Executor: Running task 0.0 in stage 35.0 (TID 113)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 13:48:20 INFO Executor: Finished task 1.0 in stage 35.0 (TID 114). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO Executor: Finished task 3.0 in stage 35.0 (TID 116). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 13:48:20 INFO Executor: Finished task 2.0 in stage 35.0 (TID 115). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 1.0 in stage 35.0 (TID 114) in 7 ms on localhost (executor driver) (1/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 3.0 in stage 35.0 (TID 116) in 6 ms on localhost (executor driver) (2/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 2.0 in stage 35.0 (TID 115) in 7 ms on localhost (executor driver) (3/4)
18/02/28 13:48:20 INFO Executor: Finished task 0.0 in stage 35.0 (TID 113). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 113) in 8 ms on localhost (executor driver) (4/4)
18/02/28 13:48:20 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
18/02/28 13:48:20 INFO DAGScheduler: ResultStage 35 (treeAggregate at LogisticRegression.scala:1892) finished in 0.008 s
18/02/28 13:48:20 INFO DAGScheduler: Job 25 finished: treeAggregate at LogisticRegression.scala:1892, took 0.013083 s
18/02/28 13:48:20 INFO TorrentBroadcast: Destroying Broadcast(50) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:61164 in memory (size: 186.0 B, free: 345.1 MB)
18/02/28 13:48:20 INFO StrongWolfeLineSearch: Line search t: 0.40498454866515676 fval: 0.28617477658052276 rhs: 0.2862039271787816 cdd: 3.5231514413734796E-9
18/02/28 13:48:20 INFO LBFGS: Step Size: 0.4050
18/02/28 13:48:20 INFO LBFGS: Val and Grad Norm: 0.286175 (rel: 0.000102) 0.00219975
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 104.0 B, free 344.3 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.3 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:61164 (size: 186.0 B, free: 345.1 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 52 from broadcast at LogisticRegression.scala:1879
18/02/28 13:48:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:48:20 INFO DAGScheduler: Got job 26 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:48:20 INFO DAGScheduler: Final stage: ResultStage 36 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:48:20 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:48:20 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:20 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[100] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 74.1 KB, free 344.3 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 29.2 KB, free 344.2 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:61164 (size: 29.2 KB, free: 345.1 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 36 (MapPartitionsRDD[100] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:20 INFO TaskSchedulerImpl: Adding task set 36.0 with 4 tasks
18/02/28 13:48:20 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 117, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 1.0 in stage 36.0 (TID 118, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 2.0 in stage 36.0 (TID 119, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 3.0 in stage 36.0 (TID 120, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO Executor: Running task 3.0 in stage 36.0 (TID 120)
18/02/28 13:48:20 INFO Executor: Running task 1.0 in stage 36.0 (TID 118)
18/02/28 13:48:20 INFO Executor: Running task 2.0 in stage 36.0 (TID 119)
18/02/28 13:48:20 INFO Executor: Running task 0.0 in stage 36.0 (TID 117)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 13:48:20 INFO Executor: Finished task 2.0 in stage 36.0 (TID 119). 3395 bytes result sent to driver
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 13:48:20 INFO Executor: Finished task 3.0 in stage 36.0 (TID 120). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO Executor: Finished task 0.0 in stage 36.0 (TID 117). 3395 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 2.0 in stage 36.0 (TID 119) in 6 ms on localhost (executor driver) (1/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 3.0 in stage 36.0 (TID 120) in 7 ms on localhost (executor driver) (2/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 117) in 7 ms on localhost (executor driver) (3/4)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 13:48:20 INFO Executor: Finished task 1.0 in stage 36.0 (TID 118). 3481 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 1.0 in stage 36.0 (TID 118) in 8 ms on localhost (executor driver) (4/4)
18/02/28 13:48:20 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
18/02/28 13:48:20 INFO DAGScheduler: ResultStage 36 (treeAggregate at LogisticRegression.scala:1892) finished in 0.009 s
18/02/28 13:48:20 INFO DAGScheduler: Job 26 finished: treeAggregate at LogisticRegression.scala:1892, took 0.014685 s
18/02/28 13:48:20 INFO TorrentBroadcast: Destroying Broadcast(52) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:48:20 INFO LBFGS: Step Size: 1.000
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:61164 in memory (size: 186.0 B, free: 345.1 MB)
18/02/28 13:48:20 INFO LBFGS: Val and Grad Norm: 0.286140 (rel: 0.000121) 0.000474267
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 104.0 B, free 344.2 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.2 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:61164 (size: 186.0 B, free: 345.1 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 54 from broadcast at LogisticRegression.scala:1879
18/02/28 13:48:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:48:20 INFO DAGScheduler: Got job 27 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:48:20 INFO DAGScheduler: Final stage: ResultStage 37 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:48:20 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:48:20 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:20 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[101] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 74.1 KB, free 344.2 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 29.2 KB, free 344.1 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:61164 (size: 29.2 KB, free: 345.1 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 37 (MapPartitionsRDD[101] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:20 INFO TaskSchedulerImpl: Adding task set 37.0 with 4 tasks
18/02/28 13:48:20 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 121, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 1.0 in stage 37.0 (TID 122, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 2.0 in stage 37.0 (TID 123, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 3.0 in stage 37.0 (TID 124, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO Executor: Running task 2.0 in stage 37.0 (TID 123)
18/02/28 13:48:20 INFO Executor: Running task 3.0 in stage 37.0 (TID 124)
18/02/28 13:48:20 INFO Executor: Running task 1.0 in stage 37.0 (TID 122)
18/02/28 13:48:20 INFO Executor: Running task 0.0 in stage 37.0 (TID 121)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 13:48:20 INFO Executor: Finished task 3.0 in stage 37.0 (TID 124). 3481 bytes result sent to driver
18/02/28 13:48:20 INFO Executor: Finished task 2.0 in stage 37.0 (TID 123). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 13:48:20 INFO Executor: Finished task 0.0 in stage 37.0 (TID 121). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 3.0 in stage 37.0 (TID 124) in 8 ms on localhost (executor driver) (1/4)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 13:48:20 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 121) in 10 ms on localhost (executor driver) (2/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 2.0 in stage 37.0 (TID 123) in 9 ms on localhost (executor driver) (3/4)
18/02/28 13:48:20 INFO Executor: Finished task 1.0 in stage 37.0 (TID 122). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 1.0 in stage 37.0 (TID 122) in 10 ms on localhost (executor driver) (4/4)
18/02/28 13:48:20 INFO DAGScheduler: ResultStage 37 (treeAggregate at LogisticRegression.scala:1892) finished in 0.011 s
18/02/28 13:48:20 INFO DAGScheduler: Job 27 finished: treeAggregate at LogisticRegression.scala:1892, took 0.015575 s
18/02/28 13:48:20 INFO TorrentBroadcast: Destroying Broadcast(54) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:48:20 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
18/02/28 13:48:20 INFO LBFGS: Step Size: 1.000
18/02/28 13:48:20 INFO LBFGS: Val and Grad Norm: 0.286139 (rel: 4.16e-06) 7.16584e-05
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 104.0 B, free 344.1 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.1 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:61164 (size: 186.0 B, free: 345.1 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 56 from broadcast at LogisticRegression.scala:1879
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:61164 in memory (size: 186.0 B, free: 345.1 MB)
18/02/28 13:48:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:48:20 INFO DAGScheduler: Got job 28 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:48:20 INFO DAGScheduler: Final stage: ResultStage 38 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:48:20 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:48:20 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:20 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[102] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 74.1 KB, free 344.1 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 29.2 KB, free 344.0 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:61164 (size: 29.2 KB, free: 345.0 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 38 (MapPartitionsRDD[102] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:20 INFO TaskSchedulerImpl: Adding task set 38.0 with 4 tasks
18/02/28 13:48:20 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 125, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 1.0 in stage 38.0 (TID 126, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 2.0 in stage 38.0 (TID 127, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 3.0 in stage 38.0 (TID 128, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO Executor: Running task 0.0 in stage 38.0 (TID 125)
18/02/28 13:48:20 INFO Executor: Running task 1.0 in stage 38.0 (TID 126)
18/02/28 13:48:20 INFO Executor: Running task 2.0 in stage 38.0 (TID 127)
18/02/28 13:48:20 INFO Executor: Running task 3.0 in stage 38.0 (TID 128)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 13:48:20 INFO Executor: Finished task 0.0 in stage 38.0 (TID 125). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 13:48:20 INFO Executor: Finished task 1.0 in stage 38.0 (TID 126). 3395 bytes result sent to driver
18/02/28 13:48:20 INFO Executor: Finished task 3.0 in stage 38.0 (TID 128). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 13:48:20 INFO Executor: Finished task 2.0 in stage 38.0 (TID 127). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 125) in 11 ms on localhost (executor driver) (1/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 1.0 in stage 38.0 (TID 126) in 12 ms on localhost (executor driver) (2/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 3.0 in stage 38.0 (TID 128) in 14 ms on localhost (executor driver) (3/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 2.0 in stage 38.0 (TID 127) in 14 ms on localhost (executor driver) (4/4)
18/02/28 13:48:20 INFO DAGScheduler: ResultStage 38 (treeAggregate at LogisticRegression.scala:1892) finished in 0.014 s
18/02/28 13:48:20 INFO DAGScheduler: Job 28 finished: treeAggregate at LogisticRegression.scala:1892, took 0.021547 s
18/02/28 13:48:20 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
18/02/28 13:48:20 INFO TorrentBroadcast: Destroying Broadcast(56) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:48:20 INFO LBFGS: Step Size: 1.000
18/02/28 13:48:20 INFO LBFGS: Val and Grad Norm: 0.286139 (rel: 1.43e-07) 6.60683e-06
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:61164 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 104.0 B, free 344.0 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.0 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:61164 (size: 186.0 B, free: 345.0 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 58 from broadcast at LogisticRegression.scala:1879
18/02/28 13:48:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:48:20 INFO DAGScheduler: Got job 29 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:48:20 INFO DAGScheduler: Final stage: ResultStage 39 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:48:20 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:48:20 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:20 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[103] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 74.1 KB, free 344.0 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 29.2 KB, free 343.9 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:61164 (size: 29.2 KB, free: 345.0 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 39 (MapPartitionsRDD[103] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:20 INFO TaskSchedulerImpl: Adding task set 39.0 with 4 tasks
18/02/28 13:48:20 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 129, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 1.0 in stage 39.0 (TID 130, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 2.0 in stage 39.0 (TID 131, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 3.0 in stage 39.0 (TID 132, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO Executor: Running task 0.0 in stage 39.0 (TID 129)
18/02/28 13:48:20 INFO Executor: Running task 3.0 in stage 39.0 (TID 132)
18/02/28 13:48:20 INFO Executor: Running task 2.0 in stage 39.0 (TID 131)
18/02/28 13:48:20 INFO Executor: Running task 1.0 in stage 39.0 (TID 130)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 13:48:20 INFO Executor: Finished task 2.0 in stage 39.0 (TID 131). 3395 bytes result sent to driver
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 13:48:20 INFO Executor: Finished task 1.0 in stage 39.0 (TID 130). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 13:48:20 INFO Executor: Finished task 3.0 in stage 39.0 (TID 132). 3481 bytes result sent to driver
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 13:48:20 INFO TaskSetManager: Finished task 2.0 in stage 39.0 (TID 131) in 11 ms on localhost (executor driver) (1/4)
18/02/28 13:48:20 INFO Executor: Finished task 0.0 in stage 39.0 (TID 129). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 1.0 in stage 39.0 (TID 130) in 12 ms on localhost (executor driver) (2/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 129) in 13 ms on localhost (executor driver) (3/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 3.0 in stage 39.0 (TID 132) in 12 ms on localhost (executor driver) (4/4)
18/02/28 13:48:20 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
18/02/28 13:48:20 INFO DAGScheduler: ResultStage 39 (treeAggregate at LogisticRegression.scala:1892) finished in 0.014 s
18/02/28 13:48:20 INFO DAGScheduler: Job 29 finished: treeAggregate at LogisticRegression.scala:1892, took 0.039746 s
18/02/28 13:48:20 INFO TorrentBroadcast: Destroying Broadcast(58) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:48:20 INFO LBFGS: Step Size: 1.000
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:61164 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 13:48:20 INFO LBFGS: Val and Grad Norm: 0.286139 (rel: 1.91e-09) 2.19290e-06
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 104.0 B, free 343.9 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.9 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:61164 (size: 186.0 B, free: 345.0 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 60 from broadcast at LogisticRegression.scala:1879
18/02/28 13:48:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:48:20 INFO DAGScheduler: Got job 30 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:48:20 INFO DAGScheduler: Final stage: ResultStage 40 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:48:20 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:48:20 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:20 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[104] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 74.1 KB, free 343.9 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 29.2 KB, free 343.8 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:61164 (size: 29.2 KB, free: 345.0 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 40 (MapPartitionsRDD[104] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:20 INFO TaskSchedulerImpl: Adding task set 40.0 with 4 tasks
18/02/28 13:48:20 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 133, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 1.0 in stage 40.0 (TID 134, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 2.0 in stage 40.0 (TID 135, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 3.0 in stage 40.0 (TID 136, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO Executor: Running task 0.0 in stage 40.0 (TID 133)
18/02/28 13:48:20 INFO Executor: Running task 2.0 in stage 40.0 (TID 135)
18/02/28 13:48:20 INFO Executor: Running task 3.0 in stage 40.0 (TID 136)
18/02/28 13:48:20 INFO Executor: Running task 1.0 in stage 40.0 (TID 134)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 13:48:20 INFO Executor: Finished task 0.0 in stage 40.0 (TID 133). 3481 bytes result sent to driver
18/02/28 13:48:20 INFO Executor: Finished task 1.0 in stage 40.0 (TID 134). 3395 bytes result sent to driver
18/02/28 13:48:20 INFO Executor: Finished task 3.0 in stage 40.0 (TID 136). 3481 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 133) in 9 ms on localhost (executor driver) (1/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 3.0 in stage 40.0 (TID 136) in 9 ms on localhost (executor driver) (2/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 1.0 in stage 40.0 (TID 134) in 10 ms on localhost (executor driver) (3/4)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 13:48:20 INFO Executor: Finished task 2.0 in stage 40.0 (TID 135). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 2.0 in stage 40.0 (TID 135) in 12 ms on localhost (executor driver) (4/4)
18/02/28 13:48:20 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
18/02/28 13:48:20 INFO DAGScheduler: ResultStage 40 (treeAggregate at LogisticRegression.scala:1892) finished in 0.013 s
18/02/28 13:48:20 INFO DAGScheduler: Job 30 finished: treeAggregate at LogisticRegression.scala:1892, took 0.025725 s
18/02/28 13:48:20 INFO TorrentBroadcast: Destroying Broadcast(60) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:61164 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 104.0 B, free 343.8 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.8 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:61164 (size: 186.0 B, free: 345.0 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 62 from broadcast at LogisticRegression.scala:1879
18/02/28 13:48:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:48:20 INFO DAGScheduler: Got job 31 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:48:20 INFO DAGScheduler: Final stage: ResultStage 41 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:48:20 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:48:20 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:20 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[105] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 74.1 KB, free 343.8 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 29.2 KB, free 343.7 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:61164 (size: 29.2 KB, free: 345.0 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 41 (MapPartitionsRDD[105] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:20 INFO TaskSchedulerImpl: Adding task set 41.0 with 4 tasks
18/02/28 13:48:20 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 137, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 1.0 in stage 41.0 (TID 138, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 2.0 in stage 41.0 (TID 139, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 3.0 in stage 41.0 (TID 140, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO Executor: Running task 1.0 in stage 41.0 (TID 138)
18/02/28 13:48:20 INFO Executor: Running task 3.0 in stage 41.0 (TID 140)
18/02/28 13:48:20 INFO Executor: Running task 2.0 in stage 41.0 (TID 139)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 13:48:20 INFO Executor: Finished task 1.0 in stage 41.0 (TID 138). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO Executor: Finished task 3.0 in stage 41.0 (TID 140). 3395 bytes result sent to driver
18/02/28 13:48:20 INFO Executor: Running task 0.0 in stage 41.0 (TID 137)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 1.0 in stage 41.0 (TID 138) in 9 ms on localhost (executor driver) (1/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 3.0 in stage 41.0 (TID 140) in 8 ms on localhost (executor driver) (2/4)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 13:48:20 INFO Executor: Finished task 2.0 in stage 41.0 (TID 139). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 13:48:20 INFO Executor: Finished task 0.0 in stage 41.0 (TID 137). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 2.0 in stage 41.0 (TID 139) in 15 ms on localhost (executor driver) (3/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 137) in 15 ms on localhost (executor driver) (4/4)
18/02/28 13:48:20 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
18/02/28 13:48:20 INFO DAGScheduler: ResultStage 41 (treeAggregate at LogisticRegression.scala:1892) finished in 0.016 s
18/02/28 13:48:20 INFO DAGScheduler: Job 31 finished: treeAggregate at LogisticRegression.scala:1892, took 0.022472 s
18/02/28 13:48:20 INFO TorrentBroadcast: Destroying Broadcast(62) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:48:20 INFO StrongWolfeLineSearch: Line search t: 0.356408904604832 fval: 0.28613898522298664 rhs: 0.28613898523621756 cdd: -2.0540352562454108E-16
18/02/28 13:48:20 INFO LBFGS: Step Size: 0.3564
18/02/28 13:48:20 INFO LBFGS: Val and Grad Norm: 0.286139 (rel: 4.62e-11) 4.35397e-07
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 127.0.0.1:61164 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 104.0 B, free 343.7 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.7 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:61164 (size: 186.0 B, free: 345.0 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 64 from broadcast at LogisticRegression.scala:1879
18/02/28 13:48:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 13:48:20 INFO DAGScheduler: Got job 32 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 13:48:20 INFO DAGScheduler: Final stage: ResultStage 42 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 13:48:20 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:48:20 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:20 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[106] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 74.1 KB, free 343.7 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 29.2 KB, free 343.6 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:61164 (size: 29.2 KB, free: 344.9 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 42 (MapPartitionsRDD[106] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:20 INFO TaskSchedulerImpl: Adding task set 42.0 with 4 tasks
18/02/28 13:48:20 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 141, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 1.0 in stage 42.0 (TID 142, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 2.0 in stage 42.0 (TID 143, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 3.0 in stage 42.0 (TID 144, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:20 INFO Executor: Running task 1.0 in stage 42.0 (TID 142)
18/02/28 13:48:20 INFO Executor: Running task 3.0 in stage 42.0 (TID 144)
18/02/28 13:48:20 INFO Executor: Running task 2.0 in stage 42.0 (TID 143)
18/02/28 13:48:20 INFO Executor: Running task 0.0 in stage 42.0 (TID 141)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 13:48:20 INFO Executor: Finished task 3.0 in stage 42.0 (TID 144). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 13:48:20 INFO Executor: Finished task 2.0 in stage 42.0 (TID 143). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO Executor: Finished task 1.0 in stage 42.0 (TID 142). 3438 bytes result sent to driver
18/02/28 13:48:20 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 13:48:20 INFO Executor: Finished task 0.0 in stage 42.0 (TID 141). 3481 bytes result sent to driver
18/02/28 13:48:20 INFO TaskSetManager: Finished task 3.0 in stage 42.0 (TID 144) in 13 ms on localhost (executor driver) (1/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 1.0 in stage 42.0 (TID 142) in 15 ms on localhost (executor driver) (2/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 2.0 in stage 42.0 (TID 143) in 15 ms on localhost (executor driver) (3/4)
18/02/28 13:48:20 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 141) in 15 ms on localhost (executor driver) (4/4)
18/02/28 13:48:20 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
18/02/28 13:48:20 INFO DAGScheduler: ResultStage 42 (treeAggregate at LogisticRegression.scala:1892) finished in 0.015 s
18/02/28 13:48:20 INFO DAGScheduler: Job 32 finished: treeAggregate at LogisticRegression.scala:1892, took 0.028097 s
18/02/28 13:48:20 INFO TorrentBroadcast: Destroying Broadcast(64) (from destroy at LogisticRegression.scala:1933)
18/02/28 13:48:20 INFO LBFGS: Step Size: 1.000
18/02/28 13:48:20 INFO LBFGS: Val and Grad Norm: 0.286139 (rel: 6.16e-12) 6.27839e-08
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:61164 in memory (size: 186.0 B, free: 344.9 MB)
18/02/28 13:48:20 INFO LBFGS: Converged because gradient converged
18/02/28 13:48:20 INFO TorrentBroadcast: Destroying Broadcast(25) (from destroy at LogisticRegression.scala:796)
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:61164 in memory (size: 109.0 B, free: 344.9 MB)
18/02/28 13:48:20 INFO MapPartitionsRDD: Removing RDD 85 from persistence list
18/02/28 13:48:20 INFO BlockManager: Removing RDD 85
18/02/28 13:48:20 INFO CodeGenerator: Code generated in 28.437847 ms
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 127.0.0.1:61164 in memory (size: 29.2 KB, free: 345.3 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 127.0.0.1:61164 in memory (size: 29.2 KB, free: 345.3 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:61164 in memory (size: 29.2 KB, free: 345.3 MB)
18/02/28 13:48:20 INFO Instrumentation: LogisticRegression-logistic_regression_29281b016def-70802161-1: training finished
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 127.0.0.1:61164 in memory (size: 29.2 KB, free: 345.4 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 127.0.0.1:61164 in memory (size: 29.2 KB, free: 345.4 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:61164 in memory (size: 29.2 KB, free: 345.4 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:61164 in memory (size: 29.2 KB, free: 345.5 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:61164 in memory (size: 29.2 KB, free: 345.5 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:61164 in memory (size: 29.2 KB, free: 345.5 MB)
18/02/28 13:48:20 INFO SparkContext: Starting job: sortByKey at BinaryClassificationMetrics.scala:155
18/02/28 13:48:20 INFO DAGScheduler: Registering RDD 111 (map at LogisticRegression.scala:1398)
18/02/28 13:48:20 INFO DAGScheduler: Got job 33 (sortByKey at BinaryClassificationMetrics.scala:155) with 4 output partitions
18/02/28 13:48:20 INFO DAGScheduler: Final stage: ResultStage 44 (sortByKey at BinaryClassificationMetrics.scala:155)
18/02/28 13:48:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)
18/02/28 13:48:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 43)
18/02/28 13:48:20 INFO DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[111] at map at LogisticRegression.scala:1398), which has no missing parents
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 83.2 KB, free 344.8 MB)
18/02/28 13:48:20 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 32.8 KB, free 344.7 MB)
18/02/28 13:48:20 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:61164 (size: 32.8 KB, free: 345.5 MB)
18/02/28 13:48:20 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:20 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[111] at map at LogisticRegression.scala:1398) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:20 INFO TaskSchedulerImpl: Adding task set 43.0 with 4 tasks
18/02/28 13:48:20 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 145, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 1.0 in stage 43.0 (TID 146, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 2.0 in stage 43.0 (TID 147, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:48:20 INFO TaskSetManager: Starting task 3.0 in stage 43.0 (TID 148, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:20 INFO Executor: Running task 0.0 in stage 43.0 (TID 145)
18/02/28 13:48:20 INFO Executor: Running task 1.0 in stage 43.0 (TID 146)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_48_0 locally
18/02/28 13:48:20 INFO Executor: Running task 2.0 in stage 43.0 (TID 147)
18/02/28 13:48:20 INFO Executor: Running task 3.0 in stage 43.0 (TID 148)
18/02/28 13:48:20 INFO BlockManager: Found block rdd_48_2 locally
18/02/28 13:48:20 INFO BlockManager: Found block rdd_48_3 locally
18/02/28 13:48:20 INFO BlockManager: Found block rdd_48_1 locally
18/02/28 13:48:20 INFO CodeGenerator: Code generated in 12.597943 ms
18/02/28 13:48:21 INFO CodeGenerator: Code generated in 6.843941 ms
18/02/28 13:48:21 INFO Executor: Finished task 3.0 in stage 43.0 (TID 148). 2215 bytes result sent to driver
18/02/28 13:48:21 INFO TaskSetManager: Finished task 3.0 in stage 43.0 (TID 148) in 200 ms on localhost (executor driver) (1/4)
18/02/28 13:48:21 INFO Executor: Finished task 1.0 in stage 43.0 (TID 146). 2258 bytes result sent to driver
18/02/28 13:48:21 INFO TaskSetManager: Finished task 1.0 in stage 43.0 (TID 146) in 215 ms on localhost (executor driver) (2/4)
18/02/28 13:48:21 INFO Executor: Finished task 0.0 in stage 43.0 (TID 145). 2215 bytes result sent to driver
18/02/28 13:48:21 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 145) in 219 ms on localhost (executor driver) (3/4)
18/02/28 13:48:21 INFO Executor: Finished task 2.0 in stage 43.0 (TID 147). 2215 bytes result sent to driver
18/02/28 13:48:21 INFO TaskSetManager: Finished task 2.0 in stage 43.0 (TID 147) in 226 ms on localhost (executor driver) (4/4)
18/02/28 13:48:21 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
18/02/28 13:48:21 INFO DAGScheduler: ShuffleMapStage 43 (map at LogisticRegression.scala:1398) finished in 0.226 s
18/02/28 13:48:21 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:48:21 INFO DAGScheduler: running: Set()
18/02/28 13:48:21 INFO DAGScheduler: waiting: Set(ResultStage 44)
18/02/28 13:48:21 INFO DAGScheduler: failed: Set()
18/02/28 13:48:21 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[114] at sortByKey at BinaryClassificationMetrics.scala:155), which has no missing parents
18/02/28 13:48:21 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 3.6 KB, free 344.7 MB)
18/02/28 13:48:21 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 2.0 KB, free 344.7 MB)
18/02/28 13:48:21 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:61164 (size: 2.0 KB, free: 345.5 MB)
18/02/28 13:48:21 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:21 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 44 (MapPartitionsRDD[114] at sortByKey at BinaryClassificationMetrics.scala:155) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:21 INFO TaskSchedulerImpl: Adding task set 44.0 with 4 tasks
18/02/28 13:48:21 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 149, localhost, executor driver, partition 0, ANY, 4621 bytes)
18/02/28 13:48:21 INFO TaskSetManager: Starting task 1.0 in stage 44.0 (TID 150, localhost, executor driver, partition 1, ANY, 4621 bytes)
18/02/28 13:48:21 INFO TaskSetManager: Starting task 2.0 in stage 44.0 (TID 151, localhost, executor driver, partition 2, ANY, 4621 bytes)
18/02/28 13:48:21 INFO TaskSetManager: Starting task 3.0 in stage 44.0 (TID 152, localhost, executor driver, partition 3, ANY, 4621 bytes)
18/02/28 13:48:21 INFO Executor: Running task 0.0 in stage 44.0 (TID 149)
18/02/28 13:48:21 INFO Executor: Running task 2.0 in stage 44.0 (TID 151)
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:48:21 INFO Executor: Running task 1.0 in stage 44.0 (TID 150)
18/02/28 13:48:21 INFO Executor: Running task 3.0 in stage 44.0 (TID 152)
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:48:21 INFO Executor: Finished task 0.0 in stage 44.0 (TID 149). 1714 bytes result sent to driver
18/02/28 13:48:21 INFO Executor: Finished task 3.0 in stage 44.0 (TID 152). 1714 bytes result sent to driver
18/02/28 13:48:21 INFO Executor: Finished task 1.0 in stage 44.0 (TID 150). 1757 bytes result sent to driver
18/02/28 13:48:21 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 149) in 31 ms on localhost (executor driver) (1/4)
18/02/28 13:48:21 INFO TaskSetManager: Finished task 3.0 in stage 44.0 (TID 152) in 32 ms on localhost (executor driver) (2/4)
18/02/28 13:48:21 INFO TaskSetManager: Finished task 1.0 in stage 44.0 (TID 150) in 32 ms on localhost (executor driver) (3/4)
18/02/28 13:48:21 INFO Executor: Finished task 2.0 in stage 44.0 (TID 151). 1714 bytes result sent to driver
18/02/28 13:48:21 INFO TaskSetManager: Finished task 2.0 in stage 44.0 (TID 151) in 35 ms on localhost (executor driver) (4/4)
18/02/28 13:48:21 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
18/02/28 13:48:21 INFO DAGScheduler: ResultStage 44 (sortByKey at BinaryClassificationMetrics.scala:155) finished in 0.036 s
18/02/28 13:48:21 INFO DAGScheduler: Job 33 finished: sortByKey at BinaryClassificationMetrics.scala:155, took 0.279146 s
18/02/28 13:48:21 INFO SparkContext: Starting job: count at BinaryClassificationMetrics.scala:163
18/02/28 13:48:21 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 10 is 171 bytes
18/02/28 13:48:21 INFO DAGScheduler: Registering RDD 112 (combineByKey at BinaryClassificationMetrics.scala:151)
18/02/28 13:48:21 INFO DAGScheduler: Got job 34 (count at BinaryClassificationMetrics.scala:163) with 4 output partitions
18/02/28 13:48:21 INFO DAGScheduler: Final stage: ResultStage 47 (count at BinaryClassificationMetrics.scala:163)
18/02/28 13:48:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 46)
18/02/28 13:48:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 46)
18/02/28 13:48:21 INFO DAGScheduler: Submitting ShuffleMapStage 46 (ShuffledRDD[112] at combineByKey at BinaryClassificationMetrics.scala:151), which has no missing parents
18/02/28 13:48:21 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 3.4 KB, free 344.7 MB)
18/02/28 13:48:21 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 1914.0 B, free 344.7 MB)
18/02/28 13:48:21 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:61164 (size: 1914.0 B, free: 345.5 MB)
18/02/28 13:48:21 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:21 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 46 (ShuffledRDD[112] at combineByKey at BinaryClassificationMetrics.scala:151) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:21 INFO TaskSchedulerImpl: Adding task set 46.0 with 4 tasks
18/02/28 13:48:21 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 153, localhost, executor driver, partition 0, ANY, 4610 bytes)
18/02/28 13:48:21 INFO TaskSetManager: Starting task 1.0 in stage 46.0 (TID 154, localhost, executor driver, partition 1, ANY, 4610 bytes)
18/02/28 13:48:21 INFO TaskSetManager: Starting task 2.0 in stage 46.0 (TID 155, localhost, executor driver, partition 2, ANY, 4610 bytes)
18/02/28 13:48:21 INFO TaskSetManager: Starting task 3.0 in stage 46.0 (TID 156, localhost, executor driver, partition 3, ANY, 4610 bytes)
18/02/28 13:48:21 INFO Executor: Running task 0.0 in stage 46.0 (TID 153)
18/02/28 13:48:21 INFO Executor: Running task 1.0 in stage 46.0 (TID 154)
18/02/28 13:48:21 INFO Executor: Running task 2.0 in stage 46.0 (TID 155)
18/02/28 13:48:21 INFO Executor: Running task 3.0 in stage 46.0 (TID 156)
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:48:21 INFO Executor: Finished task 0.0 in stage 46.0 (TID 153). 1282 bytes result sent to driver
18/02/28 13:48:21 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 153) in 90 ms on localhost (executor driver) (1/4)
18/02/28 13:48:21 INFO Executor: Finished task 1.0 in stage 46.0 (TID 154). 1196 bytes result sent to driver
18/02/28 13:48:21 INFO Executor: Finished task 2.0 in stage 46.0 (TID 155). 1239 bytes result sent to driver
18/02/28 13:48:21 INFO TaskSetManager: Finished task 1.0 in stage 46.0 (TID 154) in 134 ms on localhost (executor driver) (2/4)
18/02/28 13:48:21 INFO TaskSetManager: Finished task 2.0 in stage 46.0 (TID 155) in 135 ms on localhost (executor driver) (3/4)
18/02/28 13:48:21 INFO Executor: Finished task 3.0 in stage 46.0 (TID 156). 1239 bytes result sent to driver
18/02/28 13:48:21 INFO TaskSetManager: Finished task 3.0 in stage 46.0 (TID 156) in 140 ms on localhost (executor driver) (4/4)
18/02/28 13:48:21 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
18/02/28 13:48:21 INFO DAGScheduler: ShuffleMapStage 46 (combineByKey at BinaryClassificationMetrics.scala:151) finished in 0.140 s
18/02/28 13:48:21 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:48:21 INFO DAGScheduler: running: Set()
18/02/28 13:48:21 INFO DAGScheduler: waiting: Set(ResultStage 47)
18/02/28 13:48:21 INFO DAGScheduler: failed: Set()
18/02/28 13:48:21 INFO DAGScheduler: Submitting ResultStage 47 (ShuffledRDD[115] at sortByKey at BinaryClassificationMetrics.scala:155), which has no missing parents
18/02/28 13:48:21 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 3.1 KB, free 344.7 MB)
18/02/28 13:48:21 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 1868.0 B, free 344.7 MB)
18/02/28 13:48:21 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:61164 (size: 1868.0 B, free: 345.5 MB)
18/02/28 13:48:21 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:21 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 47 (ShuffledRDD[115] at sortByKey at BinaryClassificationMetrics.scala:155) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:21 INFO TaskSchedulerImpl: Adding task set 47.0 with 4 tasks
18/02/28 13:48:21 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 157, localhost, executor driver, partition 0, ANY, 4621 bytes)
18/02/28 13:48:21 INFO TaskSetManager: Starting task 1.0 in stage 47.0 (TID 158, localhost, executor driver, partition 1, ANY, 4621 bytes)
18/02/28 13:48:21 INFO TaskSetManager: Starting task 2.0 in stage 47.0 (TID 159, localhost, executor driver, partition 2, ANY, 4621 bytes)
18/02/28 13:48:21 INFO TaskSetManager: Starting task 3.0 in stage 47.0 (TID 160, localhost, executor driver, partition 3, ANY, 4621 bytes)
18/02/28 13:48:21 INFO Executor: Running task 0.0 in stage 47.0 (TID 157)
18/02/28 13:48:21 INFO Executor: Running task 1.0 in stage 47.0 (TID 158)
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:48:21 INFO Executor: Running task 3.0 in stage 47.0 (TID 160)
18/02/28 13:48:21 INFO Executor: Running task 2.0 in stage 47.0 (TID 159)
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:48:21 INFO Executor: Finished task 3.0 in stage 47.0 (TID 160). 1004 bytes result sent to driver
18/02/28 13:48:21 INFO Executor: Finished task 2.0 in stage 47.0 (TID 159). 1047 bytes result sent to driver
18/02/28 13:48:21 INFO Executor: Finished task 0.0 in stage 47.0 (TID 157). 1047 bytes result sent to driver
18/02/28 13:48:21 INFO Executor: Finished task 1.0 in stage 47.0 (TID 158). 1047 bytes result sent to driver
18/02/28 13:48:21 INFO TaskSetManager: Finished task 3.0 in stage 47.0 (TID 160) in 40 ms on localhost (executor driver) (1/4)
18/02/28 13:48:21 INFO TaskSetManager: Finished task 2.0 in stage 47.0 (TID 159) in 41 ms on localhost (executor driver) (2/4)
18/02/28 13:48:21 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 157) in 43 ms on localhost (executor driver) (3/4)
18/02/28 13:48:21 INFO TaskSetManager: Finished task 1.0 in stage 47.0 (TID 158) in 43 ms on localhost (executor driver) (4/4)
18/02/28 13:48:21 INFO DAGScheduler: ResultStage 47 (count at BinaryClassificationMetrics.scala:163) finished in 0.044 s
18/02/28 13:48:21 INFO DAGScheduler: Job 34 finished: count at BinaryClassificationMetrics.scala:163, took 0.205611 s
18/02/28 13:48:21 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
18/02/28 13:48:21 INFO SparkContext: Starting job: collect at BinaryClassificationMetrics.scala:192
18/02/28 13:48:21 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 10 is 171 bytes
18/02/28 13:48:21 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 11 is 169 bytes
18/02/28 13:48:21 INFO DAGScheduler: Got job 35 (collect at BinaryClassificationMetrics.scala:192) with 4 output partitions
18/02/28 13:48:21 INFO DAGScheduler: Final stage: ResultStage 50 (collect at BinaryClassificationMetrics.scala:192)
18/02/28 13:48:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 49)
18/02/28 13:48:21 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:21 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[118] at mapPartitions at BinaryClassificationMetrics.scala:188), which has no missing parents
18/02/28 13:48:21 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 4.2 KB, free 344.7 MB)
18/02/28 13:48:21 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 2.3 KB, free 344.7 MB)
18/02/28 13:48:21 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:61164 (size: 2.3 KB, free: 345.5 MB)
18/02/28 13:48:21 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:21 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 50 (MapPartitionsRDD[118] at mapPartitions at BinaryClassificationMetrics.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:21 INFO TaskSchedulerImpl: Adding task set 50.0 with 4 tasks
18/02/28 13:48:21 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 161, localhost, executor driver, partition 0, ANY, 4621 bytes)
18/02/28 13:48:21 INFO TaskSetManager: Starting task 1.0 in stage 50.0 (TID 162, localhost, executor driver, partition 1, ANY, 4621 bytes)
18/02/28 13:48:21 INFO TaskSetManager: Starting task 2.0 in stage 50.0 (TID 163, localhost, executor driver, partition 2, ANY, 4621 bytes)
18/02/28 13:48:21 INFO TaskSetManager: Starting task 3.0 in stage 50.0 (TID 164, localhost, executor driver, partition 3, ANY, 4621 bytes)
18/02/28 13:48:21 INFO Executor: Running task 0.0 in stage 50.0 (TID 161)
18/02/28 13:48:21 INFO Executor: Running task 1.0 in stage 50.0 (TID 162)
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:48:21 INFO Executor: Running task 2.0 in stage 50.0 (TID 163)
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:48:21 INFO Executor: Finished task 1.0 in stage 50.0 (TID 162). 1174 bytes result sent to driver
18/02/28 13:48:21 INFO Executor: Running task 3.0 in stage 50.0 (TID 164)
18/02/28 13:48:21 INFO Executor: Finished task 2.0 in stage 50.0 (TID 163). 1174 bytes result sent to driver
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:48:21 INFO Executor: Finished task 0.0 in stage 50.0 (TID 161). 1217 bytes result sent to driver
18/02/28 13:48:21 INFO Executor: Finished task 3.0 in stage 50.0 (TID 164). 1217 bytes result sent to driver
18/02/28 13:48:21 INFO TaskSetManager: Finished task 2.0 in stage 50.0 (TID 163) in 32 ms on localhost (executor driver) (1/4)
18/02/28 13:48:21 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 161) in 32 ms on localhost (executor driver) (2/4)
18/02/28 13:48:21 INFO TaskSetManager: Finished task 3.0 in stage 50.0 (TID 164) in 32 ms on localhost (executor driver) (3/4)
18/02/28 13:48:21 INFO TaskSetManager: Finished task 1.0 in stage 50.0 (TID 162) in 33 ms on localhost (executor driver) (4/4)
18/02/28 13:48:21 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
18/02/28 13:48:21 INFO DAGScheduler: ResultStage 50 (collect at BinaryClassificationMetrics.scala:192) finished in 0.035 s
18/02/28 13:48:21 INFO DAGScheduler: Job 35 finished: collect at BinaryClassificationMetrics.scala:192, took 0.042361 s
18/02/28 13:48:21 INFO BinaryClassificationMetrics: Total counts: {numPos: 799, numNeg: 2511}
18/02/28 13:48:21 INFO SparkContext: Starting job: collect at SlidingRDD.scala:81
18/02/28 13:48:21 INFO DAGScheduler: Got job 36 (collect at SlidingRDD.scala:81) with 6 output partitions
18/02/28 13:48:21 INFO DAGScheduler: Final stage: ResultStage 53 (collect at SlidingRDD.scala:81)
18/02/28 13:48:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)
18/02/28 13:48:21 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:21 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[126] at mapPartitions at SlidingRDD.scala:78), which has no missing parents
18/02/28 13:48:21 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 6.3 KB, free 344.7 MB)
18/02/28 13:48:21 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 3.3 KB, free 344.7 MB)
18/02/28 13:48:21 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 127.0.0.1:61164 (size: 3.3 KB, free: 345.5 MB)
18/02/28 13:48:21 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:21 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 53 (MapPartitionsRDD[126] at mapPartitions at SlidingRDD.scala:78) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
18/02/28 13:48:21 INFO TaskSchedulerImpl: Adding task set 53.0 with 6 tasks
18/02/28 13:48:21 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 165, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 13:48:21 INFO TaskSetManager: Starting task 5.0 in stage 53.0 (TID 166, localhost, executor driver, partition 5, PROCESS_LOCAL, 5058 bytes)
18/02/28 13:48:21 INFO TaskSetManager: Starting task 1.0 in stage 53.0 (TID 167, localhost, executor driver, partition 1, ANY, 4730 bytes)
18/02/28 13:48:21 INFO TaskSetManager: Starting task 2.0 in stage 53.0 (TID 168, localhost, executor driver, partition 2, ANY, 4730 bytes)
18/02/28 13:48:21 INFO Executor: Running task 5.0 in stage 53.0 (TID 166)
18/02/28 13:48:21 INFO Executor: Running task 0.0 in stage 53.0 (TID 165)
18/02/28 13:48:21 INFO Executor: Running task 1.0 in stage 53.0 (TID 167)
18/02/28 13:48:21 INFO Executor: Running task 2.0 in stage 53.0 (TID 168)
18/02/28 13:48:21 INFO Executor: Finished task 0.0 in stage 53.0 (TID 165). 856 bytes result sent to driver
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:48:21 INFO Executor: Finished task 5.0 in stage 53.0 (TID 166). 856 bytes result sent to driver
18/02/28 13:48:21 INFO TaskSetManager: Starting task 3.0 in stage 53.0 (TID 169, localhost, executor driver, partition 3, ANY, 4730 bytes)
18/02/28 13:48:21 INFO TaskSetManager: Starting task 4.0 in stage 53.0 (TID 170, localhost, executor driver, partition 4, ANY, 4730 bytes)
18/02/28 13:48:21 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 165) in 15 ms on localhost (executor driver) (1/6)
18/02/28 13:48:21 INFO TaskSetManager: Finished task 5.0 in stage 53.0 (TID 166) in 12 ms on localhost (executor driver) (2/6)
18/02/28 13:48:21 INFO Executor: Running task 3.0 in stage 53.0 (TID 169)
18/02/28 13:48:21 INFO Executor: Running task 4.0 in stage 53.0 (TID 170)
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:48:21 INFO MemoryStore: Block rdd_119_0 stored as values in memory (estimated size 2.1 KB, free 344.7 MB)
18/02/28 13:48:21 INFO BlockManagerInfo: Added rdd_119_0 in memory on 127.0.0.1:61164 (size: 2.1 KB, free: 345.5 MB)
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:48:21 INFO MemoryStore: Block rdd_119_1 stored as values in memory (estimated size 2.1 KB, free 344.7 MB)
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:48:21 INFO MemoryStore: Block rdd_119_2 stored as values in memory (estimated size 2.1 KB, free 344.7 MB)
18/02/28 13:48:21 INFO BlockManagerInfo: Added rdd_119_1 in memory on 127.0.0.1:61164 (size: 2.1 KB, free: 345.5 MB)
18/02/28 13:48:21 INFO BlockManagerInfo: Added rdd_119_2 in memory on 127.0.0.1:61164 (size: 2.1 KB, free: 345.5 MB)
18/02/28 13:48:21 INFO Executor: Finished task 1.0 in stage 53.0 (TID 167). 1983 bytes result sent to driver
18/02/28 13:48:21 INFO MemoryStore: Block rdd_119_3 stored as values in memory (estimated size 2.2 KB, free 344.7 MB)
18/02/28 13:48:21 INFO Executor: Finished task 2.0 in stage 53.0 (TID 168). 1940 bytes result sent to driver
18/02/28 13:48:21 INFO Executor: Finished task 3.0 in stage 53.0 (TID 169). 1983 bytes result sent to driver
18/02/28 13:48:21 INFO TaskSetManager: Finished task 1.0 in stage 53.0 (TID 167) in 33 ms on localhost (executor driver) (3/6)
18/02/28 13:48:21 INFO BlockManagerInfo: Added rdd_119_3 in memory on 127.0.0.1:61164 (size: 2.2 KB, free: 345.5 MB)
18/02/28 13:48:21 INFO Executor: Finished task 4.0 in stage 53.0 (TID 170). 1983 bytes result sent to driver
18/02/28 13:48:21 INFO TaskSetManager: Finished task 2.0 in stage 53.0 (TID 168) in 34 ms on localhost (executor driver) (4/6)
18/02/28 13:48:21 INFO TaskSetManager: Finished task 3.0 in stage 53.0 (TID 169) in 27 ms on localhost (executor driver) (5/6)
18/02/28 13:48:21 INFO TaskSetManager: Finished task 4.0 in stage 53.0 (TID 170) in 27 ms on localhost (executor driver) (6/6)
18/02/28 13:48:21 INFO DAGScheduler: ResultStage 53 (collect at SlidingRDD.scala:81) finished in 0.040 s
18/02/28 13:48:21 INFO DAGScheduler: Job 36 finished: collect at SlidingRDD.scala:81, took 0.048534 s
18/02/28 13:48:21 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
18/02/28 13:48:21 INFO SparkContext: Starting job: aggregate at AreaUnderCurve.scala:45
18/02/28 13:48:21 INFO DAGScheduler: Got job 37 (aggregate at AreaUnderCurve.scala:45) with 5 output partitions
18/02/28 13:48:21 INFO DAGScheduler: Final stage: ResultStage 56 (aggregate at AreaUnderCurve.scala:45)
18/02/28 13:48:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 55)
18/02/28 13:48:21 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:21 INFO DAGScheduler: Submitting ResultStage 56 (SlidingRDD[125] at RDD at SlidingRDD.scala:50), which has no missing parents
18/02/28 13:48:21 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 6.5 KB, free 344.7 MB)
18/02/28 13:48:21 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 3.4 KB, free 344.7 MB)
18/02/28 13:48:21 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 127.0.0.1:61164 (size: 3.4 KB, free: 345.5 MB)
18/02/28 13:48:21 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:21 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 56 (SlidingRDD[125] at RDD at SlidingRDD.scala:50) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/02/28 13:48:21 INFO TaskSchedulerImpl: Adding task set 56.0 with 5 tasks
18/02/28 13:48:21 INFO TaskSetManager: Starting task 1.0 in stage 56.0 (TID 171, localhost, executor driver, partition 1, PROCESS_LOCAL, 5269 bytes)
18/02/28 13:48:21 INFO TaskSetManager: Starting task 2.0 in stage 56.0 (TID 172, localhost, executor driver, partition 2, PROCESS_LOCAL, 5269 bytes)
18/02/28 13:48:21 INFO TaskSetManager: Starting task 3.0 in stage 56.0 (TID 173, localhost, executor driver, partition 3, PROCESS_LOCAL, 5269 bytes)
18/02/28 13:48:21 INFO TaskSetManager: Starting task 4.0 in stage 56.0 (TID 174, localhost, executor driver, partition 4, PROCESS_LOCAL, 5269 bytes)
18/02/28 13:48:21 INFO Executor: Running task 1.0 in stage 56.0 (TID 171)
18/02/28 13:48:21 INFO Executor: Running task 2.0 in stage 56.0 (TID 172)
18/02/28 13:48:21 INFO Executor: Running task 3.0 in stage 56.0 (TID 173)
18/02/28 13:48:21 INFO Executor: Running task 4.0 in stage 56.0 (TID 174)
18/02/28 13:48:21 INFO BlockManager: Found block rdd_119_0 locally
18/02/28 13:48:21 INFO BlockManager: Found block rdd_119_3 locally
18/02/28 13:48:21 INFO Executor: Finished task 1.0 in stage 56.0 (TID 171). 791 bytes result sent to driver
18/02/28 13:48:21 INFO BlockManager: Found block rdd_119_1 locally
18/02/28 13:48:21 INFO Executor: Finished task 2.0 in stage 56.0 (TID 172). 705 bytes result sent to driver
18/02/28 13:48:21 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 175, localhost, executor driver, partition 0, PROCESS_LOCAL, 5475 bytes)
18/02/28 13:48:21 INFO BlockManager: Found block rdd_119_2 locally
18/02/28 13:48:21 INFO Executor: Finished task 3.0 in stage 56.0 (TID 173). 748 bytes result sent to driver
18/02/28 13:48:21 INFO Executor: Finished task 4.0 in stage 56.0 (TID 174). 791 bytes result sent to driver
18/02/28 13:48:21 INFO Executor: Running task 0.0 in stage 56.0 (TID 175)
18/02/28 13:48:21 INFO TaskSetManager: Finished task 2.0 in stage 56.0 (TID 172) in 15 ms on localhost (executor driver) (1/5)
18/02/28 13:48:21 INFO TaskSetManager: Finished task 3.0 in stage 56.0 (TID 173) in 16 ms on localhost (executor driver) (2/5)
18/02/28 13:48:21 INFO TaskSetManager: Finished task 4.0 in stage 56.0 (TID 174) in 16 ms on localhost (executor driver) (3/5)
18/02/28 13:48:21 INFO TaskSetManager: Finished task 1.0 in stage 56.0 (TID 171) in 20 ms on localhost (executor driver) (4/5)
18/02/28 13:48:21 INFO Executor: Finished task 0.0 in stage 56.0 (TID 175). 662 bytes result sent to driver
18/02/28 13:48:21 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 175) in 8 ms on localhost (executor driver) (5/5)
18/02/28 13:48:21 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
18/02/28 13:48:21 INFO DAGScheduler: ResultStage 56 (aggregate at AreaUnderCurve.scala:45) finished in 0.021 s
18/02/28 13:48:21 INFO DAGScheduler: Job 37 finished: aggregate at AreaUnderCurve.scala:45, took 0.027025 s
18/02/28 13:48:21 INFO CodeGenerator: Code generated in 8.436006 ms
18/02/28 13:48:21 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:48:21 INFO DAGScheduler: Got job 38 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:48:21 INFO DAGScheduler: Final stage: ResultStage 59 (collect at utils.scala:211)
18/02/28 13:48:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 58)
18/02/28 13:48:21 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:21 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[130] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:21 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 10.4 KB, free 344.7 MB)
18/02/28 13:48:21 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.7 MB)
18/02/28 13:48:21 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 127.0.0.1:61164 (size: 4.9 KB, free: 345.5 MB)
18/02/28 13:48:21 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:21 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 59 (MapPartitionsRDD[130] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:21 INFO TaskSchedulerImpl: Adding task set 59.0 with 4 tasks
18/02/28 13:48:21 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 176, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:21 INFO TaskSetManager: Starting task 1.0 in stage 59.0 (TID 177, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:21 INFO TaskSetManager: Starting task 2.0 in stage 59.0 (TID 178, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:21 INFO TaskSetManager: Starting task 3.0 in stage 59.0 (TID 179, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:21 INFO Executor: Running task 0.0 in stage 59.0 (TID 176)
18/02/28 13:48:21 INFO BlockManager: Found block rdd_119_0 locally
18/02/28 13:48:21 INFO Executor: Running task 1.0 in stage 59.0 (TID 177)
18/02/28 13:48:21 INFO BlockManager: Found block rdd_119_1 locally
18/02/28 13:48:21 INFO Executor: Running task 3.0 in stage 59.0 (TID 179)
18/02/28 13:48:21 INFO BlockManager: Found block rdd_119_3 locally
18/02/28 13:48:21 INFO Executor: Finished task 3.0 in stage 59.0 (TID 179). 1619 bytes result sent to driver
18/02/28 13:48:21 INFO Executor: Finished task 0.0 in stage 59.0 (TID 176). 1616 bytes result sent to driver
18/02/28 13:48:21 INFO Executor: Running task 2.0 in stage 59.0 (TID 178)
18/02/28 13:48:21 INFO BlockManager: Found block rdd_119_2 locally
18/02/28 13:48:21 INFO Executor: Finished task 2.0 in stage 59.0 (TID 178). 1520 bytes result sent to driver
18/02/28 13:48:21 INFO TaskSetManager: Finished task 3.0 in stage 59.0 (TID 179) in 16 ms on localhost (executor driver) (1/4)
18/02/28 13:48:21 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 176) in 18 ms on localhost (executor driver) (2/4)
18/02/28 13:48:21 INFO TaskSetManager: Finished task 2.0 in stage 59.0 (TID 178) in 18 ms on localhost (executor driver) (3/4)
18/02/28 13:48:21 INFO Executor: Finished task 1.0 in stage 59.0 (TID 177). 1643 bytes result sent to driver
18/02/28 13:48:21 INFO TaskSetManager: Finished task 1.0 in stage 59.0 (TID 177) in 21 ms on localhost (executor driver) (4/4)
18/02/28 13:48:21 INFO DAGScheduler: ResultStage 59 (collect at utils.scala:211) finished in 0.022 s
18/02/28 13:48:21 INFO DAGScheduler: Job 38 finished: collect at utils.scala:211, took 0.028267 s
18/02/28 13:48:21 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
18/02/28 13:48:21 INFO CodeGenerator: Code generated in 5.469793 ms
18/02/28 13:48:21 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:48:21 INFO DAGScheduler: Got job 39 (collect at utils.scala:211) with 5 output partitions
18/02/28 13:48:21 INFO DAGScheduler: Final stage: ResultStage 62 (collect at utils.scala:211)
18/02/28 13:48:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 61)
18/02/28 13:48:21 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:21 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[136] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:21 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 11.1 KB, free 344.7 MB)
18/02/28 13:48:21 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 5.3 KB, free 344.7 MB)
18/02/28 13:48:21 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 127.0.0.1:61164 (size: 5.3 KB, free: 345.4 MB)
18/02/28 13:48:21 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:21 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 62 (MapPartitionsRDD[136] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/02/28 13:48:21 INFO TaskSchedulerImpl: Adding task set 62.0 with 5 tasks
18/02/28 13:48:21 INFO TaskSetManager: Starting task 1.0 in stage 62.0 (TID 180, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:48:21 INFO TaskSetManager: Starting task 2.0 in stage 62.0 (TID 181, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:48:21 INFO TaskSetManager: Starting task 3.0 in stage 62.0 (TID 182, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:48:21 INFO TaskSetManager: Starting task 4.0 in stage 62.0 (TID 183, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:48:21 INFO Executor: Running task 1.0 in stage 62.0 (TID 180)
18/02/28 13:48:21 INFO Executor: Running task 2.0 in stage 62.0 (TID 181)
18/02/28 13:48:21 INFO Executor: Running task 3.0 in stage 62.0 (TID 182)
18/02/28 13:48:21 INFO Executor: Running task 4.0 in stage 62.0 (TID 183)
18/02/28 13:48:21 INFO BlockManager: Found block rdd_119_0 locally
18/02/28 13:48:21 INFO BlockManager: Found block rdd_119_1 locally
18/02/28 13:48:21 INFO BlockManager: Found block rdd_119_2 locally
18/02/28 13:48:21 INFO Executor: Finished task 2.0 in stage 62.0 (TID 181). 1498 bytes result sent to driver
18/02/28 13:48:21 INFO BlockManager: Found block rdd_119_3 locally
18/02/28 13:48:21 INFO Executor: Finished task 4.0 in stage 62.0 (TID 183). 1605 bytes result sent to driver
18/02/28 13:48:21 INFO Executor: Finished task 1.0 in stage 62.0 (TID 180). 1399 bytes result sent to driver
18/02/28 13:48:21 INFO Executor: Finished task 3.0 in stage 62.0 (TID 182). 1567 bytes result sent to driver
18/02/28 13:48:21 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 184, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 13:48:21 INFO TaskSetManager: Finished task 2.0 in stage 62.0 (TID 181) in 13 ms on localhost (executor driver) (1/5)
18/02/28 13:48:21 INFO TaskSetManager: Finished task 4.0 in stage 62.0 (TID 183) in 14 ms on localhost (executor driver) (2/5)
18/02/28 13:48:21 INFO TaskSetManager: Finished task 1.0 in stage 62.0 (TID 180) in 15 ms on localhost (executor driver) (3/5)
18/02/28 13:48:21 INFO TaskSetManager: Finished task 3.0 in stage 62.0 (TID 182) in 14 ms on localhost (executor driver) (4/5)
18/02/28 13:48:21 INFO Executor: Running task 0.0 in stage 62.0 (TID 184)
18/02/28 13:48:21 INFO Executor: Finished task 0.0 in stage 62.0 (TID 184). 1000 bytes result sent to driver
18/02/28 13:48:21 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 184) in 13 ms on localhost (executor driver) (5/5)
18/02/28 13:48:21 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
18/02/28 13:48:21 INFO DAGScheduler: ResultStage 62 (collect at utils.scala:211) finished in 0.020 s
18/02/28 13:48:21 INFO DAGScheduler: Job 39 finished: collect at utils.scala:211, took 0.026282 s
18/02/28 13:48:22 INFO ContextCleaner: Cleaned accumulator 689
18/02/28 13:48:22 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 127.0.0.1:61164 in memory (size: 2.3 KB, free: 345.4 MB)
18/02/28 13:48:22 INFO ContextCleaner: Cleaned accumulator 688
18/02/28 13:48:22 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 127.0.0.1:61164 in memory (size: 2.0 KB, free: 345.4 MB)
18/02/28 13:48:22 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:48:22 INFO DAGScheduler: Got job 40 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:48:22 INFO DAGScheduler: Final stage: ResultStage 65 (collect at utils.scala:211)
18/02/28 13:48:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 64)
18/02/28 13:48:22 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:22 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[140] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:22 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 10.3 KB, free 344.7 MB)
18/02/28 13:48:22 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.7 MB)
18/02/28 13:48:22 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 127.0.0.1:61164 (size: 4.9 KB, free: 345.4 MB)
18/02/28 13:48:22 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:22 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 65 (MapPartitionsRDD[140] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:22 INFO TaskSchedulerImpl: Adding task set 65.0 with 4 tasks
18/02/28 13:48:22 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 185, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 1.0 in stage 65.0 (TID 186, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 2.0 in stage 65.0 (TID 187, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 3.0 in stage 65.0 (TID 188, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:22 INFO Executor: Running task 0.0 in stage 65.0 (TID 185)
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_0 locally
18/02/28 13:48:22 INFO Executor: Finished task 0.0 in stage 65.0 (TID 185). 1307 bytes result sent to driver
18/02/28 13:48:22 INFO Executor: Running task 1.0 in stage 65.0 (TID 186)
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_1 locally
18/02/28 13:48:22 INFO Executor: Running task 2.0 in stage 65.0 (TID 187)
18/02/28 13:48:22 INFO Executor: Finished task 1.0 in stage 65.0 (TID 186). 1483 bytes result sent to driver
18/02/28 13:48:22 INFO Executor: Running task 3.0 in stage 65.0 (TID 188)
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_2 locally
18/02/28 13:48:22 INFO Executor: Finished task 2.0 in stage 65.0 (TID 187). 1528 bytes result sent to driver
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_3 locally
18/02/28 13:48:22 INFO Executor: Finished task 3.0 in stage 65.0 (TID 188). 1627 bytes result sent to driver
18/02/28 13:48:22 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 185) in 14 ms on localhost (executor driver) (1/4)
18/02/28 13:48:22 INFO TaskSetManager: Finished task 1.0 in stage 65.0 (TID 186) in 14 ms on localhost (executor driver) (2/4)
18/02/28 13:48:22 INFO TaskSetManager: Finished task 2.0 in stage 65.0 (TID 187) in 15 ms on localhost (executor driver) (3/4)
18/02/28 13:48:22 INFO TaskSetManager: Finished task 3.0 in stage 65.0 (TID 188) in 15 ms on localhost (executor driver) (4/4)
18/02/28 13:48:22 INFO DAGScheduler: ResultStage 65 (collect at utils.scala:211) finished in 0.017 s
18/02/28 13:48:22 INFO DAGScheduler: Job 40 finished: collect at utils.scala:211, took 0.022317 s
18/02/28 13:48:22 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
18/02/28 13:48:22 INFO BlockManager: Removing RDD 85
18/02/28 13:48:22 INFO ContextCleaner: Cleaned RDD 85
18/02/28 13:48:22 INFO ContextCleaner: Cleaned accumulator 686
18/02/28 13:48:22 INFO SparkSqlParser: Parsing command: sparklyr_tmp_292861257c11
18/02/28 13:48:22 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 127.0.0.1:61164 in memory (size: 3.4 KB, free: 345.4 MB)
18/02/28 13:48:22 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 127.0.0.1:61164 in memory (size: 1914.0 B, free: 345.4 MB)
18/02/28 13:48:22 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 127.0.0.1:61164 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 13:48:22 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 127.0.0.1:61164 in memory (size: 3.3 KB, free: 345.5 MB)
18/02/28 13:48:22 INFO ContextCleaner: Cleaned accumulator 687
18/02/28 13:48:22 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 127.0.0.1:61164 in memory (size: 32.8 KB, free: 345.5 MB)
18/02/28 13:48:22 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 127.0.0.1:61164 in memory (size: 5.3 KB, free: 345.5 MB)
18/02/28 13:48:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:22 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 127.0.0.1:61164 in memory (size: 1868.0 B, free: 345.5 MB)
18/02/28 13:48:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_292861257c11` AS `zzz10`
WHERE (0 = 1)
18/02/28 13:48:22 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:48:22 INFO DAGScheduler: Got job 41 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:48:22 INFO DAGScheduler: Final stage: ResultStage 68 (collect at utils.scala:211)
18/02/28 13:48:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 67)
18/02/28 13:48:22 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:22 INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[144] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:22 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 10.3 KB, free 344.8 MB)
18/02/28 13:48:22 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.8 MB)
18/02/28 13:48:22 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 127.0.0.1:61164 (size: 4.9 KB, free: 345.5 MB)
18/02/28 13:48:22 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:22 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 68 (MapPartitionsRDD[144] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:22 INFO TaskSchedulerImpl: Adding task set 68.0 with 4 tasks
18/02/28 13:48:22 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 189, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 1.0 in stage 68.0 (TID 190, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 2.0 in stage 68.0 (TID 191, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 3.0 in stage 68.0 (TID 192, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:22 INFO Executor: Running task 1.0 in stage 68.0 (TID 190)
18/02/28 13:48:22 INFO Executor: Running task 0.0 in stage 68.0 (TID 189)
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_1 locally
18/02/28 13:48:22 INFO Executor: Finished task 1.0 in stage 68.0 (TID 190). 1657 bytes result sent to driver
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_0 locally
18/02/28 13:48:22 INFO Executor: Finished task 0.0 in stage 68.0 (TID 189). 1605 bytes result sent to driver
18/02/28 13:48:22 INFO Executor: Running task 2.0 in stage 68.0 (TID 191)
18/02/28 13:48:22 INFO Executor: Running task 3.0 in stage 68.0 (TID 192)
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_2 locally
18/02/28 13:48:22 INFO Executor: Finished task 2.0 in stage 68.0 (TID 191). 1527 bytes result sent to driver
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_3 locally
18/02/28 13:48:22 INFO Executor: Finished task 3.0 in stage 68.0 (TID 192). 1592 bytes result sent to driver
18/02/28 13:48:22 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 189) in 14 ms on localhost (executor driver) (1/4)
18/02/28 13:48:22 INFO TaskSetManager: Finished task 3.0 in stage 68.0 (TID 192) in 13 ms on localhost (executor driver) (2/4)
18/02/28 13:48:22 INFO TaskSetManager: Finished task 2.0 in stage 68.0 (TID 191) in 14 ms on localhost (executor driver) (3/4)
18/02/28 13:48:22 INFO TaskSetManager: Finished task 1.0 in stage 68.0 (TID 190) in 14 ms on localhost (executor driver) (4/4)
18/02/28 13:48:22 INFO DAGScheduler: ResultStage 68 (collect at utils.scala:211) finished in 0.016 s
18/02/28 13:48:22 INFO DAGScheduler: Job 41 finished: collect at utils.scala:211, took 0.020799 s
18/02/28 13:48:22 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
18/02/28 13:48:22 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:48:22 INFO DAGScheduler: Got job 42 (collect at utils.scala:211) with 6 output partitions
18/02/28 13:48:22 INFO DAGScheduler: Final stage: ResultStage 71 (collect at utils.scala:211)
18/02/28 13:48:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 70)
18/02/28 13:48:22 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:22 INFO DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[151] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:22 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 11.2 KB, free 344.8 MB)
18/02/28 13:48:22 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 5.3 KB, free 344.8 MB)
18/02/28 13:48:22 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 127.0.0.1:61164 (size: 5.3 KB, free: 345.5 MB)
18/02/28 13:48:22 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:22 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 71 (MapPartitionsRDD[151] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
18/02/28 13:48:22 INFO TaskSchedulerImpl: Adding task set 71.0 with 6 tasks
18/02/28 13:48:22 INFO TaskSetManager: Starting task 1.0 in stage 71.0 (TID 193, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 2.0 in stage 71.0 (TID 194, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 3.0 in stage 71.0 (TID 195, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 4.0 in stage 71.0 (TID 196, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:48:22 INFO Executor: Running task 1.0 in stage 71.0 (TID 193)
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_0 locally
18/02/28 13:48:22 INFO Executor: Finished task 1.0 in stage 71.0 (TID 193). 1388 bytes result sent to driver
18/02/28 13:48:22 INFO Executor: Running task 2.0 in stage 71.0 (TID 194)
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_1 locally
18/02/28 13:48:22 INFO Executor: Finished task 2.0 in stage 71.0 (TID 194). 1375 bytes result sent to driver
18/02/28 13:48:22 INFO Executor: Running task 3.0 in stage 71.0 (TID 195)
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_2 locally
18/02/28 13:48:22 INFO Executor: Finished task 3.0 in stage 71.0 (TID 195). 1516 bytes result sent to driver
18/02/28 13:48:22 INFO Executor: Running task 4.0 in stage 71.0 (TID 196)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 197, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 5.0 in stage 71.0 (TID 198, localhost, executor driver, partition 5, PROCESS_LOCAL, 5058 bytes)
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_3 locally
18/02/28 13:48:22 INFO TaskSetManager: Finished task 1.0 in stage 71.0 (TID 193) in 12 ms on localhost (executor driver) (1/6)
18/02/28 13:48:22 INFO Executor: Finished task 4.0 in stage 71.0 (TID 196). 1584 bytes result sent to driver
18/02/28 13:48:22 INFO Executor: Running task 0.0 in stage 71.0 (TID 197)
18/02/28 13:48:22 INFO Executor: Finished task 0.0 in stage 71.0 (TID 197). 999 bytes result sent to driver
18/02/28 13:48:22 INFO Executor: Running task 5.0 in stage 71.0 (TID 198)
18/02/28 13:48:22 INFO Executor: Finished task 5.0 in stage 71.0 (TID 198). 1007 bytes result sent to driver
18/02/28 13:48:22 INFO TaskSetManager: Finished task 2.0 in stage 71.0 (TID 194) in 12 ms on localhost (executor driver) (2/6)
18/02/28 13:48:22 INFO TaskSetManager: Finished task 3.0 in stage 71.0 (TID 195) in 21 ms on localhost (executor driver) (3/6)
18/02/28 13:48:22 INFO TaskSetManager: Finished task 4.0 in stage 71.0 (TID 196) in 21 ms on localhost (executor driver) (4/6)
18/02/28 13:48:22 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 197) in 12 ms on localhost (executor driver) (5/6)
18/02/28 13:48:22 INFO TaskSetManager: Finished task 5.0 in stage 71.0 (TID 198) in 12 ms on localhost (executor driver) (6/6)
18/02/28 13:48:22 INFO DAGScheduler: ResultStage 71 (collect at utils.scala:211) finished in 0.023 s
18/02/28 13:48:22 INFO DAGScheduler: Job 42 finished: collect at utils.scala:211, took 0.032276 s
18/02/28 13:48:22 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
18/02/28 13:48:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 13:48:22 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29285591631c
18/02/28 13:48:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29285591631c` AS `zzz11`
WHERE (0 = 1)
18/02/28 13:48:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29285591631c`
18/02/28 13:48:22 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:48:22 INFO DAGScheduler: Got job 43 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:48:22 INFO DAGScheduler: Final stage: ResultStage 74 (collect at utils.scala:211)
18/02/28 13:48:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 73)
18/02/28 13:48:22 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:22 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[154] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:22 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 10.4 KB, free 344.8 MB)
18/02/28 13:48:22 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.8 MB)
18/02/28 13:48:22 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 127.0.0.1:61164 (size: 4.9 KB, free: 345.5 MB)
18/02/28 13:48:22 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:22 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 74 (MapPartitionsRDD[154] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:22 INFO TaskSchedulerImpl: Adding task set 74.0 with 4 tasks
18/02/28 13:48:22 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 199, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 1.0 in stage 74.0 (TID 200, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 2.0 in stage 74.0 (TID 201, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 3.0 in stage 74.0 (TID 202, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:22 INFO Executor: Running task 0.0 in stage 74.0 (TID 199)
18/02/28 13:48:22 INFO Executor: Running task 1.0 in stage 74.0 (TID 200)
18/02/28 13:48:22 INFO Executor: Running task 2.0 in stage 74.0 (TID 201)
18/02/28 13:48:22 INFO Executor: Running task 3.0 in stage 74.0 (TID 202)
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_0 locally
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_3 locally
18/02/28 13:48:22 INFO Executor: Finished task 0.0 in stage 74.0 (TID 199). 1530 bytes result sent to driver
18/02/28 13:48:22 INFO Executor: Finished task 3.0 in stage 74.0 (TID 202). 1662 bytes result sent to driver
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_1 locally
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_2 locally
18/02/28 13:48:22 INFO Executor: Finished task 1.0 in stage 74.0 (TID 200). 1643 bytes result sent to driver
18/02/28 13:48:22 INFO Executor: Finished task 2.0 in stage 74.0 (TID 201). 1606 bytes result sent to driver
18/02/28 13:48:22 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 199) in 3 ms on localhost (executor driver) (1/4)
18/02/28 13:48:22 INFO TaskSetManager: Finished task 2.0 in stage 74.0 (TID 201) in 3 ms on localhost (executor driver) (2/4)
18/02/28 13:48:22 INFO TaskSetManager: Finished task 3.0 in stage 74.0 (TID 202) in 4 ms on localhost (executor driver) (3/4)
18/02/28 13:48:22 INFO TaskSetManager: Finished task 1.0 in stage 74.0 (TID 200) in 4 ms on localhost (executor driver) (4/4)
18/02/28 13:48:22 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
18/02/28 13:48:22 INFO DAGScheduler: ResultStage 74 (collect at utils.scala:211) finished in 0.005 s
18/02/28 13:48:22 INFO DAGScheduler: Job 43 finished: collect at utils.scala:211, took 0.013073 s
18/02/28 13:48:22 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:48:22 INFO DAGScheduler: Got job 44 (collect at utils.scala:211) with 5 output partitions
18/02/28 13:48:22 INFO DAGScheduler: Final stage: ResultStage 77 (collect at utils.scala:211)
18/02/28 13:48:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 76)
18/02/28 13:48:22 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:22 INFO DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[157] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:22 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 11.1 KB, free 344.8 MB)
18/02/28 13:48:22 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 5.3 KB, free 344.8 MB)
18/02/28 13:48:22 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 127.0.0.1:61164 (size: 5.3 KB, free: 345.5 MB)
18/02/28 13:48:22 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:22 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 77 (MapPartitionsRDD[157] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/02/28 13:48:22 INFO TaskSchedulerImpl: Adding task set 77.0 with 5 tasks
18/02/28 13:48:22 INFO TaskSetManager: Starting task 1.0 in stage 77.0 (TID 203, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 2.0 in stage 77.0 (TID 204, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 3.0 in stage 77.0 (TID 205, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 4.0 in stage 77.0 (TID 206, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:48:22 INFO Executor: Running task 1.0 in stage 77.0 (TID 203)
18/02/28 13:48:22 INFO Executor: Running task 4.0 in stage 77.0 (TID 206)
18/02/28 13:48:22 INFO Executor: Running task 3.0 in stage 77.0 (TID 205)
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_0 locally
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_2 locally
18/02/28 13:48:22 INFO Executor: Finished task 3.0 in stage 77.0 (TID 205). 1567 bytes result sent to driver
18/02/28 13:48:22 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 207, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 13:48:22 INFO Executor: Running task 2.0 in stage 77.0 (TID 204)
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_3 locally
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_1 locally
18/02/28 13:48:22 INFO Executor: Finished task 4.0 in stage 77.0 (TID 206). 1605 bytes result sent to driver
18/02/28 13:48:22 INFO Executor: Finished task 2.0 in stage 77.0 (TID 204). 1498 bytes result sent to driver
18/02/28 13:48:22 INFO TaskSetManager: Finished task 3.0 in stage 77.0 (TID 205) in 6 ms on localhost (executor driver) (1/5)
18/02/28 13:48:22 INFO TaskSetManager: Finished task 4.0 in stage 77.0 (TID 206) in 5 ms on localhost (executor driver) (2/5)
18/02/28 13:48:22 INFO TaskSetManager: Finished task 2.0 in stage 77.0 (TID 204) in 7 ms on localhost (executor driver) (3/5)
18/02/28 13:48:22 INFO Executor: Running task 0.0 in stage 77.0 (TID 207)
18/02/28 13:48:22 INFO Executor: Finished task 1.0 in stage 77.0 (TID 203). 1399 bytes result sent to driver
18/02/28 13:48:22 INFO TaskSetManager: Finished task 1.0 in stage 77.0 (TID 203) in 8 ms on localhost (executor driver) (4/5)
18/02/28 13:48:22 INFO Executor: Finished task 0.0 in stage 77.0 (TID 207). 1043 bytes result sent to driver
18/02/28 13:48:22 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 207) in 6 ms on localhost (executor driver) (5/5)
18/02/28 13:48:22 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
18/02/28 13:48:22 INFO DAGScheduler: ResultStage 77 (collect at utils.scala:211) finished in 0.011 s
18/02/28 13:48:22 INFO DAGScheduler: Job 44 finished: collect at utils.scala:211, took 0.017245 s
18/02/28 13:48:22 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:48:22 INFO DAGScheduler: Got job 45 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:48:22 INFO DAGScheduler: Final stage: ResultStage 80 (collect at utils.scala:211)
18/02/28 13:48:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 79)
18/02/28 13:48:22 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:22 INFO DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[160] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:22 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 10.3 KB, free 344.8 MB)
18/02/28 13:48:22 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.8 MB)
18/02/28 13:48:22 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 127.0.0.1:61164 (size: 4.9 KB, free: 345.5 MB)
18/02/28 13:48:22 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:22 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 80 (MapPartitionsRDD[160] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:22 INFO TaskSchedulerImpl: Adding task set 80.0 with 4 tasks
18/02/28 13:48:22 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 208, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 1.0 in stage 80.0 (TID 209, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 2.0 in stage 80.0 (TID 210, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 3.0 in stage 80.0 (TID 211, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:22 INFO Executor: Running task 0.0 in stage 80.0 (TID 208)
18/02/28 13:48:22 INFO Executor: Running task 1.0 in stage 80.0 (TID 209)
18/02/28 13:48:22 INFO Executor: Running task 2.0 in stage 80.0 (TID 210)
18/02/28 13:48:22 INFO Executor: Running task 3.0 in stage 80.0 (TID 211)
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_0 locally
18/02/28 13:48:22 INFO Executor: Finished task 0.0 in stage 80.0 (TID 208). 1307 bytes result sent to driver
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_2 locally
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_1 locally
18/02/28 13:48:22 INFO Executor: Finished task 2.0 in stage 80.0 (TID 210). 1571 bytes result sent to driver
18/02/28 13:48:22 INFO Executor: Finished task 1.0 in stage 80.0 (TID 209). 1483 bytes result sent to driver
18/02/28 13:48:22 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 208) in 5 ms on localhost (executor driver) (1/4)
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_3 locally
18/02/28 13:48:22 INFO TaskSetManager: Finished task 2.0 in stage 80.0 (TID 210) in 5 ms on localhost (executor driver) (2/4)
18/02/28 13:48:22 INFO Executor: Finished task 3.0 in stage 80.0 (TID 211). 1627 bytes result sent to driver
18/02/28 13:48:22 INFO TaskSetManager: Finished task 1.0 in stage 80.0 (TID 209) in 5 ms on localhost (executor driver) (3/4)
18/02/28 13:48:22 INFO TaskSetManager: Finished task 3.0 in stage 80.0 (TID 211) in 5 ms on localhost (executor driver) (4/4)
18/02/28 13:48:22 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
18/02/28 13:48:22 INFO DAGScheduler: ResultStage 80 (collect at utils.scala:211) finished in 0.006 s
18/02/28 13:48:22 INFO DAGScheduler: Job 45 finished: collect at utils.scala:211, took 0.011827 s
18/02/28 13:48:22 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2928fc37c02
18/02/28 13:48:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2928fc37c02` AS `zzz12`
WHERE (0 = 1)
18/02/28 13:48:22 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:48:22 INFO DAGScheduler: Got job 46 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:48:22 INFO DAGScheduler: Final stage: ResultStage 83 (collect at utils.scala:211)
18/02/28 13:48:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 82)
18/02/28 13:48:22 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:22 INFO DAGScheduler: Submitting ResultStage 83 (MapPartitionsRDD[163] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:22 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 10.3 KB, free 344.7 MB)
18/02/28 13:48:22 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.7 MB)
18/02/28 13:48:22 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 127.0.0.1:61164 (size: 4.9 KB, free: 345.5 MB)
18/02/28 13:48:22 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:22 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 83 (MapPartitionsRDD[163] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:22 INFO TaskSchedulerImpl: Adding task set 83.0 with 4 tasks
18/02/28 13:48:22 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 212, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 1.0 in stage 83.0 (TID 213, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 2.0 in stage 83.0 (TID 214, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 3.0 in stage 83.0 (TID 215, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:22 INFO Executor: Running task 1.0 in stage 83.0 (TID 213)
18/02/28 13:48:22 INFO Executor: Running task 3.0 in stage 83.0 (TID 215)
18/02/28 13:48:22 INFO Executor: Running task 2.0 in stage 83.0 (TID 214)
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_3 locally
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_1 locally
18/02/28 13:48:22 INFO Executor: Finished task 1.0 in stage 83.0 (TID 213). 1571 bytes result sent to driver
18/02/28 13:48:22 INFO Executor: Running task 0.0 in stage 83.0 (TID 212)
18/02/28 13:48:22 INFO Executor: Finished task 3.0 in stage 83.0 (TID 215). 1549 bytes result sent to driver
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_2 locally
18/02/28 13:48:22 INFO TaskSetManager: Finished task 1.0 in stage 83.0 (TID 213) in 4 ms on localhost (executor driver) (1/4)
18/02/28 13:48:22 INFO Executor: Finished task 2.0 in stage 83.0 (TID 214). 1613 bytes result sent to driver
18/02/28 13:48:22 INFO TaskSetManager: Finished task 3.0 in stage 83.0 (TID 215) in 5 ms on localhost (executor driver) (2/4)
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_0 locally
18/02/28 13:48:22 INFO TaskSetManager: Finished task 2.0 in stage 83.0 (TID 214) in 6 ms on localhost (executor driver) (3/4)
18/02/28 13:48:22 INFO Executor: Finished task 0.0 in stage 83.0 (TID 212). 1519 bytes result sent to driver
18/02/28 13:48:22 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 212) in 7 ms on localhost (executor driver) (4/4)
18/02/28 13:48:22 INFO DAGScheduler: ResultStage 83 (collect at utils.scala:211) finished in 0.007 s
18/02/28 13:48:22 INFO DAGScheduler: Job 46 finished: collect at utils.scala:211, took 0.012998 s
18/02/28 13:48:22 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool 
18/02/28 13:48:22 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:48:22 INFO DAGScheduler: Got job 47 (collect at utils.scala:211) with 6 output partitions
18/02/28 13:48:22 INFO DAGScheduler: Final stage: ResultStage 86 (collect at utils.scala:211)
18/02/28 13:48:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 85)
18/02/28 13:48:22 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:22 INFO DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[166] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:22 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 11.2 KB, free 344.7 MB)
18/02/28 13:48:22 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 5.3 KB, free 344.7 MB)
18/02/28 13:48:22 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 127.0.0.1:61164 (size: 5.3 KB, free: 345.5 MB)
18/02/28 13:48:22 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:22 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 86 (MapPartitionsRDD[166] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
18/02/28 13:48:22 INFO TaskSchedulerImpl: Adding task set 86.0 with 6 tasks
18/02/28 13:48:22 INFO TaskSetManager: Starting task 1.0 in stage 86.0 (TID 216, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 2.0 in stage 86.0 (TID 217, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 3.0 in stage 86.0 (TID 218, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 4.0 in stage 86.0 (TID 219, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:48:22 INFO Executor: Running task 1.0 in stage 86.0 (TID 216)
18/02/28 13:48:22 INFO Executor: Running task 2.0 in stage 86.0 (TID 217)
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_0 locally
18/02/28 13:48:22 INFO Executor: Finished task 1.0 in stage 86.0 (TID 216). 1345 bytes result sent to driver
18/02/28 13:48:22 INFO Executor: Running task 3.0 in stage 86.0 (TID 218)
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_1 locally
18/02/28 13:48:22 INFO Executor: Finished task 2.0 in stage 86.0 (TID 217). 1418 bytes result sent to driver
18/02/28 13:48:22 INFO Executor: Running task 4.0 in stage 86.0 (TID 219)
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_2 locally
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_3 locally
18/02/28 13:48:22 INFO Executor: Finished task 3.0 in stage 86.0 (TID 218). 1602 bytes result sent to driver
18/02/28 13:48:22 INFO Executor: Finished task 4.0 in stage 86.0 (TID 219). 1627 bytes result sent to driver
18/02/28 13:48:22 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 220, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 5.0 in stage 86.0 (TID 221, localhost, executor driver, partition 5, PROCESS_LOCAL, 5058 bytes)
18/02/28 13:48:22 INFO Executor: Running task 0.0 in stage 86.0 (TID 220)
18/02/28 13:48:22 INFO TaskSetManager: Finished task 2.0 in stage 86.0 (TID 217) in 8 ms on localhost (executor driver) (1/6)
18/02/28 13:48:22 INFO TaskSetManager: Finished task 3.0 in stage 86.0 (TID 218) in 9 ms on localhost (executor driver) (2/6)
18/02/28 13:48:22 INFO TaskSetManager: Finished task 4.0 in stage 86.0 (TID 219) in 9 ms on localhost (executor driver) (3/6)
18/02/28 13:48:22 INFO TaskSetManager: Finished task 1.0 in stage 86.0 (TID 216) in 10 ms on localhost (executor driver) (4/6)
18/02/28 13:48:22 INFO Executor: Running task 5.0 in stage 86.0 (TID 221)
18/02/28 13:48:22 INFO Executor: Finished task 0.0 in stage 86.0 (TID 220). 1042 bytes result sent to driver
18/02/28 13:48:22 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 220) in 4 ms on localhost (executor driver) (5/6)
18/02/28 13:48:22 INFO Executor: Finished task 5.0 in stage 86.0 (TID 221). 1007 bytes result sent to driver
18/02/28 13:48:22 INFO TaskSetManager: Finished task 5.0 in stage 86.0 (TID 221) in 4 ms on localhost (executor driver) (6/6)
18/02/28 13:48:22 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
18/02/28 13:48:22 INFO DAGScheduler: ResultStage 86 (collect at utils.scala:211) finished in 0.013 s
18/02/28 13:48:22 INFO DAGScheduler: Job 47 finished: collect at utils.scala:211, took 0.019051 s
18/02/28 13:48:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 13:48:22 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:48:22 INFO DAGScheduler: Got job 48 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:48:22 INFO DAGScheduler: Final stage: ResultStage 89 (collect at utils.scala:211)
18/02/28 13:48:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 88)
18/02/28 13:48:22 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:22 INFO DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[169] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:22 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 10.4 KB, free 344.7 MB)
18/02/28 13:48:22 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.7 MB)
18/02/28 13:48:22 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 127.0.0.1:61164 (size: 4.9 KB, free: 345.5 MB)
18/02/28 13:48:22 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:22 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 89 (MapPartitionsRDD[169] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:22 INFO TaskSchedulerImpl: Adding task set 89.0 with 4 tasks
18/02/28 13:48:22 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 222, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 1.0 in stage 89.0 (TID 223, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 2.0 in stage 89.0 (TID 224, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 3.0 in stage 89.0 (TID 225, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:22 INFO Executor: Running task 0.0 in stage 89.0 (TID 222)
18/02/28 13:48:22 INFO Executor: Running task 1.0 in stage 89.0 (TID 223)
18/02/28 13:48:22 INFO Executor: Running task 2.0 in stage 89.0 (TID 224)
18/02/28 13:48:22 INFO Executor: Running task 3.0 in stage 89.0 (TID 225)
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_0 locally
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_3 locally
18/02/28 13:48:22 INFO Executor: Finished task 0.0 in stage 89.0 (TID 222). 1530 bytes result sent to driver
18/02/28 13:48:22 INFO Executor: Finished task 3.0 in stage 89.0 (TID 225). 1576 bytes result sent to driver
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_2 locally
18/02/28 13:48:22 INFO Executor: Finished task 2.0 in stage 89.0 (TID 224). 1563 bytes result sent to driver
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_1 locally
18/02/28 13:48:22 INFO Executor: Finished task 1.0 in stage 89.0 (TID 223). 1557 bytes result sent to driver
18/02/28 13:48:22 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 222) in 7 ms on localhost (executor driver) (1/4)
18/02/28 13:48:22 INFO TaskSetManager: Finished task 3.0 in stage 89.0 (TID 225) in 7 ms on localhost (executor driver) (2/4)
18/02/28 13:48:22 INFO TaskSetManager: Finished task 2.0 in stage 89.0 (TID 224) in 8 ms on localhost (executor driver) (3/4)
18/02/28 13:48:22 INFO TaskSetManager: Finished task 1.0 in stage 89.0 (TID 223) in 8 ms on localhost (executor driver) (4/4)
18/02/28 13:48:22 INFO DAGScheduler: ResultStage 89 (collect at utils.scala:211) finished in 0.009 s
18/02/28 13:48:22 INFO DAGScheduler: Job 48 finished: collect at utils.scala:211, took 0.014451 s
18/02/28 13:48:22 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
18/02/28 13:48:22 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:48:22 INFO DAGScheduler: Got job 49 (collect at utils.scala:211) with 5 output partitions
18/02/28 13:48:22 INFO DAGScheduler: Final stage: ResultStage 92 (collect at utils.scala:211)
18/02/28 13:48:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 91)
18/02/28 13:48:22 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:22 INFO DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[172] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:22 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 11.1 KB, free 344.7 MB)
18/02/28 13:48:22 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 5.3 KB, free 344.7 MB)
18/02/28 13:48:22 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 127.0.0.1:61164 (size: 5.3 KB, free: 345.5 MB)
18/02/28 13:48:22 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:22 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 92 (MapPartitionsRDD[172] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/02/28 13:48:22 INFO TaskSchedulerImpl: Adding task set 92.0 with 5 tasks
18/02/28 13:48:22 INFO TaskSetManager: Starting task 1.0 in stage 92.0 (TID 226, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 2.0 in stage 92.0 (TID 227, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 3.0 in stage 92.0 (TID 228, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 4.0 in stage 92.0 (TID 229, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:48:22 INFO Executor: Running task 1.0 in stage 92.0 (TID 226)
18/02/28 13:48:22 INFO Executor: Running task 2.0 in stage 92.0 (TID 227)
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_0 locally
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_1 locally
18/02/28 13:48:22 INFO Executor: Finished task 1.0 in stage 92.0 (TID 226). 1399 bytes result sent to driver
18/02/28 13:48:22 INFO Executor: Running task 3.0 in stage 92.0 (TID 228)
18/02/28 13:48:22 INFO Executor: Finished task 2.0 in stage 92.0 (TID 227). 1455 bytes result sent to driver
18/02/28 13:48:22 INFO Executor: Running task 4.0 in stage 92.0 (TID 229)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 230, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_2 locally
18/02/28 13:48:22 INFO Executor: Finished task 3.0 in stage 92.0 (TID 228). 1524 bytes result sent to driver
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_3 locally
18/02/28 13:48:22 INFO TaskSetManager: Finished task 1.0 in stage 92.0 (TID 226) in 7 ms on localhost (executor driver) (1/5)
18/02/28 13:48:22 INFO Executor: Finished task 4.0 in stage 92.0 (TID 229). 1605 bytes result sent to driver
18/02/28 13:48:22 INFO Executor: Running task 0.0 in stage 92.0 (TID 230)
18/02/28 13:48:22 INFO TaskSetManager: Finished task 2.0 in stage 92.0 (TID 227) in 7 ms on localhost (executor driver) (2/5)
18/02/28 13:48:22 INFO TaskSetManager: Finished task 3.0 in stage 92.0 (TID 228) in 6 ms on localhost (executor driver) (3/5)
18/02/28 13:48:22 INFO TaskSetManager: Finished task 4.0 in stage 92.0 (TID 229) in 7 ms on localhost (executor driver) (4/5)
18/02/28 13:48:22 INFO Executor: Finished task 0.0 in stage 92.0 (TID 230). 1043 bytes result sent to driver
18/02/28 13:48:22 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 230) in 7 ms on localhost (executor driver) (5/5)
18/02/28 13:48:22 INFO DAGScheduler: ResultStage 92 (collect at utils.scala:211) finished in 0.012 s
18/02/28 13:48:22 INFO DAGScheduler: Job 49 finished: collect at utils.scala:211, took 0.017362 s
18/02/28 13:48:22 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
18/02/28 13:48:22 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:48:22 INFO DAGScheduler: Got job 50 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:48:22 INFO DAGScheduler: Final stage: ResultStage 95 (collect at utils.scala:211)
18/02/28 13:48:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 94)
18/02/28 13:48:22 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:22 INFO DAGScheduler: Submitting ResultStage 95 (MapPartitionsRDD[175] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:22 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 10.3 KB, free 344.7 MB)
18/02/28 13:48:22 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.7 MB)
18/02/28 13:48:22 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 127.0.0.1:61164 (size: 4.9 KB, free: 345.4 MB)
18/02/28 13:48:22 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:22 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 95 (MapPartitionsRDD[175] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:22 INFO TaskSchedulerImpl: Adding task set 95.0 with 4 tasks
18/02/28 13:48:22 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 231, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 1.0 in stage 95.0 (TID 232, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 2.0 in stage 95.0 (TID 233, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:22 INFO TaskSetManager: Starting task 3.0 in stage 95.0 (TID 234, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:22 INFO Executor: Running task 1.0 in stage 95.0 (TID 232)
18/02/28 13:48:22 INFO Executor: Running task 0.0 in stage 95.0 (TID 231)
18/02/28 13:48:22 INFO Executor: Running task 2.0 in stage 95.0 (TID 233)
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_2 locally
18/02/28 13:48:22 INFO BlockManager: Found block rdd_119_1 locally
18/02/28 13:48:22 INFO Executor: Finished task 2.0 in stage 95.0 (TID 233). 1528 bytes result sent to driver
18/02/28 13:48:22 INFO Executor: Running task 3.0 in stage 95.0 (TID 234)
18/02/28 13:48:22 INFO Executor: Finished task 1.0 in stage 95.0 (TID 232). 1440 bytes result sent to driver
18/02/28 13:48:23 INFO BlockManager: Found block rdd_119_3 locally
18/02/28 13:48:23 INFO TaskSetManager: Finished task 2.0 in stage 95.0 (TID 233) in 6 ms on localhost (executor driver) (1/4)
18/02/28 13:48:23 INFO TaskSetManager: Finished task 1.0 in stage 95.0 (TID 232) in 6 ms on localhost (executor driver) (2/4)
18/02/28 13:48:23 INFO BlockManager: Found block rdd_119_0 locally
18/02/28 13:48:23 INFO Executor: Finished task 3.0 in stage 95.0 (TID 234). 1627 bytes result sent to driver
18/02/28 13:48:23 INFO Executor: Finished task 0.0 in stage 95.0 (TID 231). 1393 bytes result sent to driver
18/02/28 13:48:23 INFO TaskSetManager: Finished task 3.0 in stage 95.0 (TID 234) in 7 ms on localhost (executor driver) (3/4)
18/02/28 13:48:23 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 231) in 8 ms on localhost (executor driver) (4/4)
18/02/28 13:48:23 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool 
18/02/28 13:48:23 INFO DAGScheduler: ResultStage 95 (collect at utils.scala:211) finished in 0.009 s
18/02/28 13:48:23 INFO DAGScheduler: Job 50 finished: collect at utils.scala:211, took 0.013949 s
18/02/28 13:48:23 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29282775274
18/02/28 13:48:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29282775274` AS `zzz13`
WHERE (0 = 1)
18/02/28 13:48:23 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:48:23 INFO DAGScheduler: Got job 51 (collect at utils.scala:211) with 4 output partitions
18/02/28 13:48:23 INFO DAGScheduler: Final stage: ResultStage 98 (collect at utils.scala:211)
18/02/28 13:48:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 97)
18/02/28 13:48:23 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:23 INFO DAGScheduler: Submitting ResultStage 98 (MapPartitionsRDD[178] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:23 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 10.3 KB, free 344.7 MB)
18/02/28 13:48:23 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.7 MB)
18/02/28 13:48:23 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 127.0.0.1:61164 (size: 4.9 KB, free: 345.4 MB)
18/02/28 13:48:23 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:23 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 98 (MapPartitionsRDD[178] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:23 INFO TaskSchedulerImpl: Adding task set 98.0 with 4 tasks
18/02/28 13:48:23 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 235, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:23 INFO TaskSetManager: Starting task 1.0 in stage 98.0 (TID 236, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:23 INFO TaskSetManager: Starting task 2.0 in stage 98.0 (TID 237, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:23 INFO TaskSetManager: Starting task 3.0 in stage 98.0 (TID 238, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 13:48:23 INFO Executor: Running task 0.0 in stage 98.0 (TID 235)
18/02/28 13:48:23 INFO Executor: Running task 1.0 in stage 98.0 (TID 236)
18/02/28 13:48:23 INFO Executor: Running task 3.0 in stage 98.0 (TID 238)
18/02/28 13:48:23 INFO Executor: Running task 2.0 in stage 98.0 (TID 237)
18/02/28 13:48:23 INFO BlockManager: Found block rdd_119_3 locally
18/02/28 13:48:23 INFO BlockManager: Found block rdd_119_2 locally
18/02/28 13:48:23 INFO BlockManager: Found block rdd_119_0 locally
18/02/28 13:48:23 INFO Executor: Finished task 2.0 in stage 98.0 (TID 237). 1613 bytes result sent to driver
18/02/28 13:48:23 INFO Executor: Finished task 0.0 in stage 98.0 (TID 235). 1605 bytes result sent to driver
18/02/28 13:48:23 INFO Executor: Finished task 3.0 in stage 98.0 (TID 238). 1635 bytes result sent to driver
18/02/28 13:48:23 INFO BlockManager: Found block rdd_119_1 locally
18/02/28 13:48:23 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 127.0.0.1:61164 in memory (size: 5.3 KB, free: 345.4 MB)
18/02/28 13:48:23 INFO Executor: Finished task 1.0 in stage 98.0 (TID 236). 1657 bytes result sent to driver
18/02/28 13:48:23 INFO TaskSetManager: Finished task 2.0 in stage 98.0 (TID 237) in 21 ms on localhost (executor driver) (1/4)
18/02/28 13:48:23 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 235) in 22 ms on localhost (executor driver) (2/4)
18/02/28 13:48:23 INFO TaskSetManager: Finished task 3.0 in stage 98.0 (TID 238) in 21 ms on localhost (executor driver) (3/4)
18/02/28 13:48:23 INFO TaskSetManager: Finished task 1.0 in stage 98.0 (TID 236) in 22 ms on localhost (executor driver) (4/4)
18/02/28 13:48:23 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool 
18/02/28 13:48:23 INFO DAGScheduler: ResultStage 98 (collect at utils.scala:211) finished in 0.023 s
18/02/28 13:48:23 INFO DAGScheduler: Job 51 finished: collect at utils.scala:211, took 0.027115 s
18/02/28 13:48:23 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 127.0.0.1:61164 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 13:48:23 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 127.0.0.1:61164 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 13:48:23 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 127.0.0.1:61164 in memory (size: 5.3 KB, free: 345.5 MB)
18/02/28 13:48:23 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 127.0.0.1:61164 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 13:48:23 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 127.0.0.1:61164 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 13:48:23 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 127.0.0.1:61164 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 13:48:23 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 127.0.0.1:61164 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 13:48:23 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 127.0.0.1:61164 in memory (size: 5.3 KB, free: 345.5 MB)
18/02/28 13:48:23 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 127.0.0.1:61164 in memory (size: 5.3 KB, free: 345.5 MB)
18/02/28 13:48:23 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 127.0.0.1:61164 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 13:48:23 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:48:23 INFO DAGScheduler: Got job 52 (collect at utils.scala:211) with 6 output partitions
18/02/28 13:48:23 INFO DAGScheduler: Final stage: ResultStage 101 (collect at utils.scala:211)
18/02/28 13:48:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 100)
18/02/28 13:48:23 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:23 INFO DAGScheduler: Submitting ResultStage 101 (MapPartitionsRDD[181] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:23 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 11.2 KB, free 344.8 MB)
18/02/28 13:48:23 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 5.3 KB, free 344.8 MB)
18/02/28 13:48:23 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 127.0.0.1:61164 (size: 5.3 KB, free: 345.5 MB)
18/02/28 13:48:23 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:23 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 101 (MapPartitionsRDD[181] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
18/02/28 13:48:23 INFO TaskSchedulerImpl: Adding task set 101.0 with 6 tasks
18/02/28 13:48:23 INFO TaskSetManager: Starting task 1.0 in stage 101.0 (TID 239, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:48:23 INFO TaskSetManager: Starting task 2.0 in stage 101.0 (TID 240, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:48:23 INFO TaskSetManager: Starting task 3.0 in stage 101.0 (TID 241, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:48:23 INFO TaskSetManager: Starting task 4.0 in stage 101.0 (TID 242, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 13:48:23 INFO Executor: Running task 1.0 in stage 101.0 (TID 239)
18/02/28 13:48:23 INFO Executor: Running task 2.0 in stage 101.0 (TID 240)
18/02/28 13:48:23 INFO Executor: Running task 4.0 in stage 101.0 (TID 242)
18/02/28 13:48:23 INFO BlockManager: Found block rdd_119_0 locally
18/02/28 13:48:23 INFO Executor: Finished task 1.0 in stage 101.0 (TID 239). 1431 bytes result sent to driver
18/02/28 13:48:23 INFO BlockManager: Found block rdd_119_1 locally
18/02/28 13:48:23 INFO Executor: Finished task 2.0 in stage 101.0 (TID 240). 1461 bytes result sent to driver
18/02/28 13:48:23 INFO Executor: Running task 3.0 in stage 101.0 (TID 241)
18/02/28 13:48:23 INFO BlockManager: Found block rdd_119_3 locally
18/02/28 13:48:23 INFO BlockManager: Found block rdd_119_2 locally
18/02/28 13:48:23 INFO Executor: Finished task 4.0 in stage 101.0 (TID 242). 1627 bytes result sent to driver
18/02/28 13:48:23 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 243, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 13:48:23 INFO Executor: Finished task 3.0 in stage 101.0 (TID 241). 1559 bytes result sent to driver
18/02/28 13:48:23 INFO Executor: Running task 0.0 in stage 101.0 (TID 243)
18/02/28 13:48:23 INFO TaskSetManager: Starting task 5.0 in stage 101.0 (TID 244, localhost, executor driver, partition 5, PROCESS_LOCAL, 5058 bytes)
18/02/28 13:48:23 INFO TaskSetManager: Finished task 2.0 in stage 101.0 (TID 240) in 9 ms on localhost (executor driver) (1/6)
18/02/28 13:48:23 INFO TaskSetManager: Finished task 4.0 in stage 101.0 (TID 242) in 8 ms on localhost (executor driver) (2/6)
18/02/28 13:48:23 INFO TaskSetManager: Finished task 3.0 in stage 101.0 (TID 241) in 9 ms on localhost (executor driver) (3/6)
18/02/28 13:48:23 INFO TaskSetManager: Finished task 1.0 in stage 101.0 (TID 239) in 10 ms on localhost (executor driver) (4/6)
18/02/28 13:48:23 INFO Executor: Running task 5.0 in stage 101.0 (TID 244)
18/02/28 13:48:23 INFO Executor: Finished task 0.0 in stage 101.0 (TID 243). 1042 bytes result sent to driver
18/02/28 13:48:23 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 243) in 4 ms on localhost (executor driver) (5/6)
18/02/28 13:48:23 INFO Executor: Finished task 5.0 in stage 101.0 (TID 244). 1050 bytes result sent to driver
18/02/28 13:48:23 INFO TaskSetManager: Finished task 5.0 in stage 101.0 (TID 244) in 4 ms on localhost (executor driver) (6/6)
18/02/28 13:48:23 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool 
18/02/28 13:48:23 INFO DAGScheduler: ResultStage 101 (collect at utils.scala:211) finished in 0.012 s
18/02/28 13:48:23 INFO DAGScheduler: Job 52 finished: collect at utils.scala:211, took 0.017546 s
18/02/28 13:48:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 13:48:23 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29281a42745f
18/02/28 13:48:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29281a42745f` AS `zzz14`
WHERE (0 = 1)
18/02/28 13:48:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29281a42745f`
18/02/28 13:48:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29284f4e3fe0`
18/02/28 13:48:23 INFO SparkSqlParser: Parsing command: sparklyr_tmp_292883b4002
18/02/28 13:48:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_292883b4002` AS `zzz15`
WHERE (0 = 1)
18/02/28 13:48:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_292883b4002`
18/02/28 13:48:23 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29283398423f
18/02/28 13:48:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29283398423f` AS `zzz16`
WHERE (0 = 1)
18/02/28 13:48:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29283398423f`
LIMIT 6
18/02/28 13:48:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29283398423f`
LIMIT 6
18/02/28 13:48:23 INFO CodeGenerator: Code generated in 101.65804 ms
18/02/28 13:48:23 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:48:23 INFO DAGScheduler: Got job 53 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:48:23 INFO DAGScheduler: Final stage: ResultStage 102 (collect at utils.scala:211)
18/02/28 13:48:23 INFO DAGScheduler: Parents of final stage: List()
18/02/28 13:48:23 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:23 INFO DAGScheduler: Submitting ResultStage 102 (MapPartitionsRDD[184] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:23 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 159.2 KB, free 344.7 MB)
18/02/28 13:48:23 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 44.4 KB, free 344.6 MB)
18/02/28 13:48:23 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 127.0.0.1:61164 (size: 44.4 KB, free: 345.4 MB)
18/02/28 13:48:23 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 102 (MapPartitionsRDD[184] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:48:23 INFO TaskSchedulerImpl: Adding task set 102.0 with 1 tasks
18/02/28 13:48:23 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 245, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 13:48:23 INFO Executor: Running task 0.0 in stage 102.0 (TID 245)
18/02/28 13:48:23 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 13:48:24 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 127.0.0.1:61164 in memory (size: 5.3 KB, free: 345.5 MB)
18/02/28 13:48:24 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 127.0.0.1:61164 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 13:48:24 INFO Executor: Finished task 0.0 in stage 102.0 (TID 245). 2429 bytes result sent to driver
18/02/28 13:48:24 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 245) in 373 ms on localhost (executor driver) (1/1)
18/02/28 13:48:24 INFO DAGScheduler: ResultStage 102 (collect at utils.scala:211) finished in 0.374 s
18/02/28 13:48:24 INFO DAGScheduler: Job 53 finished: collect at utils.scala:211, took 0.381080 s
18/02/28 13:48:24 INFO CodeGenerator: Code generated in 14.068357 ms
18/02/28 13:48:24 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool 
18/02/28 13:48:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:24 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_29283398423f`
GROUP BY `delayed`, `prediction`
18/02/28 13:48:24 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:48:24 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:48:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 13:48:24 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_29283398423f`
GROUP BY `delayed`, `prediction`
LIMIT 10
18/02/28 13:48:24 INFO HiveMetaStore: 0: get_database: default
18/02/28 13:48:24 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 13:48:24 INFO CodeGenerator: Code generated in 16.278206 ms
18/02/28 13:48:24 INFO CodeGenerator: Code generated in 46.745717 ms
18/02/28 13:48:24 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:48:24 INFO DAGScheduler: Registering RDD 187 (collect at utils.scala:211)
18/02/28 13:48:24 INFO DAGScheduler: Got job 54 (collect at utils.scala:211) with 1 output partitions
18/02/28 13:48:24 INFO DAGScheduler: Final stage: ResultStage 104 (collect at utils.scala:211)
18/02/28 13:48:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 103)
18/02/28 13:48:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 103)
18/02/28 13:48:24 INFO DAGScheduler: Submitting ShuffleMapStage 103 (MapPartitionsRDD[187] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:24 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 79.1 KB, free 344.6 MB)
18/02/28 13:48:24 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 32.2 KB, free 344.5 MB)
18/02/28 13:48:24 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 127.0.0.1:61164 (size: 32.2 KB, free: 345.4 MB)
18/02/28 13:48:24 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:24 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 103 (MapPartitionsRDD[187] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 13:48:24 INFO TaskSchedulerImpl: Adding task set 103.0 with 4 tasks
18/02/28 13:48:24 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 246, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:24 INFO TaskSetManager: Starting task 1.0 in stage 103.0 (TID 247, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:24 INFO TaskSetManager: Starting task 2.0 in stage 103.0 (TID 248, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 13:48:24 INFO TaskSetManager: Starting task 3.0 in stage 103.0 (TID 249, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 13:48:24 INFO Executor: Running task 1.0 in stage 103.0 (TID 247)
18/02/28 13:48:24 INFO Executor: Running task 0.0 in stage 103.0 (TID 246)
18/02/28 13:48:24 INFO Executor: Running task 2.0 in stage 103.0 (TID 248)
18/02/28 13:48:24 INFO BlockManager: Found block rdd_13_2 locally
18/02/28 13:48:24 INFO Executor: Running task 3.0 in stage 103.0 (TID 249)
18/02/28 13:48:24 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 13:48:24 INFO BlockManager: Found block rdd_13_1 locally
18/02/28 13:48:24 INFO BlockManager: Found block rdd_13_3 locally
18/02/28 13:48:24 INFO CodeGenerator: Code generated in 11.025977 ms
18/02/28 13:48:24 INFO CodeGenerator: Code generated in 12.338418 ms
18/02/28 13:48:24 INFO CodeGenerator: Code generated in 5.159137 ms
18/02/28 13:48:25 INFO ContextCleaner: Cleaned accumulator 1769
18/02/28 13:48:25 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 127.0.0.1:61164 in memory (size: 44.4 KB, free: 345.5 MB)
18/02/28 13:48:25 INFO Executor: Finished task 1.0 in stage 103.0 (TID 247). 2411 bytes result sent to driver
18/02/28 13:48:25 INFO TaskSetManager: Finished task 1.0 in stage 103.0 (TID 247) in 1035 ms on localhost (executor driver) (1/4)
18/02/28 13:48:25 INFO Executor: Finished task 0.0 in stage 103.0 (TID 246). 2454 bytes result sent to driver
18/02/28 13:48:25 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 246) in 1055 ms on localhost (executor driver) (2/4)
18/02/28 13:48:25 INFO Executor: Finished task 3.0 in stage 103.0 (TID 249). 2411 bytes result sent to driver
18/02/28 13:48:25 INFO TaskSetManager: Finished task 3.0 in stage 103.0 (TID 249) in 1070 ms on localhost (executor driver) (3/4)
18/02/28 13:48:25 INFO Executor: Finished task 2.0 in stage 103.0 (TID 248). 2411 bytes result sent to driver
18/02/28 13:48:25 INFO TaskSetManager: Finished task 2.0 in stage 103.0 (TID 248) in 1089 ms on localhost (executor driver) (4/4)
18/02/28 13:48:25 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool 
18/02/28 13:48:25 INFO DAGScheduler: ShuffleMapStage 103 (collect at utils.scala:211) finished in 1.089 s
18/02/28 13:48:25 INFO DAGScheduler: looking for newly runnable stages
18/02/28 13:48:25 INFO DAGScheduler: running: Set()
18/02/28 13:48:25 INFO DAGScheduler: waiting: Set(ResultStage 104)
18/02/28 13:48:25 INFO DAGScheduler: failed: Set()
18/02/28 13:48:25 INFO DAGScheduler: Submitting ResultStage 104 (MapPartitionsRDD[190] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:25 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 38.1 KB, free 344.7 MB)
18/02/28 13:48:25 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 17.9 KB, free 344.7 MB)
18/02/28 13:48:25 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 127.0.0.1:61164 (size: 17.9 KB, free: 345.5 MB)
18/02/28 13:48:25 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 104 (MapPartitionsRDD[190] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 13:48:25 INFO TaskSchedulerImpl: Adding task set 104.0 with 1 tasks
18/02/28 13:48:25 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 250, localhost, executor driver, partition 0, PROCESS_LOCAL, 4726 bytes)
18/02/28 13:48:25 INFO Executor: Running task 0.0 in stage 104.0 (TID 250)
18/02/28 13:48:25 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 13:48:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:48:25 INFO Executor: Finished task 0.0 in stage 104.0 (TID 250). 2620 bytes result sent to driver
18/02/28 13:48:25 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 250) in 12 ms on localhost (executor driver) (1/1)
18/02/28 13:48:25 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool 
18/02/28 13:48:25 INFO DAGScheduler: ResultStage 104 (collect at utils.scala:211) finished in 0.012 s
18/02/28 13:48:25 INFO DAGScheduler: Job 54 finished: collect at utils.scala:211, took 1.113106 s
18/02/28 13:48:25 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 13:48:25 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 155 bytes
18/02/28 13:48:25 INFO DAGScheduler: Got job 55 (collect at utils.scala:211) with 3 output partitions
18/02/28 13:48:25 INFO DAGScheduler: Final stage: ResultStage 106 (collect at utils.scala:211)
18/02/28 13:48:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 105)
18/02/28 13:48:25 INFO DAGScheduler: Missing parents: List()
18/02/28 13:48:25 INFO DAGScheduler: Submitting ResultStage 106 (MapPartitionsRDD[190] at collect at utils.scala:211), which has no missing parents
18/02/28 13:48:25 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 38.1 KB, free 344.7 MB)
18/02/28 13:48:25 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 17.9 KB, free 344.6 MB)
18/02/28 13:48:25 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 127.0.0.1:61164 (size: 17.9 KB, free: 345.4 MB)
18/02/28 13:48:25 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1006
18/02/28 13:48:25 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 106 (MapPartitionsRDD[190] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(1, 2, 3))
18/02/28 13:48:25 INFO TaskSchedulerImpl: Adding task set 106.0 with 3 tasks
18/02/28 13:48:25 INFO TaskSetManager: Starting task 2.0 in stage 106.0 (TID 251, localhost, executor driver, partition 3, PROCESS_LOCAL, 4726 bytes)
18/02/28 13:48:25 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 252, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 13:48:25 INFO TaskSetManager: Starting task 1.0 in stage 106.0 (TID 253, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 13:48:25 INFO Executor: Running task 2.0 in stage 106.0 (TID 251)
18/02/28 13:48:25 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 13:48:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 13:48:25 INFO Executor: Finished task 2.0 in stage 106.0 (TID 251). 2577 bytes result sent to driver
18/02/28 13:48:25 INFO Executor: Running task 0.0 in stage 106.0 (TID 252)
18/02/28 13:48:25 INFO Executor: Running task 1.0 in stage 106.0 (TID 253)
18/02/28 13:48:25 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:48:25 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 13:48:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 13:48:25 INFO Executor: Finished task 0.0 in stage 106.0 (TID 252). 2640 bytes result sent to driver
18/02/28 13:48:25 INFO TaskSetManager: Finished task 2.0 in stage 106.0 (TID 251) in 21 ms on localhost (executor driver) (1/3)
18/02/28 13:48:25 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 252) in 22 ms on localhost (executor driver) (2/3)
18/02/28 13:48:25 INFO Executor: Finished task 1.0 in stage 106.0 (TID 253). 2623 bytes result sent to driver
18/02/28 13:48:25 INFO TaskSetManager: Finished task 1.0 in stage 106.0 (TID 253) in 20 ms on localhost (executor driver) (3/3)
18/02/28 13:48:25 INFO DAGScheduler: ResultStage 106 (collect at utils.scala:211) finished in 0.026 s
18/02/28 13:48:25 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool 
18/02/28 13:48:25 INFO DAGScheduler: Job 55 finished: collect at utils.scala:211, took 0.031451 s
18/02/28 13:48:25 INFO CodeGenerator: Code generated in 6.111556 ms
18/02/28 13:48:27 INFO SparkContext: Invoking stop() from shutdown hook
18/02/28 13:48:27 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
18/02/28 13:48:27 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/02/28 13:48:27 INFO MemoryStore: MemoryStore cleared
18/02/28 13:48:27 INFO BlockManager: BlockManager stopped
18/02/28 13:48:27 INFO BlockManagerMaster: BlockManagerMaster stopped
18/02/28 13:48:27 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/02/28 13:48:27 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-b809cd80-489a-49cf-bdaa-44d24bceeb26\userFiles-33f96b26-e344-4cc0-9504-08e309e9d1d5
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-b809cd80-489a-49cf-bdaa-44d24bceeb26\userFiles-33f96b26-e344-4cc0-9504-08e309e9d1d5
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1937)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1936)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 13:48:27 INFO SparkContext: Successfully stopped SparkContext
18/02/28 13:48:27 INFO ShutdownHookManager: Shutdown hook called
18/02/28 13:48:27 INFO ShutdownHookManager: Deleting directory C:\Users\JC\AppData\Local\Temp\spark-b809cd80-489a-49cf-bdaa-44d24bceeb26
18/02/28 13:48:27 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-b809cd80-489a-49cf-bdaa-44d24bceeb26
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-b809cd80-489a-49cf-bdaa-44d24bceeb26
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 13:48:27 INFO ShutdownHookManager: Deleting directory C:\Users\JC\AppData\Local\Temp\spark-b809cd80-489a-49cf-bdaa-44d24bceeb26\userFiles-33f96b26-e344-4cc0-9504-08e309e9d1d5
18/02/28 13:48:27 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-b809cd80-489a-49cf-bdaa-44d24bceeb26\userFiles-33f96b26-e344-4cc0-9504-08e309e9d1d5
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-b809cd80-489a-49cf-bdaa-44d24bceeb26\userFiles-33f96b26-e344-4cc0-9504-08e309e9d1d5
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 14:02:07 INFO SparkContext: Running Spark version 2.2.0
18/02/28 14:02:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/02/28 14:02:07 INFO SparkContext: Submitted application: sparklyr
18/02/28 14:02:07 INFO SecurityManager: Changing view acls to: JC
18/02/28 14:02:07 INFO SecurityManager: Changing modify acls to: JC
18/02/28 14:02:07 INFO SecurityManager: Changing view acls groups to: 
18/02/28 14:02:07 INFO SecurityManager: Changing modify acls groups to: 
18/02/28 14:02:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(JC); groups with view permissions: Set(); users  with modify permissions: Set(JC); groups with modify permissions: Set()
18/02/28 14:02:07 INFO Utils: Successfully started service 'sparkDriver' on port 61306.
18/02/28 14:02:07 INFO SparkEnv: Registering MapOutputTracker
18/02/28 14:02:07 INFO SparkEnv: Registering BlockManagerMaster
18/02/28 14:02:07 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/02/28 14:02:07 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/02/28 14:02:07 INFO DiskBlockManager: Created local directory at C:\Users\JC\AppData\Local\Temp\blockmgr-766e1104-98c8-478e-9634-ef17f307055c
18/02/28 14:02:07 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/02/28 14:02:07 INFO SparkEnv: Registering OutputCommitCoordinator
18/02/28 14:02:07 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/02/28 14:02:07 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
18/02/28 14:02:08 INFO SparkContext: Added JAR file:/C:/Users/JC/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:61306/jars/sparklyr-2.2-2.11.jar with timestamp 1519855328000
18/02/28 14:02:08 INFO Executor: Starting executor ID driver on host localhost
18/02/28 14:02:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61327.
18/02/28 14:02:08 INFO NettyBlockTransferService: Server created on 127.0.0.1:61327
18/02/28 14:02:08 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/02/28 14:02:08 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 61327, None)
18/02/28 14:02:08 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:61327 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 61327, None)
18/02/28 14:02:08 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 61327, None)
18/02/28 14:02:08 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 61327, None)
18/02/28 14:02:08 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/02/28 14:02:08 INFO SharedState: loading hive config file: file:/C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
18/02/28 14:02:08 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:\Users\JC\AppData\Local\spark\spark-2.2.0-bin-hadoop2.7\tmp\hive') to the value of spark.sql.warehouse.dir ('C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive').
18/02/28 14:02:08 INFO SharedState: Warehouse path is 'C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive'.
18/02/28 14:02:09 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
18/02/28 14:02:10 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
18/02/28 14:02:10 INFO ObjectStore: ObjectStore, initialize called
18/02/28 14:02:10 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
18/02/28 14:02:10 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
18/02/28 14:02:11 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
18/02/28 14:02:12 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 14:02:12 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 14:02:13 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 14:02:13 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 14:02:13 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
18/02/28 14:02:13 INFO ObjectStore: Initialized ObjectStore
18/02/28 14:02:13 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
18/02/28 14:02:13 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
18/02/28 14:02:13 INFO HiveMetaStore: Added admin role in metastore
18/02/28 14:02:13 INFO HiveMetaStore: Added public role in metastore
18/02/28 14:02:13 INFO HiveMetaStore: No user is added in admin role, since config is empty
18/02/28 14:02:13 INFO HiveMetaStore: 0: get_all_databases
18/02/28 14:02:13 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_all_databases	
18/02/28 14:02:13 INFO HiveMetaStore: 0: get_functions: db=default pat=*
18/02/28 14:02:13 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
18/02/28 14:02:13 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 14:02:13 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/Temp/ddffb6c6-607a-427e-bd21-1b8f69cf692b_resources
18/02/28 14:02:13 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/ddffb6c6-607a-427e-bd21-1b8f69cf692b
18/02/28 14:02:13 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/ddffb6c6-607a-427e-bd21-1b8f69cf692b
18/02/28 14:02:13 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/ddffb6c6-607a-427e-bd21-1b8f69cf692b/_tmp_space.db
18/02/28 14:02:13 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive
18/02/28 14:02:13 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:02:13 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:02:13 INFO HiveMetaStore: 0: get_database: global_temp
18/02/28 14:02:13 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: global_temp	
18/02/28 14:02:13 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
18/02/28 14:02:14 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/Temp/114f116f-8778-47d8-9c7c-cc992c09ef75_resources
18/02/28 14:02:14 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/114f116f-8778-47d8-9c7c-cc992c09ef75
18/02/28 14:02:14 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/114f116f-8778-47d8-9c7c-cc992c09ef75
18/02/28 14:02:14 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/114f116f-8778-47d8-9c7c-cc992c09ef75/_tmp_space.db
18/02/28 14:02:14 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive
18/02/28 14:02:14 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
18/02/28 14:02:14 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 14:02:15 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:02:15 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:02:15 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:02:15 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:02:15 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 14:02:15 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 14:02:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:02:16 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 14:02:16 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:02:16 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:02:16 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:02:16 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:02:16 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 14:02:16 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 14:02:16 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 14:02:16 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
18/02/28 14:02:16 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
18/02/28 14:02:16 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:02:16 INFO DAGScheduler: Missing parents: List()
18/02/28 14:02:16 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55), which has no missing parents
18/02/28 14:02:16 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
18/02/28 14:02:16 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
18/02/28 14:02:16 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:61327 (size: 3.4 KB, free: 366.3 MB)
18/02/28 14:02:16 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
18/02/28 14:02:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0))
18/02/28 14:02:16 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/02/28 14:02:17 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 14:02:17 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/02/28 14:02:17 INFO Executor: Fetching spark://127.0.0.1:61306/jars/sparklyr-2.2-2.11.jar with timestamp 1519855328000
18/02/28 14:02:17 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:61306 after 18 ms (0 ms spent in bootstraps)
18/02/28 14:02:17 INFO Utils: Fetching spark://127.0.0.1:61306/jars/sparklyr-2.2-2.11.jar to C:\Users\JC\AppData\Local\Temp\spark-36323954-6d14-4996-8db0-1a77e447180a\userFiles-9965fdd6-1604-4984-9608-41b5523134f0\fetchFileTemp7138079746968983344.tmp
18/02/28 14:02:17 INFO Executor: Adding file:/C:/Users/JC/AppData/Local/Temp/spark-36323954-6d14-4996-8db0-1a77e447180a/userFiles-9965fdd6-1604-4984-9608-41b5523134f0/sparklyr-2.2-2.11.jar to class loader
18/02/28 14:02:17 INFO CodeGenerator: Code generated in 247.062084 ms
18/02/28 14:02:17 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
18/02/28 14:02:17 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 642 ms on localhost (executor driver) (1/1)
18/02/28 14:02:17 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/02/28 14:02:17 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.662 s
18/02/28 14:02:17 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.820529 s
18/02/28 14:02:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:02:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:02:17 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 14:02:17 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:02:17 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:02:17 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:02:17 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:02:17 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 14:02:17 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 14:02:17 INFO SparkSqlParser: Parsing command: spark_flights
18/02/28 14:02:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:02:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_flights` AS `zzz102`
WHERE (0 = 1)
18/02/28 14:02:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:02:18 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 14:02:18 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:02:18 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:02:18 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:02:18 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:02:18 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 14:02:18 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 14:02:18 INFO CodeGenerator: Code generated in 11.880368 ms
18/02/28 14:02:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:02:35 INFO SparkSqlParser: Parsing command: SELECT `month`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`, `sched_dep_time`, `sched_arr_time`
FROM (SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`dep_time` AS DOUBLE) AS `dep_time`, CAST(`arr_time` AS DOUBLE) AS `arr_time`, CAST(`arr_delay` AS DOUBLE) AS `arr_delay`, CAST(`dep_delay` AS DOUBLE) AS `dep_delay`, CAST(`distance` AS DOUBLE) AS `distance`, CAST(`sched_dep_time` AS DOUBLE) AS `sched_dep_time`, CAST(`sched_arr_time` AS DOUBLE) AS `sched_arr_time`
FROM (SELECT `month`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`, `sched_dep_time`, `sched_arr_time`
FROM `spark_flights`) `vbyfsxjojs`) `upymepnyjh`
18/02/28 14:02:35 INFO SparkSqlParser: Parsing command: cached_flights
18/02/28 14:02:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:02:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights` AS `zzz103`
WHERE (0 = 1)
18/02/28 14:02:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:02:35 INFO SparkSqlParser: Parsing command: CACHE TABLE `cached_flights`
18/02/28 14:02:35 INFO SparkSqlParser: Parsing command: `cached_flights`
18/02/28 14:02:35 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 14:02:35 INFO ContextCleaner: Cleaned accumulator 0
18/02/28 14:02:35 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 14:02:35 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dep_time: string, sched_dep_time: string, dep_delay: string, arr_time: string ... 6 more fields>
18/02/28 14:02:35 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 14:02:36 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:61327 in memory (size: 3.4 KB, free: 366.3 MB)
18/02/28 14:02:36 INFO CodeGenerator: Code generated in 28.880734 ms
18/02/28 14:02:36 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 282.5 KB, free 366.0 MB)
18/02/28 14:02:36 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 24.1 KB, free 366.0 MB)
18/02/28 14:02:36 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:61327 (size: 24.1 KB, free: 366.3 MB)
18/02/28 14:02:36 INFO SparkContext: Created broadcast 1 from sql at <unknown>:0
18/02/28 14:02:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21019222 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 14:02:36 INFO CodeGenerator: Code generated in 13.159662 ms
18/02/28 14:02:36 INFO CodeGenerator: Code generated in 13.850791 ms
18/02/28 14:02:36 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 14:02:36 INFO DAGScheduler: Registering RDD 10 (sql at <unknown>:0)
18/02/28 14:02:36 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
18/02/28 14:02:36 INFO DAGScheduler: Final stage: ResultStage 2 (sql at <unknown>:0)
18/02/28 14:02:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
18/02/28 14:02:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
18/02/28 14:02:36 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[10] at sql at <unknown>:0), which has no missing parents
18/02/28 14:02:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 26.7 KB, free 366.0 MB)
18/02/28 14:02:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.7 KB, free 366.0 MB)
18/02/28 14:02:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:61327 (size: 11.7 KB, free: 366.3 MB)
18/02/28 14:02:36 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
18/02/28 14:02:36 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[10] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:02:36 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks
18/02/28 14:02:36 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:02:36 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:02:36 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:02:36 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:02:36 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
18/02/28 14:02:36 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
18/02/28 14:02:36 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
18/02/28 14:02:36 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
18/02/28 14:02:36 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_7.csv, range: 0-2938867, partition values: [empty row]
18/02/28 14:02:36 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_11.csv, range: 0-2757037, partition values: [empty row]
18/02/28 14:02:36 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_4.csv, range: 0-2830543, partition values: [empty row]
18/02/28 14:02:36 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_3.csv, range: 0-2881793, partition values: [empty row]
18/02/28 14:02:36 INFO CodeGenerator: Code generated in 14.643827 ms
18/02/28 14:02:37 INFO ContextCleaner: Cleaned accumulator 55
18/02/28 14:02:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_5.csv, range: 0-2880181, partition values: [empty row]
18/02/28 14:02:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_1.csv, range: 0-2697256, partition values: [empty row]
18/02/28 14:02:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_6.csv, range: 0-2820227, partition values: [empty row]
18/02/28 14:02:37 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_8.csv, range: 0-2932019, partition values: [empty row]
18/02/28 14:02:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_2.csv, range: 0-2487144, partition values: [empty row]
18/02/28 14:02:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_12.csv, range: 0-2836468, partition values: [empty row]
18/02/28 14:02:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_9.csv, range: 0-2763076, partition values: [empty row]
18/02/28 14:02:38 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_10.csv, range: 0-2920629, partition values: [empty row]
18/02/28 14:02:38 INFO MemoryStore: Block rdd_7_3 stored as values in memory (estimated size 4.8 MB, free 361.2 MB)
18/02/28 14:02:38 INFO BlockManagerInfo: Added rdd_7_3 in memory on 127.0.0.1:61327 (size: 4.8 MB, free: 361.5 MB)
18/02/28 14:02:38 INFO CodeGenerator: Code generated in 4.982477 ms
18/02/28 14:02:38 INFO CodeGenerator: Code generated in 78.605357 ms
18/02/28 14:02:38 INFO MemoryStore: Block rdd_7_1 stored as values in memory (estimated size 5.2 MB, free 355.9 MB)
18/02/28 14:02:38 INFO BlockManagerInfo: Added rdd_7_1 in memory on 127.0.0.1:61327 (size: 5.2 MB, free: 356.2 MB)
18/02/28 14:02:38 INFO MemoryStore: Block rdd_7_2 stored as values in memory (estimated size 5.1 MB, free 350.8 MB)
18/02/28 14:02:38 INFO BlockManagerInfo: Added rdd_7_2 in memory on 127.0.0.1:61327 (size: 5.1 MB, free: 351.1 MB)
18/02/28 14:02:38 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 2547 bytes result sent to driver
18/02/28 14:02:38 INFO MemoryStore: Block rdd_7_0 stored as values in memory (estimated size 5.3 MB, free 345.5 MB)
18/02/28 14:02:38 INFO BlockManagerInfo: Added rdd_7_0 in memory on 127.0.0.1:61327 (size: 5.3 MB, free: 345.8 MB)
18/02/28 14:02:38 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 2461 bytes result sent to driver
18/02/28 14:02:38 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 2504 bytes result sent to driver
18/02/28 14:02:38 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1972 ms on localhost (executor driver) (1/4)
18/02/28 14:02:38 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1977 ms on localhost (executor driver) (2/4)
18/02/28 14:02:38 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 1977 ms on localhost (executor driver) (3/4)
18/02/28 14:02:38 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2504 bytes result sent to driver
18/02/28 14:02:38 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1989 ms on localhost (executor driver) (4/4)
18/02/28 14:02:38 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/02/28 14:02:38 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 1.989 s
18/02/28 14:02:38 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:02:38 INFO DAGScheduler: running: Set()
18/02/28 14:02:38 INFO DAGScheduler: waiting: Set(ResultStage 2)
18/02/28 14:02:38 INFO DAGScheduler: failed: Set()
18/02/28 14:02:38 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[13] at sql at <unknown>:0), which has no missing parents
18/02/28 14:02:38 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.0 KB, free 345.5 MB)
18/02/28 14:02:38 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 345.5 MB)
18/02/28 14:02:38 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:61327 (size: 3.7 KB, free: 345.8 MB)
18/02/28 14:02:38 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
18/02/28 14:02:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[13] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 14:02:38 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
18/02/28 14:02:38 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 14:02:38 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
18/02/28 14:02:38 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
18/02/28 14:02:38 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1538 bytes result sent to driver
18/02/28 14:02:38 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 38 ms on localhost (executor driver) (1/1)
18/02/28 14:02:38 INFO DAGScheduler: ResultStage 2 (sql at <unknown>:0) finished in 0.039 s
18/02/28 14:02:38 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 2.116341 s
18/02/28 14:02:38 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/02/28 14:02:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:02:38 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `cached_flights`
18/02/28 14:02:38 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:02:38 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:02:38 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:02:38 INFO DAGScheduler: Registering RDD 16 (collect at utils.scala:211)
18/02/28 14:02:38 INFO DAGScheduler: Got job 2 (collect at utils.scala:211) with 1 output partitions
18/02/28 14:02:38 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:211)
18/02/28 14:02:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
18/02/28 14:02:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
18/02/28 14:02:38 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[16] at collect at utils.scala:211), which has no missing parents
18/02/28 14:02:38 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 26.7 KB, free 345.5 MB)
18/02/28 14:02:38 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 11.8 KB, free 345.5 MB)
18/02/28 14:02:38 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:61327 (size: 11.8 KB, free: 345.8 MB)
18/02/28 14:02:38 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
18/02/28 14:02:38 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[16] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:02:38 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks
18/02/28 14:02:38 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:02:38 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:02:38 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 8, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:02:38 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 9, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:02:38 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)
18/02/28 14:02:38 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)
18/02/28 14:02:38 INFO Executor: Running task 2.0 in stage 3.0 (TID 8)
18/02/28 14:02:38 INFO Executor: Running task 3.0 in stage 3.0 (TID 9)
18/02/28 14:02:38 INFO BlockManager: Found block rdd_7_0 locally
18/02/28 14:02:38 INFO BlockManager: Found block rdd_7_3 locally
18/02/28 14:02:38 INFO BlockManager: Found block rdd_7_1 locally
18/02/28 14:02:38 INFO BlockManager: Found block rdd_7_2 locally
18/02/28 14:02:38 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 1737 bytes result sent to driver
18/02/28 14:02:38 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 1737 bytes result sent to driver
18/02/28 14:02:38 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 43 ms on localhost (executor driver) (1/4)
18/02/28 14:02:38 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 46 ms on localhost (executor driver) (2/4)
18/02/28 14:02:38 INFO Executor: Finished task 2.0 in stage 3.0 (TID 8). 1737 bytes result sent to driver
18/02/28 14:02:38 INFO Executor: Finished task 3.0 in stage 3.0 (TID 9). 1694 bytes result sent to driver
18/02/28 14:02:38 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 8) in 52 ms on localhost (executor driver) (3/4)
18/02/28 14:02:38 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 9) in 53 ms on localhost (executor driver) (4/4)
18/02/28 14:02:38 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:211) finished in 0.055 s
18/02/28 14:02:38 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:02:38 INFO DAGScheduler: running: Set()
18/02/28 14:02:38 INFO DAGScheduler: waiting: Set(ResultStage 4)
18/02/28 14:02:38 INFO DAGScheduler: failed: Set()
18/02/28 14:02:38 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/02/28 14:02:38 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[19] at collect at utils.scala:211), which has no missing parents
18/02/28 14:02:38 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 345.4 MB)
18/02/28 14:02:38 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KB, free 345.4 MB)
18/02/28 14:02:38 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:61327 (size: 3.7 KB, free: 345.8 MB)
18/02/28 14:02:38 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
18/02/28 14:02:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 14:02:38 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
18/02/28 14:02:38 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 10, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 14:02:38 INFO Executor: Running task 0.0 in stage 4.0 (TID 10)
18/02/28 14:02:38 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:61327 in memory (size: 3.7 KB, free: 345.8 MB)
18/02/28 14:02:38 INFO ContextCleaner: Cleaned accumulator 116
18/02/28 14:02:38 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:02:38 INFO Executor: Finished task 0.0 in stage 4.0 (TID 10). 1538 bytes result sent to driver
18/02/28 14:02:38 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 10) in 7 ms on localhost (executor driver) (1/1)
18/02/28 14:02:38 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:211) finished in 0.008 s
18/02/28 14:02:38 INFO DAGScheduler: Job 2 finished: collect at utils.scala:211, took 0.089688 s
18/02/28 14:02:38 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/02/28 14:02:38 INFO CodeGenerator: Code generated in 6.976878 ms
18/02/28 14:02:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:02:38 INFO SparkSqlParser: Parsing command: SHOW TABLES LIKE"cached_flights"
18/02/28 14:02:38 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:02:38 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:02:38 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:02:38 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:02:38 INFO HiveMetaStore: 0: get_tables: db=default pat=cached_flights
18/02/28 14:02:38 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=cached_flights	
18/02/28 14:02:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:02:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights` AS `zzz104`
WHERE (0 = 1)
18/02/28 14:02:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:02:38 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 14:02:38 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:02:38 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:02:38 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:02:38 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:02:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 14:02:38 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 14:08:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:08:56 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `dephour`, `prediction`, `probability`
FROM `sparklyr_tmp_30e065b62d27`
LIMIT 5
18/02/28 14:08:56 INFO HiveMetaStore: 0: get_table : db=default tbl=sparklyr_tmp_30e065b62d27
18/02/28 14:08:56 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sparklyr_tmp_30e065b62d27	
18/02/28 14:09:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:09:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
WHERE (NOT(((`arr_delay`) IS NULL)))
18/02/28 14:09:05 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e02d464ad
18/02/28 14:09:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:09:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e02d464ad` AS `zzz105`
WHERE (0 = 1)
18/02/28 14:09:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:09:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e02d464ad`
18/02/28 14:09:05 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e0759b93
18/02/28 14:09:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:09:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0759b93` AS `zzz106`
WHERE (0 = 1)
18/02/28 14:09:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:09:05 INFO SparkSqlParser: Parsing command: SELECT `month`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`, `sched_dep_time`, `sched_arr_time`, `delayed`, CONCAT("h", CAST(`dephour` AS INT)) AS `dephour`
FROM `sparklyr_tmp_30e0759b93`
18/02/28 14:09:05 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:09:05 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:09:05 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e07aa02889
18/02/28 14:09:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:09:06 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e07aa02889` AS `zzz107`
WHERE (0 = 1)
18/02/28 14:09:06 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e0186d49d8
18/02/28 14:09:06 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:09:06 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0186d49d8` AS `zzz108`
WHERE (0 = 1)
18/02/28 14:09:06 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e0680c11e4
18/02/28 14:09:06 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:09:06 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0680c11e4` AS `zzz109`
WHERE (0 = 1)
18/02/28 14:09:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:09:09 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e07aa02889`
18/02/28 14:09:09 INFO SparkSqlParser: Parsing command: training
18/02/28 14:09:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:09:09 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training` AS `zzz110`
WHERE (0 = 1)
18/02/28 14:09:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:09:09 INFO SparkSqlParser: Parsing command: CACHE TABLE `training`
18/02/28 14:09:09 INFO SparkSqlParser: Parsing command: `training`
18/02/28 14:09:09 INFO CodeGenerator: Code generated in 45.916714 ms
18/02/28 14:09:09 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 14:09:09 INFO DAGScheduler: Registering RDD 25 (sql at <unknown>:0)
18/02/28 14:09:09 INFO DAGScheduler: Got job 3 (sql at <unknown>:0) with 1 output partitions
18/02/28 14:09:09 INFO DAGScheduler: Final stage: ResultStage 6 (sql at <unknown>:0)
18/02/28 14:09:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
18/02/28 14:09:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
18/02/28 14:09:09 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[25] at sql at <unknown>:0), which has no missing parents
18/02/28 14:09:09 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 53.6 KB, free 345.4 MB)
18/02/28 14:09:09 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 22.0 KB, free 345.4 MB)
18/02/28 14:09:09 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:61327 (size: 22.0 KB, free: 345.8 MB)
18/02/28 14:09:09 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:09 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[25] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:09 INFO TaskSchedulerImpl: Adding task set 5.0 with 4 tasks
18/02/28 14:09:09 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:09:09 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 12, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:09:09 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 13, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:09:09 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 14, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:09:09 INFO Executor: Running task 3.0 in stage 5.0 (TID 14)
18/02/28 14:09:09 INFO Executor: Running task 0.0 in stage 5.0 (TID 11)
18/02/28 14:09:09 INFO Executor: Running task 2.0 in stage 5.0 (TID 13)
18/02/28 14:09:09 INFO Executor: Running task 1.0 in stage 5.0 (TID 12)
18/02/28 14:09:09 INFO BlockManager: Found block rdd_7_3 locally
18/02/28 14:09:09 INFO BlockManager: Found block rdd_7_2 locally
18/02/28 14:09:09 INFO BlockManager: Found block rdd_7_1 locally
18/02/28 14:09:09 INFO BlockManager: Found block rdd_7_0 locally
18/02/28 14:09:09 INFO CodeGenerator: Code generated in 24.495943 ms
18/02/28 14:09:09 INFO CodeGenerator: Code generated in 47.80392 ms
18/02/28 14:09:10 INFO CodeGenerator: Code generated in 24.374643 ms
18/02/28 14:09:10 INFO ContextCleaner: Cleaned accumulator 185
18/02/28 14:09:10 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:61327 in memory (size: 3.7 KB, free: 345.8 MB)
18/02/28 14:09:10 INFO MemoryStore: Block rdd_22_2 stored as values in memory (estimated size 58.0 KB, free 325.3 MB)
18/02/28 14:09:10 INFO MemoryStore: Block rdd_22_3 stored as values in memory (estimated size 55.4 KB, free 335.3 MB)
18/02/28 14:09:10 INFO MemoryStore: Block rdd_22_0 stored as values in memory (estimated size 64.3 KB, free 335.2 MB)
18/02/28 14:09:10 INFO BlockManagerInfo: Added rdd_22_2 in memory on 127.0.0.1:61327 (size: 58.0 KB, free: 345.7 MB)
18/02/28 14:09:10 INFO BlockManagerInfo: Added rdd_22_3 in memory on 127.0.0.1:61327 (size: 55.4 KB, free: 345.7 MB)
18/02/28 14:09:10 INFO BlockManagerInfo: Added rdd_22_0 in memory on 127.0.0.1:61327 (size: 64.3 KB, free: 345.6 MB)
18/02/28 14:09:10 INFO MemoryStore: Block rdd_22_1 stored as values in memory (estimated size 65.7 KB, free 345.1 MB)
18/02/28 14:09:10 INFO BlockManagerInfo: Added rdd_22_1 in memory on 127.0.0.1:61327 (size: 65.7 KB, free: 345.5 MB)
18/02/28 14:09:10 INFO Executor: Finished task 2.0 in stage 5.0 (TID 13). 3099 bytes result sent to driver
18/02/28 14:09:10 INFO Executor: Finished task 3.0 in stage 5.0 (TID 14). 3099 bytes result sent to driver
18/02/28 14:09:10 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 13) in 1086 ms on localhost (executor driver) (1/4)
18/02/28 14:09:10 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 14) in 1089 ms on localhost (executor driver) (2/4)
18/02/28 14:09:10 INFO Executor: Finished task 0.0 in stage 5.0 (TID 11). 3142 bytes result sent to driver
18/02/28 14:09:10 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 11) in 1094 ms on localhost (executor driver) (3/4)
18/02/28 14:09:10 INFO Executor: Finished task 1.0 in stage 5.0 (TID 12). 3099 bytes result sent to driver
18/02/28 14:09:10 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 12) in 1103 ms on localhost (executor driver) (4/4)
18/02/28 14:09:10 INFO DAGScheduler: ShuffleMapStage 5 (sql at <unknown>:0) finished in 1.105 s
18/02/28 14:09:10 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:09:10 INFO DAGScheduler: running: Set()
18/02/28 14:09:10 INFO DAGScheduler: waiting: Set(ResultStage 6)
18/02/28 14:09:10 INFO DAGScheduler: failed: Set()
18/02/28 14:09:10 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[28] at sql at <unknown>:0), which has no missing parents
18/02/28 14:09:10 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/02/28 14:09:10 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.0 KB, free 345.1 MB)
18/02/28 14:09:10 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KB, free 345.1 MB)
18/02/28 14:09:10 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:61327 (size: 3.7 KB, free: 345.5 MB)
18/02/28 14:09:10 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[28] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 14:09:10 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
18/02/28 14:09:10 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 15, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 14:09:10 INFO Executor: Running task 0.0 in stage 6.0 (TID 15)
18/02/28 14:09:10 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:09:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:09:10 INFO Executor: Finished task 0.0 in stage 6.0 (TID 15). 1495 bytes result sent to driver
18/02/28 14:09:10 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 15) in 8 ms on localhost (executor driver) (1/1)
18/02/28 14:09:10 INFO DAGScheduler: ResultStage 6 (sql at <unknown>:0) finished in 0.008 s
18/02/28 14:09:10 INFO DAGScheduler: Job 3 finished: sql at <unknown>:0, took 1.134235 s
18/02/28 14:09:10 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
18/02/28 14:09:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:09:10 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `training`
18/02/28 14:09:10 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:09:10 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:09:10 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:09:10 INFO DAGScheduler: Registering RDD 31 (collect at utils.scala:211)
18/02/28 14:09:10 INFO DAGScheduler: Got job 4 (collect at utils.scala:211) with 1 output partitions
18/02/28 14:09:10 INFO DAGScheduler: Final stage: ResultStage 8 (collect at utils.scala:211)
18/02/28 14:09:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
18/02/28 14:09:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
18/02/28 14:09:11 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[31] at collect at utils.scala:211), which has no missing parents
18/02/28 14:09:11 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 53.6 KB, free 345.1 MB)
18/02/28 14:09:11 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 22.0 KB, free 345.1 MB)
18/02/28 14:09:11 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:61327 (size: 22.0 KB, free: 345.5 MB)
18/02/28 14:09:11 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:11 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[31] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:11 INFO TaskSchedulerImpl: Adding task set 7.0 with 4 tasks
18/02/28 14:09:11 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:09:11 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 17, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:09:11 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 18, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:09:11 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 19, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:09:11 INFO Executor: Running task 0.0 in stage 7.0 (TID 16)
18/02/28 14:09:11 INFO Executor: Running task 1.0 in stage 7.0 (TID 17)
18/02/28 14:09:11 INFO BlockManager: Found block rdd_22_1 locally
18/02/28 14:09:11 INFO Executor: Running task 2.0 in stage 7.0 (TID 18)
18/02/28 14:09:11 INFO Executor: Running task 3.0 in stage 7.0 (TID 19)
18/02/28 14:09:11 INFO BlockManager: Found block rdd_22_2 locally
18/02/28 14:09:11 INFO BlockManager: Found block rdd_22_0 locally
18/02/28 14:09:11 INFO BlockManager: Found block rdd_22_3 locally
18/02/28 14:09:11 INFO Executor: Finished task 2.0 in stage 7.0 (TID 18). 2332 bytes result sent to driver
18/02/28 14:09:11 INFO Executor: Finished task 1.0 in stage 7.0 (TID 17). 2289 bytes result sent to driver
18/02/28 14:09:11 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 17) in 44 ms on localhost (executor driver) (1/4)
18/02/28 14:09:11 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 18) in 45 ms on localhost (executor driver) (2/4)
18/02/28 14:09:11 INFO Executor: Finished task 3.0 in stage 7.0 (TID 19). 2289 bytes result sent to driver
18/02/28 14:09:11 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 19) in 53 ms on localhost (executor driver) (3/4)
18/02/28 14:09:11 INFO Executor: Finished task 0.0 in stage 7.0 (TID 16). 2332 bytes result sent to driver
18/02/28 14:09:11 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 16) in 62 ms on localhost (executor driver) (4/4)
18/02/28 14:09:11 INFO DAGScheduler: ShuffleMapStage 7 (collect at utils.scala:211) finished in 0.064 s
18/02/28 14:09:11 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:09:11 INFO DAGScheduler: running: Set()
18/02/28 14:09:11 INFO DAGScheduler: waiting: Set(ResultStage 8)
18/02/28 14:09:11 INFO DAGScheduler: failed: Set()
18/02/28 14:09:11 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[34] at collect at utils.scala:211), which has no missing parents
18/02/28 14:09:11 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 345.1 MB)
18/02/28 14:09:11 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
18/02/28 14:09:11 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 345.1 MB)
18/02/28 14:09:11 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:61327 (size: 3.7 KB, free: 345.5 MB)
18/02/28 14:09:11 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[34] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 14:09:11 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
18/02/28 14:09:11 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 20, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 14:09:11 INFO Executor: Running task 0.0 in stage 8.0 (TID 20)
18/02/28 14:09:11 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:09:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:09:11 INFO Executor: Finished task 0.0 in stage 8.0 (TID 20). 1538 bytes result sent to driver
18/02/28 14:09:11 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 20) in 7 ms on localhost (executor driver) (1/1)
18/02/28 14:09:11 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
18/02/28 14:09:11 INFO DAGScheduler: ResultStage 8 (collect at utils.scala:211) finished in 0.008 s
18/02/28 14:09:11 INFO DAGScheduler: Job 4 finished: collect at utils.scala:211, took 0.101663 s
18/02/28 14:09:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:09:11 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 14:09:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:09:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:09:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:09:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:09:11 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 14:09:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 14:09:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:09:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 14:09:12 INFO CodeGenerator: Code generated in 6.797396 ms
18/02/28 14:09:12 INFO SparkContext: Starting job: countByValue at StringIndexer.scala:113
18/02/28 14:09:12 INFO DAGScheduler: Registering RDD 41 (countByValue at StringIndexer.scala:113)
18/02/28 14:09:12 INFO DAGScheduler: Got job 5 (countByValue at StringIndexer.scala:113) with 4 output partitions
18/02/28 14:09:12 INFO DAGScheduler: Final stage: ResultStage 10 (countByValue at StringIndexer.scala:113)
18/02/28 14:09:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
18/02/28 14:09:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
18/02/28 14:09:12 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[41] at countByValue at StringIndexer.scala:113), which has no missing parents
18/02/28 14:09:12 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 55.3 KB, free 345.0 MB)
18/02/28 14:09:12 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 22.9 KB, free 345.0 MB)
18/02/28 14:09:12 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:61327 (size: 22.9 KB, free: 345.5 MB)
18/02/28 14:09:12 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:12 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[41] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:12 INFO TaskSchedulerImpl: Adding task set 9.0 with 4 tasks
18/02/28 14:09:12 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:09:12 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 22, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:09:12 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 23, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:09:12 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 24, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:09:12 INFO Executor: Running task 1.0 in stage 9.0 (TID 22)
18/02/28 14:09:12 INFO Executor: Running task 0.0 in stage 9.0 (TID 21)
18/02/28 14:09:12 INFO Executor: Running task 2.0 in stage 9.0 (TID 23)
18/02/28 14:09:12 INFO Executor: Running task 3.0 in stage 9.0 (TID 24)
18/02/28 14:09:12 INFO BlockManager: Found block rdd_22_1 locally
18/02/28 14:09:12 INFO BlockManager: Found block rdd_22_3 locally
18/02/28 14:09:12 INFO BlockManager: Found block rdd_22_2 locally
18/02/28 14:09:12 INFO BlockManager: Found block rdd_22_0 locally
18/02/28 14:09:12 INFO CodeGenerator: Code generated in 22.940902 ms
18/02/28 14:09:12 INFO CodeGenerator: Code generated in 9.51713 ms
18/02/28 14:09:12 INFO Executor: Finished task 3.0 in stage 9.0 (TID 24). 2277 bytes result sent to driver
18/02/28 14:09:12 INFO Executor: Finished task 1.0 in stage 9.0 (TID 22). 2277 bytes result sent to driver
18/02/28 14:09:12 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 24) in 165 ms on localhost (executor driver) (1/4)
18/02/28 14:09:12 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 22) in 165 ms on localhost (executor driver) (2/4)
18/02/28 14:09:12 INFO Executor: Finished task 0.0 in stage 9.0 (TID 21). 2277 bytes result sent to driver
18/02/28 14:09:12 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 21) in 174 ms on localhost (executor driver) (3/4)
18/02/28 14:09:12 INFO Executor: Finished task 2.0 in stage 9.0 (TID 23). 2277 bytes result sent to driver
18/02/28 14:09:12 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 23) in 180 ms on localhost (executor driver) (4/4)
18/02/28 14:09:12 INFO DAGScheduler: ShuffleMapStage 9 (countByValue at StringIndexer.scala:113) finished in 0.181 s
18/02/28 14:09:12 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:09:12 INFO DAGScheduler: running: Set()
18/02/28 14:09:12 INFO DAGScheduler: waiting: Set(ResultStage 10)
18/02/28 14:09:12 INFO DAGScheduler: failed: Set()
18/02/28 14:09:12 INFO DAGScheduler: Submitting ResultStage 10 (ShuffledRDD[42] at countByValue at StringIndexer.scala:113), which has no missing parents
18/02/28 14:09:12 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
18/02/28 14:09:12 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 3.2 KB, free 345.0 MB)
18/02/28 14:09:12 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 1959.0 B, free 345.0 MB)
18/02/28 14:09:12 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:61327 (size: 1959.0 B, free: 345.5 MB)
18/02/28 14:09:12 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:12 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 10 (ShuffledRDD[42] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:12 INFO TaskSchedulerImpl: Adding task set 10.0 with 4 tasks
18/02/28 14:09:12 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 25, localhost, executor driver, partition 0, ANY, 4621 bytes)
18/02/28 14:09:12 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 26, localhost, executor driver, partition 1, ANY, 4621 bytes)
18/02/28 14:09:12 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 27, localhost, executor driver, partition 2, ANY, 4621 bytes)
18/02/28 14:09:12 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 28, localhost, executor driver, partition 3, ANY, 4621 bytes)
18/02/28 14:09:12 INFO Executor: Running task 0.0 in stage 10.0 (TID 25)
18/02/28 14:09:12 INFO Executor: Running task 1.0 in stage 10.0 (TID 26)
18/02/28 14:09:12 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:09:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:09:12 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:09:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:09:12 INFO Executor: Running task 2.0 in stage 10.0 (TID 27)
18/02/28 14:09:12 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:09:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:09:12 INFO Executor: Running task 3.0 in stage 10.0 (TID 28)
18/02/28 14:09:12 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:09:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:09:12 INFO Executor: Finished task 3.0 in stage 10.0 (TID 28). 1153 bytes result sent to driver
18/02/28 14:09:12 INFO Executor: Finished task 2.0 in stage 10.0 (TID 27). 1239 bytes result sent to driver
18/02/28 14:09:12 INFO Executor: Finished task 1.0 in stage 10.0 (TID 26). 1135 bytes result sent to driver
18/02/28 14:09:12 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 28) in 44 ms on localhost (executor driver) (1/4)
18/02/28 14:09:12 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 27) in 46 ms on localhost (executor driver) (2/4)
18/02/28 14:09:12 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 26) in 48 ms on localhost (executor driver) (3/4)
18/02/28 14:09:12 INFO Executor: Finished task 0.0 in stage 10.0 (TID 25). 1153 bytes result sent to driver
18/02/28 14:09:12 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 25) in 56 ms on localhost (executor driver) (4/4)
18/02/28 14:09:12 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
18/02/28 14:09:12 INFO DAGScheduler: ResultStage 10 (countByValue at StringIndexer.scala:113) finished in 0.057 s
18/02/28 14:09:12 INFO DAGScheduler: Job 5 finished: countByValue at StringIndexer.scala:113, took 0.351811 s
18/02/28 14:09:12 INFO CodeGenerator: Code generated in 12.761558 ms
18/02/28 14:09:12 INFO SparkContext: Starting job: countByValue at StringIndexer.scala:113
18/02/28 14:09:12 INFO DAGScheduler: Registering RDD 49 (countByValue at StringIndexer.scala:113)
18/02/28 14:09:12 INFO DAGScheduler: Got job 6 (countByValue at StringIndexer.scala:113) with 4 output partitions
18/02/28 14:09:12 INFO DAGScheduler: Final stage: ResultStage 12 (countByValue at StringIndexer.scala:113)
18/02/28 14:09:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
18/02/28 14:09:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
18/02/28 14:09:12 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[49] at countByValue at StringIndexer.scala:113), which has no missing parents
18/02/28 14:09:12 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 56.1 KB, free 344.9 MB)
18/02/28 14:09:12 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 23.1 KB, free 344.9 MB)
18/02/28 14:09:12 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:61327 (size: 23.1 KB, free: 345.5 MB)
18/02/28 14:09:12 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:12 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[49] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:12 INFO TaskSchedulerImpl: Adding task set 11.0 with 4 tasks
18/02/28 14:09:12 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 29, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:09:12 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 30, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:09:12 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 31, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:09:12 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 32, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:09:12 INFO Executor: Running task 0.0 in stage 11.0 (TID 29)
18/02/28 14:09:12 INFO Executor: Running task 1.0 in stage 11.0 (TID 30)
18/02/28 14:09:12 INFO Executor: Running task 2.0 in stage 11.0 (TID 31)
18/02/28 14:09:12 INFO Executor: Running task 3.0 in stage 11.0 (TID 32)
18/02/28 14:09:12 INFO BlockManager: Found block rdd_22_1 locally
18/02/28 14:09:12 INFO BlockManager: Found block rdd_22_2 locally
18/02/28 14:09:12 INFO BlockManager: Found block rdd_22_0 locally
18/02/28 14:09:12 INFO BlockManager: Found block rdd_22_3 locally
18/02/28 14:09:12 INFO CodeGenerator: Code generated in 22.962412 ms
18/02/28 14:09:13 INFO Executor: Finished task 1.0 in stage 11.0 (TID 30). 2277 bytes result sent to driver
18/02/28 14:09:13 INFO Executor: Finished task 3.0 in stage 11.0 (TID 32). 2234 bytes result sent to driver
18/02/28 14:09:13 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 32) in 122 ms on localhost (executor driver) (1/4)
18/02/28 14:09:13 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 30) in 125 ms on localhost (executor driver) (2/4)
18/02/28 14:09:13 INFO Executor: Finished task 2.0 in stage 11.0 (TID 31). 2320 bytes result sent to driver
18/02/28 14:09:13 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 31) in 133 ms on localhost (executor driver) (3/4)
18/02/28 14:09:13 INFO Executor: Finished task 0.0 in stage 11.0 (TID 29). 2277 bytes result sent to driver
18/02/28 14:09:13 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 29) in 144 ms on localhost (executor driver) (4/4)
18/02/28 14:09:13 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
18/02/28 14:09:13 INFO DAGScheduler: ShuffleMapStage 11 (countByValue at StringIndexer.scala:113) finished in 0.144 s
18/02/28 14:09:13 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:09:13 INFO DAGScheduler: running: Set()
18/02/28 14:09:13 INFO DAGScheduler: waiting: Set(ResultStage 12)
18/02/28 14:09:13 INFO DAGScheduler: failed: Set()
18/02/28 14:09:13 INFO DAGScheduler: Submitting ResultStage 12 (ShuffledRDD[50] at countByValue at StringIndexer.scala:113), which has no missing parents
18/02/28 14:09:13 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 3.2 KB, free 344.9 MB)
18/02/28 14:09:13 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 1961.0 B, free 344.9 MB)
18/02/28 14:09:13 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:61327 (size: 1961.0 B, free: 345.5 MB)
18/02/28 14:09:13 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:13 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 12 (ShuffledRDD[50] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:13 INFO TaskSchedulerImpl: Adding task set 12.0 with 4 tasks
18/02/28 14:09:13 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:13 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 34, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:13 INFO TaskSetManager: Starting task 2.0 in stage 12.0 (TID 35, localhost, executor driver, partition 2, ANY, 4621 bytes)
18/02/28 14:09:13 INFO TaskSetManager: Starting task 3.0 in stage 12.0 (TID 36, localhost, executor driver, partition 3, ANY, 4621 bytes)
18/02/28 14:09:13 INFO Executor: Running task 0.0 in stage 12.0 (TID 33)
18/02/28 14:09:13 INFO Executor: Running task 1.0 in stage 12.0 (TID 34)
18/02/28 14:09:13 INFO Executor: Running task 2.0 in stage 12.0 (TID 35)
18/02/28 14:09:13 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 14:09:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:09:13 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:09:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:09:13 INFO Executor: Finished task 1.0 in stage 12.0 (TID 34). 1048 bytes result sent to driver
18/02/28 14:09:13 INFO Executor: Running task 3.0 in stage 12.0 (TID 36)
18/02/28 14:09:13 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:09:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:09:13 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 14:09:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 14:09:13 INFO Executor: Finished task 2.0 in stage 12.0 (TID 35). 1154 bytes result sent to driver
18/02/28 14:09:13 INFO Executor: Finished task 3.0 in stage 12.0 (TID 36). 1111 bytes result sent to driver
18/02/28 14:09:13 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 34) in 25 ms on localhost (executor driver) (1/4)
18/02/28 14:09:13 INFO TaskSetManager: Finished task 2.0 in stage 12.0 (TID 35) in 26 ms on localhost (executor driver) (2/4)
18/02/28 14:09:13 INFO Executor: Finished task 0.0 in stage 12.0 (TID 33). 1005 bytes result sent to driver
18/02/28 14:09:13 INFO TaskSetManager: Finished task 3.0 in stage 12.0 (TID 36) in 32 ms on localhost (executor driver) (3/4)
18/02/28 14:09:13 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 33) in 34 ms on localhost (executor driver) (4/4)
18/02/28 14:09:13 INFO DAGScheduler: ResultStage 12 (countByValue at StringIndexer.scala:113) finished in 0.036 s
18/02/28 14:09:13 INFO DAGScheduler: Job 6 finished: countByValue at StringIndexer.scala:113, took 0.202770 s
18/02/28 14:09:13 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
18/02/28 14:09:13 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:61327 in memory (size: 3.7 KB, free: 345.5 MB)
18/02/28 14:09:13 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:61327 in memory (size: 22.0 KB, free: 345.5 MB)
18/02/28 14:09:13 INFO ContextCleaner: Cleaned accumulator 359
18/02/28 14:09:13 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:61327 in memory (size: 3.7 KB, free: 345.5 MB)
18/02/28 14:09:13 INFO CodeGenerator: Code generated in 32.17735 ms
18/02/28 14:09:13 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:61327 in memory (size: 23.1 KB, free: 345.5 MB)
18/02/28 14:09:13 INFO ContextCleaner: Cleaned accumulator 246
18/02/28 14:09:13 INFO ContextCleaner: Cleaned shuffle 5
18/02/28 14:09:13 INFO ContextCleaner: Cleaned accumulator 358
18/02/28 14:09:13 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:61327 in memory (size: 22.9 KB, free: 345.5 MB)
18/02/28 14:09:13 INFO ContextCleaner: Cleaned accumulator 307
18/02/28 14:09:13 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:61327 in memory (size: 1961.0 B, free: 345.5 MB)
18/02/28 14:09:13 INFO ContextCleaner: Cleaned accumulator 308
18/02/28 14:09:13 INFO ContextCleaner: Cleaned accumulator 309
18/02/28 14:09:13 INFO ContextCleaner: Cleaned shuffle 4
18/02/28 14:09:13 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:61327 in memory (size: 1959.0 B, free: 345.5 MB)
18/02/28 14:09:13 INFO ContextCleaner: Cleaned accumulator 360
18/02/28 14:09:13 INFO CodeGenerator: Code generated in 26.767149 ms
18/02/28 14:09:13 INFO Instrumentation: LogisticRegression-logistic_regression_30e0281660e8-578378292-1: training: numPartitions=4 storageLevel=StorageLevel(disk, memory, deserialized, 1 replicas)
18/02/28 14:09:13 INFO Instrumentation: LogisticRegression-logistic_regression_30e0281660e8-578378292-1: {"elasticNetParam":0.0,"fitIntercept":true,"threshold":0.5,"regParam":0.0,"tol":1.0E-6,"maxIter":100}
18/02/28 14:09:13 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:517
18/02/28 14:09:13 INFO DAGScheduler: Got job 7 (treeAggregate at LogisticRegression.scala:517) with 4 output partitions
18/02/28 14:09:13 INFO DAGScheduler: Final stage: ResultStage 13 (treeAggregate at LogisticRegression.scala:517)
18/02/28 14:09:13 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:09:13 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:13 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[60] at treeAggregate at LogisticRegression.scala:517), which has no missing parents
18/02/28 14:09:13 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 73.9 KB, free 345.1 MB)
18/02/28 14:09:13 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 29.1 KB, free 345.0 MB)
18/02/28 14:09:13 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:61327 (size: 29.1 KB, free: 345.5 MB)
18/02/28 14:09:13 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:13 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 13 (MapPartitionsRDD[60] at treeAggregate at LogisticRegression.scala:517) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:13 INFO TaskSchedulerImpl: Adding task set 13.0 with 4 tasks
18/02/28 14:09:13 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:13 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 38, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:13 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 39, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:09:13 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 40, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:13 INFO Executor: Running task 0.0 in stage 13.0 (TID 37)
18/02/28 14:09:13 INFO Executor: Running task 1.0 in stage 13.0 (TID 38)
18/02/28 14:09:13 INFO Executor: Running task 2.0 in stage 13.0 (TID 39)
18/02/28 14:09:13 INFO Executor: Running task 3.0 in stage 13.0 (TID 40)
18/02/28 14:09:13 INFO BlockManager: Found block rdd_22_0 locally
18/02/28 14:09:13 INFO BlockManager: Found block rdd_22_3 locally
18/02/28 14:09:13 INFO BlockManager: Found block rdd_22_2 locally
18/02/28 14:09:13 INFO BlockManager: Found block rdd_22_1 locally
18/02/28 14:09:13 INFO CodeGenerator: Code generated in 24.005806 ms
18/02/28 14:09:13 INFO CodeGenerator: Code generated in 11.986506 ms
18/02/28 14:09:13 INFO MemoryStore: Block rdd_59_1 stored as values in memory (estimated size 90.2 KB, free 345.0 MB)
18/02/28 14:09:13 INFO BlockManagerInfo: Added rdd_59_1 in memory on 127.0.0.1:61327 (size: 90.2 KB, free: 345.4 MB)
18/02/28 14:09:13 INFO MemoryStore: Block rdd_59_2 stored as values in memory (estimated size 79.0 KB, free 344.9 MB)
18/02/28 14:09:13 INFO BlockManagerInfo: Added rdd_59_2 in memory on 127.0.0.1:61327 (size: 79.0 KB, free: 345.3 MB)
18/02/28 14:09:13 INFO MemoryStore: Block rdd_59_3 stored as values in memory (estimated size 78.6 KB, free 344.8 MB)
18/02/28 14:09:13 INFO BlockManagerInfo: Added rdd_59_3 in memory on 127.0.0.1:61327 (size: 78.6 KB, free: 345.3 MB)
18/02/28 14:09:13 INFO MemoryStore: Block rdd_59_0 stored as values in memory (estimated size 89.5 KB, free 344.7 MB)
18/02/28 14:09:13 INFO BlockManagerInfo: Added rdd_59_0 in memory on 127.0.0.1:61327 (size: 89.5 KB, free: 345.2 MB)
18/02/28 14:09:13 INFO Executor: Finished task 2.0 in stage 13.0 (TID 39). 3936 bytes result sent to driver
18/02/28 14:09:13 INFO Executor: Finished task 3.0 in stage 13.0 (TID 40). 3936 bytes result sent to driver
18/02/28 14:09:13 INFO Executor: Finished task 0.0 in stage 13.0 (TID 37). 3893 bytes result sent to driver
18/02/28 14:09:13 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 39) in 366 ms on localhost (executor driver) (1/4)
18/02/28 14:09:13 INFO Executor: Finished task 1.0 in stage 13.0 (TID 38). 3893 bytes result sent to driver
18/02/28 14:09:13 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 40) in 366 ms on localhost (executor driver) (2/4)
18/02/28 14:09:13 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 37) in 368 ms on localhost (executor driver) (3/4)
18/02/28 14:09:13 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 38) in 369 ms on localhost (executor driver) (4/4)
18/02/28 14:09:13 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
18/02/28 14:09:13 INFO DAGScheduler: ResultStage 13 (treeAggregate at LogisticRegression.scala:517) finished in 0.372 s
18/02/28 14:09:13 INFO DAGScheduler: Job 7 finished: treeAggregate at LogisticRegression.scala:517, took 0.381603 s
18/02/28 14:09:13 INFO Instrumentation: LogisticRegression-logistic_regression_30e0281660e8-578378292-1: {"numClasses":2}
18/02/28 14:09:13 INFO Instrumentation: LogisticRegression-logistic_regression_30e0281660e8-578378292-1: {"numFeatures":5}
18/02/28 14:09:13 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 80.0 B, free 344.7 MB)
18/02/28 14:09:13 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 109.0 B, free 344.7 MB)
18/02/28 14:09:13 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:61327 (size: 109.0 B, free: 345.2 MB)
18/02/28 14:09:13 INFO SparkContext: Created broadcast 15 from broadcast at LogisticRegression.scala:600
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 104.0 B, free 344.7 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 154.0 B, free 344.7 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:61327 (size: 154.0 B, free: 345.2 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 16 from broadcast at LogisticRegression.scala:1879
18/02/28 14:09:14 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:09:14 INFO DAGScheduler: Got job 8 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:09:14 INFO DAGScheduler: Final stage: ResultStage 14 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:09:14 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:09:14 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:14 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[61] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 74.1 KB, free 344.6 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.6 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:61327 (size: 29.1 KB, free: 345.1 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 14 (MapPartitionsRDD[61] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:14 INFO TaskSchedulerImpl: Adding task set 14.0 with 4 tasks
18/02/28 14:09:14 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 41, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 42, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 2.0 in stage 14.0 (TID 43, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 3.0 in stage 14.0 (TID 44, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO Executor: Running task 0.0 in stage 14.0 (TID 41)
18/02/28 14:09:14 INFO Executor: Running task 1.0 in stage 14.0 (TID 42)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_0 locally
18/02/28 14:09:14 INFO Executor: Running task 2.0 in stage 14.0 (TID 43)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_1 locally
18/02/28 14:09:14 INFO Executor: Running task 3.0 in stage 14.0 (TID 44)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_3 locally
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_2 locally
18/02/28 14:09:14 INFO Executor: Finished task 0.0 in stage 14.0 (TID 41). 3567 bytes result sent to driver
18/02/28 14:09:14 INFO Executor: Finished task 2.0 in stage 14.0 (TID 43). 3481 bytes result sent to driver
18/02/28 14:09:14 INFO Executor: Finished task 1.0 in stage 14.0 (TID 42). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO Executor: Finished task 3.0 in stage 14.0 (TID 44). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO TaskSetManager: Finished task 2.0 in stage 14.0 (TID 43) in 39 ms on localhost (executor driver) (1/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 41) in 40 ms on localhost (executor driver) (2/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 3.0 in stage 14.0 (TID 44) in 40 ms on localhost (executor driver) (3/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 42) in 43 ms on localhost (executor driver) (4/4)
18/02/28 14:09:14 INFO DAGScheduler: ResultStage 14 (treeAggregate at LogisticRegression.scala:1892) finished in 0.043 s
18/02/28 14:09:14 INFO DAGScheduler: Job 8 finished: treeAggregate at LogisticRegression.scala:1892, took 0.050356 s
18/02/28 14:09:14 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
18/02/28 14:09:14 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
18/02/28 14:09:14 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
18/02/28 14:09:14 INFO TorrentBroadcast: Destroying Broadcast(16) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:09:14 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:61327 in memory (size: 154.0 B, free: 345.1 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 104.0 B, free 344.6 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.6 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:61327 (size: 186.0 B, free: 345.1 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 18 from broadcast at LogisticRegression.scala:1879
18/02/28 14:09:14 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:09:14 INFO DAGScheduler: Got job 9 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:09:14 INFO DAGScheduler: Final stage: ResultStage 15 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:09:14 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:09:14 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:14 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[62] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 74.1 KB, free 344.5 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.5 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:61327 (size: 29.1 KB, free: 345.1 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 15 (MapPartitionsRDD[62] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:14 INFO TaskSchedulerImpl: Adding task set 15.0 with 4 tasks
18/02/28 14:09:14 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 45, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 46, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 47, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 48, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO Executor: Running task 0.0 in stage 15.0 (TID 45)
18/02/28 14:09:14 INFO Executor: Running task 1.0 in stage 15.0 (TID 46)
18/02/28 14:09:14 INFO Executor: Running task 2.0 in stage 15.0 (TID 47)
18/02/28 14:09:14 INFO Executor: Running task 3.0 in stage 15.0 (TID 48)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_0 locally
18/02/28 14:09:14 INFO Executor: Finished task 0.0 in stage 15.0 (TID 45). 3481 bytes result sent to driver
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_3 locally
18/02/28 14:09:14 INFO Executor: Finished task 3.0 in stage 15.0 (TID 48). 3481 bytes result sent to driver
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_1 locally
18/02/28 14:09:14 INFO Executor: Finished task 1.0 in stage 15.0 (TID 46). 3481 bytes result sent to driver
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_2 locally
18/02/28 14:09:14 INFO Executor: Finished task 2.0 in stage 15.0 (TID 47). 3481 bytes result sent to driver
18/02/28 14:09:14 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 45) in 21 ms on localhost (executor driver) (1/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 46) in 22 ms on localhost (executor driver) (2/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 47) in 23 ms on localhost (executor driver) (3/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 48) in 23 ms on localhost (executor driver) (4/4)
18/02/28 14:09:14 INFO DAGScheduler: ResultStage 15 (treeAggregate at LogisticRegression.scala:1892) finished in 0.023 s
18/02/28 14:09:14 INFO DAGScheduler: Job 9 finished: treeAggregate at LogisticRegression.scala:1892, took 0.031266 s
18/02/28 14:09:14 INFO TorrentBroadcast: Destroying Broadcast(18) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:09:14 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
18/02/28 14:09:14 INFO LBFGS: Step Size: 1.000
18/02/28 14:09:14 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:61327 in memory (size: 186.0 B, free: 345.1 MB)
18/02/28 14:09:14 INFO LBFGS: Val and Grad Norm: 0.489441 (rel: 0.126) 0.210835
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 104.0 B, free 344.5 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.5 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:61327 (size: 186.0 B, free: 345.1 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 20 from broadcast at LogisticRegression.scala:1879
18/02/28 14:09:14 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:09:14 INFO DAGScheduler: Got job 10 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:09:14 INFO DAGScheduler: Final stage: ResultStage 16 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:09:14 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:09:14 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:14 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[63] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 74.1 KB, free 344.4 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.4 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:61327 (size: 29.1 KB, free: 345.1 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 16 (MapPartitionsRDD[63] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:14 INFO TaskSchedulerImpl: Adding task set 16.0 with 4 tasks
18/02/28 14:09:14 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 50, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 2.0 in stage 16.0 (TID 51, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 3.0 in stage 16.0 (TID 52, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO Executor: Running task 1.0 in stage 16.0 (TID 50)
18/02/28 14:09:14 INFO Executor: Running task 0.0 in stage 16.0 (TID 49)
18/02/28 14:09:14 INFO Executor: Running task 2.0 in stage 16.0 (TID 51)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_2 locally
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_0 locally
18/02/28 14:09:14 INFO Executor: Finished task 2.0 in stage 16.0 (TID 51). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO Executor: Running task 3.0 in stage 16.0 (TID 52)
18/02/28 14:09:14 INFO Executor: Finished task 0.0 in stage 16.0 (TID 49). 3481 bytes result sent to driver
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_3 locally
18/02/28 14:09:14 INFO TaskSetManager: Finished task 2.0 in stage 16.0 (TID 51) in 18 ms on localhost (executor driver) (1/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 49) in 19 ms on localhost (executor driver) (2/4)
18/02/28 14:09:14 INFO Executor: Finished task 3.0 in stage 16.0 (TID 52). 3481 bytes result sent to driver
18/02/28 14:09:14 INFO TaskSetManager: Finished task 3.0 in stage 16.0 (TID 52) in 21 ms on localhost (executor driver) (3/4)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_1 locally
18/02/28 14:09:14 INFO Executor: Finished task 1.0 in stage 16.0 (TID 50). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 50) in 25 ms on localhost (executor driver) (4/4)
18/02/28 14:09:14 INFO DAGScheduler: ResultStage 16 (treeAggregate at LogisticRegression.scala:1892) finished in 0.026 s
18/02/28 14:09:14 INFO DAGScheduler: Job 10 finished: treeAggregate at LogisticRegression.scala:1892, took 0.033183 s
18/02/28 14:09:14 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
18/02/28 14:09:14 INFO TorrentBroadcast: Destroying Broadcast(20) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:09:14 INFO LBFGS: Step Size: 1.000
18/02/28 14:09:14 INFO LBFGS: Val and Grad Norm: 0.364247 (rel: 0.256) 0.0799961
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 104.0 B, free 344.4 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:61327 in memory (size: 186.0 B, free: 345.1 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.4 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:61327 (size: 186.0 B, free: 345.1 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 22 from broadcast at LogisticRegression.scala:1879
18/02/28 14:09:14 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:09:14 INFO DAGScheduler: Got job 11 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:09:14 INFO DAGScheduler: Final stage: ResultStage 17 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:09:14 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:09:14 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:14 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[64] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 74.1 KB, free 344.3 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.3 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:61327 (size: 29.1 KB, free: 345.1 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 17 (MapPartitionsRDD[64] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:14 INFO TaskSchedulerImpl: Adding task set 17.0 with 4 tasks
18/02/28 14:09:14 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 54, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 55, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 3.0 in stage 17.0 (TID 56, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO Executor: Running task 0.0 in stage 17.0 (TID 53)
18/02/28 14:09:14 INFO Executor: Running task 1.0 in stage 17.0 (TID 54)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_0 locally
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_1 locally
18/02/28 14:09:14 INFO Executor: Finished task 0.0 in stage 17.0 (TID 53). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO Executor: Running task 2.0 in stage 17.0 (TID 55)
18/02/28 14:09:14 INFO Executor: Finished task 1.0 in stage 17.0 (TID 54). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO Executor: Running task 3.0 in stage 17.0 (TID 56)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_2 locally
18/02/28 14:09:14 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 53) in 16 ms on localhost (executor driver) (1/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 54) in 17 ms on localhost (executor driver) (2/4)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_3 locally
18/02/28 14:09:14 INFO Executor: Finished task 2.0 in stage 17.0 (TID 55). 3481 bytes result sent to driver
18/02/28 14:09:14 INFO Executor: Finished task 3.0 in stage 17.0 (TID 56). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 55) in 18 ms on localhost (executor driver) (3/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 3.0 in stage 17.0 (TID 56) in 18 ms on localhost (executor driver) (4/4)
18/02/28 14:09:14 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
18/02/28 14:09:14 INFO DAGScheduler: ResultStage 17 (treeAggregate at LogisticRegression.scala:1892) finished in 0.020 s
18/02/28 14:09:14 INFO DAGScheduler: Job 11 finished: treeAggregate at LogisticRegression.scala:1892, took 0.028286 s
18/02/28 14:09:14 INFO TorrentBroadcast: Destroying Broadcast(22) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:09:14 INFO LBFGS: Step Size: 1.000
18/02/28 14:09:14 INFO LBFGS: Val and Grad Norm: 0.329496 (rel: 0.0954) 0.0460553
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 104.0 B, free 344.3 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.3 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:61327 in memory (size: 186.0 B, free: 345.1 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:61327 (size: 186.0 B, free: 345.1 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 24 from broadcast at LogisticRegression.scala:1879
18/02/28 14:09:14 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:09:14 INFO DAGScheduler: Got job 12 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:09:14 INFO DAGScheduler: Final stage: ResultStage 18 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:09:14 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:09:14 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:14 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[65] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 74.1 KB, free 344.2 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.2 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:61327 (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 18 (MapPartitionsRDD[65] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:14 INFO TaskSchedulerImpl: Adding task set 18.0 with 4 tasks
18/02/28 14:09:14 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 57, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 58, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 59, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 60, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO Executor: Running task 0.0 in stage 18.0 (TID 57)
18/02/28 14:09:14 INFO Executor: Running task 1.0 in stage 18.0 (TID 58)
18/02/28 14:09:14 INFO Executor: Running task 2.0 in stage 18.0 (TID 59)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_0 locally
18/02/28 14:09:14 INFO Executor: Running task 3.0 in stage 18.0 (TID 60)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_1 locally
18/02/28 14:09:14 INFO Executor: Finished task 0.0 in stage 18.0 (TID 57). 3524 bytes result sent to driver
18/02/28 14:09:14 INFO Executor: Finished task 1.0 in stage 18.0 (TID 58). 3481 bytes result sent to driver
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_2 locally
18/02/28 14:09:14 INFO Executor: Finished task 2.0 in stage 18.0 (TID 59). 3481 bytes result sent to driver
18/02/28 14:09:14 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 57) in 11 ms on localhost (executor driver) (1/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 58) in 11 ms on localhost (executor driver) (2/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 59) in 12 ms on localhost (executor driver) (3/4)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_3 locally
18/02/28 14:09:14 INFO Executor: Finished task 3.0 in stage 18.0 (TID 60). 3481 bytes result sent to driver
18/02/28 14:09:14 INFO TaskSetManager: Finished task 3.0 in stage 18.0 (TID 60) in 14 ms on localhost (executor driver) (4/4)
18/02/28 14:09:14 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
18/02/28 14:09:14 INFO DAGScheduler: ResultStage 18 (treeAggregate at LogisticRegression.scala:1892) finished in 0.015 s
18/02/28 14:09:14 INFO DAGScheduler: Job 12 finished: treeAggregate at LogisticRegression.scala:1892, took 0.023645 s
18/02/28 14:09:14 INFO TorrentBroadcast: Destroying Broadcast(24) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:09:14 INFO LBFGS: Step Size: 1.000
18/02/28 14:09:14 INFO LBFGS: Val and Grad Norm: 0.305526 (rel: 0.0727) 0.0376048
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 104.0 B, free 344.2 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.2 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:61327 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:61327 (size: 186.0 B, free: 345.0 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 26 from broadcast at LogisticRegression.scala:1879
18/02/28 14:09:14 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:09:14 INFO DAGScheduler: Got job 13 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:09:14 INFO DAGScheduler: Final stage: ResultStage 19 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:09:14 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:09:14 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:14 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[66] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 74.1 KB, free 344.1 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.1 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:61327 (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 19 (MapPartitionsRDD[66] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:14 INFO TaskSchedulerImpl: Adding task set 19.0 with 4 tasks
18/02/28 14:09:14 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 1.0 in stage 19.0 (TID 62, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 2.0 in stage 19.0 (TID 63, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 3.0 in stage 19.0 (TID 64, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO Executor: Running task 0.0 in stage 19.0 (TID 61)
18/02/28 14:09:14 INFO Executor: Running task 1.0 in stage 19.0 (TID 62)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_0 locally
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_1 locally
18/02/28 14:09:14 INFO Executor: Finished task 0.0 in stage 19.0 (TID 61). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO Executor: Running task 2.0 in stage 19.0 (TID 63)
18/02/28 14:09:14 INFO Executor: Running task 3.0 in stage 19.0 (TID 64)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_2 locally
18/02/28 14:09:14 INFO Executor: Finished task 1.0 in stage 19.0 (TID 62). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 61) in 11 ms on localhost (executor driver) (1/4)
18/02/28 14:09:14 INFO Executor: Finished task 2.0 in stage 19.0 (TID 63). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO TaskSetManager: Finished task 1.0 in stage 19.0 (TID 62) in 14 ms on localhost (executor driver) (2/4)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_3 locally
18/02/28 14:09:14 INFO TaskSetManager: Finished task 2.0 in stage 19.0 (TID 63) in 18 ms on localhost (executor driver) (3/4)
18/02/28 14:09:14 INFO Executor: Finished task 3.0 in stage 19.0 (TID 64). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO TaskSetManager: Finished task 3.0 in stage 19.0 (TID 64) in 20 ms on localhost (executor driver) (4/4)
18/02/28 14:09:14 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
18/02/28 14:09:14 INFO DAGScheduler: ResultStage 19 (treeAggregate at LogisticRegression.scala:1892) finished in 0.021 s
18/02/28 14:09:14 INFO DAGScheduler: Job 13 finished: treeAggregate at LogisticRegression.scala:1892, took 0.027927 s
18/02/28 14:09:14 INFO TorrentBroadcast: Destroying Broadcast(26) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:09:14 INFO LBFGS: Step Size: 1.000
18/02/28 14:09:14 INFO LBFGS: Val and Grad Norm: 0.297060 (rel: 0.0277) 0.00913525
18/02/28 14:09:14 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:61327 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 104.0 B, free 344.1 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.1 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:61327 (size: 186.0 B, free: 345.0 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 28 from broadcast at LogisticRegression.scala:1879
18/02/28 14:09:14 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:09:14 INFO DAGScheduler: Got job 14 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:09:14 INFO DAGScheduler: Final stage: ResultStage 20 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:09:14 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:09:14 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:14 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[67] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 74.1 KB, free 344.0 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.0 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:61327 (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 20 (MapPartitionsRDD[67] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:14 INFO TaskSchedulerImpl: Adding task set 20.0 with 4 tasks
18/02/28 14:09:14 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 65, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 66, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 2.0 in stage 20.0 (TID 67, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 3.0 in stage 20.0 (TID 68, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO Executor: Running task 0.0 in stage 20.0 (TID 65)
18/02/28 14:09:14 INFO Executor: Running task 1.0 in stage 20.0 (TID 66)
18/02/28 14:09:14 INFO Executor: Running task 2.0 in stage 20.0 (TID 67)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_0 locally
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_2 locally
18/02/28 14:09:14 INFO Executor: Finished task 0.0 in stage 20.0 (TID 65). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO Executor: Running task 3.0 in stage 20.0 (TID 68)
18/02/28 14:09:14 INFO Executor: Finished task 2.0 in stage 20.0 (TID 67). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_3 locally
18/02/28 14:09:14 INFO Executor: Finished task 3.0 in stage 20.0 (TID 68). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO TaskSetManager: Finished task 2.0 in stage 20.0 (TID 67) in 14 ms on localhost (executor driver) (1/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 3.0 in stage 20.0 (TID 68) in 15 ms on localhost (executor driver) (2/4)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_1 locally
18/02/28 14:09:14 INFO Executor: Finished task 1.0 in stage 20.0 (TID 66). 3481 bytes result sent to driver
18/02/28 14:09:14 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 65) in 19 ms on localhost (executor driver) (3/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 66) in 18 ms on localhost (executor driver) (4/4)
18/02/28 14:09:14 INFO DAGScheduler: ResultStage 20 (treeAggregate at LogisticRegression.scala:1892) finished in 0.020 s
18/02/28 14:09:14 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
18/02/28 14:09:14 INFO DAGScheduler: Job 14 finished: treeAggregate at LogisticRegression.scala:1892, took 0.032828 s
18/02/28 14:09:14 INFO TorrentBroadcast: Destroying Broadcast(28) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:09:14 INFO LBFGS: Step Size: 1.000
18/02/28 14:09:14 INFO LBFGS: Val and Grad Norm: 0.295604 (rel: 0.00490) 0.00456522
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 104.0 B, free 344.0 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.0 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:61327 (size: 186.0 B, free: 345.0 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 30 from broadcast at LogisticRegression.scala:1879
18/02/28 14:09:14 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:61327 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 14:09:14 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:09:14 INFO DAGScheduler: Got job 15 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:09:14 INFO DAGScheduler: Final stage: ResultStage 21 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:09:14 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:09:14 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:14 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[68] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 74.1 KB, free 343.9 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 29.1 KB, free 343.9 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:61327 (size: 29.1 KB, free: 344.9 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 21 (MapPartitionsRDD[68] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:14 INFO TaskSchedulerImpl: Adding task set 21.0 with 4 tasks
18/02/28 14:09:14 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 69, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 70, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 2.0 in stage 21.0 (TID 71, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 3.0 in stage 21.0 (TID 72, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO Executor: Running task 0.0 in stage 21.0 (TID 69)
18/02/28 14:09:14 INFO Executor: Running task 1.0 in stage 21.0 (TID 70)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_1 locally
18/02/28 14:09:14 INFO Executor: Finished task 1.0 in stage 21.0 (TID 70). 3481 bytes result sent to driver
18/02/28 14:09:14 INFO Executor: Running task 2.0 in stage 21.0 (TID 71)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_0 locally
18/02/28 14:09:14 INFO Executor: Finished task 0.0 in stage 21.0 (TID 69). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO Executor: Running task 3.0 in stage 21.0 (TID 72)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_2 locally
18/02/28 14:09:14 INFO Executor: Finished task 2.0 in stage 21.0 (TID 71). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_3 locally
18/02/28 14:09:14 INFO Executor: Finished task 3.0 in stage 21.0 (TID 72). 3395 bytes result sent to driver
18/02/28 14:09:14 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 70) in 18 ms on localhost (executor driver) (1/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 2.0 in stage 21.0 (TID 71) in 19 ms on localhost (executor driver) (2/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 3.0 in stage 21.0 (TID 72) in 19 ms on localhost (executor driver) (3/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 69) in 21 ms on localhost (executor driver) (4/4)
18/02/28 14:09:14 INFO DAGScheduler: ResultStage 21 (treeAggregate at LogisticRegression.scala:1892) finished in 0.021 s
18/02/28 14:09:14 INFO DAGScheduler: Job 15 finished: treeAggregate at LogisticRegression.scala:1892, took 0.038925 s
18/02/28 14:09:14 INFO TorrentBroadcast: Destroying Broadcast(30) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:09:14 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
18/02/28 14:09:14 INFO LBFGS: Step Size: 1.000
18/02/28 14:09:14 INFO LBFGS: Val and Grad Norm: 0.294965 (rel: 0.00216) 0.00527402
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 104.0 B, free 343.9 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:61327 in memory (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:61327 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.9 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:61327 (size: 186.0 B, free: 345.0 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 32 from broadcast at LogisticRegression.scala:1879
18/02/28 14:09:14 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:09:14 INFO DAGScheduler: Got job 16 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:09:14 INFO DAGScheduler: Final stage: ResultStage 22 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:09:14 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:09:14 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:14 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[69] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 74.1 KB, free 343.9 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 29.1 KB, free 343.9 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:61327 (size: 29.1 KB, free: 344.9 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 22 (MapPartitionsRDD[69] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:14 INFO TaskSchedulerImpl: Adding task set 22.0 with 4 tasks
18/02/28 14:09:14 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 73, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 1.0 in stage 22.0 (TID 74, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 2.0 in stage 22.0 (TID 75, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 3.0 in stage 22.0 (TID 76, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO Executor: Running task 0.0 in stage 22.0 (TID 73)
18/02/28 14:09:14 INFO Executor: Running task 1.0 in stage 22.0 (TID 74)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_1 locally
18/02/28 14:09:14 INFO Executor: Finished task 1.0 in stage 22.0 (TID 74). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO Executor: Running task 2.0 in stage 22.0 (TID 75)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_0 locally
18/02/28 14:09:14 INFO Executor: Finished task 0.0 in stage 22.0 (TID 73). 3481 bytes result sent to driver
18/02/28 14:09:14 INFO Executor: Running task 3.0 in stage 22.0 (TID 76)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_2 locally
18/02/28 14:09:14 INFO Executor: Finished task 2.0 in stage 22.0 (TID 75). 3481 bytes result sent to driver
18/02/28 14:09:14 INFO TaskSetManager: Finished task 1.0 in stage 22.0 (TID 74) in 15 ms on localhost (executor driver) (1/4)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_3 locally
18/02/28 14:09:14 INFO Executor: Finished task 3.0 in stage 22.0 (TID 76). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 73) in 17 ms on localhost (executor driver) (2/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 3.0 in stage 22.0 (TID 76) in 17 ms on localhost (executor driver) (3/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 2.0 in stage 22.0 (TID 75) in 17 ms on localhost (executor driver) (4/4)
18/02/28 14:09:14 INFO DAGScheduler: ResultStage 22 (treeAggregate at LogisticRegression.scala:1892) finished in 0.018 s
18/02/28 14:09:14 INFO DAGScheduler: Job 16 finished: treeAggregate at LogisticRegression.scala:1892, took 0.029969 s
18/02/28 14:09:14 INFO TorrentBroadcast: Destroying Broadcast(32) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:09:14 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
18/02/28 14:09:14 INFO LBFGS: Step Size: 1.000
18/02/28 14:09:14 INFO LBFGS: Val and Grad Norm: 0.294523 (rel: 0.00150) 0.00627406
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 104.0 B, free 343.9 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:61327 in memory (size: 186.0 B, free: 344.9 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.9 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:61327 (size: 186.0 B, free: 344.9 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 34 from broadcast at LogisticRegression.scala:1879
18/02/28 14:09:14 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:09:14 INFO DAGScheduler: Got job 17 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:09:14 INFO DAGScheduler: Final stage: ResultStage 23 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:09:14 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:09:14 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:14 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[70] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 74.1 KB, free 343.8 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 29.1 KB, free 343.8 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:61327 (size: 29.1 KB, free: 344.9 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 23 (MapPartitionsRDD[70] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:14 INFO TaskSchedulerImpl: Adding task set 23.0 with 4 tasks
18/02/28 14:09:14 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 77, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 78, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 2.0 in stage 23.0 (TID 79, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 3.0 in stage 23.0 (TID 80, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO Executor: Running task 0.0 in stage 23.0 (TID 77)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_0 locally
18/02/28 14:09:14 INFO Executor: Finished task 0.0 in stage 23.0 (TID 77). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO Executor: Running task 1.0 in stage 23.0 (TID 78)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_1 locally
18/02/28 14:09:14 INFO Executor: Finished task 1.0 in stage 23.0 (TID 78). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO Executor: Running task 2.0 in stage 23.0 (TID 79)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_2 locally
18/02/28 14:09:14 INFO Executor: Finished task 2.0 in stage 23.0 (TID 79). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO Executor: Running task 3.0 in stage 23.0 (TID 80)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 77) in 19 ms on localhost (executor driver) (1/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 78) in 20 ms on localhost (executor driver) (2/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 2.0 in stage 23.0 (TID 79) in 21 ms on localhost (executor driver) (3/4)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_3 locally
18/02/28 14:09:14 INFO Executor: Finished task 3.0 in stage 23.0 (TID 80). 3524 bytes result sent to driver
18/02/28 14:09:14 INFO TaskSetManager: Finished task 3.0 in stage 23.0 (TID 80) in 30 ms on localhost (executor driver) (4/4)
18/02/28 14:09:14 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:61327 in memory (size: 29.1 KB, free: 344.9 MB)
18/02/28 14:09:14 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
18/02/28 14:09:14 INFO DAGScheduler: ResultStage 23 (treeAggregate at LogisticRegression.scala:1892) finished in 0.031 s
18/02/28 14:09:14 INFO DAGScheduler: Job 17 finished: treeAggregate at LogisticRegression.scala:1892, took 0.039358 s
18/02/28 14:09:14 INFO TorrentBroadcast: Destroying Broadcast(34) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:09:14 INFO LBFGS: Step Size: 1.000
18/02/28 14:09:14 INFO LBFGS: Val and Grad Norm: 0.294136 (rel: 0.00131) 0.00245388
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 104.0 B, free 343.9 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:61327 in memory (size: 186.0 B, free: 344.9 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.9 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:61327 (size: 186.0 B, free: 344.9 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 36 from broadcast at LogisticRegression.scala:1879
18/02/28 14:09:14 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:61327 in memory (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:61327 in memory (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:09:14 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:09:14 INFO DAGScheduler: Got job 18 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:09:14 INFO DAGScheduler: Final stage: ResultStage 24 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:09:14 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:09:14 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:14 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[71] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 74.1 KB, free 344.0 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 29.2 KB, free 344.0 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:61327 (size: 29.2 KB, free: 345.0 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 24 (MapPartitionsRDD[71] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:14 INFO TaskSchedulerImpl: Adding task set 24.0 with 4 tasks
18/02/28 14:09:14 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 81, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 82, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 83, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 3.0 in stage 24.0 (TID 84, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO Executor: Running task 0.0 in stage 24.0 (TID 81)
18/02/28 14:09:14 INFO Executor: Running task 1.0 in stage 24.0 (TID 82)
18/02/28 14:09:14 INFO Executor: Running task 2.0 in stage 24.0 (TID 83)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_1 locally
18/02/28 14:09:14 INFO Executor: Finished task 1.0 in stage 24.0 (TID 82). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO Executor: Running task 3.0 in stage 24.0 (TID 84)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_2 locally
18/02/28 14:09:14 INFO Executor: Finished task 2.0 in stage 24.0 (TID 83). 3395 bytes result sent to driver
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_0 locally
18/02/28 14:09:14 INFO Executor: Finished task 0.0 in stage 24.0 (TID 81). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_3 locally
18/02/28 14:09:14 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 82) in 13 ms on localhost (executor driver) (1/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 83) in 13 ms on localhost (executor driver) (2/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 81) in 14 ms on localhost (executor driver) (3/4)
18/02/28 14:09:14 INFO Executor: Finished task 3.0 in stage 24.0 (TID 84). 3481 bytes result sent to driver
18/02/28 14:09:14 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:61327 in memory (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 3.0 in stage 24.0 (TID 84) in 14 ms on localhost (executor driver) (4/4)
18/02/28 14:09:14 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
18/02/28 14:09:14 INFO DAGScheduler: ResultStage 24 (treeAggregate at LogisticRegression.scala:1892) finished in 0.017 s
18/02/28 14:09:14 INFO DAGScheduler: Job 18 finished: treeAggregate at LogisticRegression.scala:1892, took 0.022490 s
18/02/28 14:09:14 INFO TorrentBroadcast: Destroying Broadcast(36) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:09:14 INFO LBFGS: Step Size: 1.000
18/02/28 14:09:14 INFO LBFGS: Val and Grad Norm: 0.293915 (rel: 0.000754) 0.00169862
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 104.0 B, free 344.1 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.1 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:61327 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:61327 (size: 186.0 B, free: 345.0 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 38 from broadcast at LogisticRegression.scala:1879
18/02/28 14:09:14 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:61327 in memory (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:61327 in memory (size: 29.1 KB, free: 345.1 MB)
18/02/28 14:09:14 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:09:14 INFO DAGScheduler: Got job 19 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:09:14 INFO DAGScheduler: Final stage: ResultStage 25 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:09:14 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:09:14 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:14 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[72] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 74.1 KB, free 344.2 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.2 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:61327 in memory (size: 29.1 KB, free: 345.1 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:61327 (size: 29.1 KB, free: 345.1 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 25 (MapPartitionsRDD[72] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:14 INFO TaskSchedulerImpl: Adding task set 25.0 with 4 tasks
18/02/28 14:09:14 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 85, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 1.0 in stage 25.0 (TID 86, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 2.0 in stage 25.0 (TID 87, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 3.0 in stage 25.0 (TID 88, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO Executor: Running task 0.0 in stage 25.0 (TID 85)
18/02/28 14:09:14 INFO Executor: Running task 1.0 in stage 25.0 (TID 86)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_0 locally
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_1 locally
18/02/28 14:09:14 INFO Executor: Finished task 0.0 in stage 25.0 (TID 85). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO Executor: Running task 2.0 in stage 25.0 (TID 87)
18/02/28 14:09:14 INFO Executor: Finished task 1.0 in stage 25.0 (TID 86). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO Executor: Running task 3.0 in stage 25.0 (TID 88)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 85) in 7 ms on localhost (executor driver) (1/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 1.0 in stage 25.0 (TID 86) in 9 ms on localhost (executor driver) (2/4)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_3 locally
18/02/28 14:09:14 INFO Executor: Finished task 3.0 in stage 25.0 (TID 88). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO TaskSetManager: Finished task 3.0 in stage 25.0 (TID 88) in 10 ms on localhost (executor driver) (3/4)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_2 locally
18/02/28 14:09:14 INFO Executor: Finished task 2.0 in stage 25.0 (TID 87). 3481 bytes result sent to driver
18/02/28 14:09:14 INFO TaskSetManager: Finished task 2.0 in stage 25.0 (TID 87) in 14 ms on localhost (executor driver) (4/4)
18/02/28 14:09:14 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
18/02/28 14:09:14 INFO DAGScheduler: ResultStage 25 (treeAggregate at LogisticRegression.scala:1892) finished in 0.014 s
18/02/28 14:09:14 INFO DAGScheduler: Job 19 finished: treeAggregate at LogisticRegression.scala:1892, took 0.021189 s
18/02/28 14:09:14 INFO TorrentBroadcast: Destroying Broadcast(38) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:09:14 INFO LBFGS: Step Size: 1.000
18/02/28 14:09:14 INFO LBFGS: Val and Grad Norm: 0.293890 (rel: 8.36e-05) 0.000635856
18/02/28 14:09:14 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:61327 in memory (size: 186.0 B, free: 345.1 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 104.0 B, free 344.3 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.3 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:61327 (size: 186.0 B, free: 345.1 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 40 from broadcast at LogisticRegression.scala:1879
18/02/28 14:09:14 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:09:14 INFO DAGScheduler: Got job 20 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:09:14 INFO DAGScheduler: Final stage: ResultStage 26 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:09:14 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:09:14 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:14 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[73] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 74.1 KB, free 344.2 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.2 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:61327 (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 26 (MapPartitionsRDD[73] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:14 INFO TaskSchedulerImpl: Adding task set 26.0 with 4 tasks
18/02/28 14:09:14 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 89, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 1.0 in stage 26.0 (TID 90, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 2.0 in stage 26.0 (TID 91, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 3.0 in stage 26.0 (TID 92, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO Executor: Running task 0.0 in stage 26.0 (TID 89)
18/02/28 14:09:14 INFO Executor: Running task 3.0 in stage 26.0 (TID 92)
18/02/28 14:09:14 INFO Executor: Running task 2.0 in stage 26.0 (TID 91)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_2 locally
18/02/28 14:09:14 INFO Executor: Finished task 2.0 in stage 26.0 (TID 91). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO Executor: Running task 1.0 in stage 26.0 (TID 90)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_0 locally
18/02/28 14:09:14 INFO Executor: Finished task 0.0 in stage 26.0 (TID 89). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_3 locally
18/02/28 14:09:14 INFO Executor: Finished task 3.0 in stage 26.0 (TID 92). 3395 bytes result sent to driver
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_1 locally
18/02/28 14:09:14 INFO Executor: Finished task 1.0 in stage 26.0 (TID 90). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO TaskSetManager: Finished task 2.0 in stage 26.0 (TID 91) in 14 ms on localhost (executor driver) (1/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 89) in 15 ms on localhost (executor driver) (2/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 3.0 in stage 26.0 (TID 92) in 16 ms on localhost (executor driver) (3/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 1.0 in stage 26.0 (TID 90) in 16 ms on localhost (executor driver) (4/4)
18/02/28 14:09:14 INFO DAGScheduler: ResultStage 26 (treeAggregate at LogisticRegression.scala:1892) finished in 0.016 s
18/02/28 14:09:14 INFO DAGScheduler: Job 20 finished: treeAggregate at LogisticRegression.scala:1892, took 0.022956 s
18/02/28 14:09:14 INFO TorrentBroadcast: Destroying Broadcast(40) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:09:14 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 104.0 B, free 344.2 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.2 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:61327 (size: 186.0 B, free: 345.0 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 42 from broadcast at LogisticRegression.scala:1879
18/02/28 14:09:14 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:61327 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 14:09:14 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:09:14 INFO DAGScheduler: Got job 21 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:09:14 INFO DAGScheduler: Final stage: ResultStage 27 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:09:14 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:09:14 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:14 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[74] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 74.1 KB, free 344.1 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.1 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:61327 (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 27 (MapPartitionsRDD[74] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:14 INFO TaskSchedulerImpl: Adding task set 27.0 with 4 tasks
18/02/28 14:09:14 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 93, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 94, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 2.0 in stage 27.0 (TID 95, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 3.0 in stage 27.0 (TID 96, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO Executor: Running task 0.0 in stage 27.0 (TID 93)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_0 locally
18/02/28 14:09:14 INFO Executor: Finished task 0.0 in stage 27.0 (TID 93). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO Executor: Running task 1.0 in stage 27.0 (TID 94)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_1 locally
18/02/28 14:09:14 INFO Executor: Finished task 1.0 in stage 27.0 (TID 94). 3481 bytes result sent to driver
18/02/28 14:09:14 INFO Executor: Running task 2.0 in stage 27.0 (TID 95)
18/02/28 14:09:14 INFO Executor: Running task 3.0 in stage 27.0 (TID 96)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_2 locally
18/02/28 14:09:14 INFO Executor: Finished task 2.0 in stage 27.0 (TID 95). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 93) in 19 ms on localhost (executor driver) (1/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 94) in 20 ms on localhost (executor driver) (2/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 2.0 in stage 27.0 (TID 95) in 20 ms on localhost (executor driver) (3/4)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_3 locally
18/02/28 14:09:14 INFO Executor: Finished task 3.0 in stage 27.0 (TID 96). 3395 bytes result sent to driver
18/02/28 14:09:14 INFO TaskSetManager: Finished task 3.0 in stage 27.0 (TID 96) in 21 ms on localhost (executor driver) (4/4)
18/02/28 14:09:14 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
18/02/28 14:09:14 INFO DAGScheduler: ResultStage 27 (treeAggregate at LogisticRegression.scala:1892) finished in 0.023 s
18/02/28 14:09:14 INFO DAGScheduler: Job 21 finished: treeAggregate at LogisticRegression.scala:1892, took 0.031815 s
18/02/28 14:09:14 INFO TorrentBroadcast: Destroying Broadcast(42) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:09:14 INFO StrongWolfeLineSearch: Line search t: 0.5100147098113773 fval: 0.29388861150060663 rhs: 0.29389019664930677 cdd: -2.0158535528812274E-13
18/02/28 14:09:14 INFO LBFGS: Step Size: 0.5100
18/02/28 14:09:14 INFO LBFGS: Val and Grad Norm: 0.293889 (rel: 5.39e-06) 0.000222175
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 104.0 B, free 344.1 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.1 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:61327 (size: 186.0 B, free: 345.0 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 44 from broadcast at LogisticRegression.scala:1879
18/02/28 14:09:14 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:61327 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 14:09:14 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:09:14 INFO DAGScheduler: Got job 22 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:09:14 INFO DAGScheduler: Final stage: ResultStage 28 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:09:14 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:09:14 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:14 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[75] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 74.1 KB, free 344.0 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.0 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:61327 (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 28 (MapPartitionsRDD[75] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:14 INFO TaskSchedulerImpl: Adding task set 28.0 with 4 tasks
18/02/28 14:09:14 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 97, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 1.0 in stage 28.0 (TID 98, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 2.0 in stage 28.0 (TID 99, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 3.0 in stage 28.0 (TID 100, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO Executor: Running task 0.0 in stage 28.0 (TID 97)
18/02/28 14:09:14 INFO Executor: Running task 1.0 in stage 28.0 (TID 98)
18/02/28 14:09:14 INFO Executor: Running task 2.0 in stage 28.0 (TID 99)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_0 locally
18/02/28 14:09:14 INFO Executor: Running task 3.0 in stage 28.0 (TID 100)
18/02/28 14:09:14 INFO Executor: Finished task 0.0 in stage 28.0 (TID 97). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_2 locally
18/02/28 14:09:14 INFO Executor: Finished task 2.0 in stage 28.0 (TID 99). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_1 locally
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_3 locally
18/02/28 14:09:14 INFO Executor: Finished task 3.0 in stage 28.0 (TID 100). 3395 bytes result sent to driver
18/02/28 14:09:14 INFO Executor: Finished task 1.0 in stage 28.0 (TID 98). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 97) in 13 ms on localhost (executor driver) (1/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 3.0 in stage 28.0 (TID 100) in 12 ms on localhost (executor driver) (2/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 1.0 in stage 28.0 (TID 98) in 12 ms on localhost (executor driver) (3/4)
18/02/28 14:09:14 INFO TaskSetManager: Finished task 2.0 in stage 28.0 (TID 99) in 13 ms on localhost (executor driver) (4/4)
18/02/28 14:09:14 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
18/02/28 14:09:14 INFO DAGScheduler: ResultStage 28 (treeAggregate at LogisticRegression.scala:1892) finished in 0.014 s
18/02/28 14:09:14 INFO DAGScheduler: Job 22 finished: treeAggregate at LogisticRegression.scala:1892, took 0.020952 s
18/02/28 14:09:14 INFO TorrentBroadcast: Destroying Broadcast(44) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:09:14 INFO LBFGS: Step Size: 1.000
18/02/28 14:09:14 INFO LBFGS: Val and Grad Norm: 0.293888 (rel: 7.61e-07) 1.14981e-05
18/02/28 14:09:14 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:61327 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 104.0 B, free 344.0 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.0 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:61327 (size: 186.0 B, free: 345.0 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 46 from broadcast at LogisticRegression.scala:1879
18/02/28 14:09:14 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:09:14 INFO DAGScheduler: Got job 23 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:09:14 INFO DAGScheduler: Final stage: ResultStage 29 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:09:14 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:09:14 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:14 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[76] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 74.1 KB, free 343.9 MB)
18/02/28 14:09:14 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 29.1 KB, free 343.9 MB)
18/02/28 14:09:14 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:61327 (size: 29.1 KB, free: 344.9 MB)
18/02/28 14:09:14 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 29 (MapPartitionsRDD[76] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:14 INFO TaskSchedulerImpl: Adding task set 29.0 with 4 tasks
18/02/28 14:09:14 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 101, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 102, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 2.0 in stage 29.0 (TID 103, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:09:14 INFO TaskSetManager: Starting task 3.0 in stage 29.0 (TID 104, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:14 INFO Executor: Running task 0.0 in stage 29.0 (TID 101)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_0 locally
18/02/28 14:09:14 INFO Executor: Finished task 0.0 in stage 29.0 (TID 101). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO Executor: Running task 1.0 in stage 29.0 (TID 102)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_1 locally
18/02/28 14:09:14 INFO Executor: Finished task 1.0 in stage 29.0 (TID 102). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO Executor: Running task 2.0 in stage 29.0 (TID 103)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_2 locally
18/02/28 14:09:14 INFO Executor: Finished task 2.0 in stage 29.0 (TID 103). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO Executor: Running task 3.0 in stage 29.0 (TID 104)
18/02/28 14:09:14 INFO BlockManager: Found block rdd_59_3 locally
18/02/28 14:09:14 INFO Executor: Finished task 3.0 in stage 29.0 (TID 104). 3438 bytes result sent to driver
18/02/28 14:09:14 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 101) in 27 ms on localhost (executor driver) (1/4)
18/02/28 14:09:15 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 102) in 28 ms on localhost (executor driver) (2/4)
18/02/28 14:09:15 INFO TaskSetManager: Finished task 2.0 in stage 29.0 (TID 103) in 28 ms on localhost (executor driver) (3/4)
18/02/28 14:09:15 INFO TaskSetManager: Finished task 3.0 in stage 29.0 (TID 104) in 29 ms on localhost (executor driver) (4/4)
18/02/28 14:09:15 INFO DAGScheduler: ResultStage 29 (treeAggregate at LogisticRegression.scala:1892) finished in 0.030 s
18/02/28 14:09:15 INFO DAGScheduler: Job 23 finished: treeAggregate at LogisticRegression.scala:1892, took 0.036957 s
18/02/28 14:09:15 INFO TorrentBroadcast: Destroying Broadcast(46) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:09:15 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
18/02/28 14:09:15 INFO LBFGS: Step Size: 1.000
18/02/28 14:09:15 INFO LBFGS: Val and Grad Norm: 0.293888 (rel: 2.46e-09) 1.22620e-06
18/02/28 14:09:15 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 104.0 B, free 343.9 MB)
18/02/28 14:09:15 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.9 MB)
18/02/28 14:09:15 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:61327 (size: 186.0 B, free: 344.9 MB)
18/02/28 14:09:15 INFO SparkContext: Created broadcast 48 from broadcast at LogisticRegression.scala:1879
18/02/28 14:09:15 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:09:15 INFO DAGScheduler: Got job 24 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:09:15 INFO DAGScheduler: Final stage: ResultStage 30 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:09:15 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:09:15 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:15 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[77] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:09:15 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 74.1 KB, free 343.8 MB)
18/02/28 14:09:15 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:61327 in memory (size: 186.0 B, free: 344.9 MB)
18/02/28 14:09:15 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 29.1 KB, free 343.8 MB)
18/02/28 14:09:15 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:61327 (size: 29.1 KB, free: 344.9 MB)
18/02/28 14:09:15 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:15 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 30 (MapPartitionsRDD[77] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:15 INFO TaskSchedulerImpl: Adding task set 30.0 with 4 tasks
18/02/28 14:09:15 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 105, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:15 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 106, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:15 INFO TaskSetManager: Starting task 2.0 in stage 30.0 (TID 107, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:09:15 INFO TaskSetManager: Starting task 3.0 in stage 30.0 (TID 108, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:09:15 INFO Executor: Running task 0.0 in stage 30.0 (TID 105)
18/02/28 14:09:15 INFO BlockManager: Found block rdd_59_0 locally
18/02/28 14:09:15 INFO Executor: Finished task 0.0 in stage 30.0 (TID 105). 3438 bytes result sent to driver
18/02/28 14:09:15 INFO Executor: Running task 1.0 in stage 30.0 (TID 106)
18/02/28 14:09:15 INFO Executor: Running task 2.0 in stage 30.0 (TID 107)
18/02/28 14:09:15 INFO BlockManager: Found block rdd_59_2 locally
18/02/28 14:09:15 INFO Executor: Finished task 2.0 in stage 30.0 (TID 107). 3438 bytes result sent to driver
18/02/28 14:09:15 INFO Executor: Running task 3.0 in stage 30.0 (TID 108)
18/02/28 14:09:15 INFO BlockManager: Found block rdd_59_1 locally
18/02/28 14:09:15 INFO Executor: Finished task 1.0 in stage 30.0 (TID 106). 3438 bytes result sent to driver
18/02/28 14:09:15 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 105) in 19 ms on localhost (executor driver) (1/4)
18/02/28 14:09:15 INFO TaskSetManager: Finished task 2.0 in stage 30.0 (TID 107) in 19 ms on localhost (executor driver) (2/4)
18/02/28 14:09:15 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 106) in 19 ms on localhost (executor driver) (3/4)
18/02/28 14:09:15 INFO BlockManager: Found block rdd_59_3 locally
18/02/28 14:09:15 INFO Executor: Finished task 3.0 in stage 30.0 (TID 108). 3395 bytes result sent to driver
18/02/28 14:09:15 INFO TaskSetManager: Finished task 3.0 in stage 30.0 (TID 108) in 22 ms on localhost (executor driver) (4/4)
18/02/28 14:09:15 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
18/02/28 14:09:15 INFO DAGScheduler: ResultStage 30 (treeAggregate at LogisticRegression.scala:1892) finished in 0.024 s
18/02/28 14:09:15 INFO DAGScheduler: Job 24 finished: treeAggregate at LogisticRegression.scala:1892, took 0.030970 s
18/02/28 14:09:15 INFO TorrentBroadcast: Destroying Broadcast(48) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:09:15 INFO LBFGS: Step Size: 1.000
18/02/28 14:09:15 INFO LBFGS: Val and Grad Norm: 0.293888 (rel: 2.43e-11) 2.01237e-07
18/02/28 14:09:15 INFO LBFGS: Converged because gradient converged
18/02/28 14:09:15 INFO TorrentBroadcast: Destroying Broadcast(15) (from destroy at LogisticRegression.scala:796)
18/02/28 14:09:15 INFO MapPartitionsRDD: Removing RDD 59 from persistence list
18/02/28 14:09:15 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:61327 in memory (size: 186.0 B, free: 345.2 MB)
18/02/28 14:09:15 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:61327 in memory (size: 109.0 B, free: 345.2 MB)
18/02/28 14:09:15 INFO BlockManager: Removing RDD 59
18/02/28 14:09:15 INFO CodeGenerator: Code generated in 27.131754 ms
18/02/28 14:09:15 INFO Instrumentation: LogisticRegression-logistic_regression_30e0281660e8-578378292-1: training finished
18/02/28 14:09:15 INFO SparkContext: Starting job: sortByKey at BinaryClassificationMetrics.scala:155
18/02/28 14:09:15 INFO DAGScheduler: Registering RDD 82 (map at LogisticRegression.scala:1398)
18/02/28 14:09:15 INFO DAGScheduler: Got job 25 (sortByKey at BinaryClassificationMetrics.scala:155) with 4 output partitions
18/02/28 14:09:15 INFO DAGScheduler: Final stage: ResultStage 32 (sortByKey at BinaryClassificationMetrics.scala:155)
18/02/28 14:09:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
18/02/28 14:09:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 31)
18/02/28 14:09:15 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[82] at map at LogisticRegression.scala:1398), which has no missing parents
18/02/28 14:09:15 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 83.2 KB, free 344.1 MB)
18/02/28 14:09:15 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 32.8 KB, free 344.0 MB)
18/02/28 14:09:15 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:61327 (size: 32.8 KB, free: 345.2 MB)
18/02/28 14:09:15 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:15 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[82] at map at LogisticRegression.scala:1398) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:15 INFO TaskSchedulerImpl: Adding task set 31.0 with 4 tasks
18/02/28 14:09:15 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 109, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:09:15 INFO TaskSetManager: Starting task 1.0 in stage 31.0 (TID 110, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:09:15 INFO TaskSetManager: Starting task 2.0 in stage 31.0 (TID 111, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:09:15 INFO TaskSetManager: Starting task 3.0 in stage 31.0 (TID 112, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:09:15 INFO Executor: Running task 0.0 in stage 31.0 (TID 109)
18/02/28 14:09:15 INFO Executor: Running task 1.0 in stage 31.0 (TID 110)
18/02/28 14:09:15 INFO Executor: Running task 2.0 in stage 31.0 (TID 111)
18/02/28 14:09:15 INFO Executor: Running task 3.0 in stage 31.0 (TID 112)
18/02/28 14:09:15 INFO BlockManager: Found block rdd_22_1 locally
18/02/28 14:09:15 INFO BlockManager: Found block rdd_22_0 locally
18/02/28 14:09:15 INFO BlockManager: Found block rdd_22_3 locally
18/02/28 14:09:15 INFO BlockManager: Found block rdd_22_2 locally
18/02/28 14:09:15 INFO CodeGenerator: Code generated in 24.785441 ms
18/02/28 14:09:15 INFO CodeGenerator: Code generated in 11.149746 ms
18/02/28 14:09:15 INFO Executor: Finished task 3.0 in stage 31.0 (TID 112). 2215 bytes result sent to driver
18/02/28 14:09:15 INFO TaskSetManager: Finished task 3.0 in stage 31.0 (TID 112) in 204 ms on localhost (executor driver) (1/4)
18/02/28 14:09:15 INFO Executor: Finished task 0.0 in stage 31.0 (TID 109). 2215 bytes result sent to driver
18/02/28 14:09:15 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 109) in 211 ms on localhost (executor driver) (2/4)
18/02/28 14:09:15 INFO Executor: Finished task 2.0 in stage 31.0 (TID 111). 2215 bytes result sent to driver
18/02/28 14:09:15 INFO TaskSetManager: Finished task 2.0 in stage 31.0 (TID 111) in 216 ms on localhost (executor driver) (3/4)
18/02/28 14:09:15 INFO Executor: Finished task 1.0 in stage 31.0 (TID 110). 2258 bytes result sent to driver
18/02/28 14:09:15 INFO TaskSetManager: Finished task 1.0 in stage 31.0 (TID 110) in 217 ms on localhost (executor driver) (4/4)
18/02/28 14:09:15 INFO DAGScheduler: ShuffleMapStage 31 (map at LogisticRegression.scala:1398) finished in 0.218 s
18/02/28 14:09:15 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:09:15 INFO DAGScheduler: running: Set()
18/02/28 14:09:15 INFO DAGScheduler: waiting: Set(ResultStage 32)
18/02/28 14:09:15 INFO DAGScheduler: failed: Set()
18/02/28 14:09:15 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[85] at sortByKey at BinaryClassificationMetrics.scala:155), which has no missing parents
18/02/28 14:09:15 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
18/02/28 14:09:15 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 3.6 KB, free 344.0 MB)
18/02/28 14:09:15 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 2.0 KB, free 344.0 MB)
18/02/28 14:09:15 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:61327 (size: 2.0 KB, free: 345.2 MB)
18/02/28 14:09:15 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:15 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 32 (MapPartitionsRDD[85] at sortByKey at BinaryClassificationMetrics.scala:155) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:15 INFO TaskSchedulerImpl: Adding task set 32.0 with 4 tasks
18/02/28 14:09:15 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 113, localhost, executor driver, partition 0, ANY, 4621 bytes)
18/02/28 14:09:15 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 114, localhost, executor driver, partition 1, ANY, 4621 bytes)
18/02/28 14:09:15 INFO TaskSetManager: Starting task 2.0 in stage 32.0 (TID 115, localhost, executor driver, partition 2, ANY, 4621 bytes)
18/02/28 14:09:15 INFO TaskSetManager: Starting task 3.0 in stage 32.0 (TID 116, localhost, executor driver, partition 3, ANY, 4621 bytes)
18/02/28 14:09:15 INFO Executor: Running task 0.0 in stage 32.0 (TID 113)
18/02/28 14:09:15 INFO Executor: Running task 1.0 in stage 32.0 (TID 114)
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:09:15 INFO Executor: Running task 2.0 in stage 32.0 (TID 115)
18/02/28 14:09:15 INFO Executor: Running task 3.0 in stage 32.0 (TID 116)
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:09:15 INFO Executor: Finished task 2.0 in stage 32.0 (TID 115). 1757 bytes result sent to driver
18/02/28 14:09:15 INFO Executor: Finished task 3.0 in stage 32.0 (TID 116). 1757 bytes result sent to driver
18/02/28 14:09:15 INFO TaskSetManager: Finished task 2.0 in stage 32.0 (TID 115) in 26 ms on localhost (executor driver) (1/4)
18/02/28 14:09:15 INFO TaskSetManager: Finished task 3.0 in stage 32.0 (TID 116) in 27 ms on localhost (executor driver) (2/4)
18/02/28 14:09:15 INFO Executor: Finished task 0.0 in stage 32.0 (TID 113). 1757 bytes result sent to driver
18/02/28 14:09:15 INFO Executor: Finished task 1.0 in stage 32.0 (TID 114). 1757 bytes result sent to driver
18/02/28 14:09:15 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 113) in 35 ms on localhost (executor driver) (3/4)
18/02/28 14:09:15 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 114) in 35 ms on localhost (executor driver) (4/4)
18/02/28 14:09:15 INFO DAGScheduler: ResultStage 32 (sortByKey at BinaryClassificationMetrics.scala:155) finished in 0.036 s
18/02/28 14:09:15 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
18/02/28 14:09:15 INFO DAGScheduler: Job 25 finished: sortByKey at BinaryClassificationMetrics.scala:155, took 0.271868 s
18/02/28 14:09:15 INFO SparkContext: Starting job: count at BinaryClassificationMetrics.scala:163
18/02/28 14:09:15 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 169 bytes
18/02/28 14:09:15 INFO DAGScheduler: Registering RDD 83 (combineByKey at BinaryClassificationMetrics.scala:151)
18/02/28 14:09:15 INFO DAGScheduler: Got job 26 (count at BinaryClassificationMetrics.scala:163) with 4 output partitions
18/02/28 14:09:15 INFO DAGScheduler: Final stage: ResultStage 35 (count at BinaryClassificationMetrics.scala:163)
18/02/28 14:09:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)
18/02/28 14:09:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 34)
18/02/28 14:09:15 INFO DAGScheduler: Submitting ShuffleMapStage 34 (ShuffledRDD[83] at combineByKey at BinaryClassificationMetrics.scala:151), which has no missing parents
18/02/28 14:09:15 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 3.4 KB, free 344.0 MB)
18/02/28 14:09:15 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 1914.0 B, free 344.0 MB)
18/02/28 14:09:15 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:61327 (size: 1914.0 B, free: 345.2 MB)
18/02/28 14:09:15 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:15 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 34 (ShuffledRDD[83] at combineByKey at BinaryClassificationMetrics.scala:151) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:15 INFO TaskSchedulerImpl: Adding task set 34.0 with 4 tasks
18/02/28 14:09:15 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 117, localhost, executor driver, partition 0, ANY, 4610 bytes)
18/02/28 14:09:15 INFO TaskSetManager: Starting task 1.0 in stage 34.0 (TID 118, localhost, executor driver, partition 1, ANY, 4610 bytes)
18/02/28 14:09:15 INFO TaskSetManager: Starting task 2.0 in stage 34.0 (TID 119, localhost, executor driver, partition 2, ANY, 4610 bytes)
18/02/28 14:09:15 INFO TaskSetManager: Starting task 3.0 in stage 34.0 (TID 120, localhost, executor driver, partition 3, ANY, 4610 bytes)
18/02/28 14:09:15 INFO Executor: Running task 0.0 in stage 34.0 (TID 117)
18/02/28 14:09:15 INFO Executor: Running task 1.0 in stage 34.0 (TID 118)
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:09:15 INFO Executor: Running task 3.0 in stage 34.0 (TID 120)
18/02/28 14:09:15 INFO Executor: Running task 2.0 in stage 34.0 (TID 119)
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:09:15 INFO Executor: Finished task 2.0 in stage 34.0 (TID 119). 1239 bytes result sent to driver
18/02/28 14:09:15 INFO TaskSetManager: Finished task 2.0 in stage 34.0 (TID 119) in 83 ms on localhost (executor driver) (1/4)
18/02/28 14:09:15 INFO Executor: Finished task 0.0 in stage 34.0 (TID 117). 1239 bytes result sent to driver
18/02/28 14:09:15 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 117) in 121 ms on localhost (executor driver) (2/4)
18/02/28 14:09:15 INFO Executor: Finished task 1.0 in stage 34.0 (TID 118). 1196 bytes result sent to driver
18/02/28 14:09:15 INFO TaskSetManager: Finished task 1.0 in stage 34.0 (TID 118) in 132 ms on localhost (executor driver) (3/4)
18/02/28 14:09:15 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:61327 in memory (size: 29.1 KB, free: 345.2 MB)
18/02/28 14:09:15 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:61327 in memory (size: 29.1 KB, free: 345.3 MB)
18/02/28 14:09:15 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:61327 in memory (size: 29.1 KB, free: 345.3 MB)
18/02/28 14:09:15 INFO ContextCleaner: Cleaned accumulator 409
18/02/28 14:09:15 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:61327 in memory (size: 29.2 KB, free: 345.3 MB)
18/02/28 14:09:15 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:61327 in memory (size: 29.1 KB, free: 345.4 MB)
18/02/28 14:09:15 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:61327 in memory (size: 2.0 KB, free: 345.4 MB)
18/02/28 14:09:15 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:61327 in memory (size: 29.1 KB, free: 345.4 MB)
18/02/28 14:09:15 INFO ContextCleaner: Cleaned accumulator 410
18/02/28 14:09:15 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:61327 in memory (size: 29.1 KB, free: 345.4 MB)
18/02/28 14:09:15 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:61327 in memory (size: 29.1 KB, free: 345.4 MB)
18/02/28 14:09:15 INFO BlockManager: Removing RDD 59
18/02/28 14:09:15 INFO ContextCleaner: Cleaned RDD 59
18/02/28 14:09:15 INFO ContextCleaner: Cleaned accumulator 412
18/02/28 14:09:15 INFO Executor: Finished task 3.0 in stage 34.0 (TID 120). 1239 bytes result sent to driver
18/02/28 14:09:15 INFO TaskSetManager: Finished task 3.0 in stage 34.0 (TID 120) in 159 ms on localhost (executor driver) (4/4)
18/02/28 14:09:15 INFO DAGScheduler: ShuffleMapStage 34 (combineByKey at BinaryClassificationMetrics.scala:151) finished in 0.160 s
18/02/28 14:09:15 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:09:15 INFO DAGScheduler: running: Set()
18/02/28 14:09:15 INFO DAGScheduler: waiting: Set(ResultStage 35)
18/02/28 14:09:15 INFO DAGScheduler: failed: Set()
18/02/28 14:09:15 INFO DAGScheduler: Submitting ResultStage 35 (ShuffledRDD[86] at sortByKey at BinaryClassificationMetrics.scala:155), which has no missing parents
18/02/28 14:09:15 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 3.1 KB, free 344.8 MB)
18/02/28 14:09:15 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 1868.0 B, free 344.8 MB)
18/02/28 14:09:15 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
18/02/28 14:09:15 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:61327 (size: 1868.0 B, free: 345.4 MB)
18/02/28 14:09:15 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:15 INFO ContextCleaner: Cleaned accumulator 411
18/02/28 14:09:15 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 35 (ShuffledRDD[86] at sortByKey at BinaryClassificationMetrics.scala:155) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:15 INFO TaskSchedulerImpl: Adding task set 35.0 with 4 tasks
18/02/28 14:09:15 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 121, localhost, executor driver, partition 0, ANY, 4621 bytes)
18/02/28 14:09:15 INFO TaskSetManager: Starting task 1.0 in stage 35.0 (TID 122, localhost, executor driver, partition 1, ANY, 4621 bytes)
18/02/28 14:09:15 INFO TaskSetManager: Starting task 2.0 in stage 35.0 (TID 123, localhost, executor driver, partition 2, ANY, 4621 bytes)
18/02/28 14:09:15 INFO TaskSetManager: Starting task 3.0 in stage 35.0 (TID 124, localhost, executor driver, partition 3, ANY, 4621 bytes)
18/02/28 14:09:15 INFO Executor: Running task 0.0 in stage 35.0 (TID 121)
18/02/28 14:09:15 INFO Executor: Running task 1.0 in stage 35.0 (TID 122)
18/02/28 14:09:15 INFO Executor: Running task 2.0 in stage 35.0 (TID 123)
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:09:15 INFO Executor: Running task 3.0 in stage 35.0 (TID 124)
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:09:15 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:61327 in memory (size: 29.1 KB, free: 345.5 MB)
18/02/28 14:09:15 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:61327 in memory (size: 29.1 KB, free: 345.5 MB)
18/02/28 14:09:15 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:61327 in memory (size: 32.8 KB, free: 345.5 MB)
18/02/28 14:09:15 INFO Executor: Finished task 1.0 in stage 35.0 (TID 122). 1047 bytes result sent to driver
18/02/28 14:09:15 INFO TaskSetManager: Finished task 1.0 in stage 35.0 (TID 122) in 52 ms on localhost (executor driver) (1/4)
18/02/28 14:09:15 INFO Executor: Finished task 2.0 in stage 35.0 (TID 123). 1090 bytes result sent to driver
18/02/28 14:09:15 INFO Executor: Finished task 0.0 in stage 35.0 (TID 121). 1090 bytes result sent to driver
18/02/28 14:09:15 INFO Executor: Finished task 3.0 in stage 35.0 (TID 124). 1090 bytes result sent to driver
18/02/28 14:09:15 INFO TaskSetManager: Finished task 2.0 in stage 35.0 (TID 123) in 53 ms on localhost (executor driver) (2/4)
18/02/28 14:09:15 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 121) in 55 ms on localhost (executor driver) (3/4)
18/02/28 14:09:15 INFO TaskSetManager: Finished task 3.0 in stage 35.0 (TID 124) in 55 ms on localhost (executor driver) (4/4)
18/02/28 14:09:15 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
18/02/28 14:09:15 INFO DAGScheduler: ResultStage 35 (count at BinaryClassificationMetrics.scala:163) finished in 0.056 s
18/02/28 14:09:15 INFO DAGScheduler: Job 26 finished: count at BinaryClassificationMetrics.scala:163, took 0.235965 s
18/02/28 14:09:15 INFO SparkContext: Starting job: collect at BinaryClassificationMetrics.scala:192
18/02/28 14:09:15 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 169 bytes
18/02/28 14:09:15 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 7 is 168 bytes
18/02/28 14:09:15 INFO DAGScheduler: Got job 27 (collect at BinaryClassificationMetrics.scala:192) with 4 output partitions
18/02/28 14:09:15 INFO DAGScheduler: Final stage: ResultStage 38 (collect at BinaryClassificationMetrics.scala:192)
18/02/28 14:09:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 37)
18/02/28 14:09:15 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:15 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[89] at mapPartitions at BinaryClassificationMetrics.scala:188), which has no missing parents
18/02/28 14:09:15 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 4.2 KB, free 345.1 MB)
18/02/28 14:09:15 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 2.3 KB, free 345.1 MB)
18/02/28 14:09:15 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:61327 (size: 2.3 KB, free: 345.5 MB)
18/02/28 14:09:15 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:15 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 38 (MapPartitionsRDD[89] at mapPartitions at BinaryClassificationMetrics.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:15 INFO TaskSchedulerImpl: Adding task set 38.0 with 4 tasks
18/02/28 14:09:15 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 125, localhost, executor driver, partition 0, ANY, 4621 bytes)
18/02/28 14:09:15 INFO TaskSetManager: Starting task 1.0 in stage 38.0 (TID 126, localhost, executor driver, partition 1, ANY, 4621 bytes)
18/02/28 14:09:15 INFO TaskSetManager: Starting task 2.0 in stage 38.0 (TID 127, localhost, executor driver, partition 2, ANY, 4621 bytes)
18/02/28 14:09:15 INFO TaskSetManager: Starting task 3.0 in stage 38.0 (TID 128, localhost, executor driver, partition 3, ANY, 4621 bytes)
18/02/28 14:09:15 INFO Executor: Running task 0.0 in stage 38.0 (TID 125)
18/02/28 14:09:15 INFO Executor: Running task 1.0 in stage 38.0 (TID 126)
18/02/28 14:09:15 INFO Executor: Running task 2.0 in stage 38.0 (TID 127)
18/02/28 14:09:15 INFO Executor: Running task 3.0 in stage 38.0 (TID 128)
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:09:15 INFO Executor: Finished task 2.0 in stage 38.0 (TID 127). 1174 bytes result sent to driver
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 14:09:15 INFO Executor: Finished task 0.0 in stage 38.0 (TID 125). 1217 bytes result sent to driver
18/02/28 14:09:15 INFO TaskSetManager: Finished task 2.0 in stage 38.0 (TID 127) in 20 ms on localhost (executor driver) (1/4)
18/02/28 14:09:15 INFO Executor: Finished task 1.0 in stage 38.0 (TID 126). 1217 bytes result sent to driver
18/02/28 14:09:15 INFO Executor: Finished task 3.0 in stage 38.0 (TID 128). 1174 bytes result sent to driver
18/02/28 14:09:15 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 125) in 21 ms on localhost (executor driver) (2/4)
18/02/28 14:09:15 INFO TaskSetManager: Finished task 1.0 in stage 38.0 (TID 126) in 23 ms on localhost (executor driver) (3/4)
18/02/28 14:09:15 INFO TaskSetManager: Finished task 3.0 in stage 38.0 (TID 128) in 22 ms on localhost (executor driver) (4/4)
18/02/28 14:09:15 INFO DAGScheduler: ResultStage 38 (collect at BinaryClassificationMetrics.scala:192) finished in 0.024 s
18/02/28 14:09:15 INFO DAGScheduler: Job 27 finished: collect at BinaryClassificationMetrics.scala:192, took 0.029750 s
18/02/28 14:09:15 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
18/02/28 14:09:15 INFO BinaryClassificationMetrics: Total counts: {numPos: 823, numNeg: 2495}
18/02/28 14:09:15 INFO SparkContext: Starting job: collect at SlidingRDD.scala:81
18/02/28 14:09:15 INFO DAGScheduler: Got job 28 (collect at SlidingRDD.scala:81) with 6 output partitions
18/02/28 14:09:15 INFO DAGScheduler: Final stage: ResultStage 41 (collect at SlidingRDD.scala:81)
18/02/28 14:09:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 40)
18/02/28 14:09:15 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:15 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[97] at mapPartitions at SlidingRDD.scala:78), which has no missing parents
18/02/28 14:09:15 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 6.3 KB, free 345.1 MB)
18/02/28 14:09:15 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 3.3 KB, free 345.1 MB)
18/02/28 14:09:15 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:61327 (size: 3.3 KB, free: 345.5 MB)
18/02/28 14:09:15 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:15 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 41 (MapPartitionsRDD[97] at mapPartitions at SlidingRDD.scala:78) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
18/02/28 14:09:15 INFO TaskSchedulerImpl: Adding task set 41.0 with 6 tasks
18/02/28 14:09:15 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 129, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:09:15 INFO TaskSetManager: Starting task 5.0 in stage 41.0 (TID 130, localhost, executor driver, partition 5, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:09:15 INFO TaskSetManager: Starting task 1.0 in stage 41.0 (TID 131, localhost, executor driver, partition 1, ANY, 4730 bytes)
18/02/28 14:09:15 INFO TaskSetManager: Starting task 2.0 in stage 41.0 (TID 132, localhost, executor driver, partition 2, ANY, 4730 bytes)
18/02/28 14:09:15 INFO Executor: Running task 5.0 in stage 41.0 (TID 130)
18/02/28 14:09:15 INFO Executor: Running task 0.0 in stage 41.0 (TID 129)
18/02/28 14:09:15 INFO Executor: Running task 1.0 in stage 41.0 (TID 131)
18/02/28 14:09:15 INFO Executor: Running task 2.0 in stage 41.0 (TID 132)
18/02/28 14:09:15 INFO Executor: Finished task 5.0 in stage 41.0 (TID 130). 856 bytes result sent to driver
18/02/28 14:09:15 INFO TaskSetManager: Starting task 3.0 in stage 41.0 (TID 133, localhost, executor driver, partition 3, ANY, 4730 bytes)
18/02/28 14:09:15 INFO TaskSetManager: Finished task 5.0 in stage 41.0 (TID 130) in 14 ms on localhost (executor driver) (1/6)
18/02/28 14:09:15 INFO Executor: Running task 3.0 in stage 41.0 (TID 133)
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:09:15 INFO Executor: Finished task 0.0 in stage 41.0 (TID 129). 856 bytes result sent to driver
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:09:15 INFO MemoryStore: Block rdd_90_1 stored as values in memory (estimated size 2.3 KB, free 345.1 MB)
18/02/28 14:09:15 INFO TaskSetManager: Starting task 4.0 in stage 41.0 (TID 134, localhost, executor driver, partition 4, ANY, 4730 bytes)
18/02/28 14:09:15 INFO BlockManagerInfo: Added rdd_90_1 in memory on 127.0.0.1:61327 (size: 2.3 KB, free: 345.5 MB)
18/02/28 14:09:15 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 129) in 27 ms on localhost (executor driver) (2/6)
18/02/28 14:09:15 INFO Executor: Running task 4.0 in stage 41.0 (TID 134)
18/02/28 14:09:15 INFO MemoryStore: Block rdd_90_0 stored as values in memory (estimated size 2.4 KB, free 345.1 MB)
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:09:15 INFO Executor: Finished task 2.0 in stage 41.0 (TID 132). 2026 bytes result sent to driver
18/02/28 14:09:15 INFO BlockManagerInfo: Added rdd_90_0 in memory on 127.0.0.1:61327 (size: 2.4 KB, free: 345.5 MB)
18/02/28 14:09:15 INFO TaskSetManager: Finished task 2.0 in stage 41.0 (TID 132) in 31 ms on localhost (executor driver) (3/6)
18/02/28 14:09:15 INFO Executor: Finished task 1.0 in stage 41.0 (TID 131). 1983 bytes result sent to driver
18/02/28 14:09:15 INFO MemoryStore: Block rdd_90_2 stored as values in memory (estimated size 2.1 KB, free 345.1 MB)
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:09:15 INFO BlockManagerInfo: Added rdd_90_2 in memory on 127.0.0.1:61327 (size: 2.1 KB, free: 345.5 MB)
18/02/28 14:09:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:09:15 INFO TaskSetManager: Finished task 1.0 in stage 41.0 (TID 131) in 34 ms on localhost (executor driver) (4/6)
18/02/28 14:09:15 INFO Executor: Finished task 3.0 in stage 41.0 (TID 133). 1940 bytes result sent to driver
18/02/28 14:09:15 INFO TaskSetManager: Finished task 3.0 in stage 41.0 (TID 133) in 26 ms on localhost (executor driver) (5/6)
18/02/28 14:09:15 INFO MemoryStore: Block rdd_90_3 stored as values in memory (estimated size 2.1 KB, free 345.1 MB)
18/02/28 14:09:15 INFO BlockManagerInfo: Added rdd_90_3 in memory on 127.0.0.1:61327 (size: 2.1 KB, free: 345.5 MB)
18/02/28 14:09:15 INFO Executor: Finished task 4.0 in stage 41.0 (TID 134). 1983 bytes result sent to driver
18/02/28 14:09:15 INFO TaskSetManager: Finished task 4.0 in stage 41.0 (TID 134) in 19 ms on localhost (executor driver) (6/6)
18/02/28 14:09:15 INFO DAGScheduler: ResultStage 41 (collect at SlidingRDD.scala:81) finished in 0.046 s
18/02/28 14:09:15 INFO DAGScheduler: Job 28 finished: collect at SlidingRDD.scala:81, took 0.054304 s
18/02/28 14:09:15 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
18/02/28 14:09:15 INFO SparkContext: Starting job: aggregate at AreaUnderCurve.scala:45
18/02/28 14:09:15 INFO DAGScheduler: Got job 29 (aggregate at AreaUnderCurve.scala:45) with 5 output partitions
18/02/28 14:09:15 INFO DAGScheduler: Final stage: ResultStage 44 (aggregate at AreaUnderCurve.scala:45)
18/02/28 14:09:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)
18/02/28 14:09:15 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:15 INFO DAGScheduler: Submitting ResultStage 44 (SlidingRDD[96] at RDD at SlidingRDD.scala:50), which has no missing parents
18/02/28 14:09:15 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 6.5 KB, free 345.1 MB)
18/02/28 14:09:15 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 3.4 KB, free 345.1 MB)
18/02/28 14:09:15 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:61327 (size: 3.4 KB, free: 345.5 MB)
18/02/28 14:09:15 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:15 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 44 (SlidingRDD[96] at RDD at SlidingRDD.scala:50) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/02/28 14:09:15 INFO TaskSchedulerImpl: Adding task set 44.0 with 5 tasks
18/02/28 14:09:15 INFO TaskSetManager: Starting task 1.0 in stage 44.0 (TID 135, localhost, executor driver, partition 1, PROCESS_LOCAL, 5269 bytes)
18/02/28 14:09:15 INFO TaskSetManager: Starting task 2.0 in stage 44.0 (TID 136, localhost, executor driver, partition 2, PROCESS_LOCAL, 5269 bytes)
18/02/28 14:09:15 INFO TaskSetManager: Starting task 3.0 in stage 44.0 (TID 137, localhost, executor driver, partition 3, PROCESS_LOCAL, 5269 bytes)
18/02/28 14:09:15 INFO TaskSetManager: Starting task 4.0 in stage 44.0 (TID 138, localhost, executor driver, partition 4, PROCESS_LOCAL, 5269 bytes)
18/02/28 14:09:15 INFO Executor: Running task 1.0 in stage 44.0 (TID 135)
18/02/28 14:09:15 INFO Executor: Running task 2.0 in stage 44.0 (TID 136)
18/02/28 14:09:15 INFO Executor: Running task 3.0 in stage 44.0 (TID 137)
18/02/28 14:09:15 INFO Executor: Running task 4.0 in stage 44.0 (TID 138)
18/02/28 14:09:15 INFO BlockManager: Found block rdd_90_2 locally
18/02/28 14:09:15 INFO BlockManager: Found block rdd_90_3 locally
18/02/28 14:09:15 INFO BlockManager: Found block rdd_90_0 locally
18/02/28 14:09:15 INFO BlockManager: Found block rdd_90_1 locally
18/02/28 14:09:15 INFO Executor: Finished task 2.0 in stage 44.0 (TID 136). 748 bytes result sent to driver
18/02/28 14:09:15 INFO Executor: Finished task 1.0 in stage 44.0 (TID 135). 748 bytes result sent to driver
18/02/28 14:09:16 INFO Executor: Finished task 3.0 in stage 44.0 (TID 137). 748 bytes result sent to driver
18/02/28 14:09:16 INFO Executor: Finished task 4.0 in stage 44.0 (TID 138). 748 bytes result sent to driver
18/02/28 14:09:16 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 139, localhost, executor driver, partition 0, PROCESS_LOCAL, 5475 bytes)
18/02/28 14:09:16 INFO TaskSetManager: Finished task 2.0 in stage 44.0 (TID 136) in 10 ms on localhost (executor driver) (1/5)
18/02/28 14:09:16 INFO TaskSetManager: Finished task 1.0 in stage 44.0 (TID 135) in 15 ms on localhost (executor driver) (2/5)
18/02/28 14:09:16 INFO TaskSetManager: Finished task 3.0 in stage 44.0 (TID 137) in 13 ms on localhost (executor driver) (3/5)
18/02/28 14:09:16 INFO Executor: Running task 0.0 in stage 44.0 (TID 139)
18/02/28 14:09:16 INFO TaskSetManager: Finished task 4.0 in stage 44.0 (TID 138) in 14 ms on localhost (executor driver) (4/5)
18/02/28 14:09:16 INFO Executor: Finished task 0.0 in stage 44.0 (TID 139). 619 bytes result sent to driver
18/02/28 14:09:16 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 139) in 6 ms on localhost (executor driver) (5/5)
18/02/28 14:09:16 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
18/02/28 14:09:16 INFO DAGScheduler: ResultStage 44 (aggregate at AreaUnderCurve.scala:45) finished in 0.018 s
18/02/28 14:09:16 INFO DAGScheduler: Job 29 finished: aggregate at AreaUnderCurve.scala:45, took 0.024648 s
18/02/28 14:09:16 INFO CodeGenerator: Code generated in 9.048502 ms
18/02/28 14:09:16 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:09:16 INFO DAGScheduler: Got job 30 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:09:16 INFO DAGScheduler: Final stage: ResultStage 47 (collect at utils.scala:211)
18/02/28 14:09:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 46)
18/02/28 14:09:16 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:16 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[101] at collect at utils.scala:211), which has no missing parents
18/02/28 14:09:16 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 10.4 KB, free 345.1 MB)
18/02/28 14:09:16 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 4.9 KB, free 345.1 MB)
18/02/28 14:09:16 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:61327 (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:09:16 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:16 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 47 (MapPartitionsRDD[101] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:16 INFO TaskSchedulerImpl: Adding task set 47.0 with 4 tasks
18/02/28 14:09:16 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 140, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:16 INFO TaskSetManager: Starting task 1.0 in stage 47.0 (TID 141, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:16 INFO TaskSetManager: Starting task 2.0 in stage 47.0 (TID 142, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:16 INFO TaskSetManager: Starting task 3.0 in stage 47.0 (TID 143, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:16 INFO Executor: Running task 0.0 in stage 47.0 (TID 140)
18/02/28 14:09:16 INFO Executor: Running task 1.0 in stage 47.0 (TID 141)
18/02/28 14:09:16 INFO Executor: Running task 2.0 in stage 47.0 (TID 142)
18/02/28 14:09:16 INFO Executor: Running task 3.0 in stage 47.0 (TID 143)
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_1 locally
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_3 locally
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_0 locally
18/02/28 14:09:16 INFO Executor: Finished task 1.0 in stage 47.0 (TID 141). 1677 bytes result sent to driver
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_2 locally
18/02/28 14:09:16 INFO Executor: Finished task 2.0 in stage 47.0 (TID 142). 1621 bytes result sent to driver
18/02/28 14:09:16 INFO Executor: Finished task 3.0 in stage 47.0 (TID 143). 1597 bytes result sent to driver
18/02/28 14:09:16 INFO Executor: Finished task 0.0 in stage 47.0 (TID 140). 1660 bytes result sent to driver
18/02/28 14:09:16 INFO TaskSetManager: Finished task 1.0 in stage 47.0 (TID 141) in 10 ms on localhost (executor driver) (1/4)
18/02/28 14:09:16 INFO TaskSetManager: Finished task 3.0 in stage 47.0 (TID 143) in 10 ms on localhost (executor driver) (2/4)
18/02/28 14:09:16 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 140) in 11 ms on localhost (executor driver) (3/4)
18/02/28 14:09:16 INFO TaskSetManager: Finished task 2.0 in stage 47.0 (TID 142) in 11 ms on localhost (executor driver) (4/4)
18/02/28 14:09:16 INFO DAGScheduler: ResultStage 47 (collect at utils.scala:211) finished in 0.012 s
18/02/28 14:09:16 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
18/02/28 14:09:16 INFO DAGScheduler: Job 30 finished: collect at utils.scala:211, took 0.018098 s
18/02/28 14:09:16 INFO CodeGenerator: Code generated in 5.247645 ms
18/02/28 14:09:16 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:09:16 INFO DAGScheduler: Got job 31 (collect at utils.scala:211) with 5 output partitions
18/02/28 14:09:16 INFO DAGScheduler: Final stage: ResultStage 50 (collect at utils.scala:211)
18/02/28 14:09:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 49)
18/02/28 14:09:16 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:16 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[107] at collect at utils.scala:211), which has no missing parents
18/02/28 14:09:16 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 11.1 KB, free 345.1 MB)
18/02/28 14:09:16 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 5.3 KB, free 345.1 MB)
18/02/28 14:09:16 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:61327 (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:09:16 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:16 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 50 (MapPartitionsRDD[107] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/02/28 14:09:16 INFO TaskSchedulerImpl: Adding task set 50.0 with 5 tasks
18/02/28 14:09:16 INFO TaskSetManager: Starting task 1.0 in stage 50.0 (TID 144, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:09:16 INFO TaskSetManager: Starting task 2.0 in stage 50.0 (TID 145, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:09:16 INFO TaskSetManager: Starting task 3.0 in stage 50.0 (TID 146, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:09:16 INFO TaskSetManager: Starting task 4.0 in stage 50.0 (TID 147, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:09:16 INFO Executor: Running task 1.0 in stage 50.0 (TID 144)
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_0 locally
18/02/28 14:09:16 INFO Executor: Finished task 1.0 in stage 50.0 (TID 144). 1429 bytes result sent to driver
18/02/28 14:09:16 INFO Executor: Running task 2.0 in stage 50.0 (TID 145)
18/02/28 14:09:16 INFO Executor: Running task 3.0 in stage 50.0 (TID 146)
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_1 locally
18/02/28 14:09:16 INFO Executor: Finished task 2.0 in stage 50.0 (TID 145). 1558 bytes result sent to driver
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_2 locally
18/02/28 14:09:16 INFO Executor: Running task 4.0 in stage 50.0 (TID 147)
18/02/28 14:09:16 INFO Executor: Finished task 3.0 in stage 50.0 (TID 146). 1586 bytes result sent to driver
18/02/28 14:09:16 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 148, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:09:16 INFO TaskSetManager: Finished task 1.0 in stage 50.0 (TID 144) in 9 ms on localhost (executor driver) (1/5)
18/02/28 14:09:16 INFO TaskSetManager: Finished task 2.0 in stage 50.0 (TID 145) in 10 ms on localhost (executor driver) (2/5)
18/02/28 14:09:16 INFO TaskSetManager: Finished task 3.0 in stage 50.0 (TID 146) in 10 ms on localhost (executor driver) (3/5)
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_3 locally
18/02/28 14:09:16 INFO Executor: Running task 0.0 in stage 50.0 (TID 148)
18/02/28 14:09:16 INFO Executor: Finished task 4.0 in stage 50.0 (TID 147). 1631 bytes result sent to driver
18/02/28 14:09:16 INFO TaskSetManager: Finished task 4.0 in stage 50.0 (TID 147) in 12 ms on localhost (executor driver) (4/5)
18/02/28 14:09:16 INFO Executor: Finished task 0.0 in stage 50.0 (TID 148). 1043 bytes result sent to driver
18/02/28 14:09:16 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 148) in 5 ms on localhost (executor driver) (5/5)
18/02/28 14:09:16 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
18/02/28 14:09:16 INFO DAGScheduler: ResultStage 50 (collect at utils.scala:211) finished in 0.013 s
18/02/28 14:09:16 INFO DAGScheduler: Job 31 finished: collect at utils.scala:211, took 0.022006 s
18/02/28 14:09:16 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:09:16 INFO DAGScheduler: Got job 32 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:09:16 INFO DAGScheduler: Final stage: ResultStage 53 (collect at utils.scala:211)
18/02/28 14:09:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)
18/02/28 14:09:16 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:16 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[111] at collect at utils.scala:211), which has no missing parents
18/02/28 14:09:16 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 10.3 KB, free 345.1 MB)
18/02/28 14:09:16 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 4.9 KB, free 345.1 MB)
18/02/28 14:09:16 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:61327 (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:09:16 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:16 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 53 (MapPartitionsRDD[111] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:16 INFO TaskSchedulerImpl: Adding task set 53.0 with 4 tasks
18/02/28 14:09:16 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 149, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:16 INFO TaskSetManager: Starting task 1.0 in stage 53.0 (TID 150, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:16 INFO TaskSetManager: Starting task 2.0 in stage 53.0 (TID 151, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:16 INFO TaskSetManager: Starting task 3.0 in stage 53.0 (TID 152, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:16 INFO Executor: Running task 1.0 in stage 53.0 (TID 150)
18/02/28 14:09:16 INFO Executor: Running task 2.0 in stage 53.0 (TID 151)
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_1 locally
18/02/28 14:09:16 INFO Executor: Running task 0.0 in stage 53.0 (TID 149)
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_0 locally
18/02/28 14:09:16 INFO Executor: Finished task 0.0 in stage 53.0 (TID 149). 1395 bytes result sent to driver
18/02/28 14:09:16 INFO Executor: Finished task 1.0 in stage 53.0 (TID 150). 1553 bytes result sent to driver
18/02/28 14:09:16 INFO Executor: Running task 3.0 in stage 53.0 (TID 152)
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_2 locally
18/02/28 14:09:16 INFO Executor: Finished task 2.0 in stage 53.0 (TID 151). 1588 bytes result sent to driver
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_3 locally
18/02/28 14:09:16 INFO Executor: Finished task 3.0 in stage 53.0 (TID 152). 1606 bytes result sent to driver
18/02/28 14:09:16 INFO TaskSetManager: Finished task 2.0 in stage 53.0 (TID 151) in 9 ms on localhost (executor driver) (1/4)
18/02/28 14:09:16 INFO TaskSetManager: Finished task 1.0 in stage 53.0 (TID 150) in 9 ms on localhost (executor driver) (2/4)
18/02/28 14:09:16 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 149) in 10 ms on localhost (executor driver) (3/4)
18/02/28 14:09:16 INFO TaskSetManager: Finished task 3.0 in stage 53.0 (TID 152) in 9 ms on localhost (executor driver) (4/4)
18/02/28 14:09:16 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
18/02/28 14:09:16 INFO DAGScheduler: ResultStage 53 (collect at utils.scala:211) finished in 0.010 s
18/02/28 14:09:16 INFO DAGScheduler: Job 32 finished: collect at utils.scala:211, took 0.015491 s
18/02/28 14:09:16 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e034656e6
18/02/28 14:09:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:09:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e034656e6` AS `zzz111`
WHERE (0 = 1)
18/02/28 14:09:16 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:09:16 INFO DAGScheduler: Got job 33 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:09:16 INFO DAGScheduler: Final stage: ResultStage 56 (collect at utils.scala:211)
18/02/28 14:09:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 55)
18/02/28 14:09:16 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:16 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[115] at collect at utils.scala:211), which has no missing parents
18/02/28 14:09:16 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 10.3 KB, free 345.0 MB)
18/02/28 14:09:16 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 4.9 KB, free 345.0 MB)
18/02/28 14:09:16 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:61327 (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:09:16 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:16 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 56 (MapPartitionsRDD[115] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:16 INFO TaskSchedulerImpl: Adding task set 56.0 with 4 tasks
18/02/28 14:09:16 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 153, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:16 INFO TaskSetManager: Starting task 1.0 in stage 56.0 (TID 154, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:16 INFO TaskSetManager: Starting task 2.0 in stage 56.0 (TID 155, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:16 INFO TaskSetManager: Starting task 3.0 in stage 56.0 (TID 156, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:16 INFO Executor: Running task 0.0 in stage 56.0 (TID 153)
18/02/28 14:09:16 INFO Executor: Running task 1.0 in stage 56.0 (TID 154)
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_0 locally
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_1 locally
18/02/28 14:09:16 INFO Executor: Finished task 0.0 in stage 56.0 (TID 153). 1615 bytes result sent to driver
18/02/28 14:09:16 INFO Executor: Running task 2.0 in stage 56.0 (TID 155)
18/02/28 14:09:16 INFO Executor: Finished task 1.0 in stage 56.0 (TID 154). 1601 bytes result sent to driver
18/02/28 14:09:16 INFO Executor: Running task 3.0 in stage 56.0 (TID 156)
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_2 locally
18/02/28 14:09:16 INFO Executor: Finished task 2.0 in stage 56.0 (TID 155). 1546 bytes result sent to driver
18/02/28 14:09:16 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 153) in 7 ms on localhost (executor driver) (1/4)
18/02/28 14:09:16 INFO TaskSetManager: Finished task 1.0 in stage 56.0 (TID 154) in 7 ms on localhost (executor driver) (2/4)
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_3 locally
18/02/28 14:09:16 INFO Executor: Finished task 3.0 in stage 56.0 (TID 156). 1581 bytes result sent to driver
18/02/28 14:09:16 INFO TaskSetManager: Finished task 2.0 in stage 56.0 (TID 155) in 9 ms on localhost (executor driver) (3/4)
18/02/28 14:09:16 INFO TaskSetManager: Finished task 3.0 in stage 56.0 (TID 156) in 9 ms on localhost (executor driver) (4/4)
18/02/28 14:09:16 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
18/02/28 14:09:16 INFO DAGScheduler: ResultStage 56 (collect at utils.scala:211) finished in 0.010 s
18/02/28 14:09:16 INFO DAGScheduler: Job 33 finished: collect at utils.scala:211, took 0.016048 s
18/02/28 14:09:16 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:09:16 INFO DAGScheduler: Got job 34 (collect at utils.scala:211) with 6 output partitions
18/02/28 14:09:16 INFO DAGScheduler: Final stage: ResultStage 59 (collect at utils.scala:211)
18/02/28 14:09:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 58)
18/02/28 14:09:16 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:16 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[122] at collect at utils.scala:211), which has no missing parents
18/02/28 14:09:16 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 11.2 KB, free 345.0 MB)
18/02/28 14:09:16 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 5.3 KB, free 345.0 MB)
18/02/28 14:09:16 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:61327 (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:09:16 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:16 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 59 (MapPartitionsRDD[122] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
18/02/28 14:09:16 INFO TaskSchedulerImpl: Adding task set 59.0 with 6 tasks
18/02/28 14:09:16 INFO TaskSetManager: Starting task 1.0 in stage 59.0 (TID 157, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:09:16 INFO TaskSetManager: Starting task 2.0 in stage 59.0 (TID 158, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:09:16 INFO TaskSetManager: Starting task 3.0 in stage 59.0 (TID 159, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:09:16 INFO TaskSetManager: Starting task 4.0 in stage 59.0 (TID 160, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:09:16 INFO Executor: Running task 2.0 in stage 59.0 (TID 158)
18/02/28 14:09:16 INFO Executor: Running task 3.0 in stage 59.0 (TID 159)
18/02/28 14:09:16 INFO Executor: Running task 4.0 in stage 59.0 (TID 160)
18/02/28 14:09:16 INFO Executor: Running task 1.0 in stage 59.0 (TID 157)
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_3 locally
18/02/28 14:09:16 INFO Executor: Finished task 4.0 in stage 59.0 (TID 160). 1574 bytes result sent to driver
18/02/28 14:09:16 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 161, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_0 locally
18/02/28 14:09:16 INFO Executor: Finished task 1.0 in stage 59.0 (TID 157). 1418 bytes result sent to driver
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_1 locally
18/02/28 14:09:16 INFO Executor: Finished task 2.0 in stage 59.0 (TID 158). 1444 bytes result sent to driver
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_2 locally
18/02/28 14:09:16 INFO TaskSetManager: Starting task 5.0 in stage 59.0 (TID 162, localhost, executor driver, partition 5, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:09:16 INFO Executor: Finished task 3.0 in stage 59.0 (TID 159). 1571 bytes result sent to driver
18/02/28 14:09:16 INFO Executor: Running task 0.0 in stage 59.0 (TID 161)
18/02/28 14:09:16 INFO TaskSetManager: Finished task 4.0 in stage 59.0 (TID 160) in 7 ms on localhost (executor driver) (1/6)
18/02/28 14:09:16 INFO TaskSetManager: Finished task 1.0 in stage 59.0 (TID 157) in 9 ms on localhost (executor driver) (2/6)
18/02/28 14:09:16 INFO TaskSetManager: Finished task 2.0 in stage 59.0 (TID 158) in 9 ms on localhost (executor driver) (3/6)
18/02/28 14:09:16 INFO Executor: Finished task 0.0 in stage 59.0 (TID 161). 1042 bytes result sent to driver
18/02/28 14:09:16 INFO Executor: Running task 5.0 in stage 59.0 (TID 162)
18/02/28 14:09:16 INFO TaskSetManager: Finished task 3.0 in stage 59.0 (TID 159) in 10 ms on localhost (executor driver) (4/6)
18/02/28 14:09:16 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 161) in 10 ms on localhost (executor driver) (5/6)
18/02/28 14:09:16 INFO Executor: Finished task 5.0 in stage 59.0 (TID 162). 1093 bytes result sent to driver
18/02/28 14:09:16 INFO TaskSetManager: Finished task 5.0 in stage 59.0 (TID 162) in 8 ms on localhost (executor driver) (6/6)
18/02/28 14:09:16 INFO DAGScheduler: ResultStage 59 (collect at utils.scala:211) finished in 0.015 s
18/02/28 14:09:16 INFO DAGScheduler: Job 34 finished: collect at utils.scala:211, took 0.021813 s
18/02/28 14:09:16 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
18/02/28 14:09:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:09:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 14:09:16 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e04ed85ef4
18/02/28 14:09:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:09:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e04ed85ef4` AS `zzz112`
WHERE (0 = 1)
18/02/28 14:09:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:09:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e04ed85ef4`
18/02/28 14:09:16 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:09:16 INFO DAGScheduler: Got job 35 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:09:16 INFO DAGScheduler: Final stage: ResultStage 62 (collect at utils.scala:211)
18/02/28 14:09:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 61)
18/02/28 14:09:16 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:16 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[125] at collect at utils.scala:211), which has no missing parents
18/02/28 14:09:16 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 10.4 KB, free 345.0 MB)
18/02/28 14:09:16 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 4.9 KB, free 345.0 MB)
18/02/28 14:09:16 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:61327 (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:09:16 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:16 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 62 (MapPartitionsRDD[125] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:16 INFO TaskSchedulerImpl: Adding task set 62.0 with 4 tasks
18/02/28 14:09:16 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 163, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:16 INFO TaskSetManager: Starting task 1.0 in stage 62.0 (TID 164, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:16 INFO TaskSetManager: Starting task 2.0 in stage 62.0 (TID 165, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:16 INFO TaskSetManager: Starting task 3.0 in stage 62.0 (TID 166, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:16 INFO Executor: Running task 1.0 in stage 62.0 (TID 164)
18/02/28 14:09:16 INFO Executor: Running task 0.0 in stage 62.0 (TID 163)
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_1 locally
18/02/28 14:09:16 INFO Executor: Running task 2.0 in stage 62.0 (TID 165)
18/02/28 14:09:16 INFO Executor: Finished task 1.0 in stage 62.0 (TID 164). 1677 bytes result sent to driver
18/02/28 14:09:16 INFO Executor: Running task 3.0 in stage 62.0 (TID 166)
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_2 locally
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_0 locally
18/02/28 14:09:16 INFO Executor: Finished task 0.0 in stage 62.0 (TID 163). 1660 bytes result sent to driver
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_3 locally
18/02/28 14:09:16 INFO TaskSetManager: Finished task 1.0 in stage 62.0 (TID 164) in 7 ms on localhost (executor driver) (1/4)
18/02/28 14:09:16 INFO Executor: Finished task 2.0 in stage 62.0 (TID 165). 1535 bytes result sent to driver
18/02/28 14:09:16 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 163) in 7 ms on localhost (executor driver) (2/4)
18/02/28 14:09:16 INFO Executor: Finished task 3.0 in stage 62.0 (TID 166). 1597 bytes result sent to driver
18/02/28 14:09:16 INFO TaskSetManager: Finished task 2.0 in stage 62.0 (TID 165) in 8 ms on localhost (executor driver) (3/4)
18/02/28 14:09:16 INFO TaskSetManager: Finished task 3.0 in stage 62.0 (TID 166) in 8 ms on localhost (executor driver) (4/4)
18/02/28 14:09:16 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
18/02/28 14:09:16 INFO DAGScheduler: ResultStage 62 (collect at utils.scala:211) finished in 0.008 s
18/02/28 14:09:16 INFO DAGScheduler: Job 35 finished: collect at utils.scala:211, took 0.014021 s
18/02/28 14:09:16 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:09:16 INFO DAGScheduler: Got job 36 (collect at utils.scala:211) with 5 output partitions
18/02/28 14:09:16 INFO DAGScheduler: Final stage: ResultStage 65 (collect at utils.scala:211)
18/02/28 14:09:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 64)
18/02/28 14:09:16 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:16 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[128] at collect at utils.scala:211), which has no missing parents
18/02/28 14:09:16 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 11.1 KB, free 345.0 MB)
18/02/28 14:09:16 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 5.3 KB, free 345.0 MB)
18/02/28 14:09:16 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:61327 (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:09:16 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:16 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 65 (MapPartitionsRDD[128] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/02/28 14:09:16 INFO TaskSchedulerImpl: Adding task set 65.0 with 5 tasks
18/02/28 14:09:16 INFO TaskSetManager: Starting task 1.0 in stage 65.0 (TID 167, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:09:16 INFO TaskSetManager: Starting task 2.0 in stage 65.0 (TID 168, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:09:16 INFO TaskSetManager: Starting task 3.0 in stage 65.0 (TID 169, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:09:16 INFO TaskSetManager: Starting task 4.0 in stage 65.0 (TID 170, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:09:16 INFO Executor: Running task 1.0 in stage 65.0 (TID 167)
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_0 locally
18/02/28 14:09:16 INFO Executor: Running task 2.0 in stage 65.0 (TID 168)
18/02/28 14:09:16 INFO Executor: Finished task 1.0 in stage 65.0 (TID 167). 1429 bytes result sent to driver
18/02/28 14:09:16 INFO Executor: Running task 3.0 in stage 65.0 (TID 169)
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_1 locally
18/02/28 14:09:16 INFO Executor: Finished task 2.0 in stage 65.0 (TID 168). 1515 bytes result sent to driver
18/02/28 14:09:16 INFO Executor: Running task 4.0 in stage 65.0 (TID 170)
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_2 locally
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_3 locally
18/02/28 14:09:16 INFO Executor: Finished task 4.0 in stage 65.0 (TID 170). 1588 bytes result sent to driver
18/02/28 14:09:16 INFO Executor: Finished task 3.0 in stage 65.0 (TID 169). 1586 bytes result sent to driver
18/02/28 14:09:16 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 171, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:09:16 INFO TaskSetManager: Finished task 1.0 in stage 65.0 (TID 167) in 10 ms on localhost (executor driver) (1/5)
18/02/28 14:09:16 INFO TaskSetManager: Finished task 2.0 in stage 65.0 (TID 168) in 9 ms on localhost (executor driver) (2/5)
18/02/28 14:09:16 INFO TaskSetManager: Finished task 4.0 in stage 65.0 (TID 170) in 10 ms on localhost (executor driver) (3/5)
18/02/28 14:09:16 INFO Executor: Running task 0.0 in stage 65.0 (TID 171)
18/02/28 14:09:16 INFO TaskSetManager: Finished task 3.0 in stage 65.0 (TID 169) in 10 ms on localhost (executor driver) (4/5)
18/02/28 14:09:16 INFO Executor: Finished task 0.0 in stage 65.0 (TID 171). 1043 bytes result sent to driver
18/02/28 14:09:16 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 171) in 5 ms on localhost (executor driver) (5/5)
18/02/28 14:09:16 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
18/02/28 14:09:16 INFO DAGScheduler: ResultStage 65 (collect at utils.scala:211) finished in 0.015 s
18/02/28 14:09:16 INFO DAGScheduler: Job 36 finished: collect at utils.scala:211, took 0.020487 s
18/02/28 14:09:16 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:09:16 INFO DAGScheduler: Got job 37 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:09:16 INFO DAGScheduler: Final stage: ResultStage 68 (collect at utils.scala:211)
18/02/28 14:09:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 67)
18/02/28 14:09:16 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:16 INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[131] at collect at utils.scala:211), which has no missing parents
18/02/28 14:09:16 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 10.3 KB, free 345.0 MB)
18/02/28 14:09:16 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 4.9 KB, free 345.0 MB)
18/02/28 14:09:16 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:61327 (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:09:16 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:16 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 68 (MapPartitionsRDD[131] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:16 INFO TaskSchedulerImpl: Adding task set 68.0 with 4 tasks
18/02/28 14:09:16 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 172, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:16 INFO TaskSetManager: Starting task 1.0 in stage 68.0 (TID 173, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:16 INFO TaskSetManager: Starting task 2.0 in stage 68.0 (TID 174, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:16 INFO TaskSetManager: Starting task 3.0 in stage 68.0 (TID 175, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:16 INFO Executor: Running task 0.0 in stage 68.0 (TID 172)
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_0 locally
18/02/28 14:09:16 INFO Executor: Finished task 0.0 in stage 68.0 (TID 172). 1395 bytes result sent to driver
18/02/28 14:09:16 INFO Executor: Running task 1.0 in stage 68.0 (TID 173)
18/02/28 14:09:16 INFO Executor: Running task 2.0 in stage 68.0 (TID 174)
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_1 locally
18/02/28 14:09:16 INFO Executor: Running task 3.0 in stage 68.0 (TID 175)
18/02/28 14:09:16 INFO Executor: Finished task 1.0 in stage 68.0 (TID 173). 1510 bytes result sent to driver
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_3 locally
18/02/28 14:09:16 INFO BlockManager: Found block rdd_90_2 locally
18/02/28 14:09:16 INFO Executor: Finished task 3.0 in stage 68.0 (TID 175). 1606 bytes result sent to driver
18/02/28 14:09:16 INFO Executor: Finished task 2.0 in stage 68.0 (TID 174). 1588 bytes result sent to driver
18/02/28 14:09:16 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 172) in 8 ms on localhost (executor driver) (1/4)
18/02/28 14:09:16 INFO TaskSetManager: Finished task 3.0 in stage 68.0 (TID 175) in 8 ms on localhost (executor driver) (2/4)
18/02/28 14:09:16 INFO TaskSetManager: Finished task 1.0 in stage 68.0 (TID 173) in 9 ms on localhost (executor driver) (3/4)
18/02/28 14:09:16 INFO TaskSetManager: Finished task 2.0 in stage 68.0 (TID 174) in 9 ms on localhost (executor driver) (4/4)
18/02/28 14:09:16 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
18/02/28 14:09:16 INFO DAGScheduler: ResultStage 68 (collect at utils.scala:211) finished in 0.010 s
18/02/28 14:09:16 INFO DAGScheduler: Job 37 finished: collect at utils.scala:211, took 0.015367 s
18/02/28 14:09:16 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e0377f5eb1
18/02/28 14:09:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:09:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0377f5eb1` AS `zzz113`
WHERE (0 = 1)
18/02/28 14:09:17 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:09:17 INFO DAGScheduler: Got job 38 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:09:17 INFO DAGScheduler: Final stage: ResultStage 71 (collect at utils.scala:211)
18/02/28 14:09:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 70)
18/02/28 14:09:17 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:17 INFO DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[134] at collect at utils.scala:211), which has no missing parents
18/02/28 14:09:17 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 10.3 KB, free 345.0 MB)
18/02/28 14:09:17 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 4.9 KB, free 345.0 MB)
18/02/28 14:09:17 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:61327 (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:09:17 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:17 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 71 (MapPartitionsRDD[134] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:17 INFO TaskSchedulerImpl: Adding task set 71.0 with 4 tasks
18/02/28 14:09:17 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 176, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:17 INFO TaskSetManager: Starting task 1.0 in stage 71.0 (TID 177, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:17 INFO TaskSetManager: Starting task 2.0 in stage 71.0 (TID 178, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:17 INFO TaskSetManager: Starting task 3.0 in stage 71.0 (TID 179, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:17 INFO Executor: Running task 0.0 in stage 71.0 (TID 176)
18/02/28 14:09:17 INFO Executor: Running task 1.0 in stage 71.0 (TID 177)
18/02/28 14:09:17 INFO Executor: Running task 2.0 in stage 71.0 (TID 178)
18/02/28 14:09:17 INFO BlockManager: Found block rdd_90_0 locally
18/02/28 14:09:17 INFO Executor: Finished task 0.0 in stage 71.0 (TID 176). 1572 bytes result sent to driver
18/02/28 14:09:17 INFO Executor: Running task 3.0 in stage 71.0 (TID 179)
18/02/28 14:09:17 INFO BlockManager: Found block rdd_90_2 locally
18/02/28 14:09:17 INFO Executor: Finished task 2.0 in stage 71.0 (TID 178). 1589 bytes result sent to driver
18/02/28 14:09:17 INFO BlockManager: Found block rdd_90_1 locally
18/02/28 14:09:17 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 176) in 9 ms on localhost (executor driver) (1/4)
18/02/28 14:09:17 INFO TaskSetManager: Finished task 2.0 in stage 71.0 (TID 178) in 9 ms on localhost (executor driver) (2/4)
18/02/28 14:09:17 INFO BlockManager: Found block rdd_90_3 locally
18/02/28 14:09:17 INFO Executor: Finished task 3.0 in stage 71.0 (TID 179). 1581 bytes result sent to driver
18/02/28 14:09:17 INFO Executor: Finished task 1.0 in stage 71.0 (TID 177). 1601 bytes result sent to driver
18/02/28 14:09:17 INFO TaskSetManager: Finished task 3.0 in stage 71.0 (TID 179) in 12 ms on localhost (executor driver) (3/4)
18/02/28 14:09:17 INFO TaskSetManager: Finished task 1.0 in stage 71.0 (TID 177) in 12 ms on localhost (executor driver) (4/4)
18/02/28 14:09:17 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
18/02/28 14:09:17 INFO DAGScheduler: ResultStage 71 (collect at utils.scala:211) finished in 0.013 s
18/02/28 14:09:17 INFO DAGScheduler: Job 38 finished: collect at utils.scala:211, took 0.018717 s
18/02/28 14:09:17 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:09:17 INFO DAGScheduler: Got job 39 (collect at utils.scala:211) with 6 output partitions
18/02/28 14:09:17 INFO DAGScheduler: Final stage: ResultStage 74 (collect at utils.scala:211)
18/02/28 14:09:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 73)
18/02/28 14:09:17 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:17 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[137] at collect at utils.scala:211), which has no missing parents
18/02/28 14:09:17 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 11.2 KB, free 345.0 MB)
18/02/28 14:09:17 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 5.3 KB, free 345.0 MB)
18/02/28 14:09:17 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:61327 (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:09:17 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:17 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 74 (MapPartitionsRDD[137] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
18/02/28 14:09:17 INFO TaskSchedulerImpl: Adding task set 74.0 with 6 tasks
18/02/28 14:09:17 INFO TaskSetManager: Starting task 1.0 in stage 74.0 (TID 180, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:09:17 INFO TaskSetManager: Starting task 2.0 in stage 74.0 (TID 181, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:09:17 INFO TaskSetManager: Starting task 3.0 in stage 74.0 (TID 182, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:09:17 INFO TaskSetManager: Starting task 4.0 in stage 74.0 (TID 183, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:09:17 INFO Executor: Running task 1.0 in stage 74.0 (TID 180)
18/02/28 14:09:17 INFO Executor: Running task 3.0 in stage 74.0 (TID 182)
18/02/28 14:09:17 INFO Executor: Running task 4.0 in stage 74.0 (TID 183)
18/02/28 14:09:17 INFO BlockManager: Found block rdd_90_0 locally
18/02/28 14:09:17 INFO BlockManager: Found block rdd_90_3 locally
18/02/28 14:09:17 INFO Executor: Finished task 4.0 in stage 74.0 (TID 183). 1531 bytes result sent to driver
18/02/28 14:09:17 INFO BlockManager: Found block rdd_90_2 locally
18/02/28 14:09:17 INFO Executor: Running task 2.0 in stage 74.0 (TID 181)
18/02/28 14:09:17 INFO Executor: Finished task 3.0 in stage 74.0 (TID 182). 1571 bytes result sent to driver
18/02/28 14:09:17 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 184, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:09:17 INFO TaskSetManager: Starting task 5.0 in stage 74.0 (TID 185, localhost, executor driver, partition 5, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:09:17 INFO Executor: Finished task 1.0 in stage 74.0 (TID 180). 1418 bytes result sent to driver
18/02/28 14:09:17 INFO TaskSetManager: Finished task 4.0 in stage 74.0 (TID 183) in 5 ms on localhost (executor driver) (1/6)
18/02/28 14:09:17 INFO TaskSetManager: Finished task 3.0 in stage 74.0 (TID 182) in 5 ms on localhost (executor driver) (2/6)
18/02/28 14:09:17 INFO Executor: Running task 0.0 in stage 74.0 (TID 184)
18/02/28 14:09:17 INFO BlockManager: Found block rdd_90_1 locally
18/02/28 14:09:17 INFO Executor: Finished task 2.0 in stage 74.0 (TID 181). 1487 bytes result sent to driver
18/02/28 14:09:17 INFO Executor: Running task 5.0 in stage 74.0 (TID 185)
18/02/28 14:09:17 INFO Executor: Finished task 0.0 in stage 74.0 (TID 184). 1042 bytes result sent to driver
18/02/28 14:09:17 INFO TaskSetManager: Finished task 1.0 in stage 74.0 (TID 180) in 9 ms on localhost (executor driver) (3/6)
18/02/28 14:09:17 INFO Executor: Finished task 5.0 in stage 74.0 (TID 185). 1050 bytes result sent to driver
18/02/28 14:09:17 INFO TaskSetManager: Finished task 2.0 in stage 74.0 (TID 181) in 9 ms on localhost (executor driver) (4/6)
18/02/28 14:09:17 INFO TaskSetManager: Finished task 5.0 in stage 74.0 (TID 185) in 6 ms on localhost (executor driver) (5/6)
18/02/28 14:09:17 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 184) in 7 ms on localhost (executor driver) (6/6)
18/02/28 14:09:17 INFO DAGScheduler: ResultStage 74 (collect at utils.scala:211) finished in 0.011 s
18/02/28 14:09:17 INFO DAGScheduler: Job 39 finished: collect at utils.scala:211, took 0.016939 s
18/02/28 14:09:17 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
18/02/28 14:09:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:09:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 14:09:17 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:09:17 INFO DAGScheduler: Got job 40 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:09:17 INFO DAGScheduler: Final stage: ResultStage 77 (collect at utils.scala:211)
18/02/28 14:09:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 76)
18/02/28 14:09:17 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:17 INFO DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[140] at collect at utils.scala:211), which has no missing parents
18/02/28 14:09:17 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 10.4 KB, free 344.9 MB)
18/02/28 14:09:17 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.9 MB)
18/02/28 14:09:17 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:61327 (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:09:17 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:17 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 77 (MapPartitionsRDD[140] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:17 INFO TaskSchedulerImpl: Adding task set 77.0 with 4 tasks
18/02/28 14:09:17 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 186, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:17 INFO TaskSetManager: Starting task 1.0 in stage 77.0 (TID 187, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:17 INFO TaskSetManager: Starting task 2.0 in stage 77.0 (TID 188, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:17 INFO TaskSetManager: Starting task 3.0 in stage 77.0 (TID 189, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:17 INFO Executor: Running task 0.0 in stage 77.0 (TID 186)
18/02/28 14:09:17 INFO Executor: Running task 1.0 in stage 77.0 (TID 187)
18/02/28 14:09:17 INFO Executor: Running task 2.0 in stage 77.0 (TID 188)
18/02/28 14:09:17 INFO BlockManager: Found block rdd_90_0 locally
18/02/28 14:09:17 INFO Executor: Finished task 0.0 in stage 77.0 (TID 186). 1617 bytes result sent to driver
18/02/28 14:09:17 INFO Executor: Running task 3.0 in stage 77.0 (TID 189)
18/02/28 14:09:17 INFO BlockManager: Found block rdd_90_2 locally
18/02/28 14:09:17 INFO BlockManager: Found block rdd_90_3 locally
18/02/28 14:09:17 INFO Executor: Finished task 3.0 in stage 77.0 (TID 189). 1554 bytes result sent to driver
18/02/28 14:09:17 INFO Executor: Finished task 2.0 in stage 77.0 (TID 188). 1578 bytes result sent to driver
18/02/28 14:09:17 INFO BlockManager: Found block rdd_90_1 locally
18/02/28 14:09:17 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 186) in 7 ms on localhost (executor driver) (1/4)
18/02/28 14:09:17 INFO Executor: Finished task 1.0 in stage 77.0 (TID 187). 1634 bytes result sent to driver
18/02/28 14:09:17 INFO TaskSetManager: Finished task 3.0 in stage 77.0 (TID 189) in 7 ms on localhost (executor driver) (2/4)
18/02/28 14:09:17 INFO TaskSetManager: Finished task 1.0 in stage 77.0 (TID 187) in 7 ms on localhost (executor driver) (3/4)
18/02/28 14:09:17 INFO TaskSetManager: Finished task 2.0 in stage 77.0 (TID 188) in 7 ms on localhost (executor driver) (4/4)
18/02/28 14:09:17 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
18/02/28 14:09:17 INFO DAGScheduler: ResultStage 77 (collect at utils.scala:211) finished in 0.008 s
18/02/28 14:09:17 INFO DAGScheduler: Job 40 finished: collect at utils.scala:211, took 0.012947 s
18/02/28 14:09:17 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:09:17 INFO DAGScheduler: Got job 41 (collect at utils.scala:211) with 5 output partitions
18/02/28 14:09:17 INFO DAGScheduler: Final stage: ResultStage 80 (collect at utils.scala:211)
18/02/28 14:09:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 79)
18/02/28 14:09:17 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:17 INFO DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[143] at collect at utils.scala:211), which has no missing parents
18/02/28 14:09:17 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 11.1 KB, free 344.9 MB)
18/02/28 14:09:17 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 5.3 KB, free 344.9 MB)
18/02/28 14:09:17 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:61327 (size: 5.3 KB, free: 345.4 MB)
18/02/28 14:09:17 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:17 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 80 (MapPartitionsRDD[143] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/02/28 14:09:17 INFO TaskSchedulerImpl: Adding task set 80.0 with 5 tasks
18/02/28 14:09:17 INFO TaskSetManager: Starting task 1.0 in stage 80.0 (TID 190, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:09:17 INFO TaskSetManager: Starting task 2.0 in stage 80.0 (TID 191, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:09:17 INFO TaskSetManager: Starting task 3.0 in stage 80.0 (TID 192, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:09:17 INFO TaskSetManager: Starting task 4.0 in stage 80.0 (TID 193, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:09:17 INFO Executor: Running task 1.0 in stage 80.0 (TID 190)
18/02/28 14:09:17 INFO Executor: Running task 4.0 in stage 80.0 (TID 193)
18/02/28 14:09:17 INFO Executor: Running task 3.0 in stage 80.0 (TID 192)
18/02/28 14:09:17 INFO BlockManager: Found block rdd_90_2 locally
18/02/28 14:09:17 INFO Executor: Running task 2.0 in stage 80.0 (TID 191)
18/02/28 14:09:17 INFO BlockManager: Found block rdd_90_1 locally
18/02/28 14:09:17 INFO BlockManager: Found block rdd_90_3 locally
18/02/28 14:09:17 INFO Executor: Finished task 2.0 in stage 80.0 (TID 191). 1558 bytes result sent to driver
18/02/28 14:09:17 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 194, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:09:17 INFO Executor: Finished task 3.0 in stage 80.0 (TID 192). 1586 bytes result sent to driver
18/02/28 14:09:17 INFO Executor: Finished task 4.0 in stage 80.0 (TID 193). 1545 bytes result sent to driver
18/02/28 14:09:17 INFO Executor: Running task 0.0 in stage 80.0 (TID 194)
18/02/28 14:09:17 INFO TaskSetManager: Finished task 2.0 in stage 80.0 (TID 191) in 7 ms on localhost (executor driver) (1/5)
18/02/28 14:09:17 INFO TaskSetManager: Finished task 3.0 in stage 80.0 (TID 192) in 7 ms on localhost (executor driver) (2/5)
18/02/28 14:09:17 INFO BlockManager: Found block rdd_90_0 locally
18/02/28 14:09:17 INFO Executor: Finished task 1.0 in stage 80.0 (TID 190). 1429 bytes result sent to driver
18/02/28 14:09:17 INFO TaskSetManager: Finished task 4.0 in stage 80.0 (TID 193) in 8 ms on localhost (executor driver) (3/5)
18/02/28 14:09:17 INFO Executor: Finished task 0.0 in stage 80.0 (TID 194). 1043 bytes result sent to driver
18/02/28 14:09:17 INFO TaskSetManager: Finished task 1.0 in stage 80.0 (TID 190) in 10 ms on localhost (executor driver) (4/5)
18/02/28 14:09:17 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 194) in 3 ms on localhost (executor driver) (5/5)
18/02/28 14:09:17 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
18/02/28 14:09:17 INFO DAGScheduler: ResultStage 80 (collect at utils.scala:211) finished in 0.011 s
18/02/28 14:09:17 INFO DAGScheduler: Job 41 finished: collect at utils.scala:211, took 0.014767 s
18/02/28 14:09:17 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:09:17 INFO DAGScheduler: Got job 42 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:09:17 INFO DAGScheduler: Final stage: ResultStage 83 (collect at utils.scala:211)
18/02/28 14:09:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 82)
18/02/28 14:09:17 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:17 INFO DAGScheduler: Submitting ResultStage 83 (MapPartitionsRDD[146] at collect at utils.scala:211), which has no missing parents
18/02/28 14:09:17 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 10.3 KB, free 344.9 MB)
18/02/28 14:09:17 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.9 MB)
18/02/28 14:09:17 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:61327 (size: 4.9 KB, free: 345.4 MB)
18/02/28 14:09:17 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:17 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 83 (MapPartitionsRDD[146] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:17 INFO TaskSchedulerImpl: Adding task set 83.0 with 4 tasks
18/02/28 14:09:17 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 195, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:17 INFO TaskSetManager: Starting task 1.0 in stage 83.0 (TID 196, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:17 INFO TaskSetManager: Starting task 2.0 in stage 83.0 (TID 197, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:17 INFO TaskSetManager: Starting task 3.0 in stage 83.0 (TID 198, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:17 INFO Executor: Running task 0.0 in stage 83.0 (TID 195)
18/02/28 14:09:17 INFO Executor: Running task 1.0 in stage 83.0 (TID 196)
18/02/28 14:09:17 INFO BlockManager: Found block rdd_90_0 locally
18/02/28 14:09:17 INFO Executor: Finished task 0.0 in stage 83.0 (TID 195). 1352 bytes result sent to driver
18/02/28 14:09:17 INFO BlockManager: Found block rdd_90_1 locally
18/02/28 14:09:17 INFO Executor: Running task 2.0 in stage 83.0 (TID 197)
18/02/28 14:09:17 INFO Executor: Running task 3.0 in stage 83.0 (TID 198)
18/02/28 14:09:17 INFO Executor: Finished task 1.0 in stage 83.0 (TID 196). 1553 bytes result sent to driver
18/02/28 14:09:17 INFO BlockManager: Found block rdd_90_3 locally
18/02/28 14:09:17 INFO BlockManager: Found block rdd_90_2 locally
18/02/28 14:09:17 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 195) in 6 ms on localhost (executor driver) (1/4)
18/02/28 14:09:17 INFO Executor: Finished task 3.0 in stage 83.0 (TID 198). 1563 bytes result sent to driver
18/02/28 14:09:17 INFO Executor: Finished task 2.0 in stage 83.0 (TID 197). 1588 bytes result sent to driver
18/02/28 14:09:17 INFO TaskSetManager: Finished task 2.0 in stage 83.0 (TID 197) in 7 ms on localhost (executor driver) (2/4)
18/02/28 14:09:17 INFO TaskSetManager: Finished task 3.0 in stage 83.0 (TID 198) in 7 ms on localhost (executor driver) (3/4)
18/02/28 14:09:17 INFO TaskSetManager: Finished task 1.0 in stage 83.0 (TID 196) in 8 ms on localhost (executor driver) (4/4)
18/02/28 14:09:17 INFO DAGScheduler: ResultStage 83 (collect at utils.scala:211) finished in 0.009 s
18/02/28 14:09:17 INFO DAGScheduler: Job 42 finished: collect at utils.scala:211, took 0.013259 s
18/02/28 14:09:17 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool 
18/02/28 14:09:17 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e0b01eaf
18/02/28 14:09:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:09:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0b01eaf` AS `zzz114`
WHERE (0 = 1)
18/02/28 14:09:17 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:09:17 INFO DAGScheduler: Got job 43 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:09:17 INFO DAGScheduler: Final stage: ResultStage 86 (collect at utils.scala:211)
18/02/28 14:09:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 85)
18/02/28 14:09:17 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:17 INFO DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[149] at collect at utils.scala:211), which has no missing parents
18/02/28 14:09:17 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 10.3 KB, free 344.9 MB)
18/02/28 14:09:17 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.9 MB)
18/02/28 14:09:17 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:61327 (size: 4.9 KB, free: 345.4 MB)
18/02/28 14:09:17 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:17 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 86 (MapPartitionsRDD[149] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:09:17 INFO TaskSchedulerImpl: Adding task set 86.0 with 4 tasks
18/02/28 14:09:17 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 199, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:17 INFO TaskSetManager: Starting task 1.0 in stage 86.0 (TID 200, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:17 INFO TaskSetManager: Starting task 2.0 in stage 86.0 (TID 201, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:17 INFO TaskSetManager: Starting task 3.0 in stage 86.0 (TID 202, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:09:17 INFO Executor: Running task 0.0 in stage 86.0 (TID 199)
18/02/28 14:09:17 INFO Executor: Running task 1.0 in stage 86.0 (TID 200)
18/02/28 14:09:17 INFO BlockManager: Found block rdd_90_0 locally
18/02/28 14:09:17 INFO BlockManager: Found block rdd_90_1 locally
18/02/28 14:09:17 INFO Executor: Finished task 0.0 in stage 86.0 (TID 199). 1615 bytes result sent to driver
18/02/28 14:09:17 INFO Executor: Finished task 1.0 in stage 86.0 (TID 200). 1644 bytes result sent to driver
18/02/28 14:09:17 INFO Executor: Running task 2.0 in stage 86.0 (TID 201)
18/02/28 14:09:17 INFO Executor: Running task 3.0 in stage 86.0 (TID 202)
18/02/28 14:09:17 INFO BlockManager: Found block rdd_90_2 locally
18/02/28 14:09:17 INFO Executor: Finished task 2.0 in stage 86.0 (TID 201). 1546 bytes result sent to driver
18/02/28 14:09:17 INFO BlockManager: Found block rdd_90_3 locally
18/02/28 14:09:17 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 199) in 6 ms on localhost (executor driver) (1/4)
18/02/28 14:09:17 INFO Executor: Finished task 3.0 in stage 86.0 (TID 202). 1538 bytes result sent to driver
18/02/28 14:09:17 INFO TaskSetManager: Finished task 1.0 in stage 86.0 (TID 200) in 6 ms on localhost (executor driver) (2/4)
18/02/28 14:09:17 INFO TaskSetManager: Finished task 2.0 in stage 86.0 (TID 201) in 7 ms on localhost (executor driver) (3/4)
18/02/28 14:09:17 INFO TaskSetManager: Finished task 3.0 in stage 86.0 (TID 202) in 6 ms on localhost (executor driver) (4/4)
18/02/28 14:09:17 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
18/02/28 14:09:17 INFO DAGScheduler: ResultStage 86 (collect at utils.scala:211) finished in 0.007 s
18/02/28 14:09:17 INFO DAGScheduler: Job 43 finished: collect at utils.scala:211, took 0.012400 s
18/02/28 14:09:17 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:09:17 INFO DAGScheduler: Got job 44 (collect at utils.scala:211) with 6 output partitions
18/02/28 14:09:17 INFO DAGScheduler: Final stage: ResultStage 89 (collect at utils.scala:211)
18/02/28 14:09:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 88)
18/02/28 14:09:17 INFO DAGScheduler: Missing parents: List()
18/02/28 14:09:17 INFO DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[152] at collect at utils.scala:211), which has no missing parents
18/02/28 14:09:17 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:61327 in memory (size: 1914.0 B, free: 345.4 MB)
18/02/28 14:09:17 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 11.2 KB, free 344.9 MB)
18/02/28 14:09:17 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 5.3 KB, free 344.9 MB)
18/02/28 14:09:17 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 127.0.0.1:61327 (size: 5.3 KB, free: 345.4 MB)
18/02/28 14:09:17 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1006
18/02/28 14:09:17 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 89 (MapPartitionsRDD[152] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
18/02/28 14:09:17 INFO TaskSchedulerImpl: Adding task set 89.0 with 6 tasks
18/02/28 14:09:17 INFO TaskSetManager: Starting task 1.0 in stage 89.0 (TID 203, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:09:17 INFO TaskSetManager: Starting task 2.0 in stage 89.0 (TID 204, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:09:17 INFO TaskSetManager: Starting task 3.0 in stage 89.0 (TID 205, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:09:17 INFO TaskSetManager: Starting task 4.0 in stage 89.0 (TID 206, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:09:17 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 127.0.0.1:61327 in memory (size: 5.3 KB, free: 345.4 MB)
18/02/28 14:09:17 INFO Executor: Running task 1.0 in stage 89.0 (TID 203)
18/02/28 14:09:17 INFO Executor: Running task 2.0 in stage 89.0 (TID 204)
18/02/28 14:09:17 INFO Executor: Running task 3.0 in stage 89.0 (TID 205)
18/02/28 14:09:17 INFO Executor: Running task 4.0 in stage 89.0 (TID 206)
18/02/28 14:09:17 INFO BlockManager: Found block rdd_90_0 locally
18/02/28 14:09:17 INFO Executor: Finished task 1.0 in stage 89.0 (TID 203). 1461 bytes result sent to driver
18/02/28 14:09:17 INFO BlockManager: Found block rdd_90_1 locally
18/02/28 14:09:17 INFO BlockManager: Found block rdd_90_3 locally
18/02/28 14:09:17 INFO Executor: Finished task 2.0 in stage 89.0 (TID 204). 1487 bytes result sent to driver
18/02/28 14:09:17 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 207, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:09:17 INFO BlockManager: Found block rdd_90_2 locally
18/02/28 14:09:17 INFO Executor: Running task 0.0 in stage 89.0 (TID 207)
18/02/28 14:09:17 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 127.0.0.1:61327 in memory (size: 5.3 KB, free: 345.4 MB)
18/02/28 14:09:17 INFO TaskSetManager: Starting task 5.0 in stage 89.0 (TID 208, localhost, executor driver, partition 5, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:09:17 INFO Executor: Finished task 4.0 in stage 89.0 (TID 206). 1531 bytes result sent to driver
18/02/28 14:09:17 INFO Executor: Finished task 3.0 in stage 89.0 (TID 205). 1571 bytes result sent to driver
18/02/28 14:09:17 INFO TaskSetManager: Finished task 2.0 in stage 89.0 (TID 204) in 14 ms on localhost (executor driver) (1/6)
18/02/28 14:09:17 INFO Executor: Running task 5.0 in stage 89.0 (TID 208)
18/02/28 14:09:17 INFO TaskSetManager: Finished task 1.0 in stage 89.0 (TID 203) in 15 ms on localhost (executor driver) (2/6)
18/02/28 14:09:17 INFO TaskSetManager: Finished task 4.0 in stage 89.0 (TID 206) in 16 ms on localhost (executor driver) (3/6)
18/02/28 14:09:17 INFO TaskSetManager: Finished task 3.0 in stage 89.0 (TID 205) in 16 ms on localhost (executor driver) (4/6)
18/02/28 14:09:17 INFO Executor: Finished task 0.0 in stage 89.0 (TID 207). 1042 bytes result sent to driver
18/02/28 14:09:17 INFO Executor: Finished task 5.0 in stage 89.0 (TID 208). 1050 bytes result sent to driver
18/02/28 14:09:17 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 207) in 9 ms on localhost (executor driver) (5/6)
18/02/28 14:09:17 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 127.0.0.1:61327 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:09:17 INFO TaskSetManager: Finished task 5.0 in stage 89.0 (TID 208) in 7 ms on localhost (executor driver) (6/6)
18/02/28 14:09:17 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
18/02/28 14:09:17 INFO DAGScheduler: ResultStage 89 (collect at utils.scala:211) finished in 0.019 s
18/02/28 14:09:17 INFO DAGScheduler: Job 44 finished: collect at utils.scala:211, took 0.031968 s
18/02/28 14:09:17 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:61327 in memory (size: 3.4 KB, free: 345.5 MB)
18/02/28 14:09:17 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 127.0.0.1:61327 in memory (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:09:17 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 127.0.0.1:61327 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:09:17 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:61327 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:09:17 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:61327 in memory (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:09:17 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 127.0.0.1:61327 in memory (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:09:17 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 127.0.0.1:61327 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:09:17 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:61327 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:09:17 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 127.0.0.1:61327 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:09:17 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 127.0.0.1:61327 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:09:17 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:61327 in memory (size: 1868.0 B, free: 345.5 MB)
18/02/28 14:09:17 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:61327 in memory (size: 2.3 KB, free: 345.5 MB)
18/02/28 14:09:17 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 127.0.0.1:61327 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:09:17 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:61327 in memory (size: 3.3 KB, free: 345.5 MB)
18/02/28 14:09:17 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:61327 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:09:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:09:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 14:09:17 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e071ac5c56
18/02/28 14:09:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:09:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e071ac5c56` AS `zzz115`
WHERE (0 = 1)
18/02/28 14:09:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:09:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e071ac5c56`
18/02/28 14:10:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:10:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0186d49d8`
18/02/28 14:10:08 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e0621e411d
18/02/28 14:10:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:10:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0621e411d` AS `zzz116`
WHERE (0 = 1)
18/02/28 14:10:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:10:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0621e411d`
18/02/28 14:10:08 INFO SparkSqlParser: Parsing command: sparklyr_tmp_30e0169c580d
18/02/28 14:10:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:10:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_30e0169c580d` AS `zzz117`
WHERE (0 = 1)
18/02/28 14:10:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:10:10 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `dephour`, `prediction`, `probability`
FROM `sparklyr_tmp_30e0169c580d`
LIMIT 5
18/02/28 14:10:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:10:10 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `dephour`, `prediction`, `probability`
FROM `sparklyr_tmp_30e0169c580d`
LIMIT 5
18/02/28 14:10:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:10:10 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `dephour`, `prediction`, `probability`
FROM `sparklyr_tmp_30e0169c580d`
LIMIT 5
18/02/28 14:10:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:10:10 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `dephour`, `prediction`, `probability`
FROM `sparklyr_tmp_30e0169c580d`
LIMIT 5
18/02/28 14:10:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:10:10 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `dephour`, `prediction`, `probability`
FROM `sparklyr_tmp_30e0169c580d`
LIMIT 5
18/02/28 14:10:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:10:10 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `dephour`, `prediction`, `probability`
FROM `sparklyr_tmp_30e0169c580d`
LIMIT 5
18/02/28 14:10:10 INFO CodeGenerator: Code generated in 46.611016 ms
18/02/28 14:10:10 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:10:10 INFO DAGScheduler: Got job 45 (collect at utils.scala:211) with 1 output partitions
18/02/28 14:10:10 INFO DAGScheduler: Final stage: ResultStage 90 (collect at utils.scala:211)
18/02/28 14:10:10 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:10:10 INFO DAGScheduler: Missing parents: List()
18/02/28 14:10:10 INFO DAGScheduler: Submitting ResultStage 90 (MapPartitionsRDD[155] at collect at utils.scala:211), which has no missing parents
18/02/28 14:10:10 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 80.8 KB, free 345.0 MB)
18/02/28 14:10:10 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 29.8 KB, free 345.0 MB)
18/02/28 14:10:10 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 127.0.0.1:61327 (size: 29.8 KB, free: 345.5 MB)
18/02/28 14:10:10 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1006
18/02/28 14:10:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 90 (MapPartitionsRDD[155] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 14:10:10 INFO TaskSchedulerImpl: Adding task set 90.0 with 1 tasks
18/02/28 14:10:10 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 209, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:10:10 INFO Executor: Running task 0.0 in stage 90.0 (TID 209)
18/02/28 14:10:10 INFO BlockManager: Found block rdd_7_0 locally
18/02/28 14:10:11 INFO Executor: Finished task 0.0 in stage 90.0 (TID 209). 1961 bytes result sent to driver
18/02/28 14:10:11 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 209) in 385 ms on localhost (executor driver) (1/1)
18/02/28 14:10:11 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
18/02/28 14:10:11 INFO DAGScheduler: ResultStage 90 (collect at utils.scala:211) finished in 0.387 s
18/02/28 14:10:11 INFO DAGScheduler: Job 45 finished: collect at utils.scala:211, took 0.392214 s
18/02/28 14:10:11 INFO CodeGenerator: Code generated in 8.300249 ms
18/02/28 14:10:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:10:18 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_30e0169c580d`
GROUP BY `delayed`, `prediction`
18/02/28 14:10:18 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:10:18 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:10:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:10:18 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_30e0169c580d`
GROUP BY `delayed`, `prediction`
18/02/28 14:10:18 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:10:18 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:10:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:10:18 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_30e0169c580d`
GROUP BY `delayed`, `prediction`
18/02/28 14:10:18 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:10:18 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:10:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:10:18 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_30e0169c580d`
GROUP BY `delayed`, `prediction`
18/02/28 14:10:18 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:10:18 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:10:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:10:18 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_30e0169c580d`
GROUP BY `delayed`, `prediction`
18/02/28 14:10:18 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:10:18 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:10:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:10:18 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_30e0169c580d`
GROUP BY `delayed`, `prediction`
LIMIT 1000
18/02/28 14:10:18 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:10:18 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:10:18 INFO CodeGenerator: Code generated in 24.038246 ms
18/02/28 14:10:18 INFO CodeGenerator: Code generated in 59.199439 ms
18/02/28 14:10:18 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:10:18 INFO DAGScheduler: Registering RDD 158 (collect at utils.scala:211)
18/02/28 14:10:18 INFO DAGScheduler: Got job 46 (collect at utils.scala:211) with 1 output partitions
18/02/28 14:10:18 INFO DAGScheduler: Final stage: ResultStage 92 (collect at utils.scala:211)
18/02/28 14:10:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 91)
18/02/28 14:10:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 91)
18/02/28 14:10:18 INFO DAGScheduler: Submitting ShuffleMapStage 91 (MapPartitionsRDD[158] at collect at utils.scala:211), which has no missing parents
18/02/28 14:10:18 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 79.1 KB, free 344.9 MB)
18/02/28 14:10:18 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 32.2 KB, free 344.9 MB)
18/02/28 14:10:18 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 127.0.0.1:61327 (size: 32.2 KB, free: 345.5 MB)
18/02/28 14:10:18 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1006
18/02/28 14:10:18 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 91 (MapPartitionsRDD[158] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:10:18 INFO TaskSchedulerImpl: Adding task set 91.0 with 4 tasks
18/02/28 14:10:18 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 210, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:10:18 INFO TaskSetManager: Starting task 1.0 in stage 91.0 (TID 211, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:10:18 INFO TaskSetManager: Starting task 2.0 in stage 91.0 (TID 212, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:10:18 INFO TaskSetManager: Starting task 3.0 in stage 91.0 (TID 213, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:10:18 INFO Executor: Running task 0.0 in stage 91.0 (TID 210)
18/02/28 14:10:18 INFO BlockManager: Found block rdd_7_0 locally
18/02/28 14:10:18 INFO Executor: Running task 3.0 in stage 91.0 (TID 213)
18/02/28 14:10:18 INFO Executor: Running task 2.0 in stage 91.0 (TID 212)
18/02/28 14:10:18 INFO Executor: Running task 1.0 in stage 91.0 (TID 211)
18/02/28 14:10:18 INFO BlockManager: Found block rdd_7_1 locally
18/02/28 14:10:18 INFO BlockManager: Found block rdd_7_3 locally
18/02/28 14:10:18 INFO CodeGenerator: Code generated in 7.17117 ms
18/02/28 14:10:18 INFO BlockManager: Found block rdd_7_2 locally
18/02/28 14:10:18 INFO CodeGenerator: Code generated in 9.429328 ms
18/02/28 14:10:18 INFO CodeGenerator: Code generated in 10.323565 ms
18/02/28 14:10:18 INFO CodeGenerator: Code generated in 13.668489 ms
18/02/28 14:10:18 INFO CodeGenerator: Code generated in 17.838889 ms
18/02/28 14:10:18 INFO ContextCleaner: Cleaned accumulator 1420
18/02/28 14:10:19 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 127.0.0.1:61327 in memory (size: 29.8 KB, free: 345.5 MB)
18/02/28 14:10:19 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 127.0.0.1:61327 in memory (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:10:19 INFO Executor: Finished task 0.0 in stage 91.0 (TID 210). 2411 bytes result sent to driver
18/02/28 14:10:19 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 210) in 1178 ms on localhost (executor driver) (1/4)
18/02/28 14:10:19 INFO Executor: Finished task 3.0 in stage 91.0 (TID 213). 2411 bytes result sent to driver
18/02/28 14:10:19 INFO TaskSetManager: Finished task 3.0 in stage 91.0 (TID 213) in 1183 ms on localhost (executor driver) (2/4)
18/02/28 14:10:19 INFO Executor: Finished task 1.0 in stage 91.0 (TID 211). 2411 bytes result sent to driver
18/02/28 14:10:19 INFO TaskSetManager: Finished task 1.0 in stage 91.0 (TID 211) in 1192 ms on localhost (executor driver) (3/4)
18/02/28 14:10:19 INFO Executor: Finished task 2.0 in stage 91.0 (TID 212). 2411 bytes result sent to driver
18/02/28 14:10:19 INFO TaskSetManager: Finished task 2.0 in stage 91.0 (TID 212) in 1193 ms on localhost (executor driver) (4/4)
18/02/28 14:10:19 INFO DAGScheduler: ShuffleMapStage 91 (collect at utils.scala:211) finished in 1.195 s
18/02/28 14:10:19 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:10:19 INFO DAGScheduler: running: Set()
18/02/28 14:10:19 INFO DAGScheduler: waiting: Set(ResultStage 92)
18/02/28 14:10:19 INFO DAGScheduler: failed: Set()
18/02/28 14:10:19 INFO DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[161] at collect at utils.scala:211), which has no missing parents
18/02/28 14:10:19 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 38.0 KB, free 345.0 MB)
18/02/28 14:10:19 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 17.9 KB, free 345.0 MB)
18/02/28 14:10:19 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool 
18/02/28 14:10:19 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 127.0.0.1:61327 (size: 17.9 KB, free: 345.5 MB)
18/02/28 14:10:19 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1006
18/02/28 14:10:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 92 (MapPartitionsRDD[161] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 14:10:19 INFO TaskSchedulerImpl: Adding task set 92.0 with 1 tasks
18/02/28 14:10:19 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 214, localhost, executor driver, partition 0, PROCESS_LOCAL, 4726 bytes)
18/02/28 14:10:19 INFO Executor: Running task 0.0 in stage 92.0 (TID 214)
18/02/28 14:10:19 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 14:10:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:10:19 INFO Executor: Finished task 0.0 in stage 92.0 (TID 214). 2577 bytes result sent to driver
18/02/28 14:10:19 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 214) in 18 ms on localhost (executor driver) (1/1)
18/02/28 14:10:19 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
18/02/28 14:10:19 INFO DAGScheduler: ResultStage 92 (collect at utils.scala:211) finished in 0.020 s
18/02/28 14:10:19 INFO DAGScheduler: Job 46 finished: collect at utils.scala:211, took 1.233811 s
18/02/28 14:10:19 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:10:19 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 8 is 158 bytes
18/02/28 14:10:19 INFO DAGScheduler: Got job 47 (collect at utils.scala:211) with 3 output partitions
18/02/28 14:10:19 INFO DAGScheduler: Final stage: ResultStage 94 (collect at utils.scala:211)
18/02/28 14:10:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 93)
18/02/28 14:10:19 INFO DAGScheduler: Missing parents: List()
18/02/28 14:10:19 INFO DAGScheduler: Submitting ResultStage 94 (MapPartitionsRDD[161] at collect at utils.scala:211), which has no missing parents
18/02/28 14:10:19 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 38.0 KB, free 344.9 MB)
18/02/28 14:10:19 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 17.9 KB, free 344.9 MB)
18/02/28 14:10:19 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 127.0.0.1:61327 (size: 17.9 KB, free: 345.5 MB)
18/02/28 14:10:19 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1006
18/02/28 14:10:19 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 94 (MapPartitionsRDD[161] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(1, 2, 3))
18/02/28 14:10:19 INFO TaskSchedulerImpl: Adding task set 94.0 with 3 tasks
18/02/28 14:10:19 INFO TaskSetManager: Starting task 2.0 in stage 94.0 (TID 215, localhost, executor driver, partition 3, PROCESS_LOCAL, 4726 bytes)
18/02/28 14:10:19 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 216, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 14:10:19 INFO TaskSetManager: Starting task 1.0 in stage 94.0 (TID 217, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 14:10:19 INFO Executor: Running task 2.0 in stage 94.0 (TID 215)
18/02/28 14:10:19 INFO Executor: Running task 0.0 in stage 94.0 (TID 216)
18/02/28 14:10:19 INFO Executor: Running task 1.0 in stage 94.0 (TID 217)
18/02/28 14:10:19 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:10:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:10:19 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 14:10:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 14:10:19 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:10:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:10:19 INFO Executor: Finished task 2.0 in stage 94.0 (TID 215). 2577 bytes result sent to driver
18/02/28 14:10:19 INFO Executor: Finished task 0.0 in stage 94.0 (TID 216). 2597 bytes result sent to driver
18/02/28 14:10:19 INFO TaskSetManager: Finished task 2.0 in stage 94.0 (TID 215) in 14 ms on localhost (executor driver) (1/3)
18/02/28 14:10:19 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 216) in 13 ms on localhost (executor driver) (2/3)
18/02/28 14:10:19 INFO Executor: Finished task 1.0 in stage 94.0 (TID 217). 2626 bytes result sent to driver
18/02/28 14:10:19 INFO TaskSetManager: Finished task 1.0 in stage 94.0 (TID 217) in 20 ms on localhost (executor driver) (3/3)
18/02/28 14:10:19 INFO DAGScheduler: ResultStage 94 (collect at utils.scala:211) finished in 0.021 s
18/02/28 14:10:19 INFO DAGScheduler: Job 47 finished: collect at utils.scala:211, took 0.026202 s
18/02/28 14:10:19 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool 
18/02/28 14:10:19 INFO CodeGenerator: Code generated in 5.801253 ms
18/02/28 14:15:54 INFO SparkContext: Running Spark version 2.2.0
18/02/28 14:15:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/02/28 14:15:55 INFO SparkContext: Submitted application: sparklyr
18/02/28 14:15:55 INFO SecurityManager: Changing view acls to: JC
18/02/28 14:15:55 INFO SecurityManager: Changing modify acls to: JC
18/02/28 14:15:55 INFO SecurityManager: Changing view acls groups to: 
18/02/28 14:15:55 INFO SecurityManager: Changing modify acls groups to: 
18/02/28 14:15:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(JC); groups with view permissions: Set(); users  with modify permissions: Set(JC); groups with modify permissions: Set()
18/02/28 14:15:55 INFO Utils: Successfully started service 'sparkDriver' on port 61442.
18/02/28 14:15:55 INFO SparkEnv: Registering MapOutputTracker
18/02/28 14:15:55 INFO SparkEnv: Registering BlockManagerMaster
18/02/28 14:15:55 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/02/28 14:15:55 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/02/28 14:15:55 INFO DiskBlockManager: Created local directory at C:\Users\JC\AppData\Local\Temp\blockmgr-f1c0a9be-b534-4e27-942b-82ce5b4b43c2
18/02/28 14:15:55 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/02/28 14:15:55 INFO SparkEnv: Registering OutputCommitCoordinator
18/02/28 14:15:55 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
18/02/28 14:15:55 INFO Utils: Successfully started service 'SparkUI' on port 4041.
18/02/28 14:15:55 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
18/02/28 14:15:55 INFO SparkContext: Added JAR file:/C:/Users/JC/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:61442/jars/sparklyr-2.2-2.11.jar with timestamp 1519856155837
18/02/28 14:15:55 INFO Executor: Starting executor ID driver on host localhost
18/02/28 14:15:55 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61463.
18/02/28 14:15:55 INFO NettyBlockTransferService: Server created on 127.0.0.1:61463
18/02/28 14:15:56 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/02/28 14:15:56 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 61463, None)
18/02/28 14:15:56 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:61463 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 61463, None)
18/02/28 14:15:56 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 61463, None)
18/02/28 14:15:56 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 61463, None)
18/02/28 14:15:56 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/02/28 14:15:56 INFO SharedState: loading hive config file: file:/C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
18/02/28 14:15:56 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:\Users\JC\AppData\Local\spark\spark-2.2.0-bin-hadoop2.7\tmp\hive') to the value of spark.sql.warehouse.dir ('C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive').
18/02/28 14:15:56 INFO SharedState: Warehouse path is 'C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive'.
18/02/28 14:15:57 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
18/02/28 14:15:58 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
18/02/28 14:15:58 INFO ObjectStore: ObjectStore, initialize called
18/02/28 14:15:58 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
18/02/28 14:15:58 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
18/02/28 14:16:00 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
18/02/28 14:16:01 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 14:16:01 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 14:16:02 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 14:16:02 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 14:16:02 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
18/02/28 14:16:02 INFO ObjectStore: Initialized ObjectStore
18/02/28 14:16:02 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
18/02/28 14:16:03 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
18/02/28 14:16:03 INFO HiveMetaStore: Added admin role in metastore
18/02/28 14:16:03 INFO HiveMetaStore: Added public role in metastore
18/02/28 14:16:03 INFO HiveMetaStore: No user is added in admin role, since config is empty
18/02/28 14:16:03 INFO HiveMetaStore: 0: get_all_databases
18/02/28 14:16:03 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_all_databases	
18/02/28 14:16:03 INFO HiveMetaStore: 0: get_functions: db=default pat=*
18/02/28 14:16:03 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
18/02/28 14:16:03 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 14:16:03 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/Temp/2b392959-b925-4954-80e5-08bc80a4a545_resources
18/02/28 14:16:03 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/2b392959-b925-4954-80e5-08bc80a4a545
18/02/28 14:16:03 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/2b392959-b925-4954-80e5-08bc80a4a545
18/02/28 14:16:04 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/2b392959-b925-4954-80e5-08bc80a4a545/_tmp_space.db
18/02/28 14:16:04 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive
18/02/28 14:16:04 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:16:04 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:16:04 INFO HiveMetaStore: 0: get_database: global_temp
18/02/28 14:16:04 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: global_temp	
18/02/28 14:16:04 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
18/02/28 14:16:04 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/Temp/f9b1cba9-c63e-45c4-abe6-e40b4d2451a4_resources
18/02/28 14:16:04 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/f9b1cba9-c63e-45c4-abe6-e40b4d2451a4
18/02/28 14:16:04 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/f9b1cba9-c63e-45c4-abe6-e40b4d2451a4
18/02/28 14:16:05 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/f9b1cba9-c63e-45c4-abe6-e40b4d2451a4/_tmp_space.db
18/02/28 14:16:05 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive
18/02/28 14:16:05 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
18/02/28 14:16:05 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 14:16:07 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:16:07 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:16:07 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:16:07 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:16:07 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 14:16:07 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 14:16:08 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 14:16:08 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
18/02/28 14:16:08 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
18/02/28 14:16:08 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:16:08 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:08 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55), which has no missing parents
18/02/28 14:16:08 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
18/02/28 14:16:08 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
18/02/28 14:16:08 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:61463 (size: 3.4 KB, free: 366.3 MB)
18/02/28 14:16:08 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0))
18/02/28 14:16:08 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/02/28 14:16:08 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 14:16:08 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/02/28 14:16:08 INFO Executor: Fetching spark://127.0.0.1:61442/jars/sparklyr-2.2-2.11.jar with timestamp 1519856155837
18/02/28 14:16:08 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:61442 after 17 ms (0 ms spent in bootstraps)
18/02/28 14:16:08 INFO Utils: Fetching spark://127.0.0.1:61442/jars/sparklyr-2.2-2.11.jar to C:\Users\JC\AppData\Local\Temp\spark-e01f4c3c-af1d-408c-a784-906f00146bc1\userFiles-8bb8c3b4-7315-459b-9cc9-30c3add9a029\fetchFileTemp7862605407813258896.tmp
18/02/28 14:16:08 INFO Executor: Adding file:/C:/Users/JC/AppData/Local/Temp/spark-e01f4c3c-af1d-408c-a784-906f00146bc1/userFiles-8bb8c3b4-7315-459b-9cc9-30c3add9a029/sparklyr-2.2-2.11.jar to class loader
18/02/28 14:16:09 INFO CodeGenerator: Code generated in 301.995565 ms
18/02/28 14:16:09 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
18/02/28 14:16:09 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 823 ms on localhost (executor driver) (1/1)
18/02/28 14:16:09 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/02/28 14:16:09 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.850 s
18/02/28 14:16:09 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 1.048093 s
18/02/28 14:16:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:09 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 14:16:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:16:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:16:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:16:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:16:09 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 14:16:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 14:16:09 INFO SparkSqlParser: Parsing command: spark_flights
18/02/28 14:16:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:09 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_flights` AS `zzz1`
WHERE (0 = 1)
18/02/28 14:16:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:09 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_flights`
18/02/28 14:16:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:09 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_flights`
18/02/28 14:16:10 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:16:10 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:16:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:10 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_flights`
LIMIT 10
18/02/28 14:16:10 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:16:10 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:16:10 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 14:16:10 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 14:16:10 INFO FileSourceStrategy: Output Data Schema: struct<>
18/02/28 14:16:10 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 14:16:10 INFO CodeGenerator: Code generated in 26.344008 ms
18/02/28 14:16:10 INFO CodeGenerator: Code generated in 16.147385 ms
18/02/28 14:16:10 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 282.5 KB, free 366.0 MB)
18/02/28 14:16:10 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 24.1 KB, free 366.0 MB)
18/02/28 14:16:10 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:61463 (size: 24.1 KB, free: 366.3 MB)
18/02/28 14:16:10 INFO SparkContext: Created broadcast 1 from collect at utils.scala:211
18/02/28 14:16:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21019222 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 14:16:10 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:16:10 INFO DAGScheduler: Registering RDD 7 (collect at utils.scala:211)
18/02/28 14:16:10 INFO DAGScheduler: Got job 1 (collect at utils.scala:211) with 1 output partitions
18/02/28 14:16:10 INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:211)
18/02/28 14:16:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
18/02/28 14:16:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
18/02/28 14:16:10 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:10 INFO ContextCleaner: Cleaned accumulator 49
18/02/28 14:16:10 INFO ContextCleaner: Cleaned accumulator 0
18/02/28 14:16:11 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 14.2 KB, free 366.0 MB)
18/02/28 14:16:11 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:61463 in memory (size: 3.4 KB, free: 366.3 MB)
18/02/28 14:16:11 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 8.0 KB, free 366.0 MB)
18/02/28 14:16:11 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:61463 (size: 8.0 KB, free: 366.3 MB)
18/02/28 14:16:11 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:11 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:11 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks
18/02/28 14:16:11 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:11 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:11 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:16:11 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:11 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
18/02/28 14:16:11 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
18/02/28 14:16:11 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
18/02/28 14:16:11 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
18/02/28 14:16:11 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_11.csv, range: 0-2757037, partition values: [empty row]
18/02/28 14:16:11 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_4.csv, range: 0-2830543, partition values: [empty row]
18/02/28 14:16:11 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_7.csv, range: 0-2938867, partition values: [empty row]
18/02/28 14:16:11 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_3.csv, range: 0-2881793, partition values: [empty row]
18/02/28 14:16:11 INFO CodeGenerator: Code generated in 10.830628 ms
18/02/28 14:16:11 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_5.csv, range: 0-2880181, partition values: [empty row]
18/02/28 14:16:11 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_8.csv, range: 0-2932019, partition values: [empty row]
18/02/28 14:16:11 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_1.csv, range: 0-2697256, partition values: [empty row]
18/02/28 14:16:11 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_6.csv, range: 0-2820227, partition values: [empty row]
18/02/28 14:16:12 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_2.csv, range: 0-2487144, partition values: [empty row]
18/02/28 14:16:12 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_12.csv, range: 0-2836468, partition values: [empty row]
18/02/28 14:16:12 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_10.csv, range: 0-2920629, partition values: [empty row]
18/02/28 14:16:12 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_9.csv, range: 0-2763076, partition values: [empty row]
18/02/28 14:16:12 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1671 bytes result sent to driver
18/02/28 14:16:12 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1628 bytes result sent to driver
18/02/28 14:16:12 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 1671 bytes result sent to driver
18/02/28 14:16:12 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1628 bytes result sent to driver
18/02/28 14:16:12 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1284 ms on localhost (executor driver) (1/4)
18/02/28 14:16:12 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1279 ms on localhost (executor driver) (2/4)
18/02/28 14:16:12 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1280 ms on localhost (executor driver) (3/4)
18/02/28 14:16:12 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 1282 ms on localhost (executor driver) (4/4)
18/02/28 14:16:12 INFO DAGScheduler: ShuffleMapStage 1 (collect at utils.scala:211) finished in 1.290 s
18/02/28 14:16:12 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:16:12 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/02/28 14:16:12 INFO DAGScheduler: running: Set()
18/02/28 14:16:12 INFO DAGScheduler: waiting: Set(ResultStage 2)
18/02/28 14:16:12 INFO DAGScheduler: failed: Set()
18/02/28 14:16:12 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[10] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:12 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.9 KB, free 366.0 MB)
18/02/28 14:16:12 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.0 MB)
18/02/28 14:16:12 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:61463 (size: 3.7 KB, free: 366.3 MB)
18/02/28 14:16:12 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 14:16:12 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
18/02/28 14:16:12 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 14:16:12 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
18/02/28 14:16:12 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
18/02/28 14:16:12 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1514 bytes result sent to driver
18/02/28 14:16:12 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 40 ms on localhost (executor driver) (1/1)
18/02/28 14:16:12 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/02/28 14:16:12 INFO DAGScheduler: ResultStage 2 (collect at utils.scala:211) finished in 0.040 s
18/02/28 14:16:12 INFO DAGScheduler: Job 1 finished: collect at utils.scala:211, took 1.671772 s
18/02/28 14:16:12 INFO CodeGenerator: Code generated in 10.778088 ms
18/02/28 14:16:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:12 INFO SparkSqlParser: Parsing command: SELECT `month`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`, `sched_dep_time`, `sched_arr_time`
FROM (SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`dep_time` AS DOUBLE) AS `dep_time`, CAST(`arr_time` AS DOUBLE) AS `arr_time`, CAST(`arr_delay` AS DOUBLE) AS `arr_delay`, CAST(`dep_delay` AS DOUBLE) AS `dep_delay`, CAST(`distance` AS DOUBLE) AS `distance`, CAST(`sched_dep_time` AS DOUBLE) AS `sched_dep_time`, CAST(`sched_arr_time` AS DOUBLE) AS `sched_arr_time`
FROM (SELECT `month`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`, `sched_dep_time`, `sched_arr_time`
FROM `spark_flights`) `tyxsxccuky`) `fcnwnavicz`
18/02/28 14:16:12 INFO SparkSqlParser: Parsing command: cached_flights
18/02/28 14:16:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights` AS `zzz2`
WHERE (0 = 1)
18/02/28 14:16:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:12 INFO SparkSqlParser: Parsing command: CACHE TABLE `cached_flights`
18/02/28 14:16:12 INFO SparkSqlParser: Parsing command: `cached_flights`
18/02/28 14:16:12 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 14:16:12 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 14:16:12 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dep_time: string, sched_dep_time: string, dep_delay: string, arr_time: string ... 6 more fields>
18/02/28 14:16:12 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 14:16:12 INFO CodeGenerator: Code generated in 27.28338 ms
18/02/28 14:16:12 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 282.5 KB, free 365.7 MB)
18/02/28 14:16:12 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.7 MB)
18/02/28 14:16:12 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:61463 (size: 24.1 KB, free: 366.2 MB)
18/02/28 14:16:12 INFO SparkContext: Created broadcast 4 from sql at <unknown>:0
18/02/28 14:16:12 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21019222 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 14:16:12 INFO CodeGenerator: Code generated in 15.976366 ms
18/02/28 14:16:12 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 14:16:12 INFO DAGScheduler: Registering RDD 16 (sql at <unknown>:0)
18/02/28 14:16:12 INFO DAGScheduler: Got job 2 (sql at <unknown>:0) with 1 output partitions
18/02/28 14:16:12 INFO DAGScheduler: Final stage: ResultStage 4 (sql at <unknown>:0)
18/02/28 14:16:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
18/02/28 14:16:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
18/02/28 14:16:12 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[16] at sql at <unknown>:0), which has no missing parents
18/02/28 14:16:12 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 26.7 KB, free 365.6 MB)
18/02/28 14:16:12 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 11.7 KB, free 365.6 MB)
18/02/28 14:16:12 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:61463 (size: 11.7 KB, free: 366.2 MB)
18/02/28 14:16:12 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:12 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[16] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:12 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks
18/02/28 14:16:12 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:13 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:13 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 8, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:16:13 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 9, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:13 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)
18/02/28 14:16:13 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)
18/02/28 14:16:13 INFO Executor: Running task 2.0 in stage 3.0 (TID 8)
18/02/28 14:16:13 INFO Executor: Running task 3.0 in stage 3.0 (TID 9)
18/02/28 14:16:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_11.csv, range: 0-2757037, partition values: [empty row]
18/02/28 14:16:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_4.csv, range: 0-2830543, partition values: [empty row]
18/02/28 14:16:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_3.csv, range: 0-2881793, partition values: [empty row]
18/02/28 14:16:13 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_7.csv, range: 0-2938867, partition values: [empty row]
18/02/28 14:16:13 INFO CodeGenerator: Code generated in 26.076372 ms
18/02/28 14:16:13 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:61463 in memory (size: 3.7 KB, free: 366.2 MB)
18/02/28 14:16:13 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:61463 in memory (size: 8.0 KB, free: 366.2 MB)
18/02/28 14:16:13 INFO ContextCleaner: Cleaned accumulator 119
18/02/28 14:16:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_1.csv, range: 0-2697256, partition values: [empty row]
18/02/28 14:16:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_6.csv, range: 0-2820227, partition values: [empty row]
18/02/28 14:16:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_5.csv, range: 0-2880181, partition values: [empty row]
18/02/28 14:16:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_8.csv, range: 0-2932019, partition values: [empty row]
18/02/28 14:16:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_2.csv, range: 0-2487144, partition values: [empty row]
18/02/28 14:16:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_9.csv, range: 0-2763076, partition values: [empty row]
18/02/28 14:16:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_12.csv, range: 0-2836468, partition values: [empty row]
18/02/28 14:16:14 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_10.csv, range: 0-2920629, partition values: [empty row]
18/02/28 14:16:15 INFO MemoryStore: Block rdd_13_3 stored as values in memory (estimated size 4.8 MB, free 360.9 MB)
18/02/28 14:16:15 INFO BlockManagerInfo: Added rdd_13_3 in memory on 127.0.0.1:61463 (size: 4.8 MB, free: 361.4 MB)
18/02/28 14:16:15 INFO CodeGenerator: Code generated in 12.600764 ms
18/02/28 14:16:15 INFO MemoryStore: Block rdd_13_2 stored as values in memory (estimated size 5.1 MB, free 355.7 MB)
18/02/28 14:16:15 INFO BlockManagerInfo: Added rdd_13_2 in memory on 127.0.0.1:61463 (size: 5.1 MB, free: 356.3 MB)
18/02/28 14:16:15 INFO MemoryStore: Block rdd_13_1 stored as values in memory (estimated size 5.2 MB, free 350.5 MB)
18/02/28 14:16:15 INFO CodeGenerator: Code generated in 99.258129 ms
18/02/28 14:16:15 INFO BlockManagerInfo: Added rdd_13_1 in memory on 127.0.0.1:61463 (size: 5.2 MB, free: 351.1 MB)
18/02/28 14:16:15 INFO MemoryStore: Block rdd_13_0 stored as values in memory (estimated size 5.3 MB, free 345.2 MB)
18/02/28 14:16:15 INFO BlockManagerInfo: Added rdd_13_0 in memory on 127.0.0.1:61463 (size: 5.3 MB, free: 345.8 MB)
18/02/28 14:16:15 INFO Executor: Finished task 2.0 in stage 3.0 (TID 8). 2461 bytes result sent to driver
18/02/28 14:16:15 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 8) in 2417 ms on localhost (executor driver) (1/4)
18/02/28 14:16:15 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 2461 bytes result sent to driver
18/02/28 14:16:15 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 2430 ms on localhost (executor driver) (2/4)
18/02/28 14:16:15 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 2461 bytes result sent to driver
18/02/28 14:16:15 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 2460 ms on localhost (executor driver) (3/4)
18/02/28 14:16:15 INFO Executor: Finished task 3.0 in stage 3.0 (TID 9). 2504 bytes result sent to driver
18/02/28 14:16:15 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 9) in 2465 ms on localhost (executor driver) (4/4)
18/02/28 14:16:15 INFO DAGScheduler: ShuffleMapStage 3 (sql at <unknown>:0) finished in 2.470 s
18/02/28 14:16:15 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:16:15 INFO DAGScheduler: running: Set()
18/02/28 14:16:15 INFO DAGScheduler: waiting: Set(ResultStage 4)
18/02/28 14:16:15 INFO DAGScheduler: failed: Set()
18/02/28 14:16:15 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[19] at sql at <unknown>:0), which has no missing parents
18/02/28 14:16:15 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.0 KB, free 345.2 MB)
18/02/28 14:16:15 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.7 KB, free 345.2 MB)
18/02/28 14:16:15 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/02/28 14:16:15 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:61463 (size: 3.7 KB, free: 345.8 MB)
18/02/28 14:16:15 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 14:16:15 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
18/02/28 14:16:15 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 10, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 14:16:15 INFO Executor: Running task 0.0 in stage 4.0 (TID 10)
18/02/28 14:16:15 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 14:16:15 INFO Executor: Finished task 0.0 in stage 4.0 (TID 10). 1495 bytes result sent to driver
18/02/28 14:16:15 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 10) in 9 ms on localhost (executor driver) (1/1)
18/02/28 14:16:15 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/02/28 14:16:15 INFO DAGScheduler: ResultStage 4 (sql at <unknown>:0) finished in 0.010 s
18/02/28 14:16:15 INFO DAGScheduler: Job 2 finished: sql at <unknown>:0, took 2.525688 s
18/02/28 14:16:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:15 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `cached_flights`
18/02/28 14:16:15 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:16:15 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:16:15 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:16:15 INFO DAGScheduler: Registering RDD 22 (collect at utils.scala:211)
18/02/28 14:16:15 INFO DAGScheduler: Got job 3 (collect at utils.scala:211) with 1 output partitions
18/02/28 14:16:15 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:211)
18/02/28 14:16:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
18/02/28 14:16:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
18/02/28 14:16:15 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[22] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:15 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 26.7 KB, free 345.2 MB)
18/02/28 14:16:15 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.7 KB, free 345.2 MB)
18/02/28 14:16:15 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:61463 (size: 11.7 KB, free: 345.8 MB)
18/02/28 14:16:15 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:15 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[22] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:15 INFO TaskSchedulerImpl: Adding task set 5.0 with 4 tasks
18/02/28 14:16:15 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:15 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 12, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:15 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 13, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:16:15 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 14, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:15 INFO Executor: Running task 0.0 in stage 5.0 (TID 11)
18/02/28 14:16:15 INFO Executor: Running task 1.0 in stage 5.0 (TID 12)
18/02/28 14:16:15 INFO Executor: Running task 2.0 in stage 5.0 (TID 13)
18/02/28 14:16:15 INFO Executor: Running task 3.0 in stage 5.0 (TID 14)
18/02/28 14:16:15 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 14:16:15 INFO BlockManager: Found block rdd_13_1 locally
18/02/28 14:16:15 INFO BlockManager: Found block rdd_13_2 locally
18/02/28 14:16:15 INFO BlockManager: Found block rdd_13_3 locally
18/02/28 14:16:15 INFO Executor: Finished task 0.0 in stage 5.0 (TID 11). 1737 bytes result sent to driver
18/02/28 14:16:15 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 11) in 60 ms on localhost (executor driver) (1/4)
18/02/28 14:16:15 INFO Executor: Finished task 1.0 in stage 5.0 (TID 12). 1737 bytes result sent to driver
18/02/28 14:16:15 INFO Executor: Finished task 3.0 in stage 5.0 (TID 14). 1780 bytes result sent to driver
18/02/28 14:16:15 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 12) in 75 ms on localhost (executor driver) (2/4)
18/02/28 14:16:15 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 14) in 75 ms on localhost (executor driver) (3/4)
18/02/28 14:16:15 INFO Executor: Finished task 2.0 in stage 5.0 (TID 13). 1694 bytes result sent to driver
18/02/28 14:16:15 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 13) in 92 ms on localhost (executor driver) (4/4)
18/02/28 14:16:15 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:211) finished in 0.097 s
18/02/28 14:16:15 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:16:15 INFO DAGScheduler: running: Set()
18/02/28 14:16:15 INFO DAGScheduler: waiting: Set(ResultStage 6)
18/02/28 14:16:15 INFO DAGScheduler: failed: Set()
18/02/28 14:16:15 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:15 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.0 KB, free 345.1 MB)
18/02/28 14:16:15 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/02/28 14:16:15 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.7 KB, free 345.1 MB)
18/02/28 14:16:15 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:61463 (size: 3.7 KB, free: 345.8 MB)
18/02/28 14:16:15 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 14:16:15 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
18/02/28 14:16:15 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 15, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 14:16:15 INFO Executor: Running task 0.0 in stage 6.0 (TID 15)
18/02/28 14:16:15 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 14:16:15 INFO Executor: Finished task 0.0 in stage 6.0 (TID 15). 1538 bytes result sent to driver
18/02/28 14:16:15 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 15) in 9 ms on localhost (executor driver) (1/1)
18/02/28 14:16:15 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:211) finished in 0.010 s
18/02/28 14:16:15 INFO DAGScheduler: Job 3 finished: collect at utils.scala:211, took 0.129330 s
18/02/28 14:16:15 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
18/02/28 14:16:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:15 INFO SparkSqlParser: Parsing command: SHOW TABLES LIKE"cached_flights"
18/02/28 14:16:15 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:16:15 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:16:15 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:16:15 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:16:15 INFO HiveMetaStore: 0: get_tables: db=default pat=cached_flights
18/02/28 14:16:15 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=cached_flights	
18/02/28 14:16:15 INFO CodeGenerator: Code generated in 8.602442 ms
18/02/28 14:16:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights` AS `zzz3`
WHERE (0 = 1)
18/02/28 14:16:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:15 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `cached_flights`
18/02/28 14:16:15 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:16:15 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:16:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:16 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `cached_flights`
LIMIT 10
18/02/28 14:16:16 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:16:16 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:16:16 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:16:16 INFO DAGScheduler: Registering RDD 28 (collect at utils.scala:211)
18/02/28 14:16:16 INFO DAGScheduler: Got job 4 (collect at utils.scala:211) with 1 output partitions
18/02/28 14:16:16 INFO DAGScheduler: Final stage: ResultStage 8 (collect at utils.scala:211)
18/02/28 14:16:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
18/02/28 14:16:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
18/02/28 14:16:16 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[28] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:16 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 26.7 KB, free 345.1 MB)
18/02/28 14:16:16 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 11.7 KB, free 345.1 MB)
18/02/28 14:16:16 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:61463 (size: 11.7 KB, free: 345.7 MB)
18/02/28 14:16:16 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:16 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[28] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:16 INFO TaskSchedulerImpl: Adding task set 7.0 with 4 tasks
18/02/28 14:16:16 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:16 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 17, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:16 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 18, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:16:16 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 19, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:16 INFO Executor: Running task 0.0 in stage 7.0 (TID 16)
18/02/28 14:16:16 INFO Executor: Running task 1.0 in stage 7.0 (TID 17)
18/02/28 14:16:16 INFO Executor: Running task 2.0 in stage 7.0 (TID 18)
18/02/28 14:16:16 INFO Executor: Running task 3.0 in stage 7.0 (TID 19)
18/02/28 14:16:16 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 14:16:16 INFO BlockManager: Found block rdd_13_1 locally
18/02/28 14:16:16 INFO BlockManager: Found block rdd_13_2 locally
18/02/28 14:16:16 INFO BlockManager: Found block rdd_13_3 locally
18/02/28 14:16:16 INFO Executor: Finished task 0.0 in stage 7.0 (TID 16). 1694 bytes result sent to driver
18/02/28 14:16:16 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 16) in 71 ms on localhost (executor driver) (1/4)
18/02/28 14:16:16 INFO Executor: Finished task 2.0 in stage 7.0 (TID 18). 1694 bytes result sent to driver
18/02/28 14:16:16 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 18) in 105 ms on localhost (executor driver) (2/4)
18/02/28 14:16:16 INFO Executor: Finished task 3.0 in stage 7.0 (TID 19). 1737 bytes result sent to driver
18/02/28 14:16:16 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 19) in 114 ms on localhost (executor driver) (3/4)
18/02/28 14:16:16 INFO Executor: Finished task 1.0 in stage 7.0 (TID 17). 1737 bytes result sent to driver
18/02/28 14:16:16 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 17) in 130 ms on localhost (executor driver) (4/4)
18/02/28 14:16:16 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
18/02/28 14:16:16 INFO DAGScheduler: ShuffleMapStage 7 (collect at utils.scala:211) finished in 0.132 s
18/02/28 14:16:16 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:16:16 INFO DAGScheduler: running: Set()
18/02/28 14:16:16 INFO DAGScheduler: waiting: Set(ResultStage 8)
18/02/28 14:16:16 INFO DAGScheduler: failed: Set()
18/02/28 14:16:16 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[31] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:16 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 6.9 KB, free 345.1 MB)
18/02/28 14:16:16 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.7 KB, free 345.1 MB)
18/02/28 14:16:16 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:61463 (size: 3.7 KB, free: 345.7 MB)
18/02/28 14:16:16 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[31] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 14:16:16 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
18/02/28 14:16:16 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 20, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 14:16:16 INFO Executor: Running task 0.0 in stage 8.0 (TID 20)
18/02/28 14:16:16 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 14:16:16 INFO Executor: Finished task 0.0 in stage 8.0 (TID 20). 1514 bytes result sent to driver
18/02/28 14:16:16 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 20) in 7 ms on localhost (executor driver) (1/1)
18/02/28 14:16:16 INFO DAGScheduler: ResultStage 8 (collect at utils.scala:211) finished in 0.008 s
18/02/28 14:16:16 INFO DAGScheduler: Job 4 finished: collect at utils.scala:211, took 0.163993 s
18/02/28 14:16:16 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
18/02/28 14:16:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
LIMIT 5
18/02/28 14:16:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
LIMIT 5
18/02/28 14:16:16 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:16:16 INFO DAGScheduler: Got job 5 (collect at utils.scala:211) with 1 output partitions
18/02/28 14:16:16 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:211)
18/02/28 14:16:16 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:16:16 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:16 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[33] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:16 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 22.8 KB, free 345.1 MB)
18/02/28 14:16:16 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 10.3 KB, free 345.1 MB)
18/02/28 14:16:16 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:61463 (size: 10.3 KB, free: 345.7 MB)
18/02/28 14:16:16 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[33] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 14:16:16 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
18/02/28 14:16:16 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:16 INFO Executor: Running task 0.0 in stage 9.0 (TID 21)
18/02/28 14:16:16 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 14:16:16 INFO CodeGenerator: Code generated in 81.516916 ms
18/02/28 14:16:16 INFO Executor: 1 block locks were not released by TID = 21:
[rdd_13_0]
18/02/28 14:16:16 INFO Executor: Finished task 0.0 in stage 9.0 (TID 21). 1481 bytes result sent to driver
18/02/28 14:16:16 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 21) in 188 ms on localhost (executor driver) (1/1)
18/02/28 14:16:16 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:211) finished in 0.189 s
18/02/28 14:16:16 INFO DAGScheduler: Job 5 finished: collect at utils.scala:211, took 0.202501 s
18/02/28 14:16:16 INFO CodeGenerator: Code generated in 14.346924 ms
18/02/28 14:16:16 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
18/02/28 14:16:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:17 INFO SparkSqlParser: Parsing command: SELECT `month`, count(*) AS `n()`
FROM `cached_flights`
GROUP BY `month`
18/02/28 14:16:17 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:16:17 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:16:17 INFO CodeGenerator: Code generated in 29.955158 ms
18/02/28 14:16:17 INFO CodeGenerator: Code generated in 53.506087 ms
18/02/28 14:16:17 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:16:17 INFO DAGScheduler: Registering RDD 36 (collect at utils.scala:211)
18/02/28 14:16:17 INFO DAGScheduler: Got job 6 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:16:17 INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:211)
18/02/28 14:16:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
18/02/28 14:16:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
18/02/28 14:16:17 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[36] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:17 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 37.3 KB, free 345.0 MB)
18/02/28 14:16:17 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 16.6 KB, free 345.0 MB)
18/02/28 14:16:17 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:61463 (size: 16.6 KB, free: 345.7 MB)
18/02/28 14:16:17 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:17 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[36] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:17 INFO TaskSchedulerImpl: Adding task set 10.0 with 4 tasks
18/02/28 14:16:17 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:17 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:17 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:16:17 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:17 INFO Executor: Running task 0.0 in stage 10.0 (TID 22)
18/02/28 14:16:17 INFO Executor: Running task 1.0 in stage 10.0 (TID 23)
18/02/28 14:16:17 INFO Executor: Running task 2.0 in stage 10.0 (TID 24)
18/02/28 14:16:17 INFO Executor: Running task 3.0 in stage 10.0 (TID 25)
18/02/28 14:16:17 INFO BlockManager: Found block rdd_13_2 locally
18/02/28 14:16:17 INFO BlockManager: Found block rdd_13_1 locally
18/02/28 14:16:17 INFO BlockManager: Found block rdd_13_3 locally
18/02/28 14:16:17 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 14:16:17 INFO CodeGenerator: Code generated in 81.543714 ms
18/02/28 14:16:17 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:61463 in memory (size: 11.7 KB, free: 345.7 MB)
18/02/28 14:16:17 INFO CodeGenerator: Code generated in 13.444577 ms
18/02/28 14:16:17 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:61463 in memory (size: 10.3 KB, free: 345.7 MB)
18/02/28 14:16:17 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:61463 in memory (size: 11.7 KB, free: 345.8 MB)
18/02/28 14:16:17 INFO ContextCleaner: Cleaned accumulator 327
18/02/28 14:16:17 INFO ContextCleaner: Cleaned accumulator 180
18/02/28 14:16:17 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:61463 in memory (size: 3.7 KB, free: 345.8 MB)
18/02/28 14:16:17 INFO ContextCleaner: Cleaned accumulator 241
18/02/28 14:16:17 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:61463 in memory (size: 3.7 KB, free: 345.8 MB)
18/02/28 14:16:17 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:61463 in memory (size: 3.7 KB, free: 345.8 MB)
18/02/28 14:16:17 INFO CodeGenerator: Code generated in 15.244334 ms
18/02/28 14:16:17 INFO CodeGenerator: Code generated in 11.227322 ms
18/02/28 14:16:17 INFO CodeGenerator: Code generated in 16.185468 ms
18/02/28 14:16:17 INFO CodeGenerator: Code generated in 8.98362 ms
18/02/28 14:16:17 INFO Executor: Finished task 1.0 in stage 10.0 (TID 23). 2054 bytes result sent to driver
18/02/28 14:16:17 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 570 ms on localhost (executor driver) (1/4)
18/02/28 14:16:17 INFO Executor: Finished task 3.0 in stage 10.0 (TID 25). 2011 bytes result sent to driver
18/02/28 14:16:17 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 577 ms on localhost (executor driver) (2/4)
18/02/28 14:16:17 INFO Executor: Finished task 2.0 in stage 10.0 (TID 24). 2054 bytes result sent to driver
18/02/28 14:16:17 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 587 ms on localhost (executor driver) (3/4)
18/02/28 14:16:17 INFO Executor: Finished task 0.0 in stage 10.0 (TID 22). 2054 bytes result sent to driver
18/02/28 14:16:17 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 598 ms on localhost (executor driver) (4/4)
18/02/28 14:16:17 INFO DAGScheduler: ShuffleMapStage 10 (collect at utils.scala:211) finished in 0.598 s
18/02/28 14:16:17 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:16:17 INFO DAGScheduler: running: Set()
18/02/28 14:16:17 INFO DAGScheduler: waiting: Set(ResultStage 11)
18/02/28 14:16:17 INFO DAGScheduler: failed: Set()
18/02/28 14:16:17 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[39] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:17 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
18/02/28 14:16:17 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 17.6 KB, free 345.1 MB)
18/02/28 14:16:17 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 8.2 KB, free 345.1 MB)
18/02/28 14:16:17 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:61463 (size: 8.2 KB, free: 345.8 MB)
18/02/28 14:16:17 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:17 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 11 (MapPartitionsRDD[39] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:17 INFO TaskSchedulerImpl: Adding task set 11.0 with 4 tasks
18/02/28 14:16:17 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 26, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 14:16:17 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 27, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 14:16:17 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 28, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 14:16:17 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 29, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 14:16:17 INFO Executor: Running task 0.0 in stage 11.0 (TID 26)
18/02/28 14:16:17 INFO Executor: Running task 1.0 in stage 11.0 (TID 27)
18/02/28 14:16:17 INFO Executor: Running task 2.0 in stage 11.0 (TID 28)
18/02/28 14:16:17 INFO Executor: Running task 3.0 in stage 11.0 (TID 29)
18/02/28 14:16:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 14:16:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:17 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:17 INFO Executor: Finished task 1.0 in stage 11.0 (TID 27). 2306 bytes result sent to driver
18/02/28 14:16:17 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 14:16:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 14:16:17 INFO Executor: Finished task 3.0 in stage 11.0 (TID 29). 2297 bytes result sent to driver
18/02/28 14:16:17 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 14:16:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:17 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 27) in 34 ms on localhost (executor driver) (1/4)
18/02/28 14:16:17 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 29) in 39 ms on localhost (executor driver) (2/4)
18/02/28 14:16:18 INFO Executor: Finished task 0.0 in stage 11.0 (TID 26). 2238 bytes result sent to driver
18/02/28 14:16:18 INFO Executor: Finished task 2.0 in stage 11.0 (TID 28). 2281 bytes result sent to driver
18/02/28 14:16:18 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 26) in 50 ms on localhost (executor driver) (3/4)
18/02/28 14:16:18 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 28) in 50 ms on localhost (executor driver) (4/4)
18/02/28 14:16:18 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
18/02/28 14:16:18 INFO DAGScheduler: ResultStage 11 (collect at utils.scala:211) finished in 0.052 s
18/02/28 14:16:18 INFO DAGScheduler: Job 6 finished: collect at utils.scala:211, took 0.682152 s
18/02/28 14:16:18 INFO CodeGenerator: Code generated in 9.777362 ms
18/02/28 14:16:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
WHERE (NOT(((`arr_delay`) IS NULL)))
18/02/28 14:16:19 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8c82fe65084
18/02/28 14:16:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8c82fe65084` AS `zzz4`
WHERE (0 = 1)
18/02/28 14:16:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8c82fe65084`
18/02/28 14:16:20 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8c870867479
18/02/28 14:16:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:20 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8c870867479` AS `zzz5`
WHERE (0 = 1)
18/02/28 14:16:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:20 INFO SparkSqlParser: Parsing command: SELECT `month`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`, `sched_dep_time`, `sched_arr_time`, `delayed`, CONCAT("h", CAST(`dephour` AS INT)) AS `dephour`
FROM `sparklyr_tmp_8c870867479`
18/02/28 14:16:20 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:16:20 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:16:20 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8c87e3f4021
18/02/28 14:16:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:20 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8c87e3f4021` AS `zzz6`
WHERE (0 = 1)
18/02/28 14:16:20 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8c819791486
18/02/28 14:16:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:20 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8c819791486` AS `zzz7`
WHERE (0 = 1)
18/02/28 14:16:20 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8c814634638
18/02/28 14:16:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:20 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8c814634638` AS `zzz8`
WHERE (0 = 1)
18/02/28 14:16:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:20 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_8c87e3f4021`
18/02/28 14:16:20 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:16:20 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:16:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:20 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_8c87e3f4021`
LIMIT 10
18/02/28 14:16:20 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:16:20 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:16:20 INFO CodeGenerator: Code generated in 49.059235 ms
18/02/28 14:16:20 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:16:20 INFO DAGScheduler: Registering RDD 42 (collect at utils.scala:211)
18/02/28 14:16:20 INFO DAGScheduler: Got job 7 (collect at utils.scala:211) with 1 output partitions
18/02/28 14:16:20 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:211)
18/02/28 14:16:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
18/02/28 14:16:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
18/02/28 14:16:20 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[42] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:20 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 47.6 KB, free 345.1 MB)
18/02/28 14:16:20 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 20.7 KB, free 345.1 MB)
18/02/28 14:16:20 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:61463 (size: 20.7 KB, free: 345.7 MB)
18/02/28 14:16:20 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:20 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[42] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:20 INFO TaskSchedulerImpl: Adding task set 12.0 with 4 tasks
18/02/28 14:16:20 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:20 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 31, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:20 INFO TaskSetManager: Starting task 2.0 in stage 12.0 (TID 32, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:16:20 INFO TaskSetManager: Starting task 3.0 in stage 12.0 (TID 33, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:20 INFO Executor: Running task 0.0 in stage 12.0 (TID 30)
18/02/28 14:16:20 INFO Executor: Running task 1.0 in stage 12.0 (TID 31)
18/02/28 14:16:20 INFO Executor: Running task 2.0 in stage 12.0 (TID 32)
18/02/28 14:16:20 INFO Executor: Running task 3.0 in stage 12.0 (TID 33)
18/02/28 14:16:20 INFO BlockManager: Found block rdd_13_2 locally
18/02/28 14:16:20 INFO BlockManager: Found block rdd_13_1 locally
18/02/28 14:16:20 INFO BlockManager: Found block rdd_13_3 locally
18/02/28 14:16:20 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 14:16:20 INFO CodeGenerator: Code generated in 79.135341 ms
18/02/28 14:16:20 INFO CodeGenerator: Code generated in 15.036642 ms
18/02/28 14:16:21 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:61463 in memory (size: 16.6 KB, free: 345.7 MB)
18/02/28 14:16:21 INFO ContextCleaner: Cleaned accumulator 388
18/02/28 14:16:21 INFO Executor: Finished task 2.0 in stage 12.0 (TID 32). 2408 bytes result sent to driver
18/02/28 14:16:21 INFO TaskSetManager: Finished task 2.0 in stage 12.0 (TID 32) in 1188 ms on localhost (executor driver) (1/4)
18/02/28 14:16:21 INFO Executor: Finished task 1.0 in stage 12.0 (TID 31). 2408 bytes result sent to driver
18/02/28 14:16:21 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 31) in 1196 ms on localhost (executor driver) (2/4)
18/02/28 14:16:21 INFO Executor: Finished task 0.0 in stage 12.0 (TID 30). 2408 bytes result sent to driver
18/02/28 14:16:21 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 30) in 1200 ms on localhost (executor driver) (3/4)
18/02/28 14:16:21 INFO Executor: Finished task 3.0 in stage 12.0 (TID 33). 2408 bytes result sent to driver
18/02/28 14:16:21 INFO TaskSetManager: Finished task 3.0 in stage 12.0 (TID 33) in 1201 ms on localhost (executor driver) (4/4)
18/02/28 14:16:21 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
18/02/28 14:16:21 INFO DAGScheduler: ShuffleMapStage 12 (collect at utils.scala:211) finished in 1.203 s
18/02/28 14:16:21 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:16:21 INFO DAGScheduler: running: Set()
18/02/28 14:16:21 INFO DAGScheduler: waiting: Set(ResultStage 13)
18/02/28 14:16:21 INFO DAGScheduler: failed: Set()
18/02/28 14:16:21 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[45] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:21 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 6.9 KB, free 345.1 MB)
18/02/28 14:16:21 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 345.1 MB)
18/02/28 14:16:21 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:61463 (size: 3.7 KB, free: 345.7 MB)
18/02/28 14:16:21 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[45] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 14:16:21 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
18/02/28 14:16:21 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 34, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 14:16:21 INFO Executor: Running task 0.0 in stage 13.0 (TID 34)
18/02/28 14:16:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:21 INFO Executor: Finished task 0.0 in stage 13.0 (TID 34). 1471 bytes result sent to driver
18/02/28 14:16:21 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 34) in 15 ms on localhost (executor driver) (1/1)
18/02/28 14:16:21 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:211) finished in 0.016 s
18/02/28 14:16:21 INFO DAGScheduler: Job 7 finished: collect at utils.scala:211, took 1.240358 s
18/02/28 14:16:21 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
18/02/28 14:16:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8c87e3f4021`
18/02/28 14:16:22 INFO SparkSqlParser: Parsing command: training
18/02/28 14:16:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training` AS `zzz9`
WHERE (0 = 1)
18/02/28 14:16:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:22 INFO SparkSqlParser: Parsing command: CACHE TABLE `training`
18/02/28 14:16:22 INFO SparkSqlParser: Parsing command: `training`
18/02/28 14:16:22 INFO CodeGenerator: Code generated in 33.449591 ms
18/02/28 14:16:22 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 14:16:22 INFO DAGScheduler: Registering RDD 51 (sql at <unknown>:0)
18/02/28 14:16:22 INFO DAGScheduler: Got job 8 (sql at <unknown>:0) with 1 output partitions
18/02/28 14:16:22 INFO DAGScheduler: Final stage: ResultStage 15 (sql at <unknown>:0)
18/02/28 14:16:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
18/02/28 14:16:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)
18/02/28 14:16:22 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[51] at sql at <unknown>:0), which has no missing parents
18/02/28 14:16:22 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 53.6 KB, free 345.0 MB)
18/02/28 14:16:22 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 22.0 KB, free 345.0 MB)
18/02/28 14:16:22 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:61463 (size: 22.0 KB, free: 345.7 MB)
18/02/28 14:16:22 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:22 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[51] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:22 INFO TaskSchedulerImpl: Adding task set 14.0 with 4 tasks
18/02/28 14:16:22 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:22 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 36, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:22 INFO TaskSetManager: Starting task 2.0 in stage 14.0 (TID 37, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:16:22 INFO TaskSetManager: Starting task 3.0 in stage 14.0 (TID 38, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:22 INFO Executor: Running task 0.0 in stage 14.0 (TID 35)
18/02/28 14:16:22 INFO Executor: Running task 1.0 in stage 14.0 (TID 36)
18/02/28 14:16:22 INFO Executor: Running task 2.0 in stage 14.0 (TID 37)
18/02/28 14:16:22 INFO Executor: Running task 3.0 in stage 14.0 (TID 38)
18/02/28 14:16:22 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 14:16:22 INFO BlockManager: Found block rdd_13_1 locally
18/02/28 14:16:22 INFO BlockManager: Found block rdd_13_2 locally
18/02/28 14:16:22 INFO BlockManager: Found block rdd_13_3 locally
18/02/28 14:16:22 INFO MemoryStore: Block rdd_48_3 stored as values in memory (estimated size 56.1 KB, free 311.0 MB)
18/02/28 14:16:22 INFO BlockManagerInfo: Added rdd_48_3 in memory on 127.0.0.1:61463 (size: 56.1 KB, free: 345.7 MB)
18/02/28 14:16:22 INFO MemoryStore: Block rdd_48_0 stored as values in memory (estimated size 61.6 KB, free 324.9 MB)
18/02/28 14:16:22 INFO BlockManagerInfo: Added rdd_48_0 in memory on 127.0.0.1:61463 (size: 61.6 KB, free: 345.6 MB)
18/02/28 14:16:22 INFO MemoryStore: Block rdd_48_1 stored as values in memory (estimated size 66.7 KB, free 334.8 MB)
18/02/28 14:16:22 INFO BlockManagerInfo: Added rdd_48_1 in memory on 127.0.0.1:61463 (size: 66.7 KB, free: 345.5 MB)
18/02/28 14:16:22 INFO Executor: Finished task 3.0 in stage 14.0 (TID 38). 3099 bytes result sent to driver
18/02/28 14:16:22 INFO TaskSetManager: Finished task 3.0 in stage 14.0 (TID 38) in 641 ms on localhost (executor driver) (1/4)
18/02/28 14:16:22 INFO MemoryStore: Block rdd_48_2 stored as values in memory (estimated size 60.0 KB, free 344.8 MB)
18/02/28 14:16:22 INFO BlockManagerInfo: Added rdd_48_2 in memory on 127.0.0.1:61463 (size: 60.0 KB, free: 345.5 MB)
18/02/28 14:16:22 INFO Executor: Finished task 1.0 in stage 14.0 (TID 36). 3056 bytes result sent to driver
18/02/28 14:16:22 INFO Executor: Finished task 0.0 in stage 14.0 (TID 35). 3099 bytes result sent to driver
18/02/28 14:16:22 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 35) in 703 ms on localhost (executor driver) (2/4)
18/02/28 14:16:22 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 36) in 703 ms on localhost (executor driver) (3/4)
18/02/28 14:16:22 INFO Executor: Finished task 2.0 in stage 14.0 (TID 37). 3056 bytes result sent to driver
18/02/28 14:16:22 INFO TaskSetManager: Finished task 2.0 in stage 14.0 (TID 37) in 741 ms on localhost (executor driver) (4/4)
18/02/28 14:16:22 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
18/02/28 14:16:22 INFO DAGScheduler: ShuffleMapStage 14 (sql at <unknown>:0) finished in 0.744 s
18/02/28 14:16:22 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:16:22 INFO DAGScheduler: running: Set()
18/02/28 14:16:22 INFO DAGScheduler: waiting: Set(ResultStage 15)
18/02/28 14:16:22 INFO DAGScheduler: failed: Set()
18/02/28 14:16:22 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[54] at sql at <unknown>:0), which has no missing parents
18/02/28 14:16:22 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 344.8 MB)
18/02/28 14:16:22 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KB, free 344.8 MB)
18/02/28 14:16:22 INFO ContextCleaner: Cleaned accumulator 462
18/02/28 14:16:22 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:61463 (size: 3.7 KB, free: 345.5 MB)
18/02/28 14:16:22 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[54] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 14:16:22 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
18/02/28 14:16:22 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 39, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 14:16:22 INFO Executor: Running task 0.0 in stage 15.0 (TID 39)
18/02/28 14:16:22 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:61463 in memory (size: 3.7 KB, free: 345.5 MB)
18/02/28 14:16:22 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:22 INFO Executor: Finished task 0.0 in stage 15.0 (TID 39). 1538 bytes result sent to driver
18/02/28 14:16:22 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 39) in 13 ms on localhost (executor driver) (1/1)
18/02/28 14:16:22 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
18/02/28 14:16:22 INFO DAGScheduler: ResultStage 15 (sql at <unknown>:0) finished in 0.015 s
18/02/28 14:16:22 INFO DAGScheduler: Job 8 finished: sql at <unknown>:0, took 0.807628 s
18/02/28 14:16:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:23 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `training`
18/02/28 14:16:23 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:16:23 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:16:23 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:16:23 INFO DAGScheduler: Registering RDD 57 (collect at utils.scala:211)
18/02/28 14:16:23 INFO DAGScheduler: Got job 9 (collect at utils.scala:211) with 1 output partitions
18/02/28 14:16:23 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:211)
18/02/28 14:16:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
18/02/28 14:16:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)
18/02/28 14:16:23 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[57] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:23 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 53.6 KB, free 344.7 MB)
18/02/28 14:16:23 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 22.1 KB, free 344.7 MB)
18/02/28 14:16:23 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:61463 (size: 22.1 KB, free: 345.5 MB)
18/02/28 14:16:23 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:23 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[57] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:23 INFO TaskSchedulerImpl: Adding task set 16.0 with 4 tasks
18/02/28 14:16:23 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 40, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:23 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 41, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:23 INFO TaskSetManager: Starting task 2.0 in stage 16.0 (TID 42, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:16:23 INFO TaskSetManager: Starting task 3.0 in stage 16.0 (TID 43, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:23 INFO Executor: Running task 0.0 in stage 16.0 (TID 40)
18/02/28 14:16:23 INFO BlockManager: Found block rdd_48_0 locally
18/02/28 14:16:23 INFO Executor: Running task 1.0 in stage 16.0 (TID 41)
18/02/28 14:16:23 INFO Executor: Running task 2.0 in stage 16.0 (TID 42)
18/02/28 14:16:23 INFO Executor: Running task 3.0 in stage 16.0 (TID 43)
18/02/28 14:16:23 INFO BlockManager: Found block rdd_48_2 locally
18/02/28 14:16:23 INFO BlockManager: Found block rdd_48_3 locally
18/02/28 14:16:23 INFO BlockManager: Found block rdd_48_1 locally
18/02/28 14:16:23 INFO Executor: Finished task 0.0 in stage 16.0 (TID 40). 2332 bytes result sent to driver
18/02/28 14:16:23 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 40) in 70 ms on localhost (executor driver) (1/4)
18/02/28 14:16:23 INFO Executor: Finished task 3.0 in stage 16.0 (TID 43). 2332 bytes result sent to driver
18/02/28 14:16:23 INFO TaskSetManager: Finished task 3.0 in stage 16.0 (TID 43) in 72 ms on localhost (executor driver) (2/4)
18/02/28 14:16:23 INFO Executor: Finished task 2.0 in stage 16.0 (TID 42). 2332 bytes result sent to driver
18/02/28 14:16:23 INFO TaskSetManager: Finished task 2.0 in stage 16.0 (TID 42) in 78 ms on localhost (executor driver) (3/4)
18/02/28 14:16:23 INFO Executor: Finished task 1.0 in stage 16.0 (TID 41). 2289 bytes result sent to driver
18/02/28 14:16:23 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 41) in 82 ms on localhost (executor driver) (4/4)
18/02/28 14:16:23 INFO DAGScheduler: ShuffleMapStage 16 (collect at utils.scala:211) finished in 0.083 s
18/02/28 14:16:23 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:16:23 INFO DAGScheduler: running: Set()
18/02/28 14:16:23 INFO DAGScheduler: waiting: Set(ResultStage 17)
18/02/28 14:16:23 INFO DAGScheduler: failed: Set()
18/02/28 14:16:23 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[60] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:23 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 7.0 KB, free 344.7 MB)
18/02/28 14:16:23 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 3.7 KB, free 344.7 MB)
18/02/28 14:16:23 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
18/02/28 14:16:23 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:61463 (size: 3.7 KB, free: 345.5 MB)
18/02/28 14:16:23 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[60] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 14:16:23 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
18/02/28 14:16:23 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 44, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 14:16:23 INFO Executor: Running task 0.0 in stage 17.0 (TID 44)
18/02/28 14:16:23 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:23 INFO Executor: Finished task 0.0 in stage 17.0 (TID 44). 1452 bytes result sent to driver
18/02/28 14:16:23 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 44) in 9 ms on localhost (executor driver) (1/1)
18/02/28 14:16:23 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
18/02/28 14:16:23 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:211) finished in 0.009 s
18/02/28 14:16:23 INFO DAGScheduler: Job 9 finished: collect at utils.scala:211, took 0.118467 s
18/02/28 14:16:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 14:16:23 INFO CodeGenerator: Code generated in 7.254388 ms
18/02/28 14:16:23 INFO SparkContext: Starting job: countByValue at StringIndexer.scala:113
18/02/28 14:16:23 INFO DAGScheduler: Registering RDD 67 (countByValue at StringIndexer.scala:113)
18/02/28 14:16:23 INFO DAGScheduler: Got job 10 (countByValue at StringIndexer.scala:113) with 4 output partitions
18/02/28 14:16:23 INFO DAGScheduler: Final stage: ResultStage 19 (countByValue at StringIndexer.scala:113)
18/02/28 14:16:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
18/02/28 14:16:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 18)
18/02/28 14:16:23 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[67] at countByValue at StringIndexer.scala:113), which has no missing parents
18/02/28 14:16:23 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 55.3 KB, free 344.6 MB)
18/02/28 14:16:23 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 22.9 KB, free 344.6 MB)
18/02/28 14:16:23 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:61463 (size: 22.9 KB, free: 345.4 MB)
18/02/28 14:16:23 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:23 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[67] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:23 INFO TaskSchedulerImpl: Adding task set 18.0 with 4 tasks
18/02/28 14:16:23 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 45, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:23 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 46, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:23 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 47, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:16:23 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 48, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:23 INFO Executor: Running task 1.0 in stage 18.0 (TID 46)
18/02/28 14:16:23 INFO Executor: Running task 0.0 in stage 18.0 (TID 45)
18/02/28 14:16:23 INFO BlockManager: Found block rdd_48_0 locally
18/02/28 14:16:23 INFO BlockManager: Found block rdd_48_1 locally
18/02/28 14:16:23 INFO Executor: Running task 3.0 in stage 18.0 (TID 48)
18/02/28 14:16:23 INFO Executor: Running task 2.0 in stage 18.0 (TID 47)
18/02/28 14:16:23 INFO BlockManager: Found block rdd_48_2 locally
18/02/28 14:16:23 INFO CodeGenerator: Code generated in 18.264497 ms
18/02/28 14:16:23 INFO BlockManager: Found block rdd_48_3 locally
18/02/28 14:16:23 INFO CodeGenerator: Code generated in 28.678332 ms
18/02/28 14:16:24 INFO Executor: Finished task 3.0 in stage 18.0 (TID 48). 2277 bytes result sent to driver
18/02/28 14:16:24 INFO TaskSetManager: Finished task 3.0 in stage 18.0 (TID 48) in 222 ms on localhost (executor driver) (1/4)
18/02/28 14:16:24 INFO Executor: Finished task 1.0 in stage 18.0 (TID 46). 2277 bytes result sent to driver
18/02/28 14:16:24 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 46) in 236 ms on localhost (executor driver) (2/4)
18/02/28 14:16:24 INFO Executor: Finished task 0.0 in stage 18.0 (TID 45). 2277 bytes result sent to driver
18/02/28 14:16:24 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 45) in 252 ms on localhost (executor driver) (3/4)
18/02/28 14:16:24 INFO Executor: Finished task 2.0 in stage 18.0 (TID 47). 2277 bytes result sent to driver
18/02/28 14:16:24 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 47) in 258 ms on localhost (executor driver) (4/4)
18/02/28 14:16:24 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
18/02/28 14:16:24 INFO DAGScheduler: ShuffleMapStage 18 (countByValue at StringIndexer.scala:113) finished in 0.260 s
18/02/28 14:16:24 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:16:24 INFO DAGScheduler: running: Set()
18/02/28 14:16:24 INFO DAGScheduler: waiting: Set(ResultStage 19)
18/02/28 14:16:24 INFO DAGScheduler: failed: Set()
18/02/28 14:16:24 INFO DAGScheduler: Submitting ResultStage 19 (ShuffledRDD[68] at countByValue at StringIndexer.scala:113), which has no missing parents
18/02/28 14:16:24 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 3.2 KB, free 344.6 MB)
18/02/28 14:16:24 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 1963.0 B, free 344.6 MB)
18/02/28 14:16:24 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:61463 (size: 1963.0 B, free: 345.4 MB)
18/02/28 14:16:24 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:24 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 19 (ShuffledRDD[68] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:24 INFO TaskSchedulerImpl: Adding task set 19.0 with 4 tasks
18/02/28 14:16:24 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 49, localhost, executor driver, partition 0, ANY, 4621 bytes)
18/02/28 14:16:24 INFO TaskSetManager: Starting task 1.0 in stage 19.0 (TID 50, localhost, executor driver, partition 1, ANY, 4621 bytes)
18/02/28 14:16:24 INFO TaskSetManager: Starting task 2.0 in stage 19.0 (TID 51, localhost, executor driver, partition 2, ANY, 4621 bytes)
18/02/28 14:16:24 INFO TaskSetManager: Starting task 3.0 in stage 19.0 (TID 52, localhost, executor driver, partition 3, ANY, 4621 bytes)
18/02/28 14:16:24 INFO Executor: Running task 0.0 in stage 19.0 (TID 49)
18/02/28 14:16:24 INFO Executor: Running task 2.0 in stage 19.0 (TID 51)
18/02/28 14:16:24 INFO Executor: Running task 3.0 in stage 19.0 (TID 52)
18/02/28 14:16:24 INFO Executor: Running task 1.0 in stage 19.0 (TID 50)
18/02/28 14:16:24 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
18/02/28 14:16:24 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:24 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:24 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:24 INFO Executor: Finished task 0.0 in stage 19.0 (TID 49). 1153 bytes result sent to driver
18/02/28 14:16:24 INFO Executor: Finished task 1.0 in stage 19.0 (TID 50). 1178 bytes result sent to driver
18/02/28 14:16:24 INFO Executor: Finished task 3.0 in stage 19.0 (TID 52). 1153 bytes result sent to driver
18/02/28 14:16:24 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 49) in 62 ms on localhost (executor driver) (1/4)
18/02/28 14:16:24 INFO Executor: Finished task 2.0 in stage 19.0 (TID 51). 1196 bytes result sent to driver
18/02/28 14:16:24 INFO TaskSetManager: Finished task 1.0 in stage 19.0 (TID 50) in 66 ms on localhost (executor driver) (2/4)
18/02/28 14:16:24 INFO TaskSetManager: Finished task 2.0 in stage 19.0 (TID 51) in 69 ms on localhost (executor driver) (3/4)
18/02/28 14:16:24 INFO TaskSetManager: Finished task 3.0 in stage 19.0 (TID 52) in 70 ms on localhost (executor driver) (4/4)
18/02/28 14:16:24 INFO DAGScheduler: ResultStage 19 (countByValue at StringIndexer.scala:113) finished in 0.072 s
18/02/28 14:16:24 INFO DAGScheduler: Job 10 finished: countByValue at StringIndexer.scala:113, took 0.560962 s
18/02/28 14:16:24 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
18/02/28 14:16:24 INFO CodeGenerator: Code generated in 25.73786 ms
18/02/28 14:16:24 INFO SparkContext: Starting job: countByValue at StringIndexer.scala:113
18/02/28 14:16:24 INFO DAGScheduler: Registering RDD 75 (countByValue at StringIndexer.scala:113)
18/02/28 14:16:24 INFO DAGScheduler: Got job 11 (countByValue at StringIndexer.scala:113) with 4 output partitions
18/02/28 14:16:24 INFO DAGScheduler: Final stage: ResultStage 21 (countByValue at StringIndexer.scala:113)
18/02/28 14:16:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
18/02/28 14:16:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
18/02/28 14:16:24 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[75] at countByValue at StringIndexer.scala:113), which has no missing parents
18/02/28 14:16:24 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 56.1 KB, free 344.6 MB)
18/02/28 14:16:24 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 23.1 KB, free 344.5 MB)
18/02/28 14:16:24 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:61463 (size: 23.1 KB, free: 345.4 MB)
18/02/28 14:16:24 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:24 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[75] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:24 INFO TaskSchedulerImpl: Adding task set 20.0 with 4 tasks
18/02/28 14:16:24 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:24 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 54, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:24 INFO TaskSetManager: Starting task 2.0 in stage 20.0 (TID 55, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:16:24 INFO TaskSetManager: Starting task 3.0 in stage 20.0 (TID 56, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:24 INFO Executor: Running task 0.0 in stage 20.0 (TID 53)
18/02/28 14:16:24 INFO Executor: Running task 1.0 in stage 20.0 (TID 54)
18/02/28 14:16:24 INFO Executor: Running task 2.0 in stage 20.0 (TID 55)
18/02/28 14:16:24 INFO Executor: Running task 3.0 in stage 20.0 (TID 56)
18/02/28 14:16:24 INFO BlockManager: Found block rdd_48_1 locally
18/02/28 14:16:24 INFO BlockManager: Found block rdd_48_3 locally
18/02/28 14:16:24 INFO BlockManager: Found block rdd_48_2 locally
18/02/28 14:16:24 INFO BlockManager: Found block rdd_48_0 locally
18/02/28 14:16:24 INFO Executor: Finished task 1.0 in stage 20.0 (TID 54). 2363 bytes result sent to driver
18/02/28 14:16:24 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 54) in 177 ms on localhost (executor driver) (1/4)
18/02/28 14:16:24 INFO Executor: Finished task 3.0 in stage 20.0 (TID 56). 2363 bytes result sent to driver
18/02/28 14:16:24 INFO TaskSetManager: Finished task 3.0 in stage 20.0 (TID 56) in 190 ms on localhost (executor driver) (2/4)
18/02/28 14:16:24 INFO Executor: Finished task 2.0 in stage 20.0 (TID 55). 2277 bytes result sent to driver
18/02/28 14:16:24 INFO TaskSetManager: Finished task 2.0 in stage 20.0 (TID 55) in 193 ms on localhost (executor driver) (3/4)
18/02/28 14:16:24 INFO Executor: Finished task 0.0 in stage 20.0 (TID 53). 2277 bytes result sent to driver
18/02/28 14:16:24 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 53) in 199 ms on localhost (executor driver) (4/4)
18/02/28 14:16:24 INFO DAGScheduler: ShuffleMapStage 20 (countByValue at StringIndexer.scala:113) finished in 0.200 s
18/02/28 14:16:24 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:16:24 INFO DAGScheduler: running: Set()
18/02/28 14:16:24 INFO DAGScheduler: waiting: Set(ResultStage 21)
18/02/28 14:16:24 INFO DAGScheduler: failed: Set()
18/02/28 14:16:24 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
18/02/28 14:16:24 INFO DAGScheduler: Submitting ResultStage 21 (ShuffledRDD[76] at countByValue at StringIndexer.scala:113), which has no missing parents
18/02/28 14:16:24 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 3.2 KB, free 344.5 MB)
18/02/28 14:16:24 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 1963.0 B, free 344.5 MB)
18/02/28 14:16:24 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:61463 (size: 1963.0 B, free: 345.4 MB)
18/02/28 14:16:24 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:24 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 21 (ShuffledRDD[76] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:24 INFO TaskSchedulerImpl: Adding task set 21.0 with 4 tasks
18/02/28 14:16:24 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 57, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:24 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 58, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:24 INFO TaskSetManager: Starting task 2.0 in stage 21.0 (TID 59, localhost, executor driver, partition 2, ANY, 4621 bytes)
18/02/28 14:16:24 INFO TaskSetManager: Starting task 3.0 in stage 21.0 (TID 60, localhost, executor driver, partition 3, ANY, 4621 bytes)
18/02/28 14:16:24 INFO Executor: Running task 0.0 in stage 21.0 (TID 57)
18/02/28 14:16:24 INFO Executor: Running task 1.0 in stage 21.0 (TID 58)
18/02/28 14:16:24 INFO Executor: Running task 2.0 in stage 21.0 (TID 59)
18/02/28 14:16:24 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 14:16:24 INFO Executor: Running task 3.0 in stage 21.0 (TID 60)
18/02/28 14:16:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:24 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 14:16:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:24 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:24 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
18/02/28 14:16:24 INFO Executor: Finished task 1.0 in stage 21.0 (TID 58). 1005 bytes result sent to driver
18/02/28 14:16:24 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 58) in 16 ms on localhost (executor driver) (1/4)
18/02/28 14:16:24 INFO Executor: Finished task 0.0 in stage 21.0 (TID 57). 1048 bytes result sent to driver
18/02/28 14:16:24 INFO Executor: Finished task 3.0 in stage 21.0 (TID 60). 1197 bytes result sent to driver
18/02/28 14:16:24 INFO Executor: Finished task 2.0 in stage 21.0 (TID 59). 1240 bytes result sent to driver
18/02/28 14:16:24 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 57) in 23 ms on localhost (executor driver) (2/4)
18/02/28 14:16:24 INFO TaskSetManager: Finished task 3.0 in stage 21.0 (TID 60) in 24 ms on localhost (executor driver) (3/4)
18/02/28 14:16:24 INFO TaskSetManager: Finished task 2.0 in stage 21.0 (TID 59) in 24 ms on localhost (executor driver) (4/4)
18/02/28 14:16:24 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
18/02/28 14:16:24 INFO DAGScheduler: ResultStage 21 (countByValue at StringIndexer.scala:113) finished in 0.025 s
18/02/28 14:16:24 INFO DAGScheduler: Job 11 finished: countByValue at StringIndexer.scala:113, took 0.243511 s
18/02/28 14:16:24 INFO CodeGenerator: Code generated in 38.917974 ms
18/02/28 14:16:25 INFO CodeGenerator: Code generated in 31.862463 ms
18/02/28 14:16:25 INFO Instrumentation: LogisticRegression-logistic_regression_8c867e64c31-826422570-1: training: numPartitions=4 storageLevel=StorageLevel(disk, memory, deserialized, 1 replicas)
18/02/28 14:16:25 INFO Instrumentation: LogisticRegression-logistic_regression_8c867e64c31-826422570-1: {"elasticNetParam":0.0,"fitIntercept":true,"threshold":0.5,"regParam":0.0,"tol":1.0E-6,"maxIter":100}
18/02/28 14:16:25 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:517
18/02/28 14:16:25 INFO DAGScheduler: Got job 12 (treeAggregate at LogisticRegression.scala:517) with 4 output partitions
18/02/28 14:16:25 INFO DAGScheduler: Final stage: ResultStage 22 (treeAggregate at LogisticRegression.scala:517)
18/02/28 14:16:25 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:16:25 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:25 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[86] at treeAggregate at LogisticRegression.scala:517), which has no missing parents
18/02/28 14:16:25 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 73.9 KB, free 344.5 MB)
18/02/28 14:16:25 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.4 MB)
18/02/28 14:16:25 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:61463 (size: 29.1 KB, free: 345.4 MB)
18/02/28 14:16:25 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:25 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 22 (MapPartitionsRDD[86] at treeAggregate at LogisticRegression.scala:517) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:25 INFO TaskSchedulerImpl: Adding task set 22.0 with 4 tasks
18/02/28 14:16:25 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:25 INFO TaskSetManager: Starting task 1.0 in stage 22.0 (TID 62, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:25 INFO TaskSetManager: Starting task 2.0 in stage 22.0 (TID 63, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:16:25 INFO TaskSetManager: Starting task 3.0 in stage 22.0 (TID 64, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:25 INFO Executor: Running task 0.0 in stage 22.0 (TID 61)
18/02/28 14:16:25 INFO Executor: Running task 1.0 in stage 22.0 (TID 62)
18/02/28 14:16:25 INFO Executor: Running task 2.0 in stage 22.0 (TID 63)
18/02/28 14:16:25 INFO Executor: Running task 3.0 in stage 22.0 (TID 64)
18/02/28 14:16:25 INFO BlockManager: Found block rdd_48_0 locally
18/02/28 14:16:25 INFO BlockManager: Found block rdd_48_3 locally
18/02/28 14:16:25 INFO BlockManager: Found block rdd_48_2 locally
18/02/28 14:16:25 INFO BlockManager: Found block rdd_48_1 locally
18/02/28 14:16:25 INFO CodeGenerator: Code generated in 16.629413 ms
18/02/28 14:16:25 INFO CodeGenerator: Code generated in 11.758363 ms
18/02/28 14:16:25 INFO MemoryStore: Block rdd_85_1 stored as values in memory (estimated size 101.0 KB, free 344.3 MB)
18/02/28 14:16:25 INFO MemoryStore: Block rdd_85_3 stored as values in memory (estimated size 78.8 KB, free 344.2 MB)
18/02/28 14:16:25 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:61463 in memory (size: 22.9 KB, free: 345.4 MB)
18/02/28 14:16:25 INFO MemoryStore: Block rdd_85_2 stored as values in memory (estimated size 90.0 KB, free 344.2 MB)
18/02/28 14:16:25 INFO BlockManagerInfo: Added rdd_85_3 in memory on 127.0.0.1:61463 (size: 78.8 KB, free: 345.3 MB)
18/02/28 14:16:25 INFO BlockManagerInfo: Added rdd_85_2 in memory on 127.0.0.1:61463 (size: 90.0 KB, free: 345.2 MB)
18/02/28 14:16:25 INFO MemoryStore: Block rdd_85_0 stored as values in memory (estimated size 89.8 KB, free 344.2 MB)
18/02/28 14:16:25 INFO BlockManagerInfo: Added rdd_85_0 in memory on 127.0.0.1:61463 (size: 89.8 KB, free: 345.2 MB)
18/02/28 14:16:25 INFO ContextCleaner: Cleaned accumulator 474
18/02/28 14:16:25 INFO ContextCleaner: Cleaned accumulator 473
18/02/28 14:16:25 INFO ContextCleaner: Cleaned accumulator 635
18/02/28 14:16:25 INFO BlockManagerInfo: Added rdd_85_1 in memory on 127.0.0.1:61463 (size: 101.0 KB, free: 345.1 MB)
18/02/28 14:16:25 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:61463 in memory (size: 22.0 KB, free: 345.1 MB)
18/02/28 14:16:25 INFO ContextCleaner: Cleaned shuffle 6
18/02/28 14:16:25 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:61463 in memory (size: 23.1 KB, free: 345.1 MB)
18/02/28 14:16:25 INFO Executor: Finished task 0.0 in stage 22.0 (TID 61). 4022 bytes result sent to driver
18/02/28 14:16:25 INFO Executor: Finished task 2.0 in stage 22.0 (TID 63). 3979 bytes result sent to driver
18/02/28 14:16:25 INFO Executor: Finished task 3.0 in stage 22.0 (TID 64). 3936 bytes result sent to driver
18/02/28 14:16:25 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 61) in 395 ms on localhost (executor driver) (1/4)
18/02/28 14:16:25 INFO Executor: Finished task 1.0 in stage 22.0 (TID 62). 3936 bytes result sent to driver
18/02/28 14:16:25 INFO TaskSetManager: Finished task 3.0 in stage 22.0 (TID 64) in 394 ms on localhost (executor driver) (2/4)
18/02/28 14:16:25 INFO TaskSetManager: Finished task 2.0 in stage 22.0 (TID 63) in 397 ms on localhost (executor driver) (3/4)
18/02/28 14:16:25 INFO TaskSetManager: Finished task 1.0 in stage 22.0 (TID 62) in 397 ms on localhost (executor driver) (4/4)
18/02/28 14:16:25 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
18/02/28 14:16:25 INFO DAGScheduler: ResultStage 22 (treeAggregate at LogisticRegression.scala:517) finished in 0.400 s
18/02/28 14:16:25 INFO DAGScheduler: Job 12 finished: treeAggregate at LogisticRegression.scala:517, took 0.409238 s
18/02/28 14:16:25 INFO ContextCleaner: Cleaned accumulator 523
18/02/28 14:16:25 INFO ContextCleaner: Cleaned shuffle 9
18/02/28 14:16:25 INFO ContextCleaner: Cleaned accumulator 584
18/02/28 14:16:25 INFO ContextCleaner: Cleaned accumulator 585
18/02/28 14:16:25 INFO ContextCleaner: Cleaned accumulator 470
18/02/28 14:16:25 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:61463 in memory (size: 3.7 KB, free: 345.1 MB)
18/02/28 14:16:25 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:61463 in memory (size: 22.1 KB, free: 345.1 MB)
18/02/28 14:16:25 INFO Instrumentation: LogisticRegression-logistic_regression_8c867e64c31-826422570-1: {"numClasses":2}
18/02/28 14:16:25 INFO ContextCleaner: Cleaned accumulator 586
18/02/28 14:16:25 INFO ContextCleaner: Cleaned accumulator 468
18/02/28 14:16:25 INFO Instrumentation: LogisticRegression-logistic_regression_8c867e64c31-826422570-1: {"numFeatures":5}
18/02/28 14:16:25 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:61463 in memory (size: 1963.0 B, free: 345.1 MB)
18/02/28 14:16:25 INFO ContextCleaner: Cleaned accumulator 636
18/02/28 14:16:25 INFO ContextCleaner: Cleaned accumulator 465
18/02/28 14:16:25 INFO ContextCleaner: Cleaned accumulator 467
18/02/28 14:16:25 INFO ContextCleaner: Cleaned accumulator 471
18/02/28 14:16:25 INFO ContextCleaner: Cleaned accumulator 637
18/02/28 14:16:25 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 80.0 B, free 344.4 MB)
18/02/28 14:16:25 INFO ContextCleaner: Cleaned shuffle 8
18/02/28 14:16:25 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 109.0 B, free 344.4 MB)
18/02/28 14:16:25 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:61463 in memory (size: 3.7 KB, free: 345.1 MB)
18/02/28 14:16:25 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:61463 (size: 109.0 B, free: 345.1 MB)
18/02/28 14:16:25 INFO SparkContext: Created broadcast 25 from broadcast at LogisticRegression.scala:600
18/02/28 14:16:25 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:61463 in memory (size: 1963.0 B, free: 345.1 MB)
18/02/28 14:16:25 INFO ContextCleaner: Cleaned accumulator 463
18/02/28 14:16:25 INFO ContextCleaner: Cleaned accumulator 472
18/02/28 14:16:25 INFO ContextCleaner: Cleaned accumulator 469
18/02/28 14:16:25 INFO ContextCleaner: Cleaned accumulator 466
18/02/28 14:16:25 INFO ContextCleaner: Cleaned accumulator 464
18/02/28 14:16:25 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 104.0 B, free 344.4 MB)
18/02/28 14:16:25 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 154.0 B, free 344.4 MB)
18/02/28 14:16:25 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:61463 (size: 154.0 B, free: 345.1 MB)
18/02/28 14:16:25 INFO SparkContext: Created broadcast 26 from broadcast at LogisticRegression.scala:1879
18/02/28 14:16:26 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:16:26 INFO DAGScheduler: Got job 13 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:16:26 INFO DAGScheduler: Final stage: ResultStage 23 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:16:26 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:16:26 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:26 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[87] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 74.1 KB, free 344.3 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.3 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:61463 (size: 29.1 KB, free: 345.1 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 23 (MapPartitionsRDD[87] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:26 INFO TaskSchedulerImpl: Adding task set 23.0 with 4 tasks
18/02/28 14:16:26 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 65, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 66, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 2.0 in stage 23.0 (TID 67, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 3.0 in stage 23.0 (TID 68, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO Executor: Running task 0.0 in stage 23.0 (TID 65)
18/02/28 14:16:26 INFO Executor: Running task 1.0 in stage 23.0 (TID 66)
18/02/28 14:16:26 INFO Executor: Running task 3.0 in stage 23.0 (TID 68)
18/02/28 14:16:26 INFO Executor: Running task 2.0 in stage 23.0 (TID 67)
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:16:26 INFO Executor: Finished task 3.0 in stage 23.0 (TID 68). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 3.0 in stage 23.0 (TID 68) in 24 ms on localhost (executor driver) (1/4)
18/02/28 14:16:26 INFO Executor: Finished task 0.0 in stage 23.0 (TID 65). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO Executor: Finished task 2.0 in stage 23.0 (TID 67). 3524 bytes result sent to driver
18/02/28 14:16:26 INFO Executor: Finished task 1.0 in stage 23.0 (TID 66). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 65) in 28 ms on localhost (executor driver) (2/4)
18/02/28 14:16:26 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 66) in 30 ms on localhost (executor driver) (3/4)
18/02/28 14:16:26 INFO TaskSetManager: Finished task 2.0 in stage 23.0 (TID 67) in 31 ms on localhost (executor driver) (4/4)
18/02/28 14:16:26 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
18/02/28 14:16:26 INFO DAGScheduler: ResultStage 23 (treeAggregate at LogisticRegression.scala:1892) finished in 0.033 s
18/02/28 14:16:26 INFO DAGScheduler: Job 13 finished: treeAggregate at LogisticRegression.scala:1892, took 0.040739 s
18/02/28 14:16:26 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
18/02/28 14:16:26 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
18/02/28 14:16:26 INFO TorrentBroadcast: Destroying Broadcast(26) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:16:26 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:61463 in memory (size: 154.0 B, free: 345.1 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 104.0 B, free 344.3 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.3 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:61463 (size: 186.0 B, free: 345.1 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 28 from broadcast at LogisticRegression.scala:1879
18/02/28 14:16:26 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:16:26 INFO DAGScheduler: Got job 14 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:16:26 INFO DAGScheduler: Final stage: ResultStage 24 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:16:26 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:16:26 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:26 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[88] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 74.1 KB, free 344.2 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.2 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:61463 (size: 29.1 KB, free: 345.1 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 24 (MapPartitionsRDD[88] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:26 INFO TaskSchedulerImpl: Adding task set 24.0 with 4 tasks
18/02/28 14:16:26 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 69, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 70, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 71, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 3.0 in stage 24.0 (TID 72, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO Executor: Running task 0.0 in stage 24.0 (TID 69)
18/02/28 14:16:26 INFO Executor: Running task 2.0 in stage 24.0 (TID 71)
18/02/28 14:16:26 INFO Executor: Running task 1.0 in stage 24.0 (TID 70)
18/02/28 14:16:26 INFO Executor: Running task 3.0 in stage 24.0 (TID 72)
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:16:26 INFO Executor: Finished task 0.0 in stage 24.0 (TID 69). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO Executor: Finished task 1.0 in stage 24.0 (TID 70). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 69) in 12 ms on localhost (executor driver) (1/4)
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:16:26 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 70) in 15 ms on localhost (executor driver) (2/4)
18/02/28 14:16:26 INFO Executor: Finished task 2.0 in stage 24.0 (TID 71). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:16:26 INFO Executor: Finished task 3.0 in stage 24.0 (TID 72). 3524 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 71) in 22 ms on localhost (executor driver) (3/4)
18/02/28 14:16:26 INFO TaskSetManager: Finished task 3.0 in stage 24.0 (TID 72) in 23 ms on localhost (executor driver) (4/4)
18/02/28 14:16:26 INFO DAGScheduler: ResultStage 24 (treeAggregate at LogisticRegression.scala:1892) finished in 0.026 s
18/02/28 14:16:26 INFO DAGScheduler: Job 14 finished: treeAggregate at LogisticRegression.scala:1892, took 0.032951 s
18/02/28 14:16:26 INFO TorrentBroadcast: Destroying Broadcast(28) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:16:26 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
18/02/28 14:16:26 INFO LBFGS: Step Size: 1.000
18/02/28 14:16:26 INFO LBFGS: Val and Grad Norm: 0.485798 (rel: 0.130) 0.212515
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 104.0 B, free 344.2 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.2 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:61463 in memory (size: 186.0 B, free: 345.1 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:61463 (size: 186.0 B, free: 345.1 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 30 from broadcast at LogisticRegression.scala:1879
18/02/28 14:16:26 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:16:26 INFO DAGScheduler: Got job 15 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:16:26 INFO DAGScheduler: Final stage: ResultStage 25 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:16:26 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:16:26 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:26 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[89] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 74.1 KB, free 344.1 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.1 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:61463 (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 25 (MapPartitionsRDD[89] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:26 INFO TaskSchedulerImpl: Adding task set 25.0 with 4 tasks
18/02/28 14:16:26 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 73, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 1.0 in stage 25.0 (TID 74, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 2.0 in stage 25.0 (TID 75, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 3.0 in stage 25.0 (TID 76, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO Executor: Running task 0.0 in stage 25.0 (TID 73)
18/02/28 14:16:26 INFO Executor: Running task 1.0 in stage 25.0 (TID 74)
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:16:26 INFO Executor: Running task 2.0 in stage 25.0 (TID 75)
18/02/28 14:16:26 INFO Executor: Running task 3.0 in stage 25.0 (TID 76)
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:16:26 INFO Executor: Finished task 0.0 in stage 25.0 (TID 73). 3481 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 73) in 19 ms on localhost (executor driver) (1/4)
18/02/28 14:16:26 INFO Executor: Finished task 1.0 in stage 25.0 (TID 74). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 1.0 in stage 25.0 (TID 74) in 19 ms on localhost (executor driver) (2/4)
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:16:26 INFO Executor: Finished task 2.0 in stage 25.0 (TID 75). 3481 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 2.0 in stage 25.0 (TID 75) in 21 ms on localhost (executor driver) (3/4)
18/02/28 14:16:26 INFO Executor: Finished task 3.0 in stage 25.0 (TID 76). 3481 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 3.0 in stage 25.0 (TID 76) in 23 ms on localhost (executor driver) (4/4)
18/02/28 14:16:26 INFO DAGScheduler: ResultStage 25 (treeAggregate at LogisticRegression.scala:1892) finished in 0.024 s
18/02/28 14:16:26 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
18/02/28 14:16:26 INFO DAGScheduler: Job 15 finished: treeAggregate at LogisticRegression.scala:1892, took 0.032188 s
18/02/28 14:16:26 INFO TorrentBroadcast: Destroying Broadcast(30) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:16:26 INFO LBFGS: Step Size: 1.000
18/02/28 14:16:26 INFO LBFGS: Val and Grad Norm: 0.358870 (rel: 0.261) 0.0815486
18/02/28 14:16:26 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:61463 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 104.0 B, free 344.1 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.1 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:61463 (size: 186.0 B, free: 345.0 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 32 from broadcast at LogisticRegression.scala:1879
18/02/28 14:16:26 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:16:26 INFO DAGScheduler: Got job 16 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:16:26 INFO DAGScheduler: Final stage: ResultStage 26 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:16:26 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:16:26 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:26 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[90] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 74.1 KB, free 344.0 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.0 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:61463 (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 26 (MapPartitionsRDD[90] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:26 INFO TaskSchedulerImpl: Adding task set 26.0 with 4 tasks
18/02/28 14:16:26 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 77, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 1.0 in stage 26.0 (TID 78, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 2.0 in stage 26.0 (TID 79, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 3.0 in stage 26.0 (TID 80, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO Executor: Running task 0.0 in stage 26.0 (TID 77)
18/02/28 14:16:26 INFO Executor: Running task 3.0 in stage 26.0 (TID 80)
18/02/28 14:16:26 INFO Executor: Running task 2.0 in stage 26.0 (TID 79)
18/02/28 14:16:26 INFO Executor: Running task 1.0 in stage 26.0 (TID 78)
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:16:26 INFO Executor: Finished task 3.0 in stage 26.0 (TID 80). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 3.0 in stage 26.0 (TID 80) in 7 ms on localhost (executor driver) (1/4)
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:16:26 INFO Executor: Finished task 2.0 in stage 26.0 (TID 79). 3481 bytes result sent to driver
18/02/28 14:16:26 INFO Executor: Finished task 1.0 in stage 26.0 (TID 78). 3481 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 2.0 in stage 26.0 (TID 79) in 11 ms on localhost (executor driver) (2/4)
18/02/28 14:16:26 INFO TaskSetManager: Finished task 1.0 in stage 26.0 (TID 78) in 12 ms on localhost (executor driver) (3/4)
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:16:26 INFO Executor: Finished task 0.0 in stage 26.0 (TID 77). 3481 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 77) in 14 ms on localhost (executor driver) (4/4)
18/02/28 14:16:26 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
18/02/28 14:16:26 INFO DAGScheduler: ResultStage 26 (treeAggregate at LogisticRegression.scala:1892) finished in 0.014 s
18/02/28 14:16:26 INFO DAGScheduler: Job 16 finished: treeAggregate at LogisticRegression.scala:1892, took 0.022779 s
18/02/28 14:16:26 INFO TorrentBroadcast: Destroying Broadcast(32) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:16:26 INFO LBFGS: Step Size: 1.000
18/02/28 14:16:26 INFO LBFGS: Val and Grad Norm: 0.321154 (rel: 0.105) 0.0463686
18/02/28 14:16:26 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:61463 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 104.0 B, free 344.0 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.0 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:61463 (size: 186.0 B, free: 345.0 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 34 from broadcast at LogisticRegression.scala:1879
18/02/28 14:16:26 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:16:26 INFO DAGScheduler: Got job 17 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:16:26 INFO DAGScheduler: Final stage: ResultStage 27 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:16:26 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:16:26 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:26 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[91] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 74.1 KB, free 343.9 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 29.1 KB, free 343.9 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:61463 (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 27 (MapPartitionsRDD[91] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:26 INFO TaskSchedulerImpl: Adding task set 27.0 with 4 tasks
18/02/28 14:16:26 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 81, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 82, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 2.0 in stage 27.0 (TID 83, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 3.0 in stage 27.0 (TID 84, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO Executor: Running task 0.0 in stage 27.0 (TID 81)
18/02/28 14:16:26 INFO Executor: Running task 1.0 in stage 27.0 (TID 82)
18/02/28 14:16:26 INFO Executor: Running task 2.0 in stage 27.0 (TID 83)
18/02/28 14:16:26 INFO Executor: Running task 3.0 in stage 27.0 (TID 84)
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:16:26 INFO Executor: Finished task 0.0 in stage 27.0 (TID 81). 3481 bytes result sent to driver
18/02/28 14:16:26 INFO Executor: Finished task 2.0 in stage 27.0 (TID 83). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 81) in 10 ms on localhost (executor driver) (1/4)
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:16:26 INFO TaskSetManager: Finished task 2.0 in stage 27.0 (TID 83) in 11 ms on localhost (executor driver) (2/4)
18/02/28 14:16:26 INFO Executor: Finished task 3.0 in stage 27.0 (TID 84). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO Executor: Finished task 1.0 in stage 27.0 (TID 82). 3524 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 3.0 in stage 27.0 (TID 84) in 13 ms on localhost (executor driver) (3/4)
18/02/28 14:16:26 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 82) in 14 ms on localhost (executor driver) (4/4)
18/02/28 14:16:26 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
18/02/28 14:16:26 INFO DAGScheduler: ResultStage 27 (treeAggregate at LogisticRegression.scala:1892) finished in 0.014 s
18/02/28 14:16:26 INFO DAGScheduler: Job 17 finished: treeAggregate at LogisticRegression.scala:1892, took 0.020062 s
18/02/28 14:16:26 INFO TorrentBroadcast: Destroying Broadcast(34) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:16:26 INFO LBFGS: Step Size: 1.000
18/02/28 14:16:26 INFO LBFGS: Val and Grad Norm: 0.296497 (rel: 0.0768) 0.0432397
18/02/28 14:16:26 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:61463 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 104.0 B, free 343.9 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.9 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:61463 (size: 186.0 B, free: 345.0 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 36 from broadcast at LogisticRegression.scala:1879
18/02/28 14:16:26 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:16:26 INFO DAGScheduler: Got job 18 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:16:26 INFO DAGScheduler: Final stage: ResultStage 28 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:16:26 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:16:26 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:26 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[92] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 74.1 KB, free 343.8 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 29.1 KB, free 343.8 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:61463 (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 28 (MapPartitionsRDD[92] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:26 INFO TaskSchedulerImpl: Adding task set 28.0 with 4 tasks
18/02/28 14:16:26 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 85, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 1.0 in stage 28.0 (TID 86, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 2.0 in stage 28.0 (TID 87, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 3.0 in stage 28.0 (TID 88, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO Executor: Running task 1.0 in stage 28.0 (TID 86)
18/02/28 14:16:26 INFO Executor: Running task 0.0 in stage 28.0 (TID 85)
18/02/28 14:16:26 INFO Executor: Running task 2.0 in stage 28.0 (TID 87)
18/02/28 14:16:26 INFO Executor: Running task 3.0 in stage 28.0 (TID 88)
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:16:26 INFO Executor: Finished task 0.0 in stage 28.0 (TID 85). 3481 bytes result sent to driver
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:16:26 INFO Executor: Finished task 3.0 in stage 28.0 (TID 88). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:16:26 INFO Executor: Finished task 2.0 in stage 28.0 (TID 87). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 85) in 15 ms on localhost (executor driver) (1/4)
18/02/28 14:16:26 INFO Executor: Finished task 1.0 in stage 28.0 (TID 86). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 3.0 in stage 28.0 (TID 88) in 15 ms on localhost (executor driver) (2/4)
18/02/28 14:16:26 INFO TaskSetManager: Finished task 2.0 in stage 28.0 (TID 87) in 15 ms on localhost (executor driver) (3/4)
18/02/28 14:16:26 INFO TaskSetManager: Finished task 1.0 in stage 28.0 (TID 86) in 16 ms on localhost (executor driver) (4/4)
18/02/28 14:16:26 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
18/02/28 14:16:26 INFO DAGScheduler: ResultStage 28 (treeAggregate at LogisticRegression.scala:1892) finished in 0.017 s
18/02/28 14:16:26 INFO DAGScheduler: Job 18 finished: treeAggregate at LogisticRegression.scala:1892, took 0.026794 s
18/02/28 14:16:26 INFO TorrentBroadcast: Destroying Broadcast(36) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:16:26 INFO LBFGS: Step Size: 1.000
18/02/28 14:16:26 INFO LBFGS: Val and Grad Norm: 0.286293 (rel: 0.0344) 0.0104585
18/02/28 14:16:26 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:61463 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 104.0 B, free 343.8 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.8 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:61463 (size: 186.0 B, free: 345.0 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 38 from broadcast at LogisticRegression.scala:1879
18/02/28 14:16:26 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:16:26 INFO DAGScheduler: Got job 19 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:16:26 INFO DAGScheduler: Final stage: ResultStage 29 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:16:26 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:16:26 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:26 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[93] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 74.1 KB, free 343.7 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 29.1 KB, free 343.7 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:61463 (size: 29.1 KB, free: 344.9 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 29 (MapPartitionsRDD[93] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:26 INFO TaskSchedulerImpl: Adding task set 29.0 with 4 tasks
18/02/28 14:16:26 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 89, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 90, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 2.0 in stage 29.0 (TID 91, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 3.0 in stage 29.0 (TID 92, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO Executor: Running task 0.0 in stage 29.0 (TID 89)
18/02/28 14:16:26 INFO Executor: Running task 1.0 in stage 29.0 (TID 90)
18/02/28 14:16:26 INFO Executor: Running task 2.0 in stage 29.0 (TID 91)
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:16:26 INFO Executor: Running task 3.0 in stage 29.0 (TID 92)
18/02/28 14:16:26 INFO Executor: Finished task 2.0 in stage 29.0 (TID 91). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:16:26 INFO TaskSetManager: Finished task 2.0 in stage 29.0 (TID 91) in 17 ms on localhost (executor driver) (1/4)
18/02/28 14:16:26 INFO Executor: Finished task 1.0 in stage 29.0 (TID 90). 3524 bytes result sent to driver
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:16:26 INFO Executor: Finished task 0.0 in stage 29.0 (TID 89). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO Executor: Finished task 3.0 in stage 29.0 (TID 92). 3481 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 90) in 21 ms on localhost (executor driver) (2/4)
18/02/28 14:16:26 INFO TaskSetManager: Finished task 3.0 in stage 29.0 (TID 92) in 20 ms on localhost (executor driver) (3/4)
18/02/28 14:16:26 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 89) in 21 ms on localhost (executor driver) (4/4)
18/02/28 14:16:26 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
18/02/28 14:16:26 INFO DAGScheduler: ResultStage 29 (treeAggregate at LogisticRegression.scala:1892) finished in 0.022 s
18/02/28 14:16:26 INFO DAGScheduler: Job 19 finished: treeAggregate at LogisticRegression.scala:1892, took 0.030526 s
18/02/28 14:16:26 INFO TorrentBroadcast: Destroying Broadcast(38) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:16:26 INFO LBFGS: Step Size: 1.000
18/02/28 14:16:26 INFO LBFGS: Val and Grad Norm: 0.284796 (rel: 0.00523) 0.00496927
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 104.0 B, free 343.7 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.7 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:61463 (size: 186.0 B, free: 344.9 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 40 from broadcast at LogisticRegression.scala:1879
18/02/28 14:16:26 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:61463 in memory (size: 186.0 B, free: 344.9 MB)
18/02/28 14:16:26 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:16:26 INFO DAGScheduler: Got job 20 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:16:26 INFO DAGScheduler: Final stage: ResultStage 30 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:16:26 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:16:26 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:26 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[94] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 74.1 KB, free 343.6 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 29.1 KB, free 343.6 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:61463 (size: 29.1 KB, free: 344.9 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 30 (MapPartitionsRDD[94] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:26 INFO TaskSchedulerImpl: Adding task set 30.0 with 4 tasks
18/02/28 14:16:26 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 93, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 94, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 2.0 in stage 30.0 (TID 95, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 3.0 in stage 30.0 (TID 96, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO Executor: Running task 1.0 in stage 30.0 (TID 94)
18/02/28 14:16:26 INFO Executor: Running task 3.0 in stage 30.0 (TID 96)
18/02/28 14:16:26 INFO Executor: Running task 2.0 in stage 30.0 (TID 95)
18/02/28 14:16:26 INFO Executor: Running task 0.0 in stage 30.0 (TID 93)
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:16:26 INFO Executor: Finished task 2.0 in stage 30.0 (TID 95). 3481 bytes result sent to driver
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:16:26 INFO Executor: Finished task 0.0 in stage 30.0 (TID 93). 3481 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 2.0 in stage 30.0 (TID 95) in 14 ms on localhost (executor driver) (1/4)
18/02/28 14:16:26 INFO Executor: Finished task 3.0 in stage 30.0 (TID 96). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:16:26 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 93) in 16 ms on localhost (executor driver) (2/4)
18/02/28 14:16:26 INFO TaskSetManager: Finished task 3.0 in stage 30.0 (TID 96) in 17 ms on localhost (executor driver) (3/4)
18/02/28 14:16:26 INFO Executor: Finished task 1.0 in stage 30.0 (TID 94). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 94) in 18 ms on localhost (executor driver) (4/4)
18/02/28 14:16:26 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
18/02/28 14:16:26 INFO DAGScheduler: ResultStage 30 (treeAggregate at LogisticRegression.scala:1892) finished in 0.019 s
18/02/28 14:16:26 INFO DAGScheduler: Job 20 finished: treeAggregate at LogisticRegression.scala:1892, took 0.023724 s
18/02/28 14:16:26 INFO TorrentBroadcast: Destroying Broadcast(40) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:16:26 INFO LBFGS: Step Size: 1.000
18/02/28 14:16:26 INFO LBFGS: Val and Grad Norm: 0.284241 (rel: 0.00195) 0.00575008
18/02/28 14:16:26 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:61463 in memory (size: 186.0 B, free: 344.9 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 104.0 B, free 343.6 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.6 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:61463 (size: 186.0 B, free: 344.9 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 42 from broadcast at LogisticRegression.scala:1879
18/02/28 14:16:26 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:16:26 INFO DAGScheduler: Got job 21 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:16:26 INFO DAGScheduler: Final stage: ResultStage 31 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:16:26 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:16:26 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:26 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[95] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 74.1 KB, free 343.5 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 29.1 KB, free 343.5 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:61463 (size: 29.1 KB, free: 344.9 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 31 (MapPartitionsRDD[95] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:26 INFO TaskSchedulerImpl: Adding task set 31.0 with 4 tasks
18/02/28 14:16:26 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 97, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 1.0 in stage 31.0 (TID 98, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 2.0 in stage 31.0 (TID 99, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 3.0 in stage 31.0 (TID 100, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO Executor: Running task 0.0 in stage 31.0 (TID 97)
18/02/28 14:16:26 INFO Executor: Running task 3.0 in stage 31.0 (TID 100)
18/02/28 14:16:26 INFO Executor: Running task 2.0 in stage 31.0 (TID 99)
18/02/28 14:16:26 INFO Executor: Running task 1.0 in stage 31.0 (TID 98)
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:16:26 INFO Executor: Finished task 3.0 in stage 31.0 (TID 100). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:16:26 INFO Executor: Finished task 1.0 in stage 31.0 (TID 98). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:16:26 INFO TaskSetManager: Finished task 3.0 in stage 31.0 (TID 100) in 9 ms on localhost (executor driver) (1/4)
18/02/28 14:16:26 INFO Executor: Finished task 2.0 in stage 31.0 (TID 99). 3481 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 1.0 in stage 31.0 (TID 98) in 10 ms on localhost (executor driver) (2/4)
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:16:26 INFO TaskSetManager: Finished task 2.0 in stage 31.0 (TID 99) in 12 ms on localhost (executor driver) (3/4)
18/02/28 14:16:26 INFO Executor: Finished task 0.0 in stage 31.0 (TID 97). 3481 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 97) in 15 ms on localhost (executor driver) (4/4)
18/02/28 14:16:26 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
18/02/28 14:16:26 INFO DAGScheduler: ResultStage 31 (treeAggregate at LogisticRegression.scala:1892) finished in 0.017 s
18/02/28 14:16:26 INFO DAGScheduler: Job 21 finished: treeAggregate at LogisticRegression.scala:1892, took 0.023931 s
18/02/28 14:16:26 INFO TorrentBroadcast: Destroying Broadcast(42) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:16:26 INFO LBFGS: Step Size: 1.000
18/02/28 14:16:26 INFO LBFGS: Val and Grad Norm: 0.283803 (rel: 0.00154) 0.00463326
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 104.0 B, free 343.5 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.5 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:61463 in memory (size: 186.0 B, free: 344.9 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:61463 (size: 186.0 B, free: 344.9 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 44 from broadcast at LogisticRegression.scala:1879
18/02/28 14:16:26 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:16:26 INFO DAGScheduler: Got job 22 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:16:26 INFO DAGScheduler: Final stage: ResultStage 32 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:16:26 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:16:26 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:26 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[96] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 74.1 KB, free 343.4 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 29.1 KB, free 343.4 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:61463 (size: 29.1 KB, free: 344.8 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 32 (MapPartitionsRDD[96] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:26 INFO TaskSchedulerImpl: Adding task set 32.0 with 4 tasks
18/02/28 14:16:26 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 101, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 102, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 2.0 in stage 32.0 (TID 103, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 3.0 in stage 32.0 (TID 104, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO Executor: Running task 0.0 in stage 32.0 (TID 101)
18/02/28 14:16:26 INFO Executor: Running task 1.0 in stage 32.0 (TID 102)
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:16:26 INFO Executor: Finished task 0.0 in stage 32.0 (TID 101). 3481 bytes result sent to driver
18/02/28 14:16:26 INFO Executor: Running task 2.0 in stage 32.0 (TID 103)
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:16:26 INFO Executor: Finished task 1.0 in stage 32.0 (TID 102). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO Executor: Running task 3.0 in stage 32.0 (TID 104)
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:16:26 INFO Executor: Finished task 2.0 in stage 32.0 (TID 103). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:16:26 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 101) in 29 ms on localhost (executor driver) (1/4)
18/02/28 14:16:26 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 102) in 30 ms on localhost (executor driver) (2/4)
18/02/28 14:16:26 INFO TaskSetManager: Finished task 2.0 in stage 32.0 (TID 103) in 30 ms on localhost (executor driver) (3/4)
18/02/28 14:16:26 INFO Executor: Finished task 3.0 in stage 32.0 (TID 104). 3524 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 3.0 in stage 32.0 (TID 104) in 32 ms on localhost (executor driver) (4/4)
18/02/28 14:16:26 INFO DAGScheduler: ResultStage 32 (treeAggregate at LogisticRegression.scala:1892) finished in 0.034 s
18/02/28 14:16:26 INFO DAGScheduler: Job 22 finished: treeAggregate at LogisticRegression.scala:1892, took 0.046128 s
18/02/28 14:16:26 INFO TorrentBroadcast: Destroying Broadcast(44) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:16:26 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
18/02/28 14:16:26 INFO LBFGS: Step Size: 1.000
18/02/28 14:16:26 INFO LBFGS: Val and Grad Norm: 0.283457 (rel: 0.00122) 0.00342443
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 104.0 B, free 343.4 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.4 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:61463 (size: 186.0 B, free: 344.8 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 46 from broadcast at LogisticRegression.scala:1879
18/02/28 14:16:26 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:61463 in memory (size: 186.0 B, free: 344.8 MB)
18/02/28 14:16:26 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:16:26 INFO DAGScheduler: Got job 23 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:16:26 INFO DAGScheduler: Final stage: ResultStage 33 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:16:26 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:16:26 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:26 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[97] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 74.1 KB, free 343.3 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 29.1 KB, free 343.3 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:61463 (size: 29.1 KB, free: 344.8 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 33 (MapPartitionsRDD[97] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:26 INFO TaskSchedulerImpl: Adding task set 33.0 with 4 tasks
18/02/28 14:16:26 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 105, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 1.0 in stage 33.0 (TID 106, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 2.0 in stage 33.0 (TID 107, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 3.0 in stage 33.0 (TID 108, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO Executor: Running task 0.0 in stage 33.0 (TID 105)
18/02/28 14:16:26 INFO Executor: Running task 1.0 in stage 33.0 (TID 106)
18/02/28 14:16:26 INFO Executor: Running task 2.0 in stage 33.0 (TID 107)
18/02/28 14:16:26 INFO Executor: Running task 3.0 in stage 33.0 (TID 108)
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:16:26 INFO Executor: Finished task 2.0 in stage 33.0 (TID 107). 3481 bytes result sent to driver
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:16:26 INFO Executor: Finished task 0.0 in stage 33.0 (TID 105). 3524 bytes result sent to driver
18/02/28 14:16:26 INFO Executor: Finished task 1.0 in stage 33.0 (TID 106). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 2.0 in stage 33.0 (TID 107) in 32 ms on localhost (executor driver) (1/4)
18/02/28 14:16:26 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 105) in 34 ms on localhost (executor driver) (2/4)
18/02/28 14:16:26 INFO TaskSetManager: Finished task 1.0 in stage 33.0 (TID 106) in 34 ms on localhost (executor driver) (3/4)
18/02/28 14:16:26 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:61463 in memory (size: 29.1 KB, free: 344.8 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:61463 in memory (size: 29.1 KB, free: 344.9 MB)
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:16:26 INFO Executor: Finished task 3.0 in stage 33.0 (TID 108). 3481 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 3.0 in stage 33.0 (TID 108) in 37 ms on localhost (executor driver) (4/4)
18/02/28 14:16:26 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
18/02/28 14:16:26 INFO DAGScheduler: ResultStage 33 (treeAggregate at LogisticRegression.scala:1892) finished in 0.038 s
18/02/28 14:16:26 INFO DAGScheduler: Job 23 finished: treeAggregate at LogisticRegression.scala:1892, took 0.045865 s
18/02/28 14:16:26 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:61463 in memory (size: 29.1 KB, free: 344.9 MB)
18/02/28 14:16:26 INFO TorrentBroadcast: Destroying Broadcast(46) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:16:26 INFO LBFGS: Step Size: 1.000
18/02/28 14:16:26 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:61463 in memory (size: 186.0 B, free: 344.9 MB)
18/02/28 14:16:26 INFO LBFGS: Val and Grad Norm: 0.283055 (rel: 0.00142) 0.00412239
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 104.0 B, free 343.6 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:61463 in memory (size: 29.1 KB, free: 344.9 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.7 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:61463 in memory (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:61463 (size: 186.0 B, free: 345.0 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 48 from broadcast at LogisticRegression.scala:1879
18/02/28 14:16:26 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:61463 in memory (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:61463 in memory (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:61463 in memory (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:61463 in memory (size: 29.1 KB, free: 345.1 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:61463 in memory (size: 29.1 KB, free: 345.1 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:61463 in memory (size: 29.1 KB, free: 345.1 MB)
18/02/28 14:16:26 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:16:26 INFO DAGScheduler: Got job 24 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:16:26 INFO DAGScheduler: Final stage: ResultStage 34 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:16:26 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:16:26 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:26 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[98] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 74.1 KB, free 344.3 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.3 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:61463 (size: 29.1 KB, free: 345.1 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 34 (MapPartitionsRDD[98] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:26 INFO TaskSchedulerImpl: Adding task set 34.0 with 4 tasks
18/02/28 14:16:26 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 109, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 1.0 in stage 34.0 (TID 110, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 2.0 in stage 34.0 (TID 111, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 3.0 in stage 34.0 (TID 112, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO Executor: Running task 0.0 in stage 34.0 (TID 109)
18/02/28 14:16:26 INFO Executor: Running task 3.0 in stage 34.0 (TID 112)
18/02/28 14:16:26 INFO Executor: Running task 2.0 in stage 34.0 (TID 111)
18/02/28 14:16:26 INFO Executor: Running task 1.0 in stage 34.0 (TID 110)
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:16:26 INFO Executor: Finished task 2.0 in stage 34.0 (TID 111). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO Executor: Finished task 1.0 in stage 34.0 (TID 110). 3481 bytes result sent to driver
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:16:26 INFO Executor: Finished task 0.0 in stage 34.0 (TID 109). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:16:26 INFO TaskSetManager: Finished task 2.0 in stage 34.0 (TID 111) in 14 ms on localhost (executor driver) (1/4)
18/02/28 14:16:26 INFO Executor: Finished task 3.0 in stage 34.0 (TID 112). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 1.0 in stage 34.0 (TID 110) in 15 ms on localhost (executor driver) (2/4)
18/02/28 14:16:26 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 109) in 17 ms on localhost (executor driver) (3/4)
18/02/28 14:16:26 INFO TaskSetManager: Finished task 3.0 in stage 34.0 (TID 112) in 16 ms on localhost (executor driver) (4/4)
18/02/28 14:16:26 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
18/02/28 14:16:26 INFO DAGScheduler: ResultStage 34 (treeAggregate at LogisticRegression.scala:1892) finished in 0.018 s
18/02/28 14:16:26 INFO DAGScheduler: Job 24 finished: treeAggregate at LogisticRegression.scala:1892, took 0.024830 s
18/02/28 14:16:26 INFO TorrentBroadcast: Destroying Broadcast(48) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:16:26 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:61463 in memory (size: 186.0 B, free: 345.1 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 104.0 B, free 344.3 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.3 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:61463 (size: 186.0 B, free: 345.1 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 50 from broadcast at LogisticRegression.scala:1879
18/02/28 14:16:26 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:16:26 INFO DAGScheduler: Got job 25 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:16:26 INFO DAGScheduler: Final stage: ResultStage 35 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:16:26 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:16:26 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:26 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[99] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 74.1 KB, free 344.2 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.2 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:61463 (size: 29.1 KB, free: 345.1 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 35 (MapPartitionsRDD[99] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:26 INFO TaskSchedulerImpl: Adding task set 35.0 with 4 tasks
18/02/28 14:16:26 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 113, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 1.0 in stage 35.0 (TID 114, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 2.0 in stage 35.0 (TID 115, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 3.0 in stage 35.0 (TID 116, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO Executor: Running task 0.0 in stage 35.0 (TID 113)
18/02/28 14:16:26 INFO Executor: Running task 3.0 in stage 35.0 (TID 116)
18/02/28 14:16:26 INFO Executor: Running task 2.0 in stage 35.0 (TID 115)
18/02/28 14:16:26 INFO Executor: Running task 1.0 in stage 35.0 (TID 114)
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:16:26 INFO Executor: Finished task 3.0 in stage 35.0 (TID 116). 3481 bytes result sent to driver
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:16:26 INFO Executor: Finished task 1.0 in stage 35.0 (TID 114). 3481 bytes result sent to driver
18/02/28 14:16:26 INFO Executor: Finished task 0.0 in stage 35.0 (TID 113). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO Executor: Finished task 2.0 in stage 35.0 (TID 115). 3481 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 3.0 in stage 35.0 (TID 116) in 8 ms on localhost (executor driver) (1/4)
18/02/28 14:16:26 INFO TaskSetManager: Finished task 1.0 in stage 35.0 (TID 114) in 9 ms on localhost (executor driver) (2/4)
18/02/28 14:16:26 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 113) in 9 ms on localhost (executor driver) (3/4)
18/02/28 14:16:26 INFO TaskSetManager: Finished task 2.0 in stage 35.0 (TID 115) in 10 ms on localhost (executor driver) (4/4)
18/02/28 14:16:26 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
18/02/28 14:16:26 INFO DAGScheduler: ResultStage 35 (treeAggregate at LogisticRegression.scala:1892) finished in 0.010 s
18/02/28 14:16:26 INFO DAGScheduler: Job 25 finished: treeAggregate at LogisticRegression.scala:1892, took 0.017359 s
18/02/28 14:16:26 INFO TorrentBroadcast: Destroying Broadcast(50) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:16:26 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:61463 in memory (size: 186.0 B, free: 345.1 MB)
18/02/28 14:16:26 INFO StrongWolfeLineSearch: Line search t: 0.5109465313502409 fval: 0.28296906947447287 rhs: 0.28305541797107925 cdd: -5.09825339662707E-9
18/02/28 14:16:26 INFO LBFGS: Step Size: 0.5109
18/02/28 14:16:26 INFO LBFGS: Val and Grad Norm: 0.282969 (rel: 0.000305) 0.000781003
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 104.0 B, free 344.2 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.2 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:61463 (size: 186.0 B, free: 345.1 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 52 from broadcast at LogisticRegression.scala:1879
18/02/28 14:16:26 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:16:26 INFO DAGScheduler: Got job 26 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:16:26 INFO DAGScheduler: Final stage: ResultStage 36 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:16:26 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:16:26 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:26 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[100] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 74.1 KB, free 344.1 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.1 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:61463 (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 36 (MapPartitionsRDD[100] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:26 INFO TaskSchedulerImpl: Adding task set 36.0 with 4 tasks
18/02/28 14:16:26 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 117, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 1.0 in stage 36.0 (TID 118, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 2.0 in stage 36.0 (TID 119, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 3.0 in stage 36.0 (TID 120, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO Executor: Running task 1.0 in stage 36.0 (TID 118)
18/02/28 14:16:26 INFO Executor: Running task 2.0 in stage 36.0 (TID 119)
18/02/28 14:16:26 INFO Executor: Running task 3.0 in stage 36.0 (TID 120)
18/02/28 14:16:26 INFO Executor: Running task 0.0 in stage 36.0 (TID 117)
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:16:26 INFO Executor: Finished task 3.0 in stage 36.0 (TID 120). 3481 bytes result sent to driver
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:16:26 INFO Executor: Finished task 0.0 in stage 36.0 (TID 117). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:16:26 INFO Executor: Finished task 1.0 in stage 36.0 (TID 118). 3481 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 3.0 in stage 36.0 (TID 120) in 10 ms on localhost (executor driver) (1/4)
18/02/28 14:16:26 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 117) in 12 ms on localhost (executor driver) (2/4)
18/02/28 14:16:26 INFO TaskSetManager: Finished task 1.0 in stage 36.0 (TID 118) in 12 ms on localhost (executor driver) (3/4)
18/02/28 14:16:26 INFO Executor: Finished task 2.0 in stage 36.0 (TID 119). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 2.0 in stage 36.0 (TID 119) in 12 ms on localhost (executor driver) (4/4)
18/02/28 14:16:26 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
18/02/28 14:16:26 INFO DAGScheduler: ResultStage 36 (treeAggregate at LogisticRegression.scala:1892) finished in 0.013 s
18/02/28 14:16:26 INFO DAGScheduler: Job 26 finished: treeAggregate at LogisticRegression.scala:1892, took 0.019913 s
18/02/28 14:16:26 INFO TorrentBroadcast: Destroying Broadcast(52) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:16:26 INFO LBFGS: Step Size: 1.000
18/02/28 14:16:26 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:61463 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 14:16:26 INFO LBFGS: Val and Grad Norm: 0.282961 (rel: 2.83e-05) 6.46267e-05
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 104.0 B, free 344.1 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.1 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:61463 (size: 186.0 B, free: 345.0 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 54 from broadcast at LogisticRegression.scala:1879
18/02/28 14:16:26 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:16:26 INFO DAGScheduler: Got job 27 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:16:26 INFO DAGScheduler: Final stage: ResultStage 37 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:16:26 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:16:26 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:26 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[101] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 74.1 KB, free 344.0 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.0 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:61463 (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 37 (MapPartitionsRDD[101] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:26 INFO TaskSchedulerImpl: Adding task set 37.0 with 4 tasks
18/02/28 14:16:26 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 121, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 1.0 in stage 37.0 (TID 122, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 2.0 in stage 37.0 (TID 123, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 3.0 in stage 37.0 (TID 124, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO Executor: Running task 3.0 in stage 37.0 (TID 124)
18/02/28 14:16:26 INFO Executor: Running task 1.0 in stage 37.0 (TID 122)
18/02/28 14:16:26 INFO Executor: Running task 2.0 in stage 37.0 (TID 123)
18/02/28 14:16:26 INFO Executor: Running task 0.0 in stage 37.0 (TID 121)
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:16:26 INFO Executor: Finished task 0.0 in stage 37.0 (TID 121). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:16:26 INFO Executor: Finished task 2.0 in stage 37.0 (TID 123). 3395 bytes result sent to driver
18/02/28 14:16:26 INFO Executor: Finished task 1.0 in stage 37.0 (TID 122). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 121) in 7 ms on localhost (executor driver) (1/4)
18/02/28 14:16:26 INFO Executor: Finished task 3.0 in stage 37.0 (TID 124). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 1.0 in stage 37.0 (TID 122) in 7 ms on localhost (executor driver) (2/4)
18/02/28 14:16:26 INFO TaskSetManager: Finished task 3.0 in stage 37.0 (TID 124) in 8 ms on localhost (executor driver) (3/4)
18/02/28 14:16:26 INFO TaskSetManager: Finished task 2.0 in stage 37.0 (TID 123) in 8 ms on localhost (executor driver) (4/4)
18/02/28 14:16:26 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
18/02/28 14:16:26 INFO DAGScheduler: ResultStage 37 (treeAggregate at LogisticRegression.scala:1892) finished in 0.008 s
18/02/28 14:16:26 INFO DAGScheduler: Job 27 finished: treeAggregate at LogisticRegression.scala:1892, took 0.017052 s
18/02/28 14:16:26 INFO TorrentBroadcast: Destroying Broadcast(54) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:16:26 INFO LBFGS: Step Size: 1.000
18/02/28 14:16:26 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:61463 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 14:16:26 INFO LBFGS: Val and Grad Norm: 0.282961 (rel: 1.34e-07) 4.62375e-05
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 104.0 B, free 344.0 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.0 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:61463 (size: 186.0 B, free: 345.0 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 56 from broadcast at LogisticRegression.scala:1879
18/02/28 14:16:26 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:16:26 INFO DAGScheduler: Got job 28 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:16:26 INFO DAGScheduler: Final stage: ResultStage 38 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:16:26 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:16:26 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:26 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[102] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 74.1 KB, free 343.9 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 29.1 KB, free 343.9 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:61463 (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 38 (MapPartitionsRDD[102] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:26 INFO TaskSchedulerImpl: Adding task set 38.0 with 4 tasks
18/02/28 14:16:26 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 125, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 1.0 in stage 38.0 (TID 126, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 2.0 in stage 38.0 (TID 127, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 3.0 in stage 38.0 (TID 128, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO Executor: Running task 0.0 in stage 38.0 (TID 125)
18/02/28 14:16:26 INFO Executor: Running task 3.0 in stage 38.0 (TID 128)
18/02/28 14:16:26 INFO Executor: Running task 1.0 in stage 38.0 (TID 126)
18/02/28 14:16:26 INFO Executor: Running task 2.0 in stage 38.0 (TID 127)
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:16:26 INFO Executor: Finished task 3.0 in stage 38.0 (TID 128). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:16:26 INFO TaskSetManager: Finished task 3.0 in stage 38.0 (TID 128) in 8 ms on localhost (executor driver) (1/4)
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:16:26 INFO Executor: Finished task 0.0 in stage 38.0 (TID 125). 3481 bytes result sent to driver
18/02/28 14:16:26 INFO Executor: Finished task 2.0 in stage 38.0 (TID 127). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:16:26 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 125) in 19 ms on localhost (executor driver) (2/4)
18/02/28 14:16:26 INFO Executor: Finished task 1.0 in stage 38.0 (TID 126). 3481 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 2.0 in stage 38.0 (TID 127) in 22 ms on localhost (executor driver) (3/4)
18/02/28 14:16:26 INFO TaskSetManager: Finished task 1.0 in stage 38.0 (TID 126) in 24 ms on localhost (executor driver) (4/4)
18/02/28 14:16:26 INFO DAGScheduler: ResultStage 38 (treeAggregate at LogisticRegression.scala:1892) finished in 0.024 s
18/02/28 14:16:26 INFO DAGScheduler: Job 28 finished: treeAggregate at LogisticRegression.scala:1892, took 0.030045 s
18/02/28 14:16:26 INFO TorrentBroadcast: Destroying Broadcast(56) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:16:26 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
18/02/28 14:16:26 INFO LBFGS: Step Size: 1.000
18/02/28 14:16:26 INFO LBFGS: Val and Grad Norm: 0.282961 (rel: 3.50e-08) 1.51509e-06
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 104.0 B, free 343.9 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.9 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:61463 (size: 186.0 B, free: 345.0 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 58 from broadcast at LogisticRegression.scala:1879
18/02/28 14:16:26 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:61463 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 14:16:26 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:16:26 INFO DAGScheduler: Got job 29 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:16:26 INFO DAGScheduler: Final stage: ResultStage 39 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:16:26 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:16:26 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:26 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[103] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 74.1 KB, free 343.8 MB)
18/02/28 14:16:26 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 29.1 KB, free 343.8 MB)
18/02/28 14:16:26 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:61463 (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:16:26 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 39 (MapPartitionsRDD[103] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:26 INFO TaskSchedulerImpl: Adding task set 39.0 with 4 tasks
18/02/28 14:16:26 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 129, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 1.0 in stage 39.0 (TID 130, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 2.0 in stage 39.0 (TID 131, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:16:26 INFO TaskSetManager: Starting task 3.0 in stage 39.0 (TID 132, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:26 INFO Executor: Running task 0.0 in stage 39.0 (TID 129)
18/02/28 14:16:26 INFO Executor: Running task 2.0 in stage 39.0 (TID 131)
18/02/28 14:16:26 INFO Executor: Running task 1.0 in stage 39.0 (TID 130)
18/02/28 14:16:26 INFO Executor: Running task 3.0 in stage 39.0 (TID 132)
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:16:26 INFO Executor: Finished task 1.0 in stage 39.0 (TID 130). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:16:26 INFO Executor: Finished task 0.0 in stage 39.0 (TID 129). 3481 bytes result sent to driver
18/02/28 14:16:26 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:16:26 INFO Executor: Finished task 3.0 in stage 39.0 (TID 132). 3438 bytes result sent to driver
18/02/28 14:16:26 INFO Executor: Finished task 2.0 in stage 39.0 (TID 131). 3481 bytes result sent to driver
18/02/28 14:16:26 INFO TaskSetManager: Finished task 1.0 in stage 39.0 (TID 130) in 23 ms on localhost (executor driver) (1/4)
18/02/28 14:16:26 INFO TaskSetManager: Finished task 3.0 in stage 39.0 (TID 132) in 23 ms on localhost (executor driver) (2/4)
18/02/28 14:16:26 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 129) in 24 ms on localhost (executor driver) (3/4)
18/02/28 14:16:26 INFO TaskSetManager: Finished task 2.0 in stage 39.0 (TID 131) in 24 ms on localhost (executor driver) (4/4)
18/02/28 14:16:26 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
18/02/28 14:16:26 INFO DAGScheduler: ResultStage 39 (treeAggregate at LogisticRegression.scala:1892) finished in 0.024 s
18/02/28 14:16:26 INFO DAGScheduler: Job 29 finished: treeAggregate at LogisticRegression.scala:1892, took 0.048287 s
18/02/28 14:16:26 INFO TorrentBroadcast: Destroying Broadcast(58) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:16:26 INFO LBFGS: Step Size: 1.000
18/02/28 14:16:26 INFO LBFGS: Val and Grad Norm: 0.282961 (rel: 9.58e-11) 1.35783e-07
18/02/28 14:16:26 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:61463 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 14:16:26 INFO LBFGS: Converged because gradient converged
18/02/28 14:16:26 INFO TorrentBroadcast: Destroying Broadcast(25) (from destroy at LogisticRegression.scala:796)
18/02/28 14:16:26 INFO MapPartitionsRDD: Removing RDD 85 from persistence list
18/02/28 14:16:26 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:61463 in memory (size: 109.0 B, free: 345.0 MB)
18/02/28 14:16:26 INFO BlockManager: Removing RDD 85
18/02/28 14:16:26 INFO CodeGenerator: Code generated in 29.520733 ms
18/02/28 14:16:27 INFO Instrumentation: LogisticRegression-logistic_regression_8c867e64c31-826422570-1: training finished
18/02/28 14:16:27 INFO SparkContext: Starting job: sortByKey at BinaryClassificationMetrics.scala:155
18/02/28 14:16:27 INFO DAGScheduler: Registering RDD 108 (map at LogisticRegression.scala:1398)
18/02/28 14:16:27 INFO DAGScheduler: Got job 30 (sortByKey at BinaryClassificationMetrics.scala:155) with 4 output partitions
18/02/28 14:16:27 INFO DAGScheduler: Final stage: ResultStage 41 (sortByKey at BinaryClassificationMetrics.scala:155)
18/02/28 14:16:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 40)
18/02/28 14:16:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 40)
18/02/28 14:16:27 INFO DAGScheduler: Submitting ShuffleMapStage 40 (MapPartitionsRDD[108] at map at LogisticRegression.scala:1398), which has no missing parents
18/02/28 14:16:27 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 83.1 KB, free 344.1 MB)
18/02/28 14:16:27 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 32.7 KB, free 344.1 MB)
18/02/28 14:16:27 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:61463 (size: 32.7 KB, free: 345.3 MB)
18/02/28 14:16:27 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:27 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[108] at map at LogisticRegression.scala:1398) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:27 INFO TaskSchedulerImpl: Adding task set 40.0 with 4 tasks
18/02/28 14:16:27 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 133, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:27 INFO TaskSetManager: Starting task 1.0 in stage 40.0 (TID 134, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:27 INFO TaskSetManager: Starting task 2.0 in stage 40.0 (TID 135, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:16:27 INFO TaskSetManager: Starting task 3.0 in stage 40.0 (TID 136, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:27 INFO Executor: Running task 0.0 in stage 40.0 (TID 133)
18/02/28 14:16:27 INFO Executor: Running task 1.0 in stage 40.0 (TID 134)
18/02/28 14:16:27 INFO Executor: Running task 2.0 in stage 40.0 (TID 135)
18/02/28 14:16:27 INFO Executor: Running task 3.0 in stage 40.0 (TID 136)
18/02/28 14:16:27 INFO BlockManager: Found block rdd_48_3 locally
18/02/28 14:16:27 INFO BlockManager: Found block rdd_48_0 locally
18/02/28 14:16:27 INFO BlockManager: Found block rdd_48_1 locally
18/02/28 14:16:27 INFO BlockManager: Found block rdd_48_2 locally
18/02/28 14:16:27 INFO CodeGenerator: Code generated in 19.233841 ms
18/02/28 14:16:27 INFO CodeGenerator: Code generated in 15.411474 ms
18/02/28 14:16:27 INFO Executor: Finished task 2.0 in stage 40.0 (TID 135). 2215 bytes result sent to driver
18/02/28 14:16:27 INFO TaskSetManager: Finished task 2.0 in stage 40.0 (TID 135) in 281 ms on localhost (executor driver) (1/4)
18/02/28 14:16:27 INFO Executor: Finished task 3.0 in stage 40.0 (TID 136). 2258 bytes result sent to driver
18/02/28 14:16:27 INFO TaskSetManager: Finished task 3.0 in stage 40.0 (TID 136) in 294 ms on localhost (executor driver) (2/4)
18/02/28 14:16:27 INFO Executor: Finished task 1.0 in stage 40.0 (TID 134). 2215 bytes result sent to driver
18/02/28 14:16:27 INFO TaskSetManager: Finished task 1.0 in stage 40.0 (TID 134) in 298 ms on localhost (executor driver) (3/4)
18/02/28 14:16:27 INFO Executor: Finished task 0.0 in stage 40.0 (TID 133). 2215 bytes result sent to driver
18/02/28 14:16:27 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 133) in 304 ms on localhost (executor driver) (4/4)
18/02/28 14:16:27 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
18/02/28 14:16:27 INFO DAGScheduler: ShuffleMapStage 40 (map at LogisticRegression.scala:1398) finished in 0.306 s
18/02/28 14:16:27 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:16:27 INFO DAGScheduler: running: Set()
18/02/28 14:16:27 INFO DAGScheduler: waiting: Set(ResultStage 41)
18/02/28 14:16:27 INFO DAGScheduler: failed: Set()
18/02/28 14:16:27 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[111] at sortByKey at BinaryClassificationMetrics.scala:155), which has no missing parents
18/02/28 14:16:27 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 3.6 KB, free 344.0 MB)
18/02/28 14:16:27 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 2.0 KB, free 344.0 MB)
18/02/28 14:16:27 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:61463 (size: 2.0 KB, free: 345.3 MB)
18/02/28 14:16:27 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 41 (MapPartitionsRDD[111] at sortByKey at BinaryClassificationMetrics.scala:155) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:27 INFO TaskSchedulerImpl: Adding task set 41.0 with 4 tasks
18/02/28 14:16:27 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 137, localhost, executor driver, partition 0, ANY, 4621 bytes)
18/02/28 14:16:27 INFO TaskSetManager: Starting task 1.0 in stage 41.0 (TID 138, localhost, executor driver, partition 1, ANY, 4621 bytes)
18/02/28 14:16:27 INFO TaskSetManager: Starting task 2.0 in stage 41.0 (TID 139, localhost, executor driver, partition 2, ANY, 4621 bytes)
18/02/28 14:16:27 INFO TaskSetManager: Starting task 3.0 in stage 41.0 (TID 140, localhost, executor driver, partition 3, ANY, 4621 bytes)
18/02/28 14:16:27 INFO Executor: Running task 1.0 in stage 41.0 (TID 138)
18/02/28 14:16:27 INFO Executor: Running task 2.0 in stage 41.0 (TID 139)
18/02/28 14:16:27 INFO Executor: Running task 3.0 in stage 41.0 (TID 140)
18/02/28 14:16:27 INFO Executor: Running task 0.0 in stage 41.0 (TID 137)
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
18/02/28 14:16:27 INFO Executor: Finished task 2.0 in stage 41.0 (TID 139). 1757 bytes result sent to driver
18/02/28 14:16:27 INFO TaskSetManager: Finished task 2.0 in stage 41.0 (TID 139) in 27 ms on localhost (executor driver) (1/4)
18/02/28 14:16:27 INFO Executor: Finished task 0.0 in stage 41.0 (TID 137). 1714 bytes result sent to driver
18/02/28 14:16:27 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 137) in 33 ms on localhost (executor driver) (2/4)
18/02/28 14:16:27 INFO Executor: Finished task 1.0 in stage 41.0 (TID 138). 1757 bytes result sent to driver
18/02/28 14:16:27 INFO TaskSetManager: Finished task 1.0 in stage 41.0 (TID 138) in 43 ms on localhost (executor driver) (3/4)
18/02/28 14:16:27 INFO Executor: Finished task 3.0 in stage 41.0 (TID 140). 1800 bytes result sent to driver
18/02/28 14:16:27 INFO TaskSetManager: Finished task 3.0 in stage 41.0 (TID 140) in 44 ms on localhost (executor driver) (4/4)
18/02/28 14:16:27 INFO DAGScheduler: ResultStage 41 (sortByKey at BinaryClassificationMetrics.scala:155) finished in 0.046 s
18/02/28 14:16:27 INFO DAGScheduler: Job 30 finished: sortByKey at BinaryClassificationMetrics.scala:155, took 0.380183 s
18/02/28 14:16:27 INFO SparkContext: Starting job: count at BinaryClassificationMetrics.scala:163
18/02/28 14:16:27 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
18/02/28 14:16:27 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 10 is 170 bytes
18/02/28 14:16:27 INFO DAGScheduler: Registering RDD 109 (combineByKey at BinaryClassificationMetrics.scala:151)
18/02/28 14:16:27 INFO DAGScheduler: Got job 31 (count at BinaryClassificationMetrics.scala:163) with 4 output partitions
18/02/28 14:16:27 INFO DAGScheduler: Final stage: ResultStage 44 (count at BinaryClassificationMetrics.scala:163)
18/02/28 14:16:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)
18/02/28 14:16:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 43)
18/02/28 14:16:27 INFO DAGScheduler: Submitting ShuffleMapStage 43 (ShuffledRDD[109] at combineByKey at BinaryClassificationMetrics.scala:151), which has no missing parents
18/02/28 14:16:27 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 3.4 KB, free 344.0 MB)
18/02/28 14:16:27 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 1914.0 B, free 344.0 MB)
18/02/28 14:16:27 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:61463 (size: 1914.0 B, free: 345.3 MB)
18/02/28 14:16:27 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:27 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 43 (ShuffledRDD[109] at combineByKey at BinaryClassificationMetrics.scala:151) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:27 INFO TaskSchedulerImpl: Adding task set 43.0 with 4 tasks
18/02/28 14:16:27 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 141, localhost, executor driver, partition 0, ANY, 4610 bytes)
18/02/28 14:16:27 INFO TaskSetManager: Starting task 1.0 in stage 43.0 (TID 142, localhost, executor driver, partition 1, ANY, 4610 bytes)
18/02/28 14:16:27 INFO TaskSetManager: Starting task 2.0 in stage 43.0 (TID 143, localhost, executor driver, partition 2, ANY, 4610 bytes)
18/02/28 14:16:27 INFO TaskSetManager: Starting task 3.0 in stage 43.0 (TID 144, localhost, executor driver, partition 3, ANY, 4610 bytes)
18/02/28 14:16:27 INFO Executor: Running task 0.0 in stage 43.0 (TID 141)
18/02/28 14:16:27 INFO Executor: Running task 1.0 in stage 43.0 (TID 142)
18/02/28 14:16:27 INFO Executor: Running task 3.0 in stage 43.0 (TID 144)
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 14:16:27 INFO Executor: Running task 2.0 in stage 43.0 (TID 143)
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:27 INFO Executor: Finished task 1.0 in stage 43.0 (TID 142). 1282 bytes result sent to driver
18/02/28 14:16:27 INFO Executor: Finished task 3.0 in stage 43.0 (TID 144). 1282 bytes result sent to driver
18/02/28 14:16:27 INFO TaskSetManager: Finished task 1.0 in stage 43.0 (TID 142) in 154 ms on localhost (executor driver) (1/4)
18/02/28 14:16:27 INFO TaskSetManager: Finished task 3.0 in stage 43.0 (TID 144) in 153 ms on localhost (executor driver) (2/4)
18/02/28 14:16:27 INFO Executor: Finished task 0.0 in stage 43.0 (TID 141). 1239 bytes result sent to driver
18/02/28 14:16:27 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 141) in 164 ms on localhost (executor driver) (3/4)
18/02/28 14:16:27 INFO Executor: Finished task 2.0 in stage 43.0 (TID 143). 1282 bytes result sent to driver
18/02/28 14:16:27 INFO TaskSetManager: Finished task 2.0 in stage 43.0 (TID 143) in 172 ms on localhost (executor driver) (4/4)
18/02/28 14:16:27 INFO DAGScheduler: ShuffleMapStage 43 (combineByKey at BinaryClassificationMetrics.scala:151) finished in 0.175 s
18/02/28 14:16:27 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:16:27 INFO DAGScheduler: running: Set()
18/02/28 14:16:27 INFO DAGScheduler: waiting: Set(ResultStage 44)
18/02/28 14:16:27 INFO DAGScheduler: failed: Set()
18/02/28 14:16:27 INFO DAGScheduler: Submitting ResultStage 44 (ShuffledRDD[112] at sortByKey at BinaryClassificationMetrics.scala:155), which has no missing parents
18/02/28 14:16:27 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 3.1 KB, free 344.0 MB)
18/02/28 14:16:27 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
18/02/28 14:16:27 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 1868.0 B, free 344.0 MB)
18/02/28 14:16:27 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:61463 (size: 1868.0 B, free: 345.3 MB)
18/02/28 14:16:27 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 44 (ShuffledRDD[112] at sortByKey at BinaryClassificationMetrics.scala:155) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:27 INFO TaskSchedulerImpl: Adding task set 44.0 with 4 tasks
18/02/28 14:16:27 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 145, localhost, executor driver, partition 0, ANY, 4621 bytes)
18/02/28 14:16:27 INFO TaskSetManager: Starting task 1.0 in stage 44.0 (TID 146, localhost, executor driver, partition 1, ANY, 4621 bytes)
18/02/28 14:16:27 INFO TaskSetManager: Starting task 2.0 in stage 44.0 (TID 147, localhost, executor driver, partition 2, ANY, 4621 bytes)
18/02/28 14:16:27 INFO TaskSetManager: Starting task 3.0 in stage 44.0 (TID 148, localhost, executor driver, partition 3, ANY, 4621 bytes)
18/02/28 14:16:27 INFO Executor: Running task 1.0 in stage 44.0 (TID 146)
18/02/28 14:16:27 INFO Executor: Running task 2.0 in stage 44.0 (TID 147)
18/02/28 14:16:27 INFO Executor: Running task 3.0 in stage 44.0 (TID 148)
18/02/28 14:16:27 INFO Executor: Running task 0.0 in stage 44.0 (TID 145)
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:27 INFO Executor: Finished task 2.0 in stage 44.0 (TID 147). 1090 bytes result sent to driver
18/02/28 14:16:27 INFO Executor: Finished task 1.0 in stage 44.0 (TID 146). 1047 bytes result sent to driver
18/02/28 14:16:27 INFO Executor: Finished task 3.0 in stage 44.0 (TID 148). 1047 bytes result sent to driver
18/02/28 14:16:27 INFO TaskSetManager: Finished task 2.0 in stage 44.0 (TID 147) in 40 ms on localhost (executor driver) (1/4)
18/02/28 14:16:27 INFO TaskSetManager: Finished task 1.0 in stage 44.0 (TID 146) in 41 ms on localhost (executor driver) (2/4)
18/02/28 14:16:27 INFO TaskSetManager: Finished task 3.0 in stage 44.0 (TID 148) in 41 ms on localhost (executor driver) (3/4)
18/02/28 14:16:27 INFO Executor: Finished task 0.0 in stage 44.0 (TID 145). 1090 bytes result sent to driver
18/02/28 14:16:27 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 145) in 43 ms on localhost (executor driver) (4/4)
18/02/28 14:16:27 INFO DAGScheduler: ResultStage 44 (count at BinaryClassificationMetrics.scala:163) finished in 0.044 s
18/02/28 14:16:27 INFO DAGScheduler: Job 31 finished: count at BinaryClassificationMetrics.scala:163, took 0.244065 s
18/02/28 14:16:27 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
18/02/28 14:16:27 INFO SparkContext: Starting job: collect at BinaryClassificationMetrics.scala:192
18/02/28 14:16:27 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 10 is 170 bytes
18/02/28 14:16:27 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 11 is 168 bytes
18/02/28 14:16:27 INFO DAGScheduler: Got job 32 (collect at BinaryClassificationMetrics.scala:192) with 4 output partitions
18/02/28 14:16:27 INFO DAGScheduler: Final stage: ResultStage 47 (collect at BinaryClassificationMetrics.scala:192)
18/02/28 14:16:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 46)
18/02/28 14:16:27 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:27 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[115] at mapPartitions at BinaryClassificationMetrics.scala:188), which has no missing parents
18/02/28 14:16:27 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 4.2 KB, free 344.0 MB)
18/02/28 14:16:27 INFO ContextCleaner: Cleaned accumulator 688
18/02/28 14:16:27 INFO ContextCleaner: Cleaned accumulator 687
18/02/28 14:16:27 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 2.3 KB, free 344.0 MB)
18/02/28 14:16:27 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:61463 (size: 2.3 KB, free: 345.3 MB)
18/02/28 14:16:27 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 47 (MapPartitionsRDD[115] at mapPartitions at BinaryClassificationMetrics.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:27 INFO TaskSchedulerImpl: Adding task set 47.0 with 4 tasks
18/02/28 14:16:27 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 149, localhost, executor driver, partition 0, ANY, 4621 bytes)
18/02/28 14:16:27 INFO TaskSetManager: Starting task 1.0 in stage 47.0 (TID 150, localhost, executor driver, partition 1, ANY, 4621 bytes)
18/02/28 14:16:27 INFO TaskSetManager: Starting task 2.0 in stage 47.0 (TID 151, localhost, executor driver, partition 2, ANY, 4621 bytes)
18/02/28 14:16:27 INFO TaskSetManager: Starting task 3.0 in stage 47.0 (TID 152, localhost, executor driver, partition 3, ANY, 4621 bytes)
18/02/28 14:16:27 INFO Executor: Running task 0.0 in stage 47.0 (TID 149)
18/02/28 14:16:27 INFO Executor: Running task 1.0 in stage 47.0 (TID 150)
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 14:16:27 INFO Executor: Running task 2.0 in stage 47.0 (TID 151)
18/02/28 14:16:27 INFO Executor: Running task 3.0 in stage 47.0 (TID 152)
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:27 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 127.0.0.1:61463 in memory (size: 1868.0 B, free: 345.3 MB)
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:27 INFO ContextCleaner: Cleaned accumulator 686
18/02/28 14:16:27 INFO Executor: Finished task 3.0 in stage 47.0 (TID 152). 1217 bytes result sent to driver
18/02/28 14:16:27 INFO Executor: Finished task 0.0 in stage 47.0 (TID 149). 1217 bytes result sent to driver
18/02/28 14:16:27 INFO Executor: Finished task 2.0 in stage 47.0 (TID 151). 1174 bytes result sent to driver
18/02/28 14:16:27 INFO Executor: Finished task 1.0 in stage 47.0 (TID 150). 1260 bytes result sent to driver
18/02/28 14:16:27 INFO TaskSetManager: Finished task 3.0 in stage 47.0 (TID 152) in 44 ms on localhost (executor driver) (1/4)
18/02/28 14:16:27 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:61463 in memory (size: 29.1 KB, free: 345.3 MB)
18/02/28 14:16:27 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 149) in 49 ms on localhost (executor driver) (2/4)
18/02/28 14:16:27 INFO TaskSetManager: Finished task 1.0 in stage 47.0 (TID 150) in 46 ms on localhost (executor driver) (3/4)
18/02/28 14:16:27 INFO TaskSetManager: Finished task 2.0 in stage 47.0 (TID 151) in 46 ms on localhost (executor driver) (4/4)
18/02/28 14:16:27 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
18/02/28 14:16:27 INFO DAGScheduler: ResultStage 47 (collect at BinaryClassificationMetrics.scala:192) finished in 0.051 s
18/02/28 14:16:27 INFO DAGScheduler: Job 32 finished: collect at BinaryClassificationMetrics.scala:192, took 0.083553 s
18/02/28 14:16:27 INFO BlockManager: Removing RDD 85
18/02/28 14:16:27 INFO BinaryClassificationMetrics: Total counts: {numPos: 821, numNeg: 2510}
18/02/28 14:16:27 INFO ContextCleaner: Cleaned RDD 85
18/02/28 14:16:27 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:61463 in memory (size: 29.1 KB, free: 345.3 MB)
18/02/28 14:16:27 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 127.0.0.1:61463 in memory (size: 1914.0 B, free: 345.3 MB)
18/02/28 14:16:27 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 127.0.0.1:61463 in memory (size: 2.0 KB, free: 345.3 MB)
18/02/28 14:16:27 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:61463 in memory (size: 29.1 KB, free: 345.4 MB)
18/02/28 14:16:27 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 127.0.0.1:61463 in memory (size: 29.1 KB, free: 345.4 MB)
18/02/28 14:16:27 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:61463 in memory (size: 32.7 KB, free: 345.4 MB)
18/02/28 14:16:27 INFO ContextCleaner: Cleaned accumulator 689
18/02/28 14:16:27 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:61463 in memory (size: 29.1 KB, free: 345.5 MB)
18/02/28 14:16:27 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:61463 in memory (size: 29.1 KB, free: 345.5 MB)
18/02/28 14:16:27 INFO SparkContext: Starting job: collect at SlidingRDD.scala:81
18/02/28 14:16:27 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:61463 in memory (size: 29.1 KB, free: 345.5 MB)
18/02/28 14:16:27 INFO DAGScheduler: Got job 33 (collect at SlidingRDD.scala:81) with 6 output partitions
18/02/28 14:16:27 INFO DAGScheduler: Final stage: ResultStage 50 (collect at SlidingRDD.scala:81)
18/02/28 14:16:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 49)
18/02/28 14:16:27 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:27 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[123] at mapPartitions at SlidingRDD.scala:78), which has no missing parents
18/02/28 14:16:27 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 6.3 KB, free 344.9 MB)
18/02/28 14:16:27 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 3.3 KB, free 344.9 MB)
18/02/28 14:16:27 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:61463 (size: 3.3 KB, free: 345.5 MB)
18/02/28 14:16:27 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:27 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 50 (MapPartitionsRDD[123] at mapPartitions at SlidingRDD.scala:78) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
18/02/28 14:16:27 INFO TaskSchedulerImpl: Adding task set 50.0 with 6 tasks
18/02/28 14:16:27 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 153, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:16:27 INFO TaskSetManager: Starting task 5.0 in stage 50.0 (TID 154, localhost, executor driver, partition 5, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:16:27 INFO TaskSetManager: Starting task 1.0 in stage 50.0 (TID 155, localhost, executor driver, partition 1, ANY, 4730 bytes)
18/02/28 14:16:27 INFO TaskSetManager: Starting task 2.0 in stage 50.0 (TID 156, localhost, executor driver, partition 2, ANY, 4730 bytes)
18/02/28 14:16:27 INFO Executor: Running task 0.0 in stage 50.0 (TID 153)
18/02/28 14:16:27 INFO Executor: Running task 5.0 in stage 50.0 (TID 154)
18/02/28 14:16:27 INFO Executor: Running task 1.0 in stage 50.0 (TID 155)
18/02/28 14:16:27 INFO Executor: Finished task 0.0 in stage 50.0 (TID 153). 899 bytes result sent to driver
18/02/28 14:16:27 INFO Executor: Running task 2.0 in stage 50.0 (TID 156)
18/02/28 14:16:27 INFO TaskSetManager: Starting task 3.0 in stage 50.0 (TID 157, localhost, executor driver, partition 3, ANY, 4730 bytes)
18/02/28 14:16:27 INFO Executor: Finished task 5.0 in stage 50.0 (TID 154). 813 bytes result sent to driver
18/02/28 14:16:27 INFO TaskSetManager: Starting task 4.0 in stage 50.0 (TID 158, localhost, executor driver, partition 4, ANY, 4730 bytes)
18/02/28 14:16:27 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 153) in 16 ms on localhost (executor driver) (1/6)
18/02/28 14:16:27 INFO TaskSetManager: Finished task 5.0 in stage 50.0 (TID 154) in 12 ms on localhost (executor driver) (2/6)
18/02/28 14:16:27 INFO Executor: Running task 3.0 in stage 50.0 (TID 157)
18/02/28 14:16:27 INFO Executor: Running task 4.0 in stage 50.0 (TID 158)
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:27 INFO MemoryStore: Block rdd_116_0 stored as values in memory (estimated size 1952.0 B, free 344.9 MB)
18/02/28 14:16:27 INFO BlockManagerInfo: Added rdd_116_0 in memory on 127.0.0.1:61463 (size: 1952.0 B, free: 345.5 MB)
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:27 INFO Executor: Finished task 1.0 in stage 50.0 (TID 155). 1983 bytes result sent to driver
18/02/28 14:16:27 INFO MemoryStore: Block rdd_116_3 stored as values in memory (estimated size 2.2 KB, free 344.8 MB)
18/02/28 14:16:27 INFO MemoryStore: Block rdd_116_2 stored as values in memory (estimated size 2.3 KB, free 344.8 MB)
18/02/28 14:16:27 INFO MemoryStore: Block rdd_116_1 stored as values in memory (estimated size 2.1 KB, free 344.8 MB)
18/02/28 14:16:27 INFO BlockManagerInfo: Added rdd_116_3 in memory on 127.0.0.1:61463 (size: 2.2 KB, free: 345.5 MB)
18/02/28 14:16:27 INFO BlockManagerInfo: Added rdd_116_2 in memory on 127.0.0.1:61463 (size: 2.3 KB, free: 345.5 MB)
18/02/28 14:16:27 INFO BlockManagerInfo: Added rdd_116_1 in memory on 127.0.0.1:61463 (size: 2.1 KB, free: 345.5 MB)
18/02/28 14:16:27 INFO TaskSetManager: Finished task 1.0 in stage 50.0 (TID 155) in 45 ms on localhost (executor driver) (3/6)
18/02/28 14:16:27 INFO Executor: Finished task 4.0 in stage 50.0 (TID 158). 1940 bytes result sent to driver
18/02/28 14:16:27 INFO Executor: Finished task 3.0 in stage 50.0 (TID 157). 1983 bytes result sent to driver
18/02/28 14:16:27 INFO Executor: Finished task 2.0 in stage 50.0 (TID 156). 1940 bytes result sent to driver
18/02/28 14:16:27 INFO TaskSetManager: Finished task 4.0 in stage 50.0 (TID 158) in 38 ms on localhost (executor driver) (4/6)
18/02/28 14:16:27 INFO TaskSetManager: Finished task 2.0 in stage 50.0 (TID 156) in 47 ms on localhost (executor driver) (5/6)
18/02/28 14:16:27 INFO TaskSetManager: Finished task 3.0 in stage 50.0 (TID 157) in 41 ms on localhost (executor driver) (6/6)
18/02/28 14:16:27 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
18/02/28 14:16:27 INFO DAGScheduler: ResultStage 50 (collect at SlidingRDD.scala:81) finished in 0.054 s
18/02/28 14:16:27 INFO DAGScheduler: Job 33 finished: collect at SlidingRDD.scala:81, took 0.063684 s
18/02/28 14:16:27 INFO SparkContext: Starting job: aggregate at AreaUnderCurve.scala:45
18/02/28 14:16:27 INFO DAGScheduler: Got job 34 (aggregate at AreaUnderCurve.scala:45) with 5 output partitions
18/02/28 14:16:27 INFO DAGScheduler: Final stage: ResultStage 53 (aggregate at AreaUnderCurve.scala:45)
18/02/28 14:16:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)
18/02/28 14:16:27 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:27 INFO DAGScheduler: Submitting ResultStage 53 (SlidingRDD[122] at RDD at SlidingRDD.scala:50), which has no missing parents
18/02/28 14:16:27 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 6.5 KB, free 344.8 MB)
18/02/28 14:16:27 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 3.4 KB, free 344.8 MB)
18/02/28 14:16:27 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:61463 (size: 3.4 KB, free: 345.5 MB)
18/02/28 14:16:27 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:27 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 53 (SlidingRDD[122] at RDD at SlidingRDD.scala:50) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/02/28 14:16:27 INFO TaskSchedulerImpl: Adding task set 53.0 with 5 tasks
18/02/28 14:16:27 INFO TaskSetManager: Starting task 1.0 in stage 53.0 (TID 159, localhost, executor driver, partition 1, PROCESS_LOCAL, 5269 bytes)
18/02/28 14:16:27 INFO TaskSetManager: Starting task 2.0 in stage 53.0 (TID 160, localhost, executor driver, partition 2, PROCESS_LOCAL, 5269 bytes)
18/02/28 14:16:27 INFO TaskSetManager: Starting task 3.0 in stage 53.0 (TID 161, localhost, executor driver, partition 3, PROCESS_LOCAL, 5269 bytes)
18/02/28 14:16:27 INFO TaskSetManager: Starting task 4.0 in stage 53.0 (TID 162, localhost, executor driver, partition 4, PROCESS_LOCAL, 5269 bytes)
18/02/28 14:16:27 INFO Executor: Running task 1.0 in stage 53.0 (TID 159)
18/02/28 14:16:27 INFO BlockManager: Found block rdd_116_0 locally
18/02/28 14:16:27 INFO Executor: Finished task 1.0 in stage 53.0 (TID 159). 748 bytes result sent to driver
18/02/28 14:16:27 INFO Executor: Running task 2.0 in stage 53.0 (TID 160)
18/02/28 14:16:27 INFO BlockManager: Found block rdd_116_1 locally
18/02/28 14:16:27 INFO Executor: Finished task 2.0 in stage 53.0 (TID 160). 748 bytes result sent to driver
18/02/28 14:16:27 INFO Executor: Running task 3.0 in stage 53.0 (TID 161)
18/02/28 14:16:27 INFO Executor: Running task 4.0 in stage 53.0 (TID 162)
18/02/28 14:16:27 INFO BlockManager: Found block rdd_116_3 locally
18/02/28 14:16:27 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 163, localhost, executor driver, partition 0, PROCESS_LOCAL, 5475 bytes)
18/02/28 14:16:27 INFO Executor: Finished task 4.0 in stage 53.0 (TID 162). 748 bytes result sent to driver
18/02/28 14:16:27 INFO TaskSetManager: Finished task 1.0 in stage 53.0 (TID 159) in 27 ms on localhost (executor driver) (1/5)
18/02/28 14:16:27 INFO TaskSetManager: Finished task 2.0 in stage 53.0 (TID 160) in 24 ms on localhost (executor driver) (2/5)
18/02/28 14:16:27 INFO TaskSetManager: Finished task 4.0 in stage 53.0 (TID 162) in 25 ms on localhost (executor driver) (3/5)
18/02/28 14:16:27 INFO Executor: Running task 0.0 in stage 53.0 (TID 163)
18/02/28 14:16:27 INFO BlockManager: Found block rdd_116_2 locally
18/02/28 14:16:27 INFO Executor: Finished task 0.0 in stage 53.0 (TID 163). 619 bytes result sent to driver
18/02/28 14:16:27 INFO Executor: Finished task 3.0 in stage 53.0 (TID 161). 791 bytes result sent to driver
18/02/28 14:16:27 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 163) in 5 ms on localhost (executor driver) (4/5)
18/02/28 14:16:27 INFO TaskSetManager: Finished task 3.0 in stage 53.0 (TID 161) in 28 ms on localhost (executor driver) (5/5)
18/02/28 14:16:27 INFO DAGScheduler: ResultStage 53 (aggregate at AreaUnderCurve.scala:45) finished in 0.033 s
18/02/28 14:16:27 INFO DAGScheduler: Job 34 finished: aggregate at AreaUnderCurve.scala:45, took 0.040341 s
18/02/28 14:16:27 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
18/02/28 14:16:28 INFO CodeGenerator: Code generated in 9.924402 ms
18/02/28 14:16:28 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:16:28 INFO DAGScheduler: Got job 35 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:16:28 INFO DAGScheduler: Final stage: ResultStage 56 (collect at utils.scala:211)
18/02/28 14:16:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 55)
18/02/28 14:16:28 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:28 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[127] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:28 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 10.4 KB, free 344.8 MB)
18/02/28 14:16:28 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.8 MB)
18/02/28 14:16:28 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:61463 (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:16:28 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:28 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 56 (MapPartitionsRDD[127] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:28 INFO TaskSchedulerImpl: Adding task set 56.0 with 4 tasks
18/02/28 14:16:28 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 164, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:28 INFO TaskSetManager: Starting task 1.0 in stage 56.0 (TID 165, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:28 INFO TaskSetManager: Starting task 2.0 in stage 56.0 (TID 166, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:28 INFO TaskSetManager: Starting task 3.0 in stage 56.0 (TID 167, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:28 INFO Executor: Running task 0.0 in stage 56.0 (TID 164)
18/02/28 14:16:28 INFO Executor: Running task 2.0 in stage 56.0 (TID 166)
18/02/28 14:16:28 INFO Executor: Running task 3.0 in stage 56.0 (TID 167)
18/02/28 14:16:28 INFO BlockManager: Found block rdd_116_0 locally
18/02/28 14:16:28 INFO BlockManager: Found block rdd_116_3 locally
18/02/28 14:16:28 INFO Executor: Running task 1.0 in stage 56.0 (TID 165)
18/02/28 14:16:28 INFO BlockManager: Found block rdd_116_1 locally
18/02/28 14:16:28 INFO BlockManager: Found block rdd_116_2 locally
18/02/28 14:16:28 INFO Executor: Finished task 3.0 in stage 56.0 (TID 167). 1616 bytes result sent to driver
18/02/28 14:16:28 INFO Executor: Finished task 0.0 in stage 56.0 (TID 164). 1543 bytes result sent to driver
18/02/28 14:16:28 INFO Executor: Finished task 2.0 in stage 56.0 (TID 166). 1615 bytes result sent to driver
18/02/28 14:16:28 INFO TaskSetManager: Finished task 3.0 in stage 56.0 (TID 167) in 12 ms on localhost (executor driver) (1/4)
18/02/28 14:16:28 INFO Executor: Finished task 1.0 in stage 56.0 (TID 165). 1586 bytes result sent to driver
18/02/28 14:16:28 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 164) in 14 ms on localhost (executor driver) (2/4)
18/02/28 14:16:28 INFO TaskSetManager: Finished task 2.0 in stage 56.0 (TID 166) in 15 ms on localhost (executor driver) (3/4)
18/02/28 14:16:28 INFO TaskSetManager: Finished task 1.0 in stage 56.0 (TID 165) in 16 ms on localhost (executor driver) (4/4)
18/02/28 14:16:28 INFO DAGScheduler: ResultStage 56 (collect at utils.scala:211) finished in 0.016 s
18/02/28 14:16:28 INFO DAGScheduler: Job 35 finished: collect at utils.scala:211, took 0.025607 s
18/02/28 14:16:28 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
18/02/28 14:16:28 INFO CodeGenerator: Code generated in 5.587567 ms
18/02/28 14:16:28 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:16:28 INFO DAGScheduler: Got job 36 (collect at utils.scala:211) with 5 output partitions
18/02/28 14:16:28 INFO DAGScheduler: Final stage: ResultStage 59 (collect at utils.scala:211)
18/02/28 14:16:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 58)
18/02/28 14:16:28 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:28 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[133] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:28 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 11.1 KB, free 344.8 MB)
18/02/28 14:16:28 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 5.3 KB, free 344.8 MB)
18/02/28 14:16:28 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:61463 (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:16:28 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:28 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 59 (MapPartitionsRDD[133] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/02/28 14:16:28 INFO TaskSchedulerImpl: Adding task set 59.0 with 5 tasks
18/02/28 14:16:28 INFO TaskSetManager: Starting task 1.0 in stage 59.0 (TID 168, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:16:28 INFO TaskSetManager: Starting task 2.0 in stage 59.0 (TID 169, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:16:28 INFO TaskSetManager: Starting task 3.0 in stage 59.0 (TID 170, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:16:28 INFO TaskSetManager: Starting task 4.0 in stage 59.0 (TID 171, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:16:28 INFO Executor: Running task 1.0 in stage 59.0 (TID 168)
18/02/28 14:16:28 INFO BlockManager: Found block rdd_116_0 locally
18/02/28 14:16:28 INFO Executor: Finished task 1.0 in stage 59.0 (TID 168). 1381 bytes result sent to driver
18/02/28 14:16:28 INFO Executor: Running task 2.0 in stage 59.0 (TID 169)
18/02/28 14:16:28 INFO BlockManager: Found block rdd_116_1 locally
18/02/28 14:16:28 INFO Executor: Finished task 2.0 in stage 59.0 (TID 169). 1463 bytes result sent to driver
18/02/28 14:16:28 INFO Executor: Running task 3.0 in stage 59.0 (TID 170)
18/02/28 14:16:28 INFO Executor: Running task 4.0 in stage 59.0 (TID 171)
18/02/28 14:16:28 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 172, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:16:28 INFO BlockManager: Found block rdd_116_3 locally
18/02/28 14:16:28 INFO Executor: Finished task 4.0 in stage 59.0 (TID 171). 1609 bytes result sent to driver
18/02/28 14:16:28 INFO TaskSetManager: Finished task 1.0 in stage 59.0 (TID 168) in 14 ms on localhost (executor driver) (1/5)
18/02/28 14:16:28 INFO Executor: Running task 0.0 in stage 59.0 (TID 172)
18/02/28 14:16:28 INFO TaskSetManager: Finished task 2.0 in stage 59.0 (TID 169) in 15 ms on localhost (executor driver) (2/5)
18/02/28 14:16:28 INFO TaskSetManager: Finished task 4.0 in stage 59.0 (TID 171) in 14 ms on localhost (executor driver) (3/5)
18/02/28 14:16:28 INFO BlockManager: Found block rdd_116_2 locally
18/02/28 14:16:28 INFO Executor: Finished task 0.0 in stage 59.0 (TID 172). 1043 bytes result sent to driver
18/02/28 14:16:28 INFO Executor: Finished task 3.0 in stage 59.0 (TID 170). 1656 bytes result sent to driver
18/02/28 14:16:28 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 172) in 9 ms on localhost (executor driver) (4/5)
18/02/28 14:16:28 INFO TaskSetManager: Finished task 3.0 in stage 59.0 (TID 170) in 20 ms on localhost (executor driver) (5/5)
18/02/28 14:16:28 INFO DAGScheduler: ResultStage 59 (collect at utils.scala:211) finished in 0.022 s
18/02/28 14:16:28 INFO DAGScheduler: Job 36 finished: collect at utils.scala:211, took 0.030666 s
18/02/28 14:16:28 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
18/02/28 14:16:28 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:16:28 INFO DAGScheduler: Got job 37 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:16:28 INFO DAGScheduler: Final stage: ResultStage 62 (collect at utils.scala:211)
18/02/28 14:16:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 61)
18/02/28 14:16:28 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:28 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[137] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:28 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 10.3 KB, free 344.8 MB)
18/02/28 14:16:28 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.8 MB)
18/02/28 14:16:28 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:61463 (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:16:28 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:28 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 62 (MapPartitionsRDD[137] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:28 INFO TaskSchedulerImpl: Adding task set 62.0 with 4 tasks
18/02/28 14:16:28 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 173, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:28 INFO TaskSetManager: Starting task 1.0 in stage 62.0 (TID 174, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:28 INFO TaskSetManager: Starting task 2.0 in stage 62.0 (TID 175, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:28 INFO TaskSetManager: Starting task 3.0 in stage 62.0 (TID 176, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:28 INFO Executor: Running task 0.0 in stage 62.0 (TID 173)
18/02/28 14:16:28 INFO Executor: Running task 1.0 in stage 62.0 (TID 174)
18/02/28 14:16:28 INFO BlockManager: Found block rdd_116_0 locally
18/02/28 14:16:28 INFO BlockManager: Found block rdd_116_1 locally
18/02/28 14:16:28 INFO Executor: Finished task 0.0 in stage 62.0 (TID 173). 1336 bytes result sent to driver
18/02/28 14:16:28 INFO Executor: Running task 2.0 in stage 62.0 (TID 175)
18/02/28 14:16:28 INFO Executor: Finished task 1.0 in stage 62.0 (TID 174). 1448 bytes result sent to driver
18/02/28 14:16:28 INFO Executor: Running task 3.0 in stage 62.0 (TID 176)
18/02/28 14:16:28 INFO BlockManager: Found block rdd_116_2 locally
18/02/28 14:16:28 INFO BlockManager: Found block rdd_116_3 locally
18/02/28 14:16:28 INFO Executor: Finished task 3.0 in stage 62.0 (TID 176). 1623 bytes result sent to driver
18/02/28 14:16:28 INFO Executor: Finished task 2.0 in stage 62.0 (TID 175). 1618 bytes result sent to driver
18/02/28 14:16:28 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 173) in 16 ms on localhost (executor driver) (1/4)
18/02/28 14:16:28 INFO TaskSetManager: Finished task 1.0 in stage 62.0 (TID 174) in 16 ms on localhost (executor driver) (2/4)
18/02/28 14:16:28 INFO TaskSetManager: Finished task 2.0 in stage 62.0 (TID 175) in 16 ms on localhost (executor driver) (3/4)
18/02/28 14:16:28 INFO TaskSetManager: Finished task 3.0 in stage 62.0 (TID 176) in 16 ms on localhost (executor driver) (4/4)
18/02/28 14:16:28 INFO DAGScheduler: ResultStage 62 (collect at utils.scala:211) finished in 0.018 s
18/02/28 14:16:28 INFO DAGScheduler: Job 37 finished: collect at utils.scala:211, took 0.024619 s
18/02/28 14:16:28 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
18/02/28 14:16:28 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8c8443d5fe9
18/02/28 14:16:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:28 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8c8443d5fe9` AS `zzz10`
WHERE (0 = 1)
18/02/28 14:16:28 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:16:28 INFO DAGScheduler: Got job 38 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:16:28 INFO DAGScheduler: Final stage: ResultStage 65 (collect at utils.scala:211)
18/02/28 14:16:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 64)
18/02/28 14:16:28 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:28 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[141] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:28 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 10.3 KB, free 344.8 MB)
18/02/28 14:16:28 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.8 MB)
18/02/28 14:16:28 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:61463 (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:16:28 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:28 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 65 (MapPartitionsRDD[141] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:28 INFO TaskSchedulerImpl: Adding task set 65.0 with 4 tasks
18/02/28 14:16:28 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 177, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:28 INFO TaskSetManager: Starting task 1.0 in stage 65.0 (TID 178, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:28 INFO TaskSetManager: Starting task 2.0 in stage 65.0 (TID 179, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:28 INFO TaskSetManager: Starting task 3.0 in stage 65.0 (TID 180, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:28 INFO Executor: Running task 0.0 in stage 65.0 (TID 177)
18/02/28 14:16:28 INFO Executor: Running task 1.0 in stage 65.0 (TID 178)
18/02/28 14:16:28 INFO Executor: Running task 2.0 in stage 65.0 (TID 179)
18/02/28 14:16:28 INFO BlockManager: Found block rdd_116_2 locally
18/02/28 14:16:28 INFO BlockManager: Found block rdd_116_1 locally
18/02/28 14:16:28 INFO Executor: Finished task 2.0 in stage 65.0 (TID 179). 1625 bytes result sent to driver
18/02/28 14:16:28 INFO Executor: Running task 3.0 in stage 65.0 (TID 180)
18/02/28 14:16:28 INFO Executor: Finished task 1.0 in stage 65.0 (TID 178). 1634 bytes result sent to driver
18/02/28 14:16:28 INFO BlockManager: Found block rdd_116_0 locally
18/02/28 14:16:28 INFO BlockManager: Found block rdd_116_3 locally
18/02/28 14:16:28 INFO Executor: Finished task 0.0 in stage 65.0 (TID 177). 1524 bytes result sent to driver
18/02/28 14:16:28 INFO Executor: Finished task 3.0 in stage 65.0 (TID 180). 1603 bytes result sent to driver
18/02/28 14:16:28 INFO TaskSetManager: Finished task 2.0 in stage 65.0 (TID 179) in 9 ms on localhost (executor driver) (1/4)
18/02/28 14:16:28 INFO TaskSetManager: Finished task 1.0 in stage 65.0 (TID 178) in 10 ms on localhost (executor driver) (2/4)
18/02/28 14:16:28 INFO TaskSetManager: Finished task 3.0 in stage 65.0 (TID 180) in 11 ms on localhost (executor driver) (3/4)
18/02/28 14:16:28 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 177) in 12 ms on localhost (executor driver) (4/4)
18/02/28 14:16:28 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
18/02/28 14:16:28 INFO DAGScheduler: ResultStage 65 (collect at utils.scala:211) finished in 0.012 s
18/02/28 14:16:28 INFO DAGScheduler: Job 38 finished: collect at utils.scala:211, took 0.022137 s
18/02/28 14:16:28 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:16:28 INFO DAGScheduler: Got job 39 (collect at utils.scala:211) with 6 output partitions
18/02/28 14:16:28 INFO DAGScheduler: Final stage: ResultStage 68 (collect at utils.scala:211)
18/02/28 14:16:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 67)
18/02/28 14:16:28 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:28 INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[148] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:28 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 11.2 KB, free 344.8 MB)
18/02/28 14:16:28 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 5.3 KB, free 344.8 MB)
18/02/28 14:16:28 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 127.0.0.1:61463 (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:16:28 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:28 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 68 (MapPartitionsRDD[148] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
18/02/28 14:16:28 INFO TaskSchedulerImpl: Adding task set 68.0 with 6 tasks
18/02/28 14:16:28 INFO TaskSetManager: Starting task 1.0 in stage 68.0 (TID 181, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:16:28 INFO TaskSetManager: Starting task 2.0 in stage 68.0 (TID 182, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:16:28 INFO TaskSetManager: Starting task 3.0 in stage 68.0 (TID 183, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:16:28 INFO TaskSetManager: Starting task 4.0 in stage 68.0 (TID 184, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:16:28 INFO Executor: Running task 1.0 in stage 68.0 (TID 181)
18/02/28 14:16:28 INFO BlockManager: Found block rdd_116_0 locally
18/02/28 14:16:28 INFO Executor: Finished task 1.0 in stage 68.0 (TID 181). 1370 bytes result sent to driver
18/02/28 14:16:28 INFO Executor: Running task 2.0 in stage 68.0 (TID 182)
18/02/28 14:16:28 INFO Executor: Running task 3.0 in stage 68.0 (TID 183)
18/02/28 14:16:28 INFO Executor: Running task 4.0 in stage 68.0 (TID 184)
18/02/28 14:16:28 INFO BlockManager: Found block rdd_116_1 locally
18/02/28 14:16:28 INFO BlockManager: Found block rdd_116_3 locally
18/02/28 14:16:28 INFO Executor: Finished task 4.0 in stage 68.0 (TID 184). 1595 bytes result sent to driver
18/02/28 14:16:28 INFO Executor: Finished task 2.0 in stage 68.0 (TID 182). 1415 bytes result sent to driver
18/02/28 14:16:28 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 185, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:16:28 INFO TaskSetManager: Starting task 5.0 in stage 68.0 (TID 186, localhost, executor driver, partition 5, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:16:28 INFO TaskSetManager: Finished task 1.0 in stage 68.0 (TID 181) in 11 ms on localhost (executor driver) (1/6)
18/02/28 14:16:28 INFO TaskSetManager: Finished task 4.0 in stage 68.0 (TID 184) in 10 ms on localhost (executor driver) (2/6)
18/02/28 14:16:28 INFO TaskSetManager: Finished task 2.0 in stage 68.0 (TID 182) in 11 ms on localhost (executor driver) (3/6)
18/02/28 14:16:28 INFO BlockManager: Found block rdd_116_2 locally
18/02/28 14:16:28 INFO Executor: Running task 0.0 in stage 68.0 (TID 185)
18/02/28 14:16:28 INFO Executor: Finished task 3.0 in stage 68.0 (TID 183). 1565 bytes result sent to driver
18/02/28 14:16:28 INFO Executor: Running task 5.0 in stage 68.0 (TID 186)
18/02/28 14:16:28 INFO TaskSetManager: Finished task 3.0 in stage 68.0 (TID 183) in 14 ms on localhost (executor driver) (4/6)
18/02/28 14:16:28 INFO Executor: Finished task 5.0 in stage 68.0 (TID 186). 1050 bytes result sent to driver
18/02/28 14:16:28 INFO Executor: Finished task 0.0 in stage 68.0 (TID 185). 1042 bytes result sent to driver
18/02/28 14:16:28 INFO TaskSetManager: Finished task 5.0 in stage 68.0 (TID 186) in 8 ms on localhost (executor driver) (5/6)
18/02/28 14:16:28 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 185) in 8 ms on localhost (executor driver) (6/6)
18/02/28 14:16:28 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
18/02/28 14:16:28 INFO DAGScheduler: ResultStage 68 (collect at utils.scala:211) finished in 0.018 s
18/02/28 14:16:28 INFO DAGScheduler: Job 39 finished: collect at utils.scala:211, took 0.029391 s
18/02/28 14:16:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:28 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 14:16:28 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8c83ab41865
18/02/28 14:16:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:28 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8c83ab41865` AS `zzz11`
WHERE (0 = 1)
18/02/28 14:16:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:28 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8c83ab41865`
18/02/28 14:16:28 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:16:28 INFO DAGScheduler: Got job 40 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:16:28 INFO DAGScheduler: Final stage: ResultStage 71 (collect at utils.scala:211)
18/02/28 14:16:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 70)
18/02/28 14:16:29 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:29 INFO DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[151] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:29 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 10.4 KB, free 344.7 MB)
18/02/28 14:16:29 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.7 MB)
18/02/28 14:16:29 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 127.0.0.1:61463 (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:16:29 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:29 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 71 (MapPartitionsRDD[151] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:29 INFO TaskSchedulerImpl: Adding task set 71.0 with 4 tasks
18/02/28 14:16:29 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 187, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 1.0 in stage 71.0 (TID 188, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 2.0 in stage 71.0 (TID 189, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 3.0 in stage 71.0 (TID 190, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:29 INFO Executor: Running task 0.0 in stage 71.0 (TID 187)
18/02/28 14:16:29 INFO Executor: Running task 1.0 in stage 71.0 (TID 188)
18/02/28 14:16:29 INFO Executor: Running task 2.0 in stage 71.0 (TID 189)
18/02/28 14:16:29 INFO Executor: Running task 3.0 in stage 71.0 (TID 190)
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_0 locally
18/02/28 14:16:29 INFO Executor: Finished task 0.0 in stage 71.0 (TID 187). 1500 bytes result sent to driver
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_1 locally
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_3 locally
18/02/28 14:16:29 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 187) in 9 ms on localhost (executor driver) (1/4)
18/02/28 14:16:29 INFO Executor: Finished task 1.0 in stage 71.0 (TID 188). 1586 bytes result sent to driver
18/02/28 14:16:29 INFO Executor: Finished task 3.0 in stage 71.0 (TID 190). 1616 bytes result sent to driver
18/02/28 14:16:29 INFO TaskSetManager: Finished task 1.0 in stage 71.0 (TID 188) in 10 ms on localhost (executor driver) (2/4)
18/02/28 14:16:29 INFO TaskSetManager: Finished task 3.0 in stage 71.0 (TID 190) in 12 ms on localhost (executor driver) (3/4)
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_2 locally
18/02/28 14:16:29 INFO Executor: Finished task 2.0 in stage 71.0 (TID 189). 1615 bytes result sent to driver
18/02/28 14:16:29 INFO TaskSetManager: Finished task 2.0 in stage 71.0 (TID 189) in 16 ms on localhost (executor driver) (4/4)
18/02/28 14:16:29 INFO DAGScheduler: ResultStage 71 (collect at utils.scala:211) finished in 0.017 s
18/02/28 14:16:29 INFO DAGScheduler: Job 40 finished: collect at utils.scala:211, took 0.025206 s
18/02/28 14:16:29 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
18/02/28 14:16:29 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:16:29 INFO DAGScheduler: Got job 41 (collect at utils.scala:211) with 5 output partitions
18/02/28 14:16:29 INFO DAGScheduler: Final stage: ResultStage 74 (collect at utils.scala:211)
18/02/28 14:16:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 73)
18/02/28 14:16:29 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:29 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[154] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:29 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 11.1 KB, free 344.7 MB)
18/02/28 14:16:29 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 5.3 KB, free 344.7 MB)
18/02/28 14:16:29 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 127.0.0.1:61463 (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:16:29 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:29 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 74 (MapPartitionsRDD[154] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/02/28 14:16:29 INFO TaskSchedulerImpl: Adding task set 74.0 with 5 tasks
18/02/28 14:16:29 INFO TaskSetManager: Starting task 1.0 in stage 74.0 (TID 191, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 2.0 in stage 74.0 (TID 192, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 3.0 in stage 74.0 (TID 193, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 4.0 in stage 74.0 (TID 194, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:16:29 INFO Executor: Running task 1.0 in stage 74.0 (TID 191)
18/02/28 14:16:29 INFO Executor: Running task 2.0 in stage 74.0 (TID 192)
18/02/28 14:16:29 INFO Executor: Running task 3.0 in stage 74.0 (TID 193)
18/02/28 14:16:29 INFO Executor: Running task 4.0 in stage 74.0 (TID 194)
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_1 locally
18/02/28 14:16:29 INFO Executor: Finished task 2.0 in stage 74.0 (TID 192). 1420 bytes result sent to driver
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_3 locally
18/02/28 14:16:29 INFO Executor: Finished task 4.0 in stage 74.0 (TID 194). 1609 bytes result sent to driver
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_0 locally
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_2 locally
18/02/28 14:16:29 INFO Executor: Finished task 1.0 in stage 74.0 (TID 191). 1381 bytes result sent to driver
18/02/28 14:16:29 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 195, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:16:29 INFO Executor: Finished task 3.0 in stage 74.0 (TID 193). 1613 bytes result sent to driver
18/02/28 14:16:29 INFO Executor: Running task 0.0 in stage 74.0 (TID 195)
18/02/28 14:16:29 INFO TaskSetManager: Finished task 4.0 in stage 74.0 (TID 194) in 7 ms on localhost (executor driver) (1/5)
18/02/28 14:16:29 INFO TaskSetManager: Finished task 1.0 in stage 74.0 (TID 191) in 9 ms on localhost (executor driver) (2/5)
18/02/28 14:16:29 INFO TaskSetManager: Finished task 3.0 in stage 74.0 (TID 193) in 10 ms on localhost (executor driver) (3/5)
18/02/28 14:16:29 INFO TaskSetManager: Finished task 2.0 in stage 74.0 (TID 192) in 11 ms on localhost (executor driver) (4/5)
18/02/28 14:16:29 INFO Executor: Finished task 0.0 in stage 74.0 (TID 195). 1086 bytes result sent to driver
18/02/28 14:16:29 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 195) in 7 ms on localhost (executor driver) (5/5)
18/02/28 14:16:29 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
18/02/28 14:16:29 INFO DAGScheduler: ResultStage 74 (collect at utils.scala:211) finished in 0.014 s
18/02/28 14:16:29 INFO DAGScheduler: Job 41 finished: collect at utils.scala:211, took 0.020761 s
18/02/28 14:16:29 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:16:29 INFO DAGScheduler: Got job 42 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:16:29 INFO DAGScheduler: Final stage: ResultStage 77 (collect at utils.scala:211)
18/02/28 14:16:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 76)
18/02/28 14:16:29 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:29 INFO DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[157] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:29 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 10.3 KB, free 344.7 MB)
18/02/28 14:16:29 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.7 MB)
18/02/28 14:16:29 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 127.0.0.1:61463 (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:16:29 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:29 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 77 (MapPartitionsRDD[157] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:29 INFO TaskSchedulerImpl: Adding task set 77.0 with 4 tasks
18/02/28 14:16:29 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 196, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 1.0 in stage 77.0 (TID 197, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 2.0 in stage 77.0 (TID 198, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 3.0 in stage 77.0 (TID 199, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:29 INFO Executor: Running task 0.0 in stage 77.0 (TID 196)
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_0 locally
18/02/28 14:16:29 INFO Executor: Finished task 0.0 in stage 77.0 (TID 196). 1336 bytes result sent to driver
18/02/28 14:16:29 INFO Executor: Running task 1.0 in stage 77.0 (TID 197)
18/02/28 14:16:29 INFO Executor: Running task 2.0 in stage 77.0 (TID 198)
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_1 locally
18/02/28 14:16:29 INFO Executor: Finished task 1.0 in stage 77.0 (TID 197). 1448 bytes result sent to driver
18/02/28 14:16:29 INFO Executor: Running task 3.0 in stage 77.0 (TID 199)
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_2 locally
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_3 locally
18/02/28 14:16:29 INFO Executor: Finished task 3.0 in stage 77.0 (TID 199). 1623 bytes result sent to driver
18/02/28 14:16:29 INFO Executor: Finished task 2.0 in stage 77.0 (TID 198). 1618 bytes result sent to driver
18/02/28 14:16:29 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 196) in 11 ms on localhost (executor driver) (1/4)
18/02/28 14:16:29 INFO TaskSetManager: Finished task 2.0 in stage 77.0 (TID 198) in 12 ms on localhost (executor driver) (2/4)
18/02/28 14:16:29 INFO TaskSetManager: Finished task 1.0 in stage 77.0 (TID 197) in 12 ms on localhost (executor driver) (3/4)
18/02/28 14:16:29 INFO TaskSetManager: Finished task 3.0 in stage 77.0 (TID 199) in 11 ms on localhost (executor driver) (4/4)
18/02/28 14:16:29 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
18/02/28 14:16:29 INFO DAGScheduler: ResultStage 77 (collect at utils.scala:211) finished in 0.013 s
18/02/28 14:16:29 INFO DAGScheduler: Job 42 finished: collect at utils.scala:211, took 0.018894 s
18/02/28 14:16:29 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8c824e21d24
18/02/28 14:16:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8c824e21d24` AS `zzz12`
WHERE (0 = 1)
18/02/28 14:16:29 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:16:29 INFO DAGScheduler: Got job 43 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:16:29 INFO DAGScheduler: Final stage: ResultStage 80 (collect at utils.scala:211)
18/02/28 14:16:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 79)
18/02/28 14:16:29 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:29 INFO DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[160] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:29 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 10.3 KB, free 344.7 MB)
18/02/28 14:16:29 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.7 MB)
18/02/28 14:16:29 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 127.0.0.1:61463 (size: 4.9 KB, free: 345.4 MB)
18/02/28 14:16:29 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:29 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 80 (MapPartitionsRDD[160] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:29 INFO TaskSchedulerImpl: Adding task set 80.0 with 4 tasks
18/02/28 14:16:29 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 200, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 1.0 in stage 80.0 (TID 201, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 2.0 in stage 80.0 (TID 202, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 3.0 in stage 80.0 (TID 203, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:29 INFO Executor: Running task 0.0 in stage 80.0 (TID 200)
18/02/28 14:16:29 INFO Executor: Running task 3.0 in stage 80.0 (TID 203)
18/02/28 14:16:29 INFO Executor: Running task 2.0 in stage 80.0 (TID 202)
18/02/28 14:16:29 INFO Executor: Running task 1.0 in stage 80.0 (TID 201)
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_0 locally
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_1 locally
18/02/28 14:16:29 INFO Executor: Finished task 0.0 in stage 80.0 (TID 200). 1481 bytes result sent to driver
18/02/28 14:16:29 INFO Executor: Finished task 1.0 in stage 80.0 (TID 201). 1591 bytes result sent to driver
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_3 locally
18/02/28 14:16:29 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 200) in 6 ms on localhost (executor driver) (1/4)
18/02/28 14:16:29 INFO TaskSetManager: Finished task 1.0 in stage 80.0 (TID 201) in 6 ms on localhost (executor driver) (2/4)
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_2 locally
18/02/28 14:16:29 INFO Executor: Finished task 3.0 in stage 80.0 (TID 203). 1603 bytes result sent to driver
18/02/28 14:16:29 INFO Executor: Finished task 2.0 in stage 80.0 (TID 202). 1625 bytes result sent to driver
18/02/28 14:16:29 INFO TaskSetManager: Finished task 3.0 in stage 80.0 (TID 203) in 11 ms on localhost (executor driver) (3/4)
18/02/28 14:16:29 INFO TaskSetManager: Finished task 2.0 in stage 80.0 (TID 202) in 11 ms on localhost (executor driver) (4/4)
18/02/28 14:16:29 INFO DAGScheduler: ResultStage 80 (collect at utils.scala:211) finished in 0.013 s
18/02/28 14:16:29 INFO DAGScheduler: Job 43 finished: collect at utils.scala:211, took 0.017656 s
18/02/28 14:16:29 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
18/02/28 14:16:29 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:16:29 INFO DAGScheduler: Got job 44 (collect at utils.scala:211) with 6 output partitions
18/02/28 14:16:29 INFO DAGScheduler: Final stage: ResultStage 83 (collect at utils.scala:211)
18/02/28 14:16:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 82)
18/02/28 14:16:29 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:29 INFO DAGScheduler: Submitting ResultStage 83 (MapPartitionsRDD[163] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:29 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 11.2 KB, free 344.7 MB)
18/02/28 14:16:29 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 5.3 KB, free 344.7 MB)
18/02/28 14:16:29 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 127.0.0.1:61463 (size: 5.3 KB, free: 345.4 MB)
18/02/28 14:16:29 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:29 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 83 (MapPartitionsRDD[163] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
18/02/28 14:16:29 INFO TaskSchedulerImpl: Adding task set 83.0 with 6 tasks
18/02/28 14:16:29 INFO TaskSetManager: Starting task 1.0 in stage 83.0 (TID 204, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 2.0 in stage 83.0 (TID 205, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 3.0 in stage 83.0 (TID 206, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 4.0 in stage 83.0 (TID 207, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:16:29 INFO Executor: Running task 1.0 in stage 83.0 (TID 204)
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_0 locally
18/02/28 14:16:29 INFO Executor: Finished task 1.0 in stage 83.0 (TID 204). 1370 bytes result sent to driver
18/02/28 14:16:29 INFO Executor: Running task 2.0 in stage 83.0 (TID 205)
18/02/28 14:16:29 INFO Executor: Running task 3.0 in stage 83.0 (TID 206)
18/02/28 14:16:29 INFO Executor: Running task 4.0 in stage 83.0 (TID 207)
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_1 locally
18/02/28 14:16:29 INFO Executor: Finished task 2.0 in stage 83.0 (TID 205). 1415 bytes result sent to driver
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_3 locally
18/02/28 14:16:29 INFO Executor: Finished task 4.0 in stage 83.0 (TID 207). 1595 bytes result sent to driver
18/02/28 14:16:29 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 208, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 5.0 in stage 83.0 (TID 209, localhost, executor driver, partition 5, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_2 locally
18/02/28 14:16:29 INFO Executor: Finished task 3.0 in stage 83.0 (TID 206). 1565 bytes result sent to driver
18/02/28 14:16:29 INFO Executor: Running task 0.0 in stage 83.0 (TID 208)
18/02/28 14:16:29 INFO TaskSetManager: Finished task 1.0 in stage 83.0 (TID 204) in 16 ms on localhost (executor driver) (1/6)
18/02/28 14:16:29 INFO TaskSetManager: Finished task 2.0 in stage 83.0 (TID 205) in 16 ms on localhost (executor driver) (2/6)
18/02/28 14:16:29 INFO TaskSetManager: Finished task 4.0 in stage 83.0 (TID 207) in 15 ms on localhost (executor driver) (3/6)
18/02/28 14:16:29 INFO TaskSetManager: Finished task 3.0 in stage 83.0 (TID 206) in 18 ms on localhost (executor driver) (4/6)
18/02/28 14:16:29 INFO Executor: Running task 5.0 in stage 83.0 (TID 209)
18/02/28 14:16:29 INFO Executor: Finished task 0.0 in stage 83.0 (TID 208). 999 bytes result sent to driver
18/02/28 14:16:29 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 208) in 8 ms on localhost (executor driver) (5/6)
18/02/28 14:16:29 INFO Executor: Finished task 5.0 in stage 83.0 (TID 209). 1007 bytes result sent to driver
18/02/28 14:16:29 INFO TaskSetManager: Finished task 5.0 in stage 83.0 (TID 209) in 9 ms on localhost (executor driver) (6/6)
18/02/28 14:16:29 INFO DAGScheduler: ResultStage 83 (collect at utils.scala:211) finished in 0.022 s
18/02/28 14:16:29 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool 
18/02/28 14:16:29 INFO DAGScheduler: Job 44 finished: collect at utils.scala:211, took 0.030301 s
18/02/28 14:16:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 14:16:29 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:16:29 INFO DAGScheduler: Got job 45 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:16:29 INFO DAGScheduler: Final stage: ResultStage 86 (collect at utils.scala:211)
18/02/28 14:16:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 85)
18/02/28 14:16:29 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:29 INFO DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[166] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:29 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 10.4 KB, free 344.7 MB)
18/02/28 14:16:29 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.7 MB)
18/02/28 14:16:29 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 127.0.0.1:61463 (size: 4.9 KB, free: 345.4 MB)
18/02/28 14:16:29 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:29 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 86 (MapPartitionsRDD[166] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:29 INFO TaskSchedulerImpl: Adding task set 86.0 with 4 tasks
18/02/28 14:16:29 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 210, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 1.0 in stage 86.0 (TID 211, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 2.0 in stage 86.0 (TID 212, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 3.0 in stage 86.0 (TID 213, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:29 INFO Executor: Running task 1.0 in stage 86.0 (TID 211)
18/02/28 14:16:29 INFO Executor: Running task 0.0 in stage 86.0 (TID 210)
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_1 locally
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_0 locally
18/02/28 14:16:29 INFO Executor: Finished task 0.0 in stage 86.0 (TID 210). 1500 bytes result sent to driver
18/02/28 14:16:29 INFO Executor: Finished task 1.0 in stage 86.0 (TID 211). 1586 bytes result sent to driver
18/02/28 14:16:29 INFO Executor: Running task 2.0 in stage 86.0 (TID 212)
18/02/28 14:16:29 INFO Executor: Running task 3.0 in stage 86.0 (TID 213)
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_2 locally
18/02/28 14:16:29 INFO Executor: Finished task 2.0 in stage 86.0 (TID 212). 1572 bytes result sent to driver
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_3 locally
18/02/28 14:16:29 INFO Executor: Finished task 3.0 in stage 86.0 (TID 213). 1616 bytes result sent to driver
18/02/28 14:16:29 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 210) in 12 ms on localhost (executor driver) (1/4)
18/02/28 14:16:29 INFO TaskSetManager: Finished task 1.0 in stage 86.0 (TID 211) in 11 ms on localhost (executor driver) (2/4)
18/02/28 14:16:29 INFO TaskSetManager: Finished task 2.0 in stage 86.0 (TID 212) in 11 ms on localhost (executor driver) (3/4)
18/02/28 14:16:29 INFO TaskSetManager: Finished task 3.0 in stage 86.0 (TID 213) in 12 ms on localhost (executor driver) (4/4)
18/02/28 14:16:29 INFO DAGScheduler: ResultStage 86 (collect at utils.scala:211) finished in 0.013 s
18/02/28 14:16:29 INFO DAGScheduler: Job 45 finished: collect at utils.scala:211, took 0.019692 s
18/02/28 14:16:29 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
18/02/28 14:16:29 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:16:29 INFO DAGScheduler: Got job 46 (collect at utils.scala:211) with 5 output partitions
18/02/28 14:16:29 INFO DAGScheduler: Final stage: ResultStage 89 (collect at utils.scala:211)
18/02/28 14:16:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 88)
18/02/28 14:16:29 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:29 INFO DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[169] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:29 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 11.1 KB, free 344.7 MB)
18/02/28 14:16:29 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 5.3 KB, free 344.7 MB)
18/02/28 14:16:29 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 127.0.0.1:61463 (size: 5.3 KB, free: 345.4 MB)
18/02/28 14:16:29 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:29 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 89 (MapPartitionsRDD[169] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/02/28 14:16:29 INFO TaskSchedulerImpl: Adding task set 89.0 with 5 tasks
18/02/28 14:16:29 INFO TaskSetManager: Starting task 1.0 in stage 89.0 (TID 214, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 2.0 in stage 89.0 (TID 215, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 3.0 in stage 89.0 (TID 216, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 4.0 in stage 89.0 (TID 217, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:16:29 INFO Executor: Running task 1.0 in stage 89.0 (TID 214)
18/02/28 14:16:29 INFO Executor: Running task 3.0 in stage 89.0 (TID 216)
18/02/28 14:16:29 INFO Executor: Running task 4.0 in stage 89.0 (TID 217)
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_0 locally
18/02/28 14:16:29 INFO Executor: Finished task 1.0 in stage 89.0 (TID 214). 1338 bytes result sent to driver
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_2 locally
18/02/28 14:16:29 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 218, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:16:29 INFO Executor: Running task 2.0 in stage 89.0 (TID 215)
18/02/28 14:16:29 INFO Executor: Finished task 3.0 in stage 89.0 (TID 216). 1613 bytes result sent to driver
18/02/28 14:16:29 INFO TaskSetManager: Finished task 1.0 in stage 89.0 (TID 214) in 5 ms on localhost (executor driver) (1/5)
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_3 locally
18/02/28 14:16:29 INFO TaskSetManager: Finished task 3.0 in stage 89.0 (TID 216) in 5 ms on localhost (executor driver) (2/5)
18/02/28 14:16:29 INFO Executor: Finished task 4.0 in stage 89.0 (TID 217). 1609 bytes result sent to driver
18/02/28 14:16:29 INFO Executor: Running task 0.0 in stage 89.0 (TID 218)
18/02/28 14:16:29 INFO TaskSetManager: Finished task 4.0 in stage 89.0 (TID 217) in 6 ms on localhost (executor driver) (3/5)
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_1 locally
18/02/28 14:16:29 INFO Executor: Finished task 2.0 in stage 89.0 (TID 215). 1463 bytes result sent to driver
18/02/28 14:16:29 INFO Executor: Finished task 0.0 in stage 89.0 (TID 218). 1000 bytes result sent to driver
18/02/28 14:16:29 INFO TaskSetManager: Finished task 2.0 in stage 89.0 (TID 215) in 9 ms on localhost (executor driver) (4/5)
18/02/28 14:16:29 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 218) in 6 ms on localhost (executor driver) (5/5)
18/02/28 14:16:29 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
18/02/28 14:16:29 INFO DAGScheduler: ResultStage 89 (collect at utils.scala:211) finished in 0.010 s
18/02/28 14:16:29 INFO DAGScheduler: Job 46 finished: collect at utils.scala:211, took 0.015937 s
18/02/28 14:16:29 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 127.0.0.1:61463 in memory (size: 5.3 KB, free: 345.4 MB)
18/02/28 14:16:29 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:16:29 INFO DAGScheduler: Got job 47 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:16:29 INFO DAGScheduler: Final stage: ResultStage 92 (collect at utils.scala:211)
18/02/28 14:16:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 91)
18/02/28 14:16:29 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 127.0.0.1:61463 in memory (size: 4.9 KB, free: 345.4 MB)
18/02/28 14:16:29 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:29 INFO DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[172] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:29 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 10.3 KB, free 344.7 MB)
18/02/28 14:16:29 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.7 MB)
18/02/28 14:16:29 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 127.0.0.1:61463 (size: 4.9 KB, free: 345.4 MB)
18/02/28 14:16:29 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:29 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 92 (MapPartitionsRDD[172] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:29 INFO TaskSchedulerImpl: Adding task set 92.0 with 4 tasks
18/02/28 14:16:29 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 219, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 1.0 in stage 92.0 (TID 220, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 2.0 in stage 92.0 (TID 221, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 3.0 in stage 92.0 (TID 222, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:29 INFO Executor: Running task 0.0 in stage 92.0 (TID 219)
18/02/28 14:16:29 INFO Executor: Running task 1.0 in stage 92.0 (TID 220)
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_0 locally
18/02/28 14:16:29 INFO Executor: Finished task 0.0 in stage 92.0 (TID 219). 1379 bytes result sent to driver
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_1 locally
18/02/28 14:16:29 INFO Executor: Finished task 1.0 in stage 92.0 (TID 220). 1448 bytes result sent to driver
18/02/28 14:16:29 INFO Executor: Running task 2.0 in stage 92.0 (TID 221)
18/02/28 14:16:29 INFO Executor: Running task 3.0 in stage 92.0 (TID 222)
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_2 locally
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_3 locally
18/02/28 14:16:29 INFO Executor: Finished task 2.0 in stage 92.0 (TID 221). 1618 bytes result sent to driver
18/02/28 14:16:29 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 127.0.0.1:61463 in memory (size: 4.9 KB, free: 345.4 MB)
18/02/28 14:16:29 INFO Executor: Finished task 3.0 in stage 92.0 (TID 222). 1623 bytes result sent to driver
18/02/28 14:16:29 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 219) in 11 ms on localhost (executor driver) (1/4)
18/02/28 14:16:29 INFO TaskSetManager: Finished task 1.0 in stage 92.0 (TID 220) in 12 ms on localhost (executor driver) (2/4)
18/02/28 14:16:29 INFO TaskSetManager: Finished task 2.0 in stage 92.0 (TID 221) in 12 ms on localhost (executor driver) (3/4)
18/02/28 14:16:29 INFO TaskSetManager: Finished task 3.0 in stage 92.0 (TID 222) in 13 ms on localhost (executor driver) (4/4)
18/02/28 14:16:29 INFO DAGScheduler: ResultStage 92 (collect at utils.scala:211) finished in 0.014 s
18/02/28 14:16:29 INFO DAGScheduler: Job 47 finished: collect at utils.scala:211, took 0.020775 s
18/02/28 14:16:29 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
18/02/28 14:16:29 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 127.0.0.1:61463 in memory (size: 4.9 KB, free: 345.4 MB)
18/02/28 14:16:29 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8c875fa29f8
18/02/28 14:16:29 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 127.0.0.1:61463 in memory (size: 3.4 KB, free: 345.5 MB)
18/02/28 14:16:29 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:61463 in memory (size: 2.3 KB, free: 345.5 MB)
18/02/28 14:16:29 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 127.0.0.1:61463 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:16:29 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 127.0.0.1:61463 in memory (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:16:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:29 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 127.0.0.1:61463 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:16:29 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 127.0.0.1:61463 in memory (size: 3.3 KB, free: 345.5 MB)
18/02/28 14:16:29 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 127.0.0.1:61463 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:16:29 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 127.0.0.1:61463 in memory (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:16:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8c875fa29f8` AS `zzz13`
WHERE (0 = 1)
18/02/28 14:16:29 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 127.0.0.1:61463 in memory (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:16:29 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 127.0.0.1:61463 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:16:29 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 127.0.0.1:61463 in memory (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:16:29 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:16:29 INFO DAGScheduler: Got job 48 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:16:29 INFO DAGScheduler: Final stage: ResultStage 95 (collect at utils.scala:211)
18/02/28 14:16:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 94)
18/02/28 14:16:29 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:29 INFO DAGScheduler: Submitting ResultStage 95 (MapPartitionsRDD[175] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:29 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 10.3 KB, free 344.8 MB)
18/02/28 14:16:29 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.8 MB)
18/02/28 14:16:29 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 127.0.0.1:61463 (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:16:29 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:29 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 95 (MapPartitionsRDD[175] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:29 INFO TaskSchedulerImpl: Adding task set 95.0 with 4 tasks
18/02/28 14:16:29 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 223, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 1.0 in stage 95.0 (TID 224, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 2.0 in stage 95.0 (TID 225, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 3.0 in stage 95.0 (TID 226, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:16:29 INFO Executor: Running task 0.0 in stage 95.0 (TID 223)
18/02/28 14:16:29 INFO Executor: Running task 1.0 in stage 95.0 (TID 224)
18/02/28 14:16:29 INFO Executor: Running task 2.0 in stage 95.0 (TID 225)
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_1 locally
18/02/28 14:16:29 INFO Executor: Finished task 1.0 in stage 95.0 (TID 224). 1591 bytes result sent to driver
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_2 locally
18/02/28 14:16:29 INFO Executor: Running task 3.0 in stage 95.0 (TID 226)
18/02/28 14:16:29 INFO Executor: Finished task 2.0 in stage 95.0 (TID 225). 1625 bytes result sent to driver
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_3 locally
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_0 locally
18/02/28 14:16:29 INFO Executor: Finished task 0.0 in stage 95.0 (TID 223). 1524 bytes result sent to driver
18/02/28 14:16:29 INFO Executor: Finished task 3.0 in stage 95.0 (TID 226). 1603 bytes result sent to driver
18/02/28 14:16:29 INFO TaskSetManager: Finished task 1.0 in stage 95.0 (TID 224) in 10 ms on localhost (executor driver) (1/4)
18/02/28 14:16:29 INFO TaskSetManager: Finished task 2.0 in stage 95.0 (TID 225) in 10 ms on localhost (executor driver) (2/4)
18/02/28 14:16:29 INFO TaskSetManager: Finished task 3.0 in stage 95.0 (TID 226) in 10 ms on localhost (executor driver) (3/4)
18/02/28 14:16:29 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 223) in 13 ms on localhost (executor driver) (4/4)
18/02/28 14:16:29 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool 
18/02/28 14:16:29 INFO DAGScheduler: ResultStage 95 (collect at utils.scala:211) finished in 0.013 s
18/02/28 14:16:29 INFO DAGScheduler: Job 48 finished: collect at utils.scala:211, took 0.018733 s
18/02/28 14:16:29 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:16:29 INFO DAGScheduler: Got job 49 (collect at utils.scala:211) with 6 output partitions
18/02/28 14:16:29 INFO DAGScheduler: Final stage: ResultStage 98 (collect at utils.scala:211)
18/02/28 14:16:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 97)
18/02/28 14:16:29 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:29 INFO DAGScheduler: Submitting ResultStage 98 (MapPartitionsRDD[178] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:29 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 11.2 KB, free 344.8 MB)
18/02/28 14:16:29 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 5.3 KB, free 344.8 MB)
18/02/28 14:16:29 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 127.0.0.1:61463 (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:16:29 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:29 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 98 (MapPartitionsRDD[178] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
18/02/28 14:16:29 INFO TaskSchedulerImpl: Adding task set 98.0 with 6 tasks
18/02/28 14:16:29 INFO TaskSetManager: Starting task 1.0 in stage 98.0 (TID 227, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 2.0 in stage 98.0 (TID 228, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 3.0 in stage 98.0 (TID 229, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 4.0 in stage 98.0 (TID 230, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:16:29 INFO Executor: Running task 1.0 in stage 98.0 (TID 227)
18/02/28 14:16:29 INFO Executor: Running task 2.0 in stage 98.0 (TID 228)
18/02/28 14:16:29 INFO Executor: Running task 3.0 in stage 98.0 (TID 229)
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_0 locally
18/02/28 14:16:29 INFO Executor: Finished task 1.0 in stage 98.0 (TID 227). 1327 bytes result sent to driver
18/02/28 14:16:29 INFO Executor: Running task 4.0 in stage 98.0 (TID 230)
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_2 locally
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_3 locally
18/02/28 14:16:29 INFO Executor: Finished task 3.0 in stage 98.0 (TID 229). 1565 bytes result sent to driver
18/02/28 14:16:29 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 231, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:16:29 INFO TaskSetManager: Starting task 5.0 in stage 98.0 (TID 232, localhost, executor driver, partition 5, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:16:29 INFO BlockManager: Found block rdd_116_1 locally
18/02/28 14:16:29 INFO Executor: Finished task 2.0 in stage 98.0 (TID 228). 1415 bytes result sent to driver
18/02/28 14:16:29 INFO TaskSetManager: Finished task 1.0 in stage 98.0 (TID 227) in 7 ms on localhost (executor driver) (1/6)
18/02/28 14:16:29 INFO TaskSetManager: Finished task 3.0 in stage 98.0 (TID 229) in 10 ms on localhost (executor driver) (2/6)
18/02/28 14:16:29 INFO TaskSetManager: Finished task 2.0 in stage 98.0 (TID 228) in 10 ms on localhost (executor driver) (3/6)
18/02/28 14:16:29 INFO Executor: Running task 0.0 in stage 98.0 (TID 231)
18/02/28 14:16:29 INFO Executor: Running task 5.0 in stage 98.0 (TID 232)
18/02/28 14:16:29 INFO Executor: Finished task 5.0 in stage 98.0 (TID 232). 1007 bytes result sent to driver
18/02/28 14:16:29 INFO Executor: Finished task 0.0 in stage 98.0 (TID 231). 1085 bytes result sent to driver
18/02/28 14:16:29 INFO Executor: Finished task 4.0 in stage 98.0 (TID 230). 1552 bytes result sent to driver
18/02/28 14:16:29 INFO TaskSetManager: Finished task 5.0 in stage 98.0 (TID 232) in 11 ms on localhost (executor driver) (4/6)
18/02/28 14:16:29 INFO TaskSetManager: Finished task 4.0 in stage 98.0 (TID 230) in 17 ms on localhost (executor driver) (5/6)
18/02/28 14:16:29 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 231) in 12 ms on localhost (executor driver) (6/6)
18/02/28 14:16:29 INFO DAGScheduler: ResultStage 98 (collect at utils.scala:211) finished in 0.018 s
18/02/28 14:16:29 INFO DAGScheduler: Job 49 finished: collect at utils.scala:211, took 0.032107 s
18/02/28 14:16:29 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool 
18/02/28 14:16:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 14:16:29 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8c85b912f95
18/02/28 14:16:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8c85b912f95` AS `zzz14`
WHERE (0 = 1)
18/02/28 14:16:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8c85b912f95`
18/02/28 14:16:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8c819791486`
18/02/28 14:16:30 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8c83aa71564
18/02/28 14:16:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8c83aa71564` AS `zzz15`
WHERE (0 = 1)
18/02/28 14:16:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8c83aa71564`
18/02/28 14:16:30 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8c828865dd9
18/02/28 14:16:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8c828865dd9` AS `zzz16`
WHERE (0 = 1)
18/02/28 14:16:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:30 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `dephour`, `prediction`, `probability`
FROM `sparklyr_tmp_8c828865dd9`
LIMIT 5
18/02/28 14:16:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:30 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `dephour`, `prediction`, `probability`
FROM `sparklyr_tmp_8c828865dd9`
LIMIT 5
18/02/28 14:16:30 INFO CodeGenerator: Code generated in 53.109041 ms
18/02/28 14:16:30 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:16:30 INFO DAGScheduler: Got job 50 (collect at utils.scala:211) with 1 output partitions
18/02/28 14:16:30 INFO DAGScheduler: Final stage: ResultStage 99 (collect at utils.scala:211)
18/02/28 14:16:30 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:16:30 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:30 INFO DAGScheduler: Submitting ResultStage 99 (MapPartitionsRDD[181] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:30 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 80.8 KB, free 344.7 MB)
18/02/28 14:16:30 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 29.8 KB, free 344.7 MB)
18/02/28 14:16:30 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 127.0.0.1:61463 (size: 29.8 KB, free: 345.5 MB)
18/02/28 14:16:30 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 99 (MapPartitionsRDD[181] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 14:16:30 INFO TaskSchedulerImpl: Adding task set 99.0 with 1 tasks
18/02/28 14:16:30 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 233, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:16:30 INFO Executor: Running task 0.0 in stage 99.0 (TID 233)
18/02/28 14:16:30 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 14:16:30 INFO Executor: Finished task 0.0 in stage 99.0 (TID 233). 1993 bytes result sent to driver
18/02/28 14:16:30 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 233) in 401 ms on localhost (executor driver) (1/1)
18/02/28 14:16:30 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool 
18/02/28 14:16:30 INFO DAGScheduler: ResultStage 99 (collect at utils.scala:211) finished in 0.402 s
18/02/28 14:16:30 INFO DAGScheduler: Job 50 finished: collect at utils.scala:211, took 0.409457 s
18/02/28 14:16:30 INFO CodeGenerator: Code generated in 9.058023 ms
18/02/28 14:16:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:31 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_8c828865dd9`
GROUP BY `delayed`, `prediction`
18/02/28 14:16:31 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:16:31 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:16:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:16:31 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_8c828865dd9`
GROUP BY `delayed`, `prediction`
LIMIT 10
18/02/28 14:16:31 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:16:31 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:16:31 INFO CodeGenerator: Code generated in 25.123953 ms
18/02/28 14:16:31 INFO CodeGenerator: Code generated in 60.718866 ms
18/02/28 14:16:31 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:16:31 INFO DAGScheduler: Registering RDD 184 (collect at utils.scala:211)
18/02/28 14:16:31 INFO DAGScheduler: Got job 51 (collect at utils.scala:211) with 1 output partitions
18/02/28 14:16:31 INFO DAGScheduler: Final stage: ResultStage 101 (collect at utils.scala:211)
18/02/28 14:16:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 100)
18/02/28 14:16:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 100)
18/02/28 14:16:31 INFO DAGScheduler: Submitting ShuffleMapStage 100 (MapPartitionsRDD[184] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:31 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 79.1 KB, free 344.6 MB)
18/02/28 14:16:31 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 32.2 KB, free 344.6 MB)
18/02/28 14:16:31 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 127.0.0.1:61463 (size: 32.2 KB, free: 345.4 MB)
18/02/28 14:16:31 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:31 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 100 (MapPartitionsRDD[184] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:16:31 INFO TaskSchedulerImpl: Adding task set 100.0 with 4 tasks
18/02/28 14:16:31 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 234, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:31 INFO TaskSetManager: Starting task 1.0 in stage 100.0 (TID 235, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:31 INFO TaskSetManager: Starting task 2.0 in stage 100.0 (TID 236, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:16:31 INFO TaskSetManager: Starting task 3.0 in stage 100.0 (TID 237, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:16:31 INFO Executor: Running task 0.0 in stage 100.0 (TID 234)
18/02/28 14:16:31 INFO Executor: Running task 1.0 in stage 100.0 (TID 235)
18/02/28 14:16:31 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 14:16:31 INFO BlockManager: Found block rdd_13_1 locally
18/02/28 14:16:31 INFO Executor: Running task 2.0 in stage 100.0 (TID 236)
18/02/28 14:16:31 INFO Executor: Running task 3.0 in stage 100.0 (TID 237)
18/02/28 14:16:31 INFO BlockManager: Found block rdd_13_2 locally
18/02/28 14:16:31 INFO ContextCleaner: Cleaned accumulator 1697
18/02/28 14:16:31 INFO BlockManager: Found block rdd_13_3 locally
18/02/28 14:16:31 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 127.0.0.1:61463 in memory (size: 5.3 KB, free: 345.4 MB)
18/02/28 14:16:31 INFO CodeGenerator: Code generated in 20.69297 ms
18/02/28 14:16:31 INFO CodeGenerator: Code generated in 29.816226 ms
18/02/28 14:16:31 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 127.0.0.1:61463 in memory (size: 4.9 KB, free: 345.4 MB)
18/02/28 14:16:31 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 127.0.0.1:61463 in memory (size: 29.8 KB, free: 345.5 MB)
18/02/28 14:16:31 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 127.0.0.1:61463 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:16:31 INFO CodeGenerator: Code generated in 34.796235 ms
18/02/28 14:16:32 INFO Executor: Finished task 3.0 in stage 100.0 (TID 237). 2411 bytes result sent to driver
18/02/28 14:16:32 INFO TaskSetManager: Finished task 3.0 in stage 100.0 (TID 237) in 1191 ms on localhost (executor driver) (1/4)
18/02/28 14:16:32 INFO Executor: Finished task 2.0 in stage 100.0 (TID 236). 2411 bytes result sent to driver
18/02/28 14:16:32 INFO TaskSetManager: Finished task 2.0 in stage 100.0 (TID 236) in 1202 ms on localhost (executor driver) (2/4)
18/02/28 14:16:32 INFO Executor: Finished task 0.0 in stage 100.0 (TID 234). 2454 bytes result sent to driver
18/02/28 14:16:32 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 234) in 1213 ms on localhost (executor driver) (3/4)
18/02/28 14:16:32 INFO Executor: Finished task 1.0 in stage 100.0 (TID 235). 2454 bytes result sent to driver
18/02/28 14:16:32 INFO TaskSetManager: Finished task 1.0 in stage 100.0 (TID 235) in 1223 ms on localhost (executor driver) (4/4)
18/02/28 14:16:32 INFO DAGScheduler: ShuffleMapStage 100 (collect at utils.scala:211) finished in 1.225 s
18/02/28 14:16:32 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:16:32 INFO DAGScheduler: running: Set()
18/02/28 14:16:32 INFO DAGScheduler: waiting: Set(ResultStage 101)
18/02/28 14:16:32 INFO DAGScheduler: failed: Set()
18/02/28 14:16:32 INFO DAGScheduler: Submitting ResultStage 101 (MapPartitionsRDD[187] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:32 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 38.0 KB, free 344.7 MB)
18/02/28 14:16:32 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool 
18/02/28 14:16:32 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 17.9 KB, free 344.7 MB)
18/02/28 14:16:32 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 127.0.0.1:61463 (size: 17.9 KB, free: 345.5 MB)
18/02/28 14:16:32 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 101 (MapPartitionsRDD[187] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 14:16:32 INFO TaskSchedulerImpl: Adding task set 101.0 with 1 tasks
18/02/28 14:16:32 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 238, localhost, executor driver, partition 0, PROCESS_LOCAL, 4726 bytes)
18/02/28 14:16:32 INFO Executor: Running task 0.0 in stage 101.0 (TID 238)
18/02/28 14:16:32 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 14:16:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 14:16:32 INFO Executor: Finished task 0.0 in stage 101.0 (TID 238). 2620 bytes result sent to driver
18/02/28 14:16:32 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 238) in 15 ms on localhost (executor driver) (1/1)
18/02/28 14:16:32 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool 
18/02/28 14:16:32 INFO DAGScheduler: ResultStage 101 (collect at utils.scala:211) finished in 0.016 s
18/02/28 14:16:32 INFO DAGScheduler: Job 51 finished: collect at utils.scala:211, took 1.258671 s
18/02/28 14:16:32 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:16:32 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 158 bytes
18/02/28 14:16:32 INFO DAGScheduler: Got job 52 (collect at utils.scala:211) with 3 output partitions
18/02/28 14:16:32 INFO DAGScheduler: Final stage: ResultStage 103 (collect at utils.scala:211)
18/02/28 14:16:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 102)
18/02/28 14:16:32 INFO DAGScheduler: Missing parents: List()
18/02/28 14:16:32 INFO DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[187] at collect at utils.scala:211), which has no missing parents
18/02/28 14:16:32 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 38.0 KB, free 344.7 MB)
18/02/28 14:16:32 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 17.9 KB, free 344.6 MB)
18/02/28 14:16:32 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 127.0.0.1:61463 (size: 17.9 KB, free: 345.4 MB)
18/02/28 14:16:32 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1006
18/02/28 14:16:32 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 103 (MapPartitionsRDD[187] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(1, 2, 3))
18/02/28 14:16:32 INFO TaskSchedulerImpl: Adding task set 103.0 with 3 tasks
18/02/28 14:16:32 INFO TaskSetManager: Starting task 2.0 in stage 103.0 (TID 239, localhost, executor driver, partition 3, PROCESS_LOCAL, 4726 bytes)
18/02/28 14:16:32 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 240, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 14:16:32 INFO TaskSetManager: Starting task 1.0 in stage 103.0 (TID 241, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 14:16:32 INFO Executor: Running task 1.0 in stage 103.0 (TID 241)
18/02/28 14:16:32 INFO Executor: Running task 0.0 in stage 103.0 (TID 240)
18/02/28 14:16:32 INFO Executor: Running task 2.0 in stage 103.0 (TID 239)
18/02/28 14:16:32 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:32 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 14:16:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:32 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:16:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:16:32 INFO Executor: Finished task 2.0 in stage 103.0 (TID 239). 2577 bytes result sent to driver
18/02/28 14:16:32 INFO Executor: Finished task 0.0 in stage 103.0 (TID 240). 2597 bytes result sent to driver
18/02/28 14:16:32 INFO Executor: Finished task 1.0 in stage 103.0 (TID 241). 2623 bytes result sent to driver
18/02/28 14:16:32 INFO TaskSetManager: Finished task 2.0 in stage 103.0 (TID 239) in 12 ms on localhost (executor driver) (1/3)
18/02/28 14:16:32 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 240) in 12 ms on localhost (executor driver) (2/3)
18/02/28 14:16:32 INFO TaskSetManager: Finished task 1.0 in stage 103.0 (TID 241) in 12 ms on localhost (executor driver) (3/3)
18/02/28 14:16:32 INFO DAGScheduler: ResultStage 103 (collect at utils.scala:211) finished in 0.013 s
18/02/28 14:16:32 INFO DAGScheduler: Job 52 finished: collect at utils.scala:211, took 0.019908 s
18/02/28 14:16:32 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool 
18/02/28 14:16:32 INFO CodeGenerator: Code generated in 6.131655 ms
18/02/28 14:16:34 INFO SparkContext: Invoking stop() from shutdown hook
18/02/28 14:16:34 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
18/02/28 14:16:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/02/28 14:16:34 INFO MemoryStore: MemoryStore cleared
18/02/28 14:16:34 INFO BlockManager: BlockManager stopped
18/02/28 14:16:34 INFO BlockManagerMaster: BlockManagerMaster stopped
18/02/28 14:16:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/02/28 14:16:34 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-e01f4c3c-af1d-408c-a784-906f00146bc1\userFiles-8bb8c3b4-7315-459b-9cc9-30c3add9a029
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-e01f4c3c-af1d-408c-a784-906f00146bc1\userFiles-8bb8c3b4-7315-459b-9cc9-30c3add9a029
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1937)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1936)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 14:16:34 INFO SparkContext: Successfully stopped SparkContext
18/02/28 14:16:34 INFO ShutdownHookManager: Shutdown hook called
18/02/28 14:16:34 INFO ShutdownHookManager: Deleting directory C:\Users\JC\AppData\Local\Temp\spark-e01f4c3c-af1d-408c-a784-906f00146bc1
18/02/28 14:16:34 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-e01f4c3c-af1d-408c-a784-906f00146bc1
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-e01f4c3c-af1d-408c-a784-906f00146bc1
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 14:16:34 INFO ShutdownHookManager: Deleting directory C:\Users\JC\AppData\Local\Temp\spark-e01f4c3c-af1d-408c-a784-906f00146bc1\userFiles-8bb8c3b4-7315-459b-9cc9-30c3add9a029
18/02/28 14:16:34 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-e01f4c3c-af1d-408c-a784-906f00146bc1\userFiles-8bb8c3b4-7315-459b-9cc9-30c3add9a029
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-e01f4c3c-af1d-408c-a784-906f00146bc1\userFiles-8bb8c3b4-7315-459b-9cc9-30c3add9a029
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 14:19:59 INFO SparkContext: Running Spark version 2.2.0
18/02/28 14:20:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/02/28 14:20:00 INFO SparkContext: Submitted application: sparklyr
18/02/28 14:20:00 INFO SecurityManager: Changing view acls to: JC
18/02/28 14:20:00 INFO SecurityManager: Changing modify acls to: JC
18/02/28 14:20:00 INFO SecurityManager: Changing view acls groups to: 
18/02/28 14:20:00 INFO SecurityManager: Changing modify acls groups to: 
18/02/28 14:20:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(JC); groups with view permissions: Set(); users  with modify permissions: Set(JC); groups with modify permissions: Set()
18/02/28 14:20:00 INFO Utils: Successfully started service 'sparkDriver' on port 61539.
18/02/28 14:20:00 INFO SparkEnv: Registering MapOutputTracker
18/02/28 14:20:00 INFO SparkEnv: Registering BlockManagerMaster
18/02/28 14:20:00 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/02/28 14:20:00 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/02/28 14:20:00 INFO DiskBlockManager: Created local directory at C:\Users\JC\AppData\Local\Temp\blockmgr-58d31373-3730-4b06-a6de-bae5c341de26
18/02/28 14:20:00 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/02/28 14:20:00 INFO SparkEnv: Registering OutputCommitCoordinator
18/02/28 14:20:00 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
18/02/28 14:20:00 INFO Utils: Successfully started service 'SparkUI' on port 4041.
18/02/28 14:20:00 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
18/02/28 14:20:01 INFO SparkContext: Added JAR file:/C:/Users/JC/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:61539/jars/sparklyr-2.2-2.11.jar with timestamp 1519856401019
18/02/28 14:20:01 INFO Executor: Starting executor ID driver on host localhost
18/02/28 14:20:01 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61560.
18/02/28 14:20:01 INFO NettyBlockTransferService: Server created on 127.0.0.1:61560
18/02/28 14:20:01 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/02/28 14:20:01 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 61560, None)
18/02/28 14:20:01 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:61560 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 61560, None)
18/02/28 14:20:01 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 61560, None)
18/02/28 14:20:01 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 61560, None)
18/02/28 14:20:01 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/02/28 14:20:01 INFO SharedState: loading hive config file: file:/C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
18/02/28 14:20:01 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:\Users\JC\AppData\Local\spark\spark-2.2.0-bin-hadoop2.7\tmp\hive') to the value of spark.sql.warehouse.dir ('C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive').
18/02/28 14:20:01 INFO SharedState: Warehouse path is 'C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive'.
18/02/28 14:20:02 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
18/02/28 14:20:03 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
18/02/28 14:20:03 INFO ObjectStore: ObjectStore, initialize called
18/02/28 14:20:03 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
18/02/28 14:20:03 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
18/02/28 14:20:05 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
18/02/28 14:20:06 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 14:20:06 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 14:20:07 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 14:20:07 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 14:20:07 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
18/02/28 14:20:07 INFO ObjectStore: Initialized ObjectStore
18/02/28 14:20:07 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
18/02/28 14:20:08 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
18/02/28 14:20:08 INFO HiveMetaStore: Added admin role in metastore
18/02/28 14:20:08 INFO HiveMetaStore: Added public role in metastore
18/02/28 14:20:08 INFO HiveMetaStore: No user is added in admin role, since config is empty
18/02/28 14:20:08 INFO HiveMetaStore: 0: get_all_databases
18/02/28 14:20:08 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_all_databases	
18/02/28 14:20:08 INFO HiveMetaStore: 0: get_functions: db=default pat=*
18/02/28 14:20:08 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
18/02/28 14:20:08 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 14:20:08 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/Temp/16876ae4-96b9-492c-8d53-afbb86b73eb8_resources
18/02/28 14:20:08 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/16876ae4-96b9-492c-8d53-afbb86b73eb8
18/02/28 14:20:08 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/16876ae4-96b9-492c-8d53-afbb86b73eb8
18/02/28 14:20:08 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/16876ae4-96b9-492c-8d53-afbb86b73eb8/_tmp_space.db
18/02/28 14:20:08 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive
18/02/28 14:20:09 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:20:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:20:09 INFO HiveMetaStore: 0: get_database: global_temp
18/02/28 14:20:09 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: global_temp	
18/02/28 14:20:09 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
18/02/28 14:20:09 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/Temp/98a8528b-d446-4df3-872b-2035330a51ab_resources
18/02/28 14:20:09 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/98a8528b-d446-4df3-872b-2035330a51ab
18/02/28 14:20:09 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/98a8528b-d446-4df3-872b-2035330a51ab
18/02/28 14:20:09 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/98a8528b-d446-4df3-872b-2035330a51ab/_tmp_space.db
18/02/28 14:20:09 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive
18/02/28 14:20:09 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
18/02/28 14:20:09 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 14:20:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:20:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:20:11 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:20:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:20:11 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 14:20:11 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 14:20:12 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 14:20:12 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
18/02/28 14:20:12 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
18/02/28 14:20:12 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:20:12 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:12 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55), which has no missing parents
18/02/28 14:20:12 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
18/02/28 14:20:12 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
18/02/28 14:20:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:61560 (size: 3.4 KB, free: 366.3 MB)
18/02/28 14:20:12 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0))
18/02/28 14:20:12 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/02/28 14:20:12 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 14:20:12 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/02/28 14:20:12 INFO Executor: Fetching spark://127.0.0.1:61539/jars/sparklyr-2.2-2.11.jar with timestamp 1519856401019
18/02/28 14:20:12 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:61539 after 41 ms (0 ms spent in bootstraps)
18/02/28 14:20:12 INFO Utils: Fetching spark://127.0.0.1:61539/jars/sparklyr-2.2-2.11.jar to C:\Users\JC\AppData\Local\Temp\spark-72c5f5e9-5b4e-4e8c-81bb-4b2be2cb0998\userFiles-f0c036d9-cd96-4d92-a179-b70bc14fa387\fetchFileTemp3061447411548999422.tmp
18/02/28 14:20:12 INFO Executor: Adding file:/C:/Users/JC/AppData/Local/Temp/spark-72c5f5e9-5b4e-4e8c-81bb-4b2be2cb0998/userFiles-f0c036d9-cd96-4d92-a179-b70bc14fa387/sparklyr-2.2-2.11.jar to class loader
18/02/28 14:20:13 INFO CodeGenerator: Code generated in 444.465131 ms
18/02/28 14:20:13 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1056 bytes result sent to driver
18/02/28 14:20:13 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1083 ms on localhost (executor driver) (1/1)
18/02/28 14:20:13 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/02/28 14:20:13 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 1.113 s
18/02/28 14:20:13 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 1.321705 s
18/02/28 14:20:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:14 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 14:20:14 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:20:14 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:20:14 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:20:14 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:20:14 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 14:20:14 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 14:20:14 INFO SparkSqlParser: Parsing command: spark_flights
18/02/28 14:20:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_flights` AS `zzz1`
WHERE (0 = 1)
18/02/28 14:20:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_flights`
18/02/28 14:20:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:14 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_flights`
18/02/28 14:20:14 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:20:14 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:20:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:14 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_flights`
LIMIT 10
18/02/28 14:20:14 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:20:14 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:20:14 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 14:20:14 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 14:20:14 INFO FileSourceStrategy: Output Data Schema: struct<>
18/02/28 14:20:14 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 14:20:15 INFO CodeGenerator: Code generated in 28.712889 ms
18/02/28 14:20:15 INFO CodeGenerator: Code generated in 14.218571 ms
18/02/28 14:20:15 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 282.5 KB, free 366.0 MB)
18/02/28 14:20:15 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 24.1 KB, free 366.0 MB)
18/02/28 14:20:15 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:61560 (size: 24.1 KB, free: 366.3 MB)
18/02/28 14:20:15 INFO SparkContext: Created broadcast 1 from collect at utils.scala:211
18/02/28 14:20:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21019222 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 14:20:15 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:20:15 INFO DAGScheduler: Registering RDD 7 (collect at utils.scala:211)
18/02/28 14:20:15 INFO DAGScheduler: Got job 1 (collect at utils.scala:211) with 1 output partitions
18/02/28 14:20:15 INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:211)
18/02/28 14:20:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
18/02/28 14:20:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
18/02/28 14:20:15 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:15 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 14.2 KB, free 366.0 MB)
18/02/28 14:20:15 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 8.0 KB, free 366.0 MB)
18/02/28 14:20:15 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:61560 (size: 8.0 KB, free: 366.3 MB)
18/02/28 14:20:15 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:15 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:15 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks
18/02/28 14:20:15 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:15 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:15 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:20:15 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:15 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
18/02/28 14:20:15 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:61560 in memory (size: 3.4 KB, free: 366.3 MB)
18/02/28 14:20:15 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
18/02/28 14:20:15 INFO ContextCleaner: Cleaned accumulator 49
18/02/28 14:20:15 INFO ContextCleaner: Cleaned accumulator 0
18/02/28 14:20:15 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
18/02/28 14:20:15 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
18/02/28 14:20:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_3.csv, range: 0-2881793, partition values: [empty row]
18/02/28 14:20:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_11.csv, range: 0-2757037, partition values: [empty row]
18/02/28 14:20:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_7.csv, range: 0-2938867, partition values: [empty row]
18/02/28 14:20:15 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_4.csv, range: 0-2830543, partition values: [empty row]
18/02/28 14:20:15 INFO CodeGenerator: Code generated in 14.376543 ms
18/02/28 14:20:16 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_1.csv, range: 0-2697256, partition values: [empty row]
18/02/28 14:20:16 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_8.csv, range: 0-2932019, partition values: [empty row]
18/02/28 14:20:16 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_5.csv, range: 0-2880181, partition values: [empty row]
18/02/28 14:20:16 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_6.csv, range: 0-2820227, partition values: [empty row]
18/02/28 14:20:16 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_2.csv, range: 0-2487144, partition values: [empty row]
18/02/28 14:20:16 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_10.csv, range: 0-2920629, partition values: [empty row]
18/02/28 14:20:16 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_12.csv, range: 0-2836468, partition values: [empty row]
18/02/28 14:20:16 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_9.csv, range: 0-2763076, partition values: [empty row]
18/02/28 14:20:16 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 1671 bytes result sent to driver
18/02/28 14:20:16 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 1085 ms on localhost (executor driver) (1/4)
18/02/28 14:20:16 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1585 bytes result sent to driver
18/02/28 14:20:16 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1105 ms on localhost (executor driver) (2/4)
18/02/28 14:20:16 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1585 bytes result sent to driver
18/02/28 14:20:16 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1585 bytes result sent to driver
18/02/28 14:20:16 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1110 ms on localhost (executor driver) (3/4)
18/02/28 14:20:16 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1118 ms on localhost (executor driver) (4/4)
18/02/28 14:20:16 INFO DAGScheduler: ShuffleMapStage 1 (collect at utils.scala:211) finished in 1.118 s
18/02/28 14:20:16 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:20:16 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/02/28 14:20:16 INFO DAGScheduler: running: Set()
18/02/28 14:20:16 INFO DAGScheduler: waiting: Set(ResultStage 2)
18/02/28 14:20:16 INFO DAGScheduler: failed: Set()
18/02/28 14:20:16 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[10] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:16 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.9 KB, free 366.0 MB)
18/02/28 14:20:16 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.0 MB)
18/02/28 14:20:16 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:61560 (size: 3.7 KB, free: 366.3 MB)
18/02/28 14:20:16 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 14:20:16 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
18/02/28 14:20:16 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 14:20:16 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
18/02/28 14:20:16 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
18/02/28 14:20:16 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1514 bytes result sent to driver
18/02/28 14:20:16 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 54 ms on localhost (executor driver) (1/1)
18/02/28 14:20:16 INFO DAGScheduler: ResultStage 2 (collect at utils.scala:211) finished in 0.055 s
18/02/28 14:20:16 INFO DAGScheduler: Job 1 finished: collect at utils.scala:211, took 1.539523 s
18/02/28 14:20:16 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/02/28 14:20:16 INFO CodeGenerator: Code generated in 7.865119 ms
18/02/28 14:20:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:16 INFO SparkSqlParser: Parsing command: SELECT `month`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`, `sched_dep_time`, `sched_arr_time`
FROM (SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`dep_time` AS DOUBLE) AS `dep_time`, CAST(`arr_time` AS DOUBLE) AS `arr_time`, CAST(`arr_delay` AS DOUBLE) AS `arr_delay`, CAST(`dep_delay` AS DOUBLE) AS `dep_delay`, CAST(`distance` AS DOUBLE) AS `distance`, CAST(`sched_dep_time` AS DOUBLE) AS `sched_dep_time`, CAST(`sched_arr_time` AS DOUBLE) AS `sched_arr_time`
FROM (SELECT `month`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`, `sched_dep_time`, `sched_arr_time`
FROM `spark_flights`) `kaoitbwvfl`) `isgcoitimu`
18/02/28 14:20:17 INFO SparkSqlParser: Parsing command: cached_flights
18/02/28 14:20:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights` AS `zzz2`
WHERE (0 = 1)
18/02/28 14:20:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:17 INFO SparkSqlParser: Parsing command: CACHE TABLE `cached_flights`
18/02/28 14:20:17 INFO SparkSqlParser: Parsing command: `cached_flights`
18/02/28 14:20:17 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 14:20:17 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 14:20:17 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dep_time: string, sched_dep_time: string, dep_delay: string, arr_time: string ... 6 more fields>
18/02/28 14:20:17 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 14:20:17 INFO CodeGenerator: Code generated in 21.021961 ms
18/02/28 14:20:17 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 282.5 KB, free 365.7 MB)
18/02/28 14:20:17 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.7 MB)
18/02/28 14:20:17 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:61560 (size: 24.1 KB, free: 366.2 MB)
18/02/28 14:20:17 INFO SparkContext: Created broadcast 4 from sql at <unknown>:0
18/02/28 14:20:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21019222 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 14:20:17 INFO CodeGenerator: Code generated in 10.105647 ms
18/02/28 14:20:17 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 14:20:17 INFO DAGScheduler: Registering RDD 16 (sql at <unknown>:0)
18/02/28 14:20:17 INFO DAGScheduler: Got job 2 (sql at <unknown>:0) with 1 output partitions
18/02/28 14:20:17 INFO DAGScheduler: Final stage: ResultStage 4 (sql at <unknown>:0)
18/02/28 14:20:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
18/02/28 14:20:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
18/02/28 14:20:17 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[16] at sql at <unknown>:0), which has no missing parents
18/02/28 14:20:17 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 26.7 KB, free 365.6 MB)
18/02/28 14:20:17 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 11.7 KB, free 365.6 MB)
18/02/28 14:20:17 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:61560 (size: 11.7 KB, free: 366.2 MB)
18/02/28 14:20:17 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:17 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[16] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:17 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks
18/02/28 14:20:17 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:17 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:17 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 8, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:20:17 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 9, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:17 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)
18/02/28 14:20:17 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)
18/02/28 14:20:17 INFO Executor: Running task 2.0 in stage 3.0 (TID 8)
18/02/28 14:20:17 INFO Executor: Running task 3.0 in stage 3.0 (TID 9)
18/02/28 14:20:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_7.csv, range: 0-2938867, partition values: [empty row]
18/02/28 14:20:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_4.csv, range: 0-2830543, partition values: [empty row]
18/02/28 14:20:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_3.csv, range: 0-2881793, partition values: [empty row]
18/02/28 14:20:17 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_11.csv, range: 0-2757037, partition values: [empty row]
18/02/28 14:20:17 INFO CodeGenerator: Code generated in 23.256495 ms
18/02/28 14:20:17 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:61560 in memory (size: 8.0 KB, free: 366.2 MB)
18/02/28 14:20:17 INFO ContextCleaner: Cleaned accumulator 119
18/02/28 14:20:17 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:61560 in memory (size: 3.7 KB, free: 366.2 MB)
18/02/28 14:20:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_5.csv, range: 0-2880181, partition values: [empty row]
18/02/28 14:20:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_8.csv, range: 0-2932019, partition values: [empty row]
18/02/28 14:20:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_1.csv, range: 0-2697256, partition values: [empty row]
18/02/28 14:20:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_6.csv, range: 0-2820227, partition values: [empty row]
18/02/28 14:20:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_12.csv, range: 0-2836468, partition values: [empty row]
18/02/28 14:20:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_2.csv, range: 0-2487144, partition values: [empty row]
18/02/28 14:20:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_10.csv, range: 0-2920629, partition values: [empty row]
18/02/28 14:20:18 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_9.csv, range: 0-2763076, partition values: [empty row]
18/02/28 14:20:18 INFO MemoryStore: Block rdd_13_1 stored as values in memory (estimated size 5.2 MB, free 360.5 MB)
18/02/28 14:20:18 INFO BlockManagerInfo: Added rdd_13_1 in memory on 127.0.0.1:61560 (size: 5.2 MB, free: 361.0 MB)
18/02/28 14:20:18 INFO MemoryStore: Block rdd_13_0 stored as values in memory (estimated size 5.3 MB, free 355.1 MB)
18/02/28 14:20:18 INFO BlockManagerInfo: Added rdd_13_0 in memory on 127.0.0.1:61560 (size: 5.3 MB, free: 355.7 MB)
18/02/28 14:20:18 INFO CodeGenerator: Code generated in 16.062758 ms
18/02/28 14:20:18 INFO MemoryStore: Block rdd_13_3 stored as values in memory (estimated size 4.8 MB, free 350.3 MB)
18/02/28 14:20:18 INFO BlockManagerInfo: Added rdd_13_3 in memory on 127.0.0.1:61560 (size: 4.8 MB, free: 350.9 MB)
18/02/28 14:20:18 INFO CodeGenerator: Code generated in 37.84355 ms
18/02/28 14:20:19 INFO MemoryStore: Block rdd_13_2 stored as values in memory (estimated size 5.1 MB, free 345.2 MB)
18/02/28 14:20:19 INFO BlockManagerInfo: Added rdd_13_2 in memory on 127.0.0.1:61560 (size: 5.1 MB, free: 345.8 MB)
18/02/28 14:20:19 INFO Executor: Finished task 3.0 in stage 3.0 (TID 9). 2461 bytes result sent to driver
18/02/28 14:20:19 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 9) in 1811 ms on localhost (executor driver) (1/4)
18/02/28 14:20:19 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 2461 bytes result sent to driver
18/02/28 14:20:19 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 1819 ms on localhost (executor driver) (2/4)
18/02/28 14:20:19 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 2461 bytes result sent to driver
18/02/28 14:20:19 INFO Executor: Finished task 2.0 in stage 3.0 (TID 8). 2504 bytes result sent to driver
18/02/28 14:20:19 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 1831 ms on localhost (executor driver) (3/4)
18/02/28 14:20:19 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 8) in 1831 ms on localhost (executor driver) (4/4)
18/02/28 14:20:19 INFO DAGScheduler: ShuffleMapStage 3 (sql at <unknown>:0) finished in 1.832 s
18/02/28 14:20:19 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:20:19 INFO DAGScheduler: running: Set()
18/02/28 14:20:19 INFO DAGScheduler: waiting: Set(ResultStage 4)
18/02/28 14:20:19 INFO DAGScheduler: failed: Set()
18/02/28 14:20:19 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[19] at sql at <unknown>:0), which has no missing parents
18/02/28 14:20:19 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/02/28 14:20:19 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.0 KB, free 345.2 MB)
18/02/28 14:20:19 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.7 KB, free 345.2 MB)
18/02/28 14:20:19 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:61560 (size: 3.7 KB, free: 345.8 MB)
18/02/28 14:20:19 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 14:20:19 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
18/02/28 14:20:19 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 10, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 14:20:19 INFO Executor: Running task 0.0 in stage 4.0 (TID 10)
18/02/28 14:20:19 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 14:20:19 INFO Executor: Finished task 0.0 in stage 4.0 (TID 10). 1495 bytes result sent to driver
18/02/28 14:20:19 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 10) in 7 ms on localhost (executor driver) (1/1)
18/02/28 14:20:19 INFO DAGScheduler: ResultStage 4 (sql at <unknown>:0) finished in 0.007 s
18/02/28 14:20:19 INFO DAGScheduler: Job 2 finished: sql at <unknown>:0, took 1.868989 s
18/02/28 14:20:19 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/02/28 14:20:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:19 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `cached_flights`
18/02/28 14:20:19 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:20:19 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:20:19 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:20:19 INFO DAGScheduler: Registering RDD 22 (collect at utils.scala:211)
18/02/28 14:20:19 INFO DAGScheduler: Got job 3 (collect at utils.scala:211) with 1 output partitions
18/02/28 14:20:19 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:211)
18/02/28 14:20:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
18/02/28 14:20:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
18/02/28 14:20:19 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[22] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:19 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 26.7 KB, free 345.2 MB)
18/02/28 14:20:19 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.7 KB, free 345.2 MB)
18/02/28 14:20:19 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:61560 (size: 11.7 KB, free: 345.8 MB)
18/02/28 14:20:19 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:19 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[22] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:19 INFO TaskSchedulerImpl: Adding task set 5.0 with 4 tasks
18/02/28 14:20:19 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:19 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 12, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:19 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 13, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:20:19 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 14, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:19 INFO Executor: Running task 0.0 in stage 5.0 (TID 11)
18/02/28 14:20:19 INFO Executor: Running task 1.0 in stage 5.0 (TID 12)
18/02/28 14:20:19 INFO Executor: Running task 2.0 in stage 5.0 (TID 13)
18/02/28 14:20:19 INFO Executor: Running task 3.0 in stage 5.0 (TID 14)
18/02/28 14:20:19 INFO BlockManager: Found block rdd_13_2 locally
18/02/28 14:20:19 INFO BlockManager: Found block rdd_13_3 locally
18/02/28 14:20:19 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 14:20:19 INFO BlockManager: Found block rdd_13_1 locally
18/02/28 14:20:19 INFO Executor: Finished task 1.0 in stage 5.0 (TID 12). 1737 bytes result sent to driver
18/02/28 14:20:19 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 12) in 44 ms on localhost (executor driver) (1/4)
18/02/28 14:20:19 INFO Executor: Finished task 3.0 in stage 5.0 (TID 14). 1737 bytes result sent to driver
18/02/28 14:20:19 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 14) in 47 ms on localhost (executor driver) (2/4)
18/02/28 14:20:19 INFO Executor: Finished task 0.0 in stage 5.0 (TID 11). 1694 bytes result sent to driver
18/02/28 14:20:19 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 11) in 58 ms on localhost (executor driver) (3/4)
18/02/28 14:20:19 INFO Executor: Finished task 2.0 in stage 5.0 (TID 13). 1737 bytes result sent to driver
18/02/28 14:20:19 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 13) in 56 ms on localhost (executor driver) (4/4)
18/02/28 14:20:19 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:211) finished in 0.060 s
18/02/28 14:20:19 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:20:19 INFO DAGScheduler: running: Set()
18/02/28 14:20:19 INFO DAGScheduler: waiting: Set(ResultStage 6)
18/02/28 14:20:19 INFO DAGScheduler: failed: Set()
18/02/28 14:20:19 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:19 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.0 KB, free 345.1 MB)
18/02/28 14:20:19 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.7 KB, free 345.1 MB)
18/02/28 14:20:19 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/02/28 14:20:19 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:61560 (size: 3.7 KB, free: 345.8 MB)
18/02/28 14:20:19 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 14:20:19 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
18/02/28 14:20:19 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 15, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 14:20:19 INFO Executor: Running task 0.0 in stage 6.0 (TID 15)
18/02/28 14:20:19 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:20:19 INFO Executor: Finished task 0.0 in stage 6.0 (TID 15). 1538 bytes result sent to driver
18/02/28 14:20:19 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 15) in 7 ms on localhost (executor driver) (1/1)
18/02/28 14:20:19 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
18/02/28 14:20:19 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:211) finished in 0.008 s
18/02/28 14:20:19 INFO DAGScheduler: Job 3 finished: collect at utils.scala:211, took 0.086823 s
18/02/28 14:20:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:19 INFO SparkSqlParser: Parsing command: SHOW TABLES LIKE"cached_flights"
18/02/28 14:20:19 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:20:19 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:20:19 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:20:19 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:20:19 INFO HiveMetaStore: 0: get_tables: db=default pat=cached_flights
18/02/28 14:20:19 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=cached_flights	
18/02/28 14:20:19 INFO CodeGenerator: Code generated in 8.65604 ms
18/02/28 14:20:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights` AS `zzz3`
WHERE (0 = 1)
18/02/28 14:20:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:19 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `cached_flights`
18/02/28 14:20:19 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:20:19 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:20:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:19 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `cached_flights`
LIMIT 10
18/02/28 14:20:19 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:20:19 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:20:19 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:20:19 INFO DAGScheduler: Registering RDD 28 (collect at utils.scala:211)
18/02/28 14:20:19 INFO DAGScheduler: Got job 4 (collect at utils.scala:211) with 1 output partitions
18/02/28 14:20:19 INFO DAGScheduler: Final stage: ResultStage 8 (collect at utils.scala:211)
18/02/28 14:20:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
18/02/28 14:20:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
18/02/28 14:20:19 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[28] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:19 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 26.7 KB, free 345.1 MB)
18/02/28 14:20:19 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 11.7 KB, free 345.1 MB)
18/02/28 14:20:19 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:61560 (size: 11.7 KB, free: 345.7 MB)
18/02/28 14:20:19 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:19 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[28] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:19 INFO TaskSchedulerImpl: Adding task set 7.0 with 4 tasks
18/02/28 14:20:19 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:19 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 17, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:19 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 18, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:20:19 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 19, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:19 INFO Executor: Running task 0.0 in stage 7.0 (TID 16)
18/02/28 14:20:19 INFO Executor: Running task 1.0 in stage 7.0 (TID 17)
18/02/28 14:20:19 INFO Executor: Running task 2.0 in stage 7.0 (TID 18)
18/02/28 14:20:19 INFO BlockManager: Found block rdd_13_1 locally
18/02/28 14:20:19 INFO Executor: Running task 3.0 in stage 7.0 (TID 19)
18/02/28 14:20:19 INFO BlockManager: Found block rdd_13_3 locally
18/02/28 14:20:19 INFO BlockManager: Found block rdd_13_2 locally
18/02/28 14:20:19 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 14:20:19 INFO Executor: Finished task 0.0 in stage 7.0 (TID 16). 1694 bytes result sent to driver
18/02/28 14:20:19 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 16) in 51 ms on localhost (executor driver) (1/4)
18/02/28 14:20:19 INFO Executor: Finished task 1.0 in stage 7.0 (TID 17). 1694 bytes result sent to driver
18/02/28 14:20:19 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 17) in 64 ms on localhost (executor driver) (2/4)
18/02/28 14:20:19 INFO Executor: Finished task 3.0 in stage 7.0 (TID 19). 1694 bytes result sent to driver
18/02/28 14:20:19 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 19) in 74 ms on localhost (executor driver) (3/4)
18/02/28 14:20:19 INFO Executor: Finished task 2.0 in stage 7.0 (TID 18). 1737 bytes result sent to driver
18/02/28 14:20:19 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 18) in 82 ms on localhost (executor driver) (4/4)
18/02/28 14:20:19 INFO DAGScheduler: ShuffleMapStage 7 (collect at utils.scala:211) finished in 0.084 s
18/02/28 14:20:19 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:20:19 INFO DAGScheduler: running: Set()
18/02/28 14:20:19 INFO DAGScheduler: waiting: Set(ResultStage 8)
18/02/28 14:20:19 INFO DAGScheduler: failed: Set()
18/02/28 14:20:19 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[31] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:19 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 6.9 KB, free 345.1 MB)
18/02/28 14:20:19 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.7 KB, free 345.1 MB)
18/02/28 14:20:19 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
18/02/28 14:20:19 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:61560 (size: 3.7 KB, free: 345.7 MB)
18/02/28 14:20:19 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[31] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 14:20:19 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
18/02/28 14:20:19 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 20, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 14:20:19 INFO Executor: Running task 0.0 in stage 8.0 (TID 20)
18/02/28 14:20:19 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:20:19 INFO Executor: Finished task 0.0 in stage 8.0 (TID 20). 1557 bytes result sent to driver
18/02/28 14:20:19 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 20) in 10 ms on localhost (executor driver) (1/1)
18/02/28 14:20:19 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
18/02/28 14:20:19 INFO DAGScheduler: ResultStage 8 (collect at utils.scala:211) finished in 0.011 s
18/02/28 14:20:19 INFO DAGScheduler: Job 4 finished: collect at utils.scala:211, took 0.117055 s
18/02/28 14:20:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
LIMIT 5
18/02/28 14:20:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
LIMIT 5
18/02/28 14:20:19 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:20:19 INFO DAGScheduler: Got job 5 (collect at utils.scala:211) with 1 output partitions
18/02/28 14:20:19 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:211)
18/02/28 14:20:19 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:20:19 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:19 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[33] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:19 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 22.8 KB, free 345.1 MB)
18/02/28 14:20:19 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 10.3 KB, free 345.1 MB)
18/02/28 14:20:19 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:61560 (size: 10.3 KB, free: 345.7 MB)
18/02/28 14:20:19 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[33] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 14:20:19 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
18/02/28 14:20:19 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:19 INFO Executor: Running task 0.0 in stage 9.0 (TID 21)
18/02/28 14:20:19 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 14:20:19 INFO CodeGenerator: Code generated in 22.04455 ms
18/02/28 14:20:19 INFO Executor: 1 block locks were not released by TID = 21:
[rdd_13_0]
18/02/28 14:20:19 INFO Executor: Finished task 0.0 in stage 9.0 (TID 21). 1438 bytes result sent to driver
18/02/28 14:20:19 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 21) in 62 ms on localhost (executor driver) (1/1)
18/02/28 14:20:19 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:211) finished in 0.063 s
18/02/28 14:20:19 INFO DAGScheduler: Job 5 finished: collect at utils.scala:211, took 0.080904 s
18/02/28 14:20:19 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
18/02/28 14:20:19 INFO CodeGenerator: Code generated in 10.368347 ms
18/02/28 14:20:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:19 INFO SparkSqlParser: Parsing command: SELECT `month`, count(*) AS `n()`
FROM `cached_flights`
GROUP BY `month`
18/02/28 14:20:19 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:20:19 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:20:20 INFO CodeGenerator: Code generated in 25.508306 ms
18/02/28 14:20:20 INFO CodeGenerator: Code generated in 38.834404 ms
18/02/28 14:20:20 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:20:20 INFO DAGScheduler: Registering RDD 36 (collect at utils.scala:211)
18/02/28 14:20:20 INFO DAGScheduler: Got job 6 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:20:20 INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:211)
18/02/28 14:20:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
18/02/28 14:20:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
18/02/28 14:20:20 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[36] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:20 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 37.3 KB, free 345.0 MB)
18/02/28 14:20:20 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 16.6 KB, free 345.0 MB)
18/02/28 14:20:20 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:61560 in memory (size: 3.7 KB, free: 345.7 MB)
18/02/28 14:20:20 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:61560 (size: 16.6 KB, free: 345.7 MB)
18/02/28 14:20:20 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:20 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[36] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:20 INFO TaskSchedulerImpl: Adding task set 10.0 with 4 tasks
18/02/28 14:20:20 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:61560 in memory (size: 10.3 KB, free: 345.7 MB)
18/02/28 14:20:20 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:20 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:20 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:20:20 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:20 INFO Executor: Running task 0.0 in stage 10.0 (TID 22)
18/02/28 14:20:20 INFO Executor: Running task 1.0 in stage 10.0 (TID 23)
18/02/28 14:20:20 INFO Executor: Running task 2.0 in stage 10.0 (TID 24)
18/02/28 14:20:20 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 14:20:20 INFO Executor: Running task 3.0 in stage 10.0 (TID 25)
18/02/28 14:20:20 INFO BlockManager: Found block rdd_13_2 locally
18/02/28 14:20:20 INFO BlockManager: Found block rdd_13_1 locally
18/02/28 14:20:20 INFO BlockManager: Found block rdd_13_3 locally
18/02/28 14:20:20 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:61560 in memory (size: 3.7 KB, free: 345.7 MB)
18/02/28 14:20:20 INFO CodeGenerator: Code generated in 20.768782 ms
18/02/28 14:20:20 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:61560 in memory (size: 11.7 KB, free: 345.7 MB)
18/02/28 14:20:20 INFO ContextCleaner: Cleaned accumulator 241
18/02/28 14:20:20 INFO ContextCleaner: Cleaned accumulator 327
18/02/28 14:20:20 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:61560 in memory (size: 3.7 KB, free: 345.7 MB)
18/02/28 14:20:20 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:61560 in memory (size: 11.7 KB, free: 345.8 MB)
18/02/28 14:20:20 INFO CodeGenerator: Code generated in 9.862342 ms
18/02/28 14:20:20 INFO ContextCleaner: Cleaned accumulator 180
18/02/28 14:20:20 INFO CodeGenerator: Code generated in 8.773109 ms
18/02/28 14:20:20 INFO CodeGenerator: Code generated in 8.569649 ms
18/02/28 14:20:20 INFO CodeGenerator: Code generated in 16.245413 ms
18/02/28 14:20:20 INFO CodeGenerator: Code generated in 6.052669 ms
18/02/28 14:20:20 INFO Executor: Finished task 1.0 in stage 10.0 (TID 23). 1968 bytes result sent to driver
18/02/28 14:20:20 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 322 ms on localhost (executor driver) (1/4)
18/02/28 14:20:20 INFO Executor: Finished task 2.0 in stage 10.0 (TID 24). 1968 bytes result sent to driver
18/02/28 14:20:20 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 328 ms on localhost (executor driver) (2/4)
18/02/28 14:20:20 INFO Executor: Finished task 3.0 in stage 10.0 (TID 25). 1968 bytes result sent to driver
18/02/28 14:20:20 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 333 ms on localhost (executor driver) (3/4)
18/02/28 14:20:20 INFO Executor: Finished task 0.0 in stage 10.0 (TID 22). 1968 bytes result sent to driver
18/02/28 14:20:20 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 342 ms on localhost (executor driver) (4/4)
18/02/28 14:20:20 INFO DAGScheduler: ShuffleMapStage 10 (collect at utils.scala:211) finished in 0.343 s
18/02/28 14:20:20 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:20:20 INFO DAGScheduler: running: Set()
18/02/28 14:20:20 INFO DAGScheduler: waiting: Set(ResultStage 11)
18/02/28 14:20:20 INFO DAGScheduler: failed: Set()
18/02/28 14:20:20 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[39] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:20 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
18/02/28 14:20:20 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 17.6 KB, free 345.1 MB)
18/02/28 14:20:20 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 8.2 KB, free 345.1 MB)
18/02/28 14:20:20 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:61560 (size: 8.2 KB, free: 345.8 MB)
18/02/28 14:20:20 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 11 (MapPartitionsRDD[39] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:20 INFO TaskSchedulerImpl: Adding task set 11.0 with 4 tasks
18/02/28 14:20:20 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 26, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 14:20:20 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 27, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 14:20:20 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 28, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 14:20:20 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 29, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 14:20:20 INFO Executor: Running task 1.0 in stage 11.0 (TID 27)
18/02/28 14:20:20 INFO Executor: Running task 0.0 in stage 11.0 (TID 26)
18/02/28 14:20:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 14:20:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 14:20:20 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 14:20:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:20:20 INFO Executor: Running task 2.0 in stage 11.0 (TID 28)
18/02/28 14:20:20 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 14:20:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 14:20:20 INFO Executor: Running task 3.0 in stage 11.0 (TID 29)
18/02/28 14:20:20 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 14:20:20 INFO Executor: Finished task 2.0 in stage 11.0 (TID 28). 2281 bytes result sent to driver
18/02/28 14:20:20 INFO Executor: Finished task 0.0 in stage 11.0 (TID 26). 2324 bytes result sent to driver
18/02/28 14:20:20 INFO Executor: Finished task 1.0 in stage 11.0 (TID 27). 2263 bytes result sent to driver
18/02/28 14:20:20 INFO Executor: Finished task 3.0 in stage 11.0 (TID 29). 2254 bytes result sent to driver
18/02/28 14:20:20 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 28) in 29 ms on localhost (executor driver) (1/4)
18/02/28 14:20:20 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 26) in 31 ms on localhost (executor driver) (2/4)
18/02/28 14:20:20 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 27) in 31 ms on localhost (executor driver) (3/4)
18/02/28 14:20:20 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 29) in 31 ms on localhost (executor driver) (4/4)
18/02/28 14:20:20 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
18/02/28 14:20:20 INFO DAGScheduler: ResultStage 11 (collect at utils.scala:211) finished in 0.033 s
18/02/28 14:20:20 INFO DAGScheduler: Job 6 finished: collect at utils.scala:211, took 0.392982 s
18/02/28 14:20:20 INFO CodeGenerator: Code generated in 5.941242 ms
18/02/28 14:20:21 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
WHERE (NOT(((`arr_delay`) IS NULL)))
18/02/28 14:20:21 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2ef8755773b5
18/02/28 14:20:21 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ef8755773b5` AS `zzz4`
WHERE (0 = 1)
18/02/28 14:20:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ef8755773b5`
18/02/28 14:20:22 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2ef8243e3800
18/02/28 14:20:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ef8243e3800` AS `zzz5`
WHERE (0 = 1)
18/02/28 14:20:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:22 INFO SparkSqlParser: Parsing command: SELECT `month`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`, `sched_dep_time`, `sched_arr_time`, `delayed`, CONCAT("h", CAST(`dephour` AS INT)) AS `dephour`
FROM `sparklyr_tmp_2ef8243e3800`
18/02/28 14:20:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:20:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:20:22 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2ef869765cb3
18/02/28 14:20:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ef869765cb3` AS `zzz6`
WHERE (0 = 1)
18/02/28 14:20:22 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2ef86a7557ba
18/02/28 14:20:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ef86a7557ba` AS `zzz7`
WHERE (0 = 1)
18/02/28 14:20:22 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2ef8225b81a
18/02/28 14:20:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ef8225b81a` AS `zzz8`
WHERE (0 = 1)
18/02/28 14:20:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:22 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_2ef869765cb3`
18/02/28 14:20:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:20:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:20:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:22 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_2ef869765cb3`
LIMIT 10
18/02/28 14:20:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:20:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:20:22 INFO CodeGenerator: Code generated in 44.496726 ms
18/02/28 14:20:22 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:20:22 INFO DAGScheduler: Registering RDD 42 (collect at utils.scala:211)
18/02/28 14:20:22 INFO DAGScheduler: Got job 7 (collect at utils.scala:211) with 1 output partitions
18/02/28 14:20:22 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:211)
18/02/28 14:20:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
18/02/28 14:20:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
18/02/28 14:20:22 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[42] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:22 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 47.6 KB, free 345.1 MB)
18/02/28 14:20:22 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 20.6 KB, free 345.1 MB)
18/02/28 14:20:22 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:61560 (size: 20.6 KB, free: 345.7 MB)
18/02/28 14:20:22 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:22 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[42] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:22 INFO TaskSchedulerImpl: Adding task set 12.0 with 4 tasks
18/02/28 14:20:22 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:22 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 31, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:22 INFO TaskSetManager: Starting task 2.0 in stage 12.0 (TID 32, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:20:22 INFO TaskSetManager: Starting task 3.0 in stage 12.0 (TID 33, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:22 INFO Executor: Running task 0.0 in stage 12.0 (TID 30)
18/02/28 14:20:22 INFO Executor: Running task 1.0 in stage 12.0 (TID 31)
18/02/28 14:20:22 INFO Executor: Running task 2.0 in stage 12.0 (TID 32)
18/02/28 14:20:22 INFO Executor: Running task 3.0 in stage 12.0 (TID 33)
18/02/28 14:20:22 INFO BlockManager: Found block rdd_13_2 locally
18/02/28 14:20:22 INFO BlockManager: Found block rdd_13_3 locally
18/02/28 14:20:22 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 14:20:22 INFO BlockManager: Found block rdd_13_1 locally
18/02/28 14:20:22 INFO CodeGenerator: Code generated in 56.025888 ms
18/02/28 14:20:22 INFO CodeGenerator: Code generated in 13.315519 ms
18/02/28 14:20:23 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:61560 in memory (size: 8.2 KB, free: 345.7 MB)
18/02/28 14:20:23 INFO ContextCleaner: Cleaned accumulator 388
18/02/28 14:20:23 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:61560 in memory (size: 16.6 KB, free: 345.8 MB)
18/02/28 14:20:23 INFO Executor: Finished task 0.0 in stage 12.0 (TID 30). 2451 bytes result sent to driver
18/02/28 14:20:23 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 30) in 969 ms on localhost (executor driver) (1/4)
18/02/28 14:20:23 INFO Executor: Finished task 3.0 in stage 12.0 (TID 33). 2451 bytes result sent to driver
18/02/28 14:20:23 INFO TaskSetManager: Finished task 3.0 in stage 12.0 (TID 33) in 973 ms on localhost (executor driver) (2/4)
18/02/28 14:20:23 INFO Executor: Finished task 2.0 in stage 12.0 (TID 32). 2408 bytes result sent to driver
18/02/28 14:20:23 INFO TaskSetManager: Finished task 2.0 in stage 12.0 (TID 32) in 990 ms on localhost (executor driver) (3/4)
18/02/28 14:20:23 INFO Executor: Finished task 1.0 in stage 12.0 (TID 31). 2408 bytes result sent to driver
18/02/28 14:20:23 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 31) in 996 ms on localhost (executor driver) (4/4)
18/02/28 14:20:23 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
18/02/28 14:20:23 INFO DAGScheduler: ShuffleMapStage 12 (collect at utils.scala:211) finished in 0.998 s
18/02/28 14:20:23 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:20:23 INFO DAGScheduler: running: Set()
18/02/28 14:20:23 INFO DAGScheduler: waiting: Set(ResultStage 13)
18/02/28 14:20:23 INFO DAGScheduler: failed: Set()
18/02/28 14:20:23 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[45] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:23 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 6.9 KB, free 345.1 MB)
18/02/28 14:20:23 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 345.1 MB)
18/02/28 14:20:23 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:61560 (size: 3.7 KB, free: 345.8 MB)
18/02/28 14:20:23 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[45] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 14:20:23 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
18/02/28 14:20:23 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 34, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 14:20:23 INFO Executor: Running task 0.0 in stage 13.0 (TID 34)
18/02/28 14:20:23 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 14:20:23 INFO Executor: Finished task 0.0 in stage 13.0 (TID 34). 1514 bytes result sent to driver
18/02/28 14:20:23 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 34) in 6 ms on localhost (executor driver) (1/1)
18/02/28 14:20:23 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
18/02/28 14:20:23 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:211) finished in 0.006 s
18/02/28 14:20:23 INFO DAGScheduler: Job 7 finished: collect at utils.scala:211, took 1.026433 s
18/02/28 14:20:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ef869765cb3`
18/02/28 14:20:23 INFO SparkSqlParser: Parsing command: training
18/02/28 14:20:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training` AS `zzz9`
WHERE (0 = 1)
18/02/28 14:20:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:23 INFO SparkSqlParser: Parsing command: CACHE TABLE `training`
18/02/28 14:20:23 INFO SparkSqlParser: Parsing command: `training`
18/02/28 14:20:24 INFO CodeGenerator: Code generated in 41.164849 ms
18/02/28 14:20:24 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 14:20:24 INFO DAGScheduler: Registering RDD 51 (sql at <unknown>:0)
18/02/28 14:20:24 INFO DAGScheduler: Got job 8 (sql at <unknown>:0) with 1 output partitions
18/02/28 14:20:24 INFO DAGScheduler: Final stage: ResultStage 15 (sql at <unknown>:0)
18/02/28 14:20:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
18/02/28 14:20:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)
18/02/28 14:20:24 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[51] at sql at <unknown>:0), which has no missing parents
18/02/28 14:20:24 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 53.6 KB, free 345.1 MB)
18/02/28 14:20:24 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 22.0 KB, free 345.0 MB)
18/02/28 14:20:24 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:61560 (size: 22.0 KB, free: 345.7 MB)
18/02/28 14:20:24 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:24 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[51] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:24 INFO TaskSchedulerImpl: Adding task set 14.0 with 4 tasks
18/02/28 14:20:24 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:24 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 36, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:24 INFO TaskSetManager: Starting task 2.0 in stage 14.0 (TID 37, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:20:24 INFO TaskSetManager: Starting task 3.0 in stage 14.0 (TID 38, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:24 INFO Executor: Running task 0.0 in stage 14.0 (TID 35)
18/02/28 14:20:24 INFO Executor: Running task 1.0 in stage 14.0 (TID 36)
18/02/28 14:20:24 INFO Executor: Running task 2.0 in stage 14.0 (TID 37)
18/02/28 14:20:24 INFO Executor: Running task 3.0 in stage 14.0 (TID 38)
18/02/28 14:20:24 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 14:20:24 INFO BlockManager: Found block rdd_13_1 locally
18/02/28 14:20:24 INFO BlockManager: Found block rdd_13_2 locally
18/02/28 14:20:24 INFO BlockManager: Found block rdd_13_3 locally
18/02/28 14:20:24 INFO ContextCleaner: Cleaned accumulator 462
18/02/28 14:20:24 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:61560 in memory (size: 3.7 KB, free: 345.7 MB)
18/02/28 14:20:24 INFO MemoryStore: Block rdd_48_2 stored as values in memory (estimated size 56.9 KB, free 325.0 MB)
18/02/28 14:20:24 INFO BlockManagerInfo: Added rdd_48_2 in memory on 127.0.0.1:61560 (size: 56.9 KB, free: 345.7 MB)
18/02/28 14:20:24 INFO MemoryStore: Block rdd_48_0 stored as values in memory (estimated size 59.5 KB, free 334.9 MB)
18/02/28 14:20:24 INFO BlockManagerInfo: Added rdd_48_0 in memory on 127.0.0.1:61560 (size: 59.5 KB, free: 345.6 MB)
18/02/28 14:20:24 INFO MemoryStore: Block rdd_48_1 stored as values in memory (estimated size 59.1 KB, free 344.9 MB)
18/02/28 14:20:24 INFO BlockManagerInfo: Added rdd_48_1 in memory on 127.0.0.1:61560 (size: 59.1 KB, free: 345.6 MB)
18/02/28 14:20:24 INFO MemoryStore: Block rdd_48_3 stored as values in memory (estimated size 56.9 KB, free 344.8 MB)
18/02/28 14:20:24 INFO BlockManagerInfo: Added rdd_48_3 in memory on 127.0.0.1:61560 (size: 56.9 KB, free: 345.5 MB)
18/02/28 14:20:24 INFO Executor: Finished task 2.0 in stage 14.0 (TID 37). 3142 bytes result sent to driver
18/02/28 14:20:24 INFO TaskSetManager: Finished task 2.0 in stage 14.0 (TID 37) in 643 ms on localhost (executor driver) (1/4)
18/02/28 14:20:24 INFO Executor: Finished task 1.0 in stage 14.0 (TID 36). 3099 bytes result sent to driver
18/02/28 14:20:24 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 36) in 658 ms on localhost (executor driver) (2/4)
18/02/28 14:20:24 INFO Executor: Finished task 3.0 in stage 14.0 (TID 38). 3099 bytes result sent to driver
18/02/28 14:20:24 INFO TaskSetManager: Finished task 3.0 in stage 14.0 (TID 38) in 681 ms on localhost (executor driver) (3/4)
18/02/28 14:20:24 INFO Executor: Finished task 0.0 in stage 14.0 (TID 35). 3142 bytes result sent to driver
18/02/28 14:20:24 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 35) in 698 ms on localhost (executor driver) (4/4)
18/02/28 14:20:24 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
18/02/28 14:20:24 INFO DAGScheduler: ShuffleMapStage 14 (sql at <unknown>:0) finished in 0.698 s
18/02/28 14:20:24 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:20:24 INFO DAGScheduler: running: Set()
18/02/28 14:20:24 INFO DAGScheduler: waiting: Set(ResultStage 15)
18/02/28 14:20:24 INFO DAGScheduler: failed: Set()
18/02/28 14:20:24 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[54] at sql at <unknown>:0), which has no missing parents
18/02/28 14:20:24 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 344.8 MB)
18/02/28 14:20:24 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KB, free 344.8 MB)
18/02/28 14:20:24 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:61560 (size: 3.7 KB, free: 345.5 MB)
18/02/28 14:20:24 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[54] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 14:20:24 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
18/02/28 14:20:24 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 39, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 14:20:24 INFO Executor: Running task 0.0 in stage 15.0 (TID 39)
18/02/28 14:20:24 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:20:24 INFO Executor: Finished task 0.0 in stage 15.0 (TID 39). 1495 bytes result sent to driver
18/02/28 14:20:24 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 39) in 8 ms on localhost (executor driver) (1/1)
18/02/28 14:20:24 INFO DAGScheduler: ResultStage 15 (sql at <unknown>:0) finished in 0.010 s
18/02/28 14:20:24 INFO DAGScheduler: Job 8 finished: sql at <unknown>:0, took 0.729233 s
18/02/28 14:20:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:24 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
18/02/28 14:20:24 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `training`
18/02/28 14:20:24 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:20:24 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:20:24 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:20:24 INFO DAGScheduler: Registering RDD 57 (collect at utils.scala:211)
18/02/28 14:20:24 INFO DAGScheduler: Got job 9 (collect at utils.scala:211) with 1 output partitions
18/02/28 14:20:24 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:211)
18/02/28 14:20:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
18/02/28 14:20:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)
18/02/28 14:20:24 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[57] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:24 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 53.6 KB, free 344.8 MB)
18/02/28 14:20:24 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 22.1 KB, free 344.7 MB)
18/02/28 14:20:24 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:61560 (size: 22.1 KB, free: 345.5 MB)
18/02/28 14:20:24 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:24 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[57] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:24 INFO TaskSchedulerImpl: Adding task set 16.0 with 4 tasks
18/02/28 14:20:24 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 40, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:24 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 41, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:24 INFO TaskSetManager: Starting task 2.0 in stage 16.0 (TID 42, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:20:24 INFO TaskSetManager: Starting task 3.0 in stage 16.0 (TID 43, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:24 INFO Executor: Running task 0.0 in stage 16.0 (TID 40)
18/02/28 14:20:24 INFO Executor: Running task 1.0 in stage 16.0 (TID 41)
18/02/28 14:20:24 INFO BlockManager: Found block rdd_48_0 locally
18/02/28 14:20:24 INFO BlockManager: Found block rdd_48_1 locally
18/02/28 14:20:24 INFO Executor: Running task 3.0 in stage 16.0 (TID 43)
18/02/28 14:20:24 INFO Executor: Running task 2.0 in stage 16.0 (TID 42)
18/02/28 14:20:24 INFO BlockManager: Found block rdd_48_3 locally
18/02/28 14:20:24 INFO BlockManager: Found block rdd_48_2 locally
18/02/28 14:20:24 INFO Executor: Finished task 2.0 in stage 16.0 (TID 42). 2289 bytes result sent to driver
18/02/28 14:20:24 INFO TaskSetManager: Finished task 2.0 in stage 16.0 (TID 42) in 41 ms on localhost (executor driver) (1/4)
18/02/28 14:20:24 INFO Executor: Finished task 1.0 in stage 16.0 (TID 41). 2289 bytes result sent to driver
18/02/28 14:20:24 INFO Executor: Finished task 3.0 in stage 16.0 (TID 43). 2332 bytes result sent to driver
18/02/28 14:20:24 INFO TaskSetManager: Finished task 3.0 in stage 16.0 (TID 43) in 48 ms on localhost (executor driver) (2/4)
18/02/28 14:20:24 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 41) in 49 ms on localhost (executor driver) (3/4)
18/02/28 14:20:24 INFO Executor: Finished task 0.0 in stage 16.0 (TID 40). 2289 bytes result sent to driver
18/02/28 14:20:24 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 40) in 54 ms on localhost (executor driver) (4/4)
18/02/28 14:20:24 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
18/02/28 14:20:24 INFO DAGScheduler: ShuffleMapStage 16 (collect at utils.scala:211) finished in 0.054 s
18/02/28 14:20:24 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:20:24 INFO DAGScheduler: running: Set()
18/02/28 14:20:24 INFO DAGScheduler: waiting: Set(ResultStage 17)
18/02/28 14:20:24 INFO DAGScheduler: failed: Set()
18/02/28 14:20:24 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[60] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:24 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 7.0 KB, free 344.7 MB)
18/02/28 14:20:24 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 3.7 KB, free 344.7 MB)
18/02/28 14:20:24 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:61560 (size: 3.7 KB, free: 345.5 MB)
18/02/28 14:20:24 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[60] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 14:20:24 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
18/02/28 14:20:24 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 44, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 14:20:24 INFO Executor: Running task 0.0 in stage 17.0 (TID 44)
18/02/28 14:20:24 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:20:24 INFO Executor: Finished task 0.0 in stage 17.0 (TID 44). 1495 bytes result sent to driver
18/02/28 14:20:24 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 44) in 6 ms on localhost (executor driver) (1/1)
18/02/28 14:20:24 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
18/02/28 14:20:24 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:211) finished in 0.006 s
18/02/28 14:20:24 INFO DAGScheduler: Job 9 finished: collect at utils.scala:211, took 0.076557 s
18/02/28 14:20:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 14:20:25 INFO CodeGenerator: Code generated in 6.150343 ms
18/02/28 14:20:25 INFO SparkContext: Starting job: countByValue at StringIndexer.scala:113
18/02/28 14:20:25 INFO DAGScheduler: Registering RDD 67 (countByValue at StringIndexer.scala:113)
18/02/28 14:20:25 INFO DAGScheduler: Got job 10 (countByValue at StringIndexer.scala:113) with 4 output partitions
18/02/28 14:20:25 INFO DAGScheduler: Final stage: ResultStage 19 (countByValue at StringIndexer.scala:113)
18/02/28 14:20:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
18/02/28 14:20:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 18)
18/02/28 14:20:25 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[67] at countByValue at StringIndexer.scala:113), which has no missing parents
18/02/28 14:20:25 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 55.3 KB, free 344.7 MB)
18/02/28 14:20:25 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 22.8 KB, free 344.7 MB)
18/02/28 14:20:25 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:61560 (size: 22.8 KB, free: 345.5 MB)
18/02/28 14:20:25 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:25 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[67] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:25 INFO TaskSchedulerImpl: Adding task set 18.0 with 4 tasks
18/02/28 14:20:25 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 45, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:25 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 46, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:25 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 47, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:20:25 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 48, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:25 INFO Executor: Running task 0.0 in stage 18.0 (TID 45)
18/02/28 14:20:25 INFO Executor: Running task 1.0 in stage 18.0 (TID 46)
18/02/28 14:20:25 INFO Executor: Running task 2.0 in stage 18.0 (TID 47)
18/02/28 14:20:25 INFO Executor: Running task 3.0 in stage 18.0 (TID 48)
18/02/28 14:20:25 INFO BlockManager: Found block rdd_48_3 locally
18/02/28 14:20:25 INFO BlockManager: Found block rdd_48_0 locally
18/02/28 14:20:25 INFO BlockManager: Found block rdd_48_1 locally
18/02/28 14:20:25 INFO BlockManager: Found block rdd_48_2 locally
18/02/28 14:20:25 INFO CodeGenerator: Code generated in 20.709895 ms
18/02/28 14:20:25 INFO CodeGenerator: Code generated in 6.435963 ms
18/02/28 14:20:25 INFO Executor: Finished task 1.0 in stage 18.0 (TID 46). 2277 bytes result sent to driver
18/02/28 14:20:25 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 46) in 129 ms on localhost (executor driver) (1/4)
18/02/28 14:20:25 INFO Executor: Finished task 2.0 in stage 18.0 (TID 47). 2277 bytes result sent to driver
18/02/28 14:20:25 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 47) in 134 ms on localhost (executor driver) (2/4)
18/02/28 14:20:25 INFO Executor: Finished task 0.0 in stage 18.0 (TID 45). 2277 bytes result sent to driver
18/02/28 14:20:25 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 45) in 137 ms on localhost (executor driver) (3/4)
18/02/28 14:20:25 INFO Executor: Finished task 3.0 in stage 18.0 (TID 48). 2277 bytes result sent to driver
18/02/28 14:20:25 INFO TaskSetManager: Finished task 3.0 in stage 18.0 (TID 48) in 141 ms on localhost (executor driver) (4/4)
18/02/28 14:20:25 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
18/02/28 14:20:25 INFO DAGScheduler: ShuffleMapStage 18 (countByValue at StringIndexer.scala:113) finished in 0.142 s
18/02/28 14:20:25 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:20:25 INFO DAGScheduler: running: Set()
18/02/28 14:20:25 INFO DAGScheduler: waiting: Set(ResultStage 19)
18/02/28 14:20:25 INFO DAGScheduler: failed: Set()
18/02/28 14:20:25 INFO DAGScheduler: Submitting ResultStage 19 (ShuffledRDD[68] at countByValue at StringIndexer.scala:113), which has no missing parents
18/02/28 14:20:25 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 3.2 KB, free 344.7 MB)
18/02/28 14:20:25 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 1963.0 B, free 344.7 MB)
18/02/28 14:20:25 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:61560 (size: 1963.0 B, free: 345.5 MB)
18/02/28 14:20:25 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:25 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 19 (ShuffledRDD[68] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:25 INFO TaskSchedulerImpl: Adding task set 19.0 with 4 tasks
18/02/28 14:20:25 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 49, localhost, executor driver, partition 0, ANY, 4621 bytes)
18/02/28 14:20:25 INFO TaskSetManager: Starting task 1.0 in stage 19.0 (TID 50, localhost, executor driver, partition 1, ANY, 4621 bytes)
18/02/28 14:20:25 INFO TaskSetManager: Starting task 2.0 in stage 19.0 (TID 51, localhost, executor driver, partition 2, ANY, 4621 bytes)
18/02/28 14:20:25 INFO TaskSetManager: Starting task 3.0 in stage 19.0 (TID 52, localhost, executor driver, partition 3, ANY, 4621 bytes)
18/02/28 14:20:25 INFO Executor: Running task 0.0 in stage 19.0 (TID 49)
18/02/28 14:20:25 INFO Executor: Running task 1.0 in stage 19.0 (TID 50)
18/02/28 14:20:25 INFO Executor: Running task 2.0 in stage 19.0 (TID 51)
18/02/28 14:20:25 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:20:25 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:20:25 INFO Executor: Running task 3.0 in stage 19.0 (TID 52)
18/02/28 14:20:25 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:20:25 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 14:20:25 INFO Executor: Finished task 3.0 in stage 19.0 (TID 52). 1196 bytes result sent to driver
18/02/28 14:20:25 INFO Executor: Finished task 1.0 in stage 19.0 (TID 50). 1178 bytes result sent to driver
18/02/28 14:20:25 INFO Executor: Finished task 2.0 in stage 19.0 (TID 51). 1153 bytes result sent to driver
18/02/28 14:20:25 INFO Executor: Finished task 0.0 in stage 19.0 (TID 49). 1196 bytes result sent to driver
18/02/28 14:20:25 INFO TaskSetManager: Finished task 3.0 in stage 19.0 (TID 52) in 47 ms on localhost (executor driver) (1/4)
18/02/28 14:20:25 INFO TaskSetManager: Finished task 1.0 in stage 19.0 (TID 50) in 48 ms on localhost (executor driver) (2/4)
18/02/28 14:20:25 INFO TaskSetManager: Finished task 2.0 in stage 19.0 (TID 51) in 49 ms on localhost (executor driver) (3/4)
18/02/28 14:20:25 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 49) in 51 ms on localhost (executor driver) (4/4)
18/02/28 14:20:25 INFO DAGScheduler: ResultStage 19 (countByValue at StringIndexer.scala:113) finished in 0.051 s
18/02/28 14:20:25 INFO DAGScheduler: Job 10 finished: countByValue at StringIndexer.scala:113, took 0.348328 s
18/02/28 14:20:25 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
18/02/28 14:20:25 INFO CodeGenerator: Code generated in 10.332733 ms
18/02/28 14:20:25 INFO SparkContext: Starting job: countByValue at StringIndexer.scala:113
18/02/28 14:20:25 INFO DAGScheduler: Registering RDD 75 (countByValue at StringIndexer.scala:113)
18/02/28 14:20:25 INFO DAGScheduler: Got job 11 (countByValue at StringIndexer.scala:113) with 4 output partitions
18/02/28 14:20:25 INFO DAGScheduler: Final stage: ResultStage 21 (countByValue at StringIndexer.scala:113)
18/02/28 14:20:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
18/02/28 14:20:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
18/02/28 14:20:25 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[75] at countByValue at StringIndexer.scala:113), which has no missing parents
18/02/28 14:20:25 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 56.1 KB, free 344.6 MB)
18/02/28 14:20:25 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 23.1 KB, free 344.6 MB)
18/02/28 14:20:25 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:61560 (size: 23.1 KB, free: 345.4 MB)
18/02/28 14:20:25 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:25 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[75] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:25 INFO TaskSchedulerImpl: Adding task set 20.0 with 4 tasks
18/02/28 14:20:25 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:25 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 54, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:25 INFO TaskSetManager: Starting task 2.0 in stage 20.0 (TID 55, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:20:25 INFO TaskSetManager: Starting task 3.0 in stage 20.0 (TID 56, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:25 INFO Executor: Running task 0.0 in stage 20.0 (TID 53)
18/02/28 14:20:25 INFO Executor: Running task 1.0 in stage 20.0 (TID 54)
18/02/28 14:20:25 INFO Executor: Running task 2.0 in stage 20.0 (TID 55)
18/02/28 14:20:25 INFO Executor: Running task 3.0 in stage 20.0 (TID 56)
18/02/28 14:20:25 INFO BlockManager: Found block rdd_48_0 locally
18/02/28 14:20:25 INFO BlockManager: Found block rdd_48_2 locally
18/02/28 14:20:25 INFO BlockManager: Found block rdd_48_1 locally
18/02/28 14:20:25 INFO BlockManager: Found block rdd_48_3 locally
18/02/28 14:20:26 INFO Executor: Finished task 3.0 in stage 20.0 (TID 56). 2234 bytes result sent to driver
18/02/28 14:20:26 INFO TaskSetManager: Finished task 3.0 in stage 20.0 (TID 56) in 86 ms on localhost (executor driver) (1/4)
18/02/28 14:20:26 INFO Executor: Finished task 2.0 in stage 20.0 (TID 55). 2277 bytes result sent to driver
18/02/28 14:20:26 INFO TaskSetManager: Finished task 2.0 in stage 20.0 (TID 55) in 94 ms on localhost (executor driver) (2/4)
18/02/28 14:20:26 INFO Executor: Finished task 1.0 in stage 20.0 (TID 54). 2277 bytes result sent to driver
18/02/28 14:20:26 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 54) in 96 ms on localhost (executor driver) (3/4)
18/02/28 14:20:26 INFO Executor: Finished task 0.0 in stage 20.0 (TID 53). 2277 bytes result sent to driver
18/02/28 14:20:26 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 53) in 99 ms on localhost (executor driver) (4/4)
18/02/28 14:20:26 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
18/02/28 14:20:26 INFO DAGScheduler: ShuffleMapStage 20 (countByValue at StringIndexer.scala:113) finished in 0.101 s
18/02/28 14:20:26 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:20:26 INFO DAGScheduler: running: Set()
18/02/28 14:20:26 INFO DAGScheduler: waiting: Set(ResultStage 21)
18/02/28 14:20:26 INFO DAGScheduler: failed: Set()
18/02/28 14:20:26 INFO DAGScheduler: Submitting ResultStage 21 (ShuffledRDD[76] at countByValue at StringIndexer.scala:113), which has no missing parents
18/02/28 14:20:26 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 3.2 KB, free 344.6 MB)
18/02/28 14:20:26 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 1963.0 B, free 344.6 MB)
18/02/28 14:20:26 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:61560 (size: 1963.0 B, free: 345.4 MB)
18/02/28 14:20:26 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 21 (ShuffledRDD[76] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:26 INFO TaskSchedulerImpl: Adding task set 21.0 with 4 tasks
18/02/28 14:20:26 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 57, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:26 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 58, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:26 INFO TaskSetManager: Starting task 2.0 in stage 21.0 (TID 59, localhost, executor driver, partition 2, ANY, 4621 bytes)
18/02/28 14:20:26 INFO TaskSetManager: Starting task 3.0 in stage 21.0 (TID 60, localhost, executor driver, partition 3, ANY, 4621 bytes)
18/02/28 14:20:26 INFO Executor: Running task 0.0 in stage 21.0 (TID 57)
18/02/28 14:20:26 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 14:20:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 14:20:26 INFO Executor: Running task 1.0 in stage 21.0 (TID 58)
18/02/28 14:20:26 INFO Executor: Finished task 0.0 in stage 21.0 (TID 57). 1048 bytes result sent to driver
18/02/28 14:20:26 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 14:20:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:20:26 INFO Executor: Running task 2.0 in stage 21.0 (TID 59)
18/02/28 14:20:26 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:20:26 INFO Executor: Running task 3.0 in stage 21.0 (TID 60)
18/02/28 14:20:26 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:20:26 INFO Executor: Finished task 1.0 in stage 21.0 (TID 58). 1005 bytes result sent to driver
18/02/28 14:20:26 INFO Executor: Finished task 3.0 in stage 21.0 (TID 60). 1154 bytes result sent to driver
18/02/28 14:20:26 INFO Executor: Finished task 2.0 in stage 21.0 (TID 59). 1154 bytes result sent to driver
18/02/28 14:20:26 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 57) in 19 ms on localhost (executor driver) (1/4)
18/02/28 14:20:26 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 58) in 19 ms on localhost (executor driver) (2/4)
18/02/28 14:20:26 INFO TaskSetManager: Finished task 3.0 in stage 21.0 (TID 60) in 20 ms on localhost (executor driver) (3/4)
18/02/28 14:20:26 INFO TaskSetManager: Finished task 2.0 in stage 21.0 (TID 59) in 21 ms on localhost (executor driver) (4/4)
18/02/28 14:20:26 INFO DAGScheduler: ResultStage 21 (countByValue at StringIndexer.scala:113) finished in 0.024 s
18/02/28 14:20:26 INFO DAGScheduler: Job 11 finished: countByValue at StringIndexer.scala:113, took 0.146763 s
18/02/28 14:20:26 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
18/02/28 14:20:26 INFO CodeGenerator: Code generated in 26.611997 ms
18/02/28 14:20:26 INFO ContextCleaner: Cleaned accumulator 465
18/02/28 14:20:26 INFO ContextCleaner: Cleaned accumulator 472
18/02/28 14:20:26 INFO CodeGenerator: Code generated in 50.372381 ms
18/02/28 14:20:26 INFO Instrumentation: LogisticRegression-logistic_regression_2ef85b2178c2-811601224-1: training: numPartitions=4 storageLevel=StorageLevel(disk, memory, deserialized, 1 replicas)
18/02/28 14:20:26 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:61560 in memory (size: 22.1 KB, free: 345.5 MB)
18/02/28 14:20:26 INFO ContextCleaner: Cleaned accumulator 463
18/02/28 14:20:26 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:61560 in memory (size: 1963.0 B, free: 345.5 MB)
18/02/28 14:20:26 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:61560 in memory (size: 1963.0 B, free: 345.5 MB)
18/02/28 14:20:26 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:61560 in memory (size: 22.8 KB, free: 345.5 MB)
18/02/28 14:20:26 INFO ContextCleaner: Cleaned shuffle 6
18/02/28 14:20:26 INFO ContextCleaner: Cleaned accumulator 635
18/02/28 14:20:26 INFO ContextCleaner: Cleaned accumulator 467
18/02/28 14:20:26 INFO Instrumentation: LogisticRegression-logistic_regression_2ef85b2178c2-811601224-1: {"elasticNetParam":0.0,"fitIntercept":true,"threshold":0.5,"regParam":0.0,"tol":1.0E-6,"maxIter":100}
18/02/28 14:20:26 INFO ContextCleaner: Cleaned shuffle 9
18/02/28 14:20:26 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:61560 in memory (size: 3.7 KB, free: 345.5 MB)
18/02/28 14:20:26 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:517
18/02/28 14:20:26 INFO DAGScheduler: Got job 12 (treeAggregate at LogisticRegression.scala:517) with 4 output partitions
18/02/28 14:20:26 INFO DAGScheduler: Final stage: ResultStage 22 (treeAggregate at LogisticRegression.scala:517)
18/02/28 14:20:26 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:20:26 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:26 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[86] at treeAggregate at LogisticRegression.scala:517), which has no missing parents
18/02/28 14:20:26 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 73.9 KB, free 344.7 MB)
18/02/28 14:20:26 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.6 MB)
18/02/28 14:20:26 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:61560 (size: 29.1 KB, free: 345.5 MB)
18/02/28 14:20:26 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 22 (MapPartitionsRDD[86] at treeAggregate at LogisticRegression.scala:517) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:26 INFO TaskSchedulerImpl: Adding task set 22.0 with 4 tasks
18/02/28 14:20:26 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:26 INFO TaskSetManager: Starting task 1.0 in stage 22.0 (TID 62, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:26 INFO TaskSetManager: Starting task 2.0 in stage 22.0 (TID 63, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:20:26 INFO TaskSetManager: Starting task 3.0 in stage 22.0 (TID 64, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:26 INFO Executor: Running task 0.0 in stage 22.0 (TID 61)
18/02/28 14:20:26 INFO Executor: Running task 1.0 in stage 22.0 (TID 62)
18/02/28 14:20:26 INFO Executor: Running task 2.0 in stage 22.0 (TID 63)
18/02/28 14:20:26 INFO Executor: Running task 3.0 in stage 22.0 (TID 64)
18/02/28 14:20:26 INFO BlockManager: Found block rdd_48_0 locally
18/02/28 14:20:26 INFO BlockManager: Found block rdd_48_2 locally
18/02/28 14:20:26 INFO BlockManager: Found block rdd_48_1 locally
18/02/28 14:20:26 INFO BlockManager: Found block rdd_48_3 locally
18/02/28 14:20:26 INFO ContextCleaner: Cleaned accumulator 466
18/02/28 14:20:26 INFO ContextCleaner: Cleaned accumulator 464
18/02/28 14:20:26 INFO ContextCleaner: Cleaned accumulator 585
18/02/28 14:20:26 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:61560 in memory (size: 3.7 KB, free: 345.5 MB)
18/02/28 14:20:26 INFO ContextCleaner: Cleaned accumulator 473
18/02/28 14:20:26 INFO ContextCleaner: Cleaned shuffle 8
18/02/28 14:20:26 INFO ContextCleaner: Cleaned accumulator 474
18/02/28 14:20:26 INFO ContextCleaner: Cleaned accumulator 636
18/02/28 14:20:26 INFO ContextCleaner: Cleaned accumulator 471
18/02/28 14:20:26 INFO ContextCleaner: Cleaned accumulator 523
18/02/28 14:20:26 INFO ContextCleaner: Cleaned accumulator 469
18/02/28 14:20:26 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:61560 in memory (size: 22.0 KB, free: 345.5 MB)
18/02/28 14:20:26 INFO ContextCleaner: Cleaned accumulator 470
18/02/28 14:20:26 INFO ContextCleaner: Cleaned accumulator 468
18/02/28 14:20:26 INFO ContextCleaner: Cleaned accumulator 637
18/02/28 14:20:26 INFO ContextCleaner: Cleaned accumulator 586
18/02/28 14:20:26 INFO CodeGenerator: Code generated in 18.19609 ms
18/02/28 14:20:26 INFO CodeGenerator: Code generated in 10.099301 ms
18/02/28 14:20:26 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:61560 in memory (size: 23.1 KB, free: 345.5 MB)
18/02/28 14:20:26 INFO ContextCleaner: Cleaned accumulator 584
18/02/28 14:20:26 INFO MemoryStore: Block rdd_85_2 stored as values in memory (estimated size 78.6 KB, free 344.7 MB)
18/02/28 14:20:26 INFO BlockManagerInfo: Added rdd_85_2 in memory on 127.0.0.1:61560 (size: 78.6 KB, free: 345.4 MB)
18/02/28 14:20:26 INFO MemoryStore: Block rdd_85_0 stored as values in memory (estimated size 89.4 KB, free 344.6 MB)
18/02/28 14:20:26 INFO BlockManagerInfo: Added rdd_85_0 in memory on 127.0.0.1:61560 (size: 89.4 KB, free: 345.3 MB)
18/02/28 14:20:26 INFO MemoryStore: Block rdd_85_3 stored as values in memory (estimated size 78.6 KB, free 344.6 MB)
18/02/28 14:20:26 INFO BlockManagerInfo: Added rdd_85_3 in memory on 127.0.0.1:61560 (size: 78.6 KB, free: 345.3 MB)
18/02/28 14:20:26 INFO Executor: Finished task 3.0 in stage 22.0 (TID 64). 3936 bytes result sent to driver
18/02/28 14:20:26 INFO Executor: Finished task 0.0 in stage 22.0 (TID 61). 3936 bytes result sent to driver
18/02/28 14:20:26 INFO TaskSetManager: Finished task 3.0 in stage 22.0 (TID 64) in 375 ms on localhost (executor driver) (1/4)
18/02/28 14:20:26 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 61) in 377 ms on localhost (executor driver) (2/4)
18/02/28 14:20:26 INFO Executor: Finished task 2.0 in stage 22.0 (TID 63). 3893 bytes result sent to driver
18/02/28 14:20:26 INFO TaskSetManager: Finished task 2.0 in stage 22.0 (TID 63) in 381 ms on localhost (executor driver) (3/4)
18/02/28 14:20:26 INFO MemoryStore: Block rdd_85_1 stored as values in memory (estimated size 89.6 KB, free 344.5 MB)
18/02/28 14:20:26 INFO BlockManagerInfo: Added rdd_85_1 in memory on 127.0.0.1:61560 (size: 89.6 KB, free: 345.2 MB)
18/02/28 14:20:26 INFO Executor: Finished task 1.0 in stage 22.0 (TID 62). 3936 bytes result sent to driver
18/02/28 14:20:26 INFO TaskSetManager: Finished task 1.0 in stage 22.0 (TID 62) in 385 ms on localhost (executor driver) (4/4)
18/02/28 14:20:26 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
18/02/28 14:20:26 INFO DAGScheduler: ResultStage 22 (treeAggregate at LogisticRegression.scala:517) finished in 0.386 s
18/02/28 14:20:26 INFO DAGScheduler: Job 12 finished: treeAggregate at LogisticRegression.scala:517, took 0.394244 s
18/02/28 14:20:26 INFO Instrumentation: LogisticRegression-logistic_regression_2ef85b2178c2-811601224-1: {"numClasses":2}
18/02/28 14:20:26 INFO Instrumentation: LogisticRegression-logistic_regression_2ef85b2178c2-811601224-1: {"numFeatures":5}
18/02/28 14:20:26 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 80.0 B, free 344.5 MB)
18/02/28 14:20:26 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 109.0 B, free 344.5 MB)
18/02/28 14:20:26 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:61560 (size: 109.0 B, free: 345.2 MB)
18/02/28 14:20:26 INFO SparkContext: Created broadcast 25 from broadcast at LogisticRegression.scala:600
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 104.0 B, free 344.5 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 154.0 B, free 344.5 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:61560 (size: 154.0 B, free: 345.2 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 26 from broadcast at LogisticRegression.scala:1879
18/02/28 14:20:27 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:20:27 INFO DAGScheduler: Got job 13 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:20:27 INFO DAGScheduler: Final stage: ResultStage 23 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:20:27 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:20:27 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:27 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[87] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 74.1 KB, free 344.4 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.4 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:61560 (size: 29.1 KB, free: 345.1 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 23 (MapPartitionsRDD[87] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:27 INFO TaskSchedulerImpl: Adding task set 23.0 with 4 tasks
18/02/28 14:20:27 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 65, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 66, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 2.0 in stage 23.0 (TID 67, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 3.0 in stage 23.0 (TID 68, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO Executor: Running task 0.0 in stage 23.0 (TID 65)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:20:27 INFO Executor: Running task 1.0 in stage 23.0 (TID 66)
18/02/28 14:20:27 INFO Executor: Running task 2.0 in stage 23.0 (TID 67)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:20:27 INFO Executor: Running task 3.0 in stage 23.0 (TID 68)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:20:27 INFO Executor: Finished task 0.0 in stage 23.0 (TID 65). 3524 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Finished task 1.0 in stage 23.0 (TID 66). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Finished task 2.0 in stage 23.0 (TID 67). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Finished task 3.0 in stage 23.0 (TID 68). 3481 bytes result sent to driver
18/02/28 14:20:27 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 65) in 33 ms on localhost (executor driver) (1/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 3.0 in stage 23.0 (TID 68) in 32 ms on localhost (executor driver) (2/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 2.0 in stage 23.0 (TID 67) in 33 ms on localhost (executor driver) (3/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 66) in 33 ms on localhost (executor driver) (4/4)
18/02/28 14:20:27 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
18/02/28 14:20:27 INFO DAGScheduler: ResultStage 23 (treeAggregate at LogisticRegression.scala:1892) finished in 0.034 s
18/02/28 14:20:27 INFO DAGScheduler: Job 13 finished: treeAggregate at LogisticRegression.scala:1892, took 0.040511 s
18/02/28 14:20:27 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
18/02/28 14:20:27 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
18/02/28 14:20:27 INFO TorrentBroadcast: Destroying Broadcast(26) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:20:27 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:61560 in memory (size: 154.0 B, free: 345.1 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 104.0 B, free 344.4 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.4 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:61560 (size: 186.0 B, free: 345.1 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 28 from broadcast at LogisticRegression.scala:1879
18/02/28 14:20:27 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:20:27 INFO DAGScheduler: Got job 14 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:20:27 INFO DAGScheduler: Final stage: ResultStage 24 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:20:27 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:20:27 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:27 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[88] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 74.1 KB, free 344.3 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.3 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:61560 (size: 29.1 KB, free: 345.1 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 24 (MapPartitionsRDD[88] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:27 INFO TaskSchedulerImpl: Adding task set 24.0 with 4 tasks
18/02/28 14:20:27 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 69, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 70, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 71, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 3.0 in stage 24.0 (TID 72, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO Executor: Running task 0.0 in stage 24.0 (TID 69)
18/02/28 14:20:27 INFO Executor: Running task 1.0 in stage 24.0 (TID 70)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:20:27 INFO Executor: Finished task 0.0 in stage 24.0 (TID 69). 3481 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Running task 2.0 in stage 24.0 (TID 71)
18/02/28 14:20:27 INFO Executor: Finished task 1.0 in stage 24.0 (TID 70). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Running task 3.0 in stage 24.0 (TID 72)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 69) in 9 ms on localhost (executor driver) (1/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 70) in 10 ms on localhost (executor driver) (2/4)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:20:27 INFO Executor: Finished task 2.0 in stage 24.0 (TID 71). 3481 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Finished task 3.0 in stage 24.0 (TID 72). 3481 bytes result sent to driver
18/02/28 14:20:27 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 71) in 17 ms on localhost (executor driver) (3/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 3.0 in stage 24.0 (TID 72) in 17 ms on localhost (executor driver) (4/4)
18/02/28 14:20:27 INFO DAGScheduler: ResultStage 24 (treeAggregate at LogisticRegression.scala:1892) finished in 0.018 s
18/02/28 14:20:27 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
18/02/28 14:20:27 INFO DAGScheduler: Job 14 finished: treeAggregate at LogisticRegression.scala:1892, took 0.024932 s
18/02/28 14:20:27 INFO TorrentBroadcast: Destroying Broadcast(28) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:20:27 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:61560 in memory (size: 186.0 B, free: 345.1 MB)
18/02/28 14:20:27 INFO LBFGS: Step Size: 1.000
18/02/28 14:20:27 INFO LBFGS: Val and Grad Norm: 0.491732 (rel: 0.121) 0.207740
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 104.0 B, free 344.3 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.3 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:61560 (size: 186.0 B, free: 345.1 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 30 from broadcast at LogisticRegression.scala:1879
18/02/28 14:20:27 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:20:27 INFO DAGScheduler: Got job 15 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:20:27 INFO DAGScheduler: Final stage: ResultStage 25 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:20:27 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:20:27 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:27 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[89] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 74.1 KB, free 344.2 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.2 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:61560 (size: 29.1 KB, free: 345.1 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 25 (MapPartitionsRDD[89] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:27 INFO TaskSchedulerImpl: Adding task set 25.0 with 4 tasks
18/02/28 14:20:27 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 73, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 1.0 in stage 25.0 (TID 74, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 2.0 in stage 25.0 (TID 75, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 3.0 in stage 25.0 (TID 76, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO Executor: Running task 0.0 in stage 25.0 (TID 73)
18/02/28 14:20:27 INFO Executor: Running task 1.0 in stage 25.0 (TID 74)
18/02/28 14:20:27 INFO Executor: Running task 2.0 in stage 25.0 (TID 75)
18/02/28 14:20:27 INFO Executor: Running task 3.0 in stage 25.0 (TID 76)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:20:27 INFO Executor: Finished task 3.0 in stage 25.0 (TID 76). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:20:27 INFO Executor: Finished task 2.0 in stage 25.0 (TID 75). 3481 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Finished task 1.0 in stage 25.0 (TID 74). 3481 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Finished task 0.0 in stage 25.0 (TID 73). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO TaskSetManager: Finished task 2.0 in stage 25.0 (TID 75) in 18 ms on localhost (executor driver) (1/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 1.0 in stage 25.0 (TID 74) in 19 ms on localhost (executor driver) (2/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 73) in 20 ms on localhost (executor driver) (3/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 3.0 in stage 25.0 (TID 76) in 20 ms on localhost (executor driver) (4/4)
18/02/28 14:20:27 INFO DAGScheduler: ResultStage 25 (treeAggregate at LogisticRegression.scala:1892) finished in 0.021 s
18/02/28 14:20:27 INFO DAGScheduler: Job 15 finished: treeAggregate at LogisticRegression.scala:1892, took 0.026735 s
18/02/28 14:20:27 INFO TorrentBroadcast: Destroying Broadcast(30) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:20:27 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
18/02/28 14:20:27 INFO LBFGS: Step Size: 1.000
18/02/28 14:20:27 INFO LBFGS: Val and Grad Norm: 0.363835 (rel: 0.260) 0.0877729
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 104.0 B, free 344.2 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.2 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:61560 in memory (size: 186.0 B, free: 345.1 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:61560 (size: 186.0 B, free: 345.1 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 32 from broadcast at LogisticRegression.scala:1879
18/02/28 14:20:27 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:20:27 INFO DAGScheduler: Got job 16 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:20:27 INFO DAGScheduler: Final stage: ResultStage 26 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:20:27 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:20:27 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:27 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[90] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 74.1 KB, free 344.1 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.1 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:61560 (size: 29.1 KB, free: 345.1 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 26 (MapPartitionsRDD[90] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:27 INFO TaskSchedulerImpl: Adding task set 26.0 with 4 tasks
18/02/28 14:20:27 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 77, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 1.0 in stage 26.0 (TID 78, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 2.0 in stage 26.0 (TID 79, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 3.0 in stage 26.0 (TID 80, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO Executor: Running task 0.0 in stage 26.0 (TID 77)
18/02/28 14:20:27 INFO Executor: Running task 1.0 in stage 26.0 (TID 78)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:20:27 INFO Executor: Finished task 1.0 in stage 26.0 (TID 78). 3481 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Running task 2.0 in stage 26.0 (TID 79)
18/02/28 14:20:27 INFO Executor: Running task 3.0 in stage 26.0 (TID 80)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:20:27 INFO Executor: Finished task 0.0 in stage 26.0 (TID 77). 3524 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Finished task 2.0 in stage 26.0 (TID 79). 3395 bytes result sent to driver
18/02/28 14:20:27 INFO TaskSetManager: Finished task 1.0 in stage 26.0 (TID 78) in 15 ms on localhost (executor driver) (1/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 77) in 17 ms on localhost (executor driver) (2/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 2.0 in stage 26.0 (TID 79) in 16 ms on localhost (executor driver) (3/4)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:20:27 INFO Executor: Finished task 3.0 in stage 26.0 (TID 80). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO TaskSetManager: Finished task 3.0 in stage 26.0 (TID 80) in 22 ms on localhost (executor driver) (4/4)
18/02/28 14:20:27 INFO DAGScheduler: ResultStage 26 (treeAggregate at LogisticRegression.scala:1892) finished in 0.024 s
18/02/28 14:20:27 INFO DAGScheduler: Job 16 finished: treeAggregate at LogisticRegression.scala:1892, took 0.030889 s
18/02/28 14:20:27 INFO TorrentBroadcast: Destroying Broadcast(32) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:20:27 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
18/02/28 14:20:27 INFO LBFGS: Step Size: 1.000
18/02/28 14:20:27 INFO LBFGS: Val and Grad Norm: 0.321599 (rel: 0.116) 0.0533353
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 104.0 B, free 344.1 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.1 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:61560 (size: 186.0 B, free: 345.1 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 34 from broadcast at LogisticRegression.scala:1879
18/02/28 14:20:27 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:61560 in memory (size: 186.0 B, free: 345.1 MB)
18/02/28 14:20:27 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:20:27 INFO DAGScheduler: Got job 17 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:20:27 INFO DAGScheduler: Final stage: ResultStage 27 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:20:27 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:20:27 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:27 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[91] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 74.1 KB, free 344.0 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.0 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:61560 (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 27 (MapPartitionsRDD[91] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:27 INFO TaskSchedulerImpl: Adding task set 27.0 with 4 tasks
18/02/28 14:20:27 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 81, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 82, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 2.0 in stage 27.0 (TID 83, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 3.0 in stage 27.0 (TID 84, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO Executor: Running task 0.0 in stage 27.0 (TID 81)
18/02/28 14:20:27 INFO Executor: Running task 1.0 in stage 27.0 (TID 82)
18/02/28 14:20:27 INFO Executor: Running task 2.0 in stage 27.0 (TID 83)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:20:27 INFO Executor: Running task 3.0 in stage 27.0 (TID 84)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:20:27 INFO Executor: Finished task 1.0 in stage 27.0 (TID 82). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Finished task 2.0 in stage 27.0 (TID 83). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Finished task 0.0 in stage 27.0 (TID 81). 3481 bytes result sent to driver
18/02/28 14:20:27 INFO TaskSetManager: Finished task 2.0 in stage 27.0 (TID 83) in 13 ms on localhost (executor driver) (1/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 81) in 15 ms on localhost (executor driver) (2/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 82) in 17 ms on localhost (executor driver) (3/4)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:20:27 INFO Executor: Finished task 3.0 in stage 27.0 (TID 84). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO TaskSetManager: Finished task 3.0 in stage 27.0 (TID 84) in 19 ms on localhost (executor driver) (4/4)
18/02/28 14:20:27 INFO DAGScheduler: ResultStage 27 (treeAggregate at LogisticRegression.scala:1892) finished in 0.021 s
18/02/28 14:20:27 INFO DAGScheduler: Job 17 finished: treeAggregate at LogisticRegression.scala:1892, took 0.028311 s
18/02/28 14:20:27 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
18/02/28 14:20:27 INFO TorrentBroadcast: Destroying Broadcast(34) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:20:27 INFO LBFGS: Step Size: 1.000
18/02/28 14:20:27 INFO LBFGS: Val and Grad Norm: 0.288662 (rel: 0.102) 0.0342807
18/02/28 14:20:27 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:61560 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 104.0 B, free 344.0 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.0 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:61560 (size: 186.0 B, free: 345.0 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 36 from broadcast at LogisticRegression.scala:1879
18/02/28 14:20:27 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:20:27 INFO DAGScheduler: Got job 18 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:20:27 INFO DAGScheduler: Final stage: ResultStage 28 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:20:27 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:20:27 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:27 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[92] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 74.1 KB, free 343.9 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 29.1 KB, free 343.9 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:61560 (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 28 (MapPartitionsRDD[92] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:27 INFO TaskSchedulerImpl: Adding task set 28.0 with 4 tasks
18/02/28 14:20:27 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 85, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 1.0 in stage 28.0 (TID 86, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 2.0 in stage 28.0 (TID 87, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 3.0 in stage 28.0 (TID 88, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO Executor: Running task 2.0 in stage 28.0 (TID 87)
18/02/28 14:20:27 INFO Executor: Running task 1.0 in stage 28.0 (TID 86)
18/02/28 14:20:27 INFO Executor: Running task 3.0 in stage 28.0 (TID 88)
18/02/28 14:20:27 INFO Executor: Running task 0.0 in stage 28.0 (TID 85)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:20:27 INFO Executor: Finished task 3.0 in stage 28.0 (TID 88). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Finished task 2.0 in stage 28.0 (TID 87). 3481 bytes result sent to driver
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:20:27 INFO Executor: Finished task 0.0 in stage 28.0 (TID 85). 3481 bytes result sent to driver
18/02/28 14:20:27 INFO TaskSetManager: Finished task 3.0 in stage 28.0 (TID 88) in 7 ms on localhost (executor driver) (1/4)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:20:27 INFO TaskSetManager: Finished task 2.0 in stage 28.0 (TID 87) in 8 ms on localhost (executor driver) (2/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 85) in 9 ms on localhost (executor driver) (3/4)
18/02/28 14:20:27 INFO Executor: Finished task 1.0 in stage 28.0 (TID 86). 3481 bytes result sent to driver
18/02/28 14:20:27 INFO TaskSetManager: Finished task 1.0 in stage 28.0 (TID 86) in 9 ms on localhost (executor driver) (4/4)
18/02/28 14:20:27 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
18/02/28 14:20:27 INFO DAGScheduler: ResultStage 28 (treeAggregate at LogisticRegression.scala:1892) finished in 0.009 s
18/02/28 14:20:27 INFO DAGScheduler: Job 18 finished: treeAggregate at LogisticRegression.scala:1892, took 0.014252 s
18/02/28 14:20:27 INFO TorrentBroadcast: Destroying Broadcast(36) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:20:27 INFO LBFGS: Step Size: 1.000
18/02/28 14:20:27 INFO LBFGS: Val and Grad Norm: 0.277024 (rel: 0.0403) 0.0117874
18/02/28 14:20:27 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:61560 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 104.0 B, free 343.9 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.9 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:61560 (size: 186.0 B, free: 345.0 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 38 from broadcast at LogisticRegression.scala:1879
18/02/28 14:20:27 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:20:27 INFO DAGScheduler: Got job 19 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:20:27 INFO DAGScheduler: Final stage: ResultStage 29 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:20:27 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:20:27 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:27 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[93] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 74.1 KB, free 343.8 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 29.1 KB, free 343.8 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:61560 (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 29 (MapPartitionsRDD[93] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:27 INFO TaskSchedulerImpl: Adding task set 29.0 with 4 tasks
18/02/28 14:20:27 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 89, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 90, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 2.0 in stage 29.0 (TID 91, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 3.0 in stage 29.0 (TID 92, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO Executor: Running task 0.0 in stage 29.0 (TID 89)
18/02/28 14:20:27 INFO Executor: Running task 1.0 in stage 29.0 (TID 90)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:20:27 INFO Executor: Finished task 0.0 in stage 29.0 (TID 89). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Running task 2.0 in stage 29.0 (TID 91)
18/02/28 14:20:27 INFO Executor: Running task 3.0 in stage 29.0 (TID 92)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:20:27 INFO Executor: Finished task 1.0 in stage 29.0 (TID 90). 3481 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Finished task 2.0 in stage 29.0 (TID 91). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:20:27 INFO Executor: Finished task 3.0 in stage 29.0 (TID 92). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 89) in 16 ms on localhost (executor driver) (1/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 90) in 16 ms on localhost (executor driver) (2/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 2.0 in stage 29.0 (TID 91) in 16 ms on localhost (executor driver) (3/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 3.0 in stage 29.0 (TID 92) in 15 ms on localhost (executor driver) (4/4)
18/02/28 14:20:27 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
18/02/28 14:20:27 INFO DAGScheduler: ResultStage 29 (treeAggregate at LogisticRegression.scala:1892) finished in 0.018 s
18/02/28 14:20:27 INFO DAGScheduler: Job 19 finished: treeAggregate at LogisticRegression.scala:1892, took 0.023771 s
18/02/28 14:20:27 INFO TorrentBroadcast: Destroying Broadcast(38) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:20:27 INFO LBFGS: Step Size: 1.000
18/02/28 14:20:27 INFO LBFGS: Val and Grad Norm: 0.273653 (rel: 0.0122) 0.00652309
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 104.0 B, free 343.8 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.8 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:61560 (size: 186.0 B, free: 345.0 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 40 from broadcast at LogisticRegression.scala:1879
18/02/28 14:20:27 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:61560 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 14:20:27 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:20:27 INFO DAGScheduler: Got job 20 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:20:27 INFO DAGScheduler: Final stage: ResultStage 30 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:20:27 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:20:27 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:27 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[94] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 74.1 KB, free 343.7 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 29.1 KB, free 343.7 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:61560 (size: 29.1 KB, free: 344.9 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 30 (MapPartitionsRDD[94] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:27 INFO TaskSchedulerImpl: Adding task set 30.0 with 4 tasks
18/02/28 14:20:27 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 93, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 94, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 2.0 in stage 30.0 (TID 95, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 3.0 in stage 30.0 (TID 96, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO Executor: Running task 1.0 in stage 30.0 (TID 94)
18/02/28 14:20:27 INFO Executor: Running task 3.0 in stage 30.0 (TID 96)
18/02/28 14:20:27 INFO Executor: Running task 2.0 in stage 30.0 (TID 95)
18/02/28 14:20:27 INFO Executor: Running task 0.0 in stage 30.0 (TID 93)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:20:27 INFO Executor: Finished task 0.0 in stage 30.0 (TID 93). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:20:27 INFO Executor: Finished task 3.0 in stage 30.0 (TID 96). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Finished task 2.0 in stage 30.0 (TID 95). 3481 bytes result sent to driver
18/02/28 14:20:27 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 93) in 8 ms on localhost (executor driver) (1/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 3.0 in stage 30.0 (TID 96) in 7 ms on localhost (executor driver) (2/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 2.0 in stage 30.0 (TID 95) in 8 ms on localhost (executor driver) (3/4)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:20:27 INFO Executor: Finished task 1.0 in stage 30.0 (TID 94). 3481 bytes result sent to driver
18/02/28 14:20:27 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 94) in 9 ms on localhost (executor driver) (4/4)
18/02/28 14:20:27 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
18/02/28 14:20:27 INFO DAGScheduler: ResultStage 30 (treeAggregate at LogisticRegression.scala:1892) finished in 0.010 s
18/02/28 14:20:27 INFO DAGScheduler: Job 20 finished: treeAggregate at LogisticRegression.scala:1892, took 0.014844 s
18/02/28 14:20:27 INFO TorrentBroadcast: Destroying Broadcast(40) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:20:27 INFO LBFGS: Step Size: 1.000
18/02/28 14:20:27 INFO LBFGS: Val and Grad Norm: 0.273114 (rel: 0.00197) 0.00574119
18/02/28 14:20:27 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:61560 in memory (size: 186.0 B, free: 344.9 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 104.0 B, free 343.7 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.7 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:61560 (size: 186.0 B, free: 344.9 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 42 from broadcast at LogisticRegression.scala:1879
18/02/28 14:20:27 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:20:27 INFO DAGScheduler: Got job 21 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:20:27 INFO DAGScheduler: Final stage: ResultStage 31 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:20:27 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:20:27 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:27 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[95] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 74.1 KB, free 343.6 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 29.1 KB, free 343.6 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:61560 (size: 29.1 KB, free: 344.9 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 31 (MapPartitionsRDD[95] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:27 INFO TaskSchedulerImpl: Adding task set 31.0 with 4 tasks
18/02/28 14:20:27 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 97, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 1.0 in stage 31.0 (TID 98, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 2.0 in stage 31.0 (TID 99, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 3.0 in stage 31.0 (TID 100, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO Executor: Running task 0.0 in stage 31.0 (TID 97)
18/02/28 14:20:27 INFO Executor: Running task 3.0 in stage 31.0 (TID 100)
18/02/28 14:20:27 INFO Executor: Running task 1.0 in stage 31.0 (TID 98)
18/02/28 14:20:27 INFO Executor: Running task 2.0 in stage 31.0 (TID 99)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:20:27 INFO Executor: Finished task 0.0 in stage 31.0 (TID 97). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:20:27 INFO Executor: Finished task 2.0 in stage 31.0 (TID 99). 3481 bytes result sent to driver
18/02/28 14:20:27 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 97) in 19 ms on localhost (executor driver) (1/4)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:20:27 INFO Executor: Finished task 1.0 in stage 31.0 (TID 98). 3481 bytes result sent to driver
18/02/28 14:20:27 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:61560 in memory (size: 29.1 KB, free: 344.9 MB)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 2.0 in stage 31.0 (TID 99) in 21 ms on localhost (executor driver) (2/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 1.0 in stage 31.0 (TID 98) in 22 ms on localhost (executor driver) (3/4)
18/02/28 14:20:27 INFO Executor: Finished task 3.0 in stage 31.0 (TID 100). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO TaskSetManager: Finished task 3.0 in stage 31.0 (TID 100) in 23 ms on localhost (executor driver) (4/4)
18/02/28 14:20:27 INFO DAGScheduler: ResultStage 31 (treeAggregate at LogisticRegression.scala:1892) finished in 0.023 s
18/02/28 14:20:27 INFO DAGScheduler: Job 21 finished: treeAggregate at LogisticRegression.scala:1892, took 0.028564 s
18/02/28 14:20:27 INFO TorrentBroadcast: Destroying Broadcast(42) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:20:27 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
18/02/28 14:20:27 INFO LBFGS: Step Size: 1.000
18/02/28 14:20:27 INFO LBFGS: Val and Grad Norm: 0.272906 (rel: 0.000763) 0.00311536
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 104.0 B, free 343.7 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.7 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:61560 (size: 186.0 B, free: 344.9 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 44 from broadcast at LogisticRegression.scala:1879
18/02/28 14:20:27 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:20:27 INFO DAGScheduler: Got job 22 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:20:27 INFO DAGScheduler: Final stage: ResultStage 32 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:20:27 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:20:27 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:27 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[96] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 74.1 KB, free 343.6 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 29.1 KB, free 343.6 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:61560 in memory (size: 186.0 B, free: 344.9 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:61560 (size: 29.1 KB, free: 344.9 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 32 (MapPartitionsRDD[96] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:27 INFO TaskSchedulerImpl: Adding task set 32.0 with 4 tasks
18/02/28 14:20:27 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:61560 in memory (size: 29.1 KB, free: 344.9 MB)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 101, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 102, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 2.0 in stage 32.0 (TID 103, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 3.0 in stage 32.0 (TID 104, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO Executor: Running task 0.0 in stage 32.0 (TID 101)
18/02/28 14:20:27 INFO Executor: Running task 2.0 in stage 32.0 (TID 103)
18/02/28 14:20:27 INFO Executor: Running task 3.0 in stage 32.0 (TID 104)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:20:27 INFO Executor: Finished task 0.0 in stage 32.0 (TID 101). 3481 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Running task 1.0 in stage 32.0 (TID 102)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:20:27 INFO Executor: Finished task 1.0 in stage 32.0 (TID 102). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Finished task 3.0 in stage 32.0 (TID 104). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 101) in 15 ms on localhost (executor driver) (1/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 102) in 15 ms on localhost (executor driver) (2/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 3.0 in stage 32.0 (TID 104) in 15 ms on localhost (executor driver) (3/4)
18/02/28 14:20:27 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:61560 in memory (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:20:27 INFO Executor: Finished task 2.0 in stage 32.0 (TID 103). 3524 bytes result sent to driver
18/02/28 14:20:27 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:61560 in memory (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 2.0 in stage 32.0 (TID 103) in 19 ms on localhost (executor driver) (4/4)
18/02/28 14:20:27 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
18/02/28 14:20:27 INFO DAGScheduler: ResultStage 32 (treeAggregate at LogisticRegression.scala:1892) finished in 0.021 s
18/02/28 14:20:27 INFO DAGScheduler: Job 22 finished: treeAggregate at LogisticRegression.scala:1892, took 0.027372 s
18/02/28 14:20:27 INFO TorrentBroadcast: Destroying Broadcast(44) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:20:27 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:61560 in memory (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:20:27 INFO LBFGS: Step Size: 1.000
18/02/28 14:20:27 INFO LBFGS: Val and Grad Norm: 0.272669 (rel: 0.000868) 0.00276507
18/02/28 14:20:27 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:61560 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 104.0 B, free 344.0 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.0 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:61560 in memory (size: 29.1 KB, free: 345.1 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:61560 (size: 186.0 B, free: 345.1 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 46 from broadcast at LogisticRegression.scala:1879
18/02/28 14:20:27 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:61560 in memory (size: 29.1 KB, free: 345.1 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:61560 in memory (size: 29.1 KB, free: 345.1 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:61560 in memory (size: 29.1 KB, free: 345.1 MB)
18/02/28 14:20:27 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:20:27 INFO DAGScheduler: Got job 23 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:20:27 INFO DAGScheduler: Final stage: ResultStage 33 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:20:27 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:20:27 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:27 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[97] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 74.1 KB, free 344.3 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.3 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:61560 (size: 29.1 KB, free: 345.1 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 33 (MapPartitionsRDD[97] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:27 INFO TaskSchedulerImpl: Adding task set 33.0 with 4 tasks
18/02/28 14:20:27 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 105, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 1.0 in stage 33.0 (TID 106, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 2.0 in stage 33.0 (TID 107, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 3.0 in stage 33.0 (TID 108, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO Executor: Running task 1.0 in stage 33.0 (TID 106)
18/02/28 14:20:27 INFO Executor: Running task 0.0 in stage 33.0 (TID 105)
18/02/28 14:20:27 INFO Executor: Running task 2.0 in stage 33.0 (TID 107)
18/02/28 14:20:27 INFO Executor: Running task 3.0 in stage 33.0 (TID 108)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:20:27 INFO Executor: Finished task 1.0 in stage 33.0 (TID 106). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:20:27 INFO TaskSetManager: Finished task 1.0 in stage 33.0 (TID 106) in 8 ms on localhost (executor driver) (1/4)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:20:27 INFO Executor: Finished task 0.0 in stage 33.0 (TID 105). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Finished task 3.0 in stage 33.0 (TID 108). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 105) in 9 ms on localhost (executor driver) (2/4)
18/02/28 14:20:27 INFO Executor: Finished task 2.0 in stage 33.0 (TID 107). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO TaskSetManager: Finished task 3.0 in stage 33.0 (TID 108) in 9 ms on localhost (executor driver) (3/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 2.0 in stage 33.0 (TID 107) in 10 ms on localhost (executor driver) (4/4)
18/02/28 14:20:27 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
18/02/28 14:20:27 INFO DAGScheduler: ResultStage 33 (treeAggregate at LogisticRegression.scala:1892) finished in 0.011 s
18/02/28 14:20:27 INFO DAGScheduler: Job 23 finished: treeAggregate at LogisticRegression.scala:1892, took 0.016257 s
18/02/28 14:20:27 INFO TorrentBroadcast: Destroying Broadcast(46) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:20:27 INFO LBFGS: Step Size: 1.000
18/02/28 14:20:27 INFO LBFGS: Val and Grad Norm: 0.272401 (rel: 0.000985) 0.00323571
18/02/28 14:20:27 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:61560 in memory (size: 186.0 B, free: 345.1 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 104.0 B, free 344.3 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.3 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:61560 (size: 186.0 B, free: 345.1 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 48 from broadcast at LogisticRegression.scala:1879
18/02/28 14:20:27 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:20:27 INFO DAGScheduler: Got job 24 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:20:27 INFO DAGScheduler: Final stage: ResultStage 34 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:20:27 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:20:27 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:27 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[98] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 74.1 KB, free 344.2 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.2 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:61560 (size: 29.1 KB, free: 345.1 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 34 (MapPartitionsRDD[98] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:27 INFO TaskSchedulerImpl: Adding task set 34.0 with 4 tasks
18/02/28 14:20:27 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 109, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 1.0 in stage 34.0 (TID 110, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 2.0 in stage 34.0 (TID 111, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 3.0 in stage 34.0 (TID 112, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO Executor: Running task 0.0 in stage 34.0 (TID 109)
18/02/28 14:20:27 INFO Executor: Running task 3.0 in stage 34.0 (TID 112)
18/02/28 14:20:27 INFO Executor: Running task 2.0 in stage 34.0 (TID 111)
18/02/28 14:20:27 INFO Executor: Running task 1.0 in stage 34.0 (TID 110)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:20:27 INFO Executor: Finished task 0.0 in stage 34.0 (TID 109). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Finished task 2.0 in stage 34.0 (TID 111). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:20:27 INFO Executor: Finished task 1.0 in stage 34.0 (TID 110). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO TaskSetManager: Finished task 2.0 in stage 34.0 (TID 111) in 8 ms on localhost (executor driver) (1/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 109) in 9 ms on localhost (executor driver) (2/4)
18/02/28 14:20:27 INFO Executor: Finished task 3.0 in stage 34.0 (TID 112). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO TaskSetManager: Finished task 1.0 in stage 34.0 (TID 110) in 10 ms on localhost (executor driver) (3/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 3.0 in stage 34.0 (TID 112) in 9 ms on localhost (executor driver) (4/4)
18/02/28 14:20:27 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
18/02/28 14:20:27 INFO DAGScheduler: ResultStage 34 (treeAggregate at LogisticRegression.scala:1892) finished in 0.010 s
18/02/28 14:20:27 INFO DAGScheduler: Job 24 finished: treeAggregate at LogisticRegression.scala:1892, took 0.015520 s
18/02/28 14:20:27 INFO TorrentBroadcast: Destroying Broadcast(48) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:20:27 INFO LBFGS: Step Size: 1.000
18/02/28 14:20:27 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:61560 in memory (size: 186.0 B, free: 345.1 MB)
18/02/28 14:20:27 INFO LBFGS: Val and Grad Norm: 0.272274 (rel: 0.000465) 0.00202479
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 104.0 B, free 344.2 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.2 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:61560 (size: 186.0 B, free: 345.1 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 50 from broadcast at LogisticRegression.scala:1879
18/02/28 14:20:27 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:20:27 INFO DAGScheduler: Got job 25 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:20:27 INFO DAGScheduler: Final stage: ResultStage 35 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:20:27 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:20:27 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:27 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[99] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 74.1 KB, free 344.1 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.1 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:61560 (size: 29.1 KB, free: 345.1 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 35 (MapPartitionsRDD[99] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:27 INFO TaskSchedulerImpl: Adding task set 35.0 with 4 tasks
18/02/28 14:20:27 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 113, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 1.0 in stage 35.0 (TID 114, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 2.0 in stage 35.0 (TID 115, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 3.0 in stage 35.0 (TID 116, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO Executor: Running task 0.0 in stage 35.0 (TID 113)
18/02/28 14:20:27 INFO Executor: Running task 2.0 in stage 35.0 (TID 115)
18/02/28 14:20:27 INFO Executor: Running task 3.0 in stage 35.0 (TID 116)
18/02/28 14:20:27 INFO Executor: Running task 1.0 in stage 35.0 (TID 114)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:20:27 INFO Executor: Finished task 3.0 in stage 35.0 (TID 116). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Finished task 1.0 in stage 35.0 (TID 114). 3481 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Finished task 0.0 in stage 35.0 (TID 113). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO TaskSetManager: Finished task 3.0 in stage 35.0 (TID 116) in 5 ms on localhost (executor driver) (1/4)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:20:27 INFO TaskSetManager: Finished task 1.0 in stage 35.0 (TID 114) in 6 ms on localhost (executor driver) (2/4)
18/02/28 14:20:27 INFO Executor: Finished task 2.0 in stage 35.0 (TID 115). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 113) in 7 ms on localhost (executor driver) (3/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 2.0 in stage 35.0 (TID 115) in 7 ms on localhost (executor driver) (4/4)
18/02/28 14:20:27 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
18/02/28 14:20:27 INFO DAGScheduler: ResultStage 35 (treeAggregate at LogisticRegression.scala:1892) finished in 0.008 s
18/02/28 14:20:27 INFO DAGScheduler: Job 25 finished: treeAggregate at LogisticRegression.scala:1892, took 0.014233 s
18/02/28 14:20:27 INFO TorrentBroadcast: Destroying Broadcast(50) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:20:27 INFO LBFGS: Step Size: 1.000
18/02/28 14:20:27 INFO LBFGS: Val and Grad Norm: 0.272265 (rel: 3.41e-05) 0.00147891
18/02/28 14:20:27 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:61560 in memory (size: 186.0 B, free: 345.1 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 104.0 B, free 344.1 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.1 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:61560 (size: 186.0 B, free: 345.1 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 52 from broadcast at LogisticRegression.scala:1879
18/02/28 14:20:27 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:20:27 INFO DAGScheduler: Got job 26 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:20:27 INFO DAGScheduler: Final stage: ResultStage 36 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:20:27 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:20:27 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:27 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[100] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 74.1 KB, free 344.0 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 29.1 KB, free 344.0 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:61560 (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 36 (MapPartitionsRDD[100] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:27 INFO TaskSchedulerImpl: Adding task set 36.0 with 4 tasks
18/02/28 14:20:27 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 117, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 1.0 in stage 36.0 (TID 118, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 2.0 in stage 36.0 (TID 119, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 3.0 in stage 36.0 (TID 120, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO Executor: Running task 3.0 in stage 36.0 (TID 120)
18/02/28 14:20:27 INFO Executor: Running task 0.0 in stage 36.0 (TID 117)
18/02/28 14:20:27 INFO Executor: Running task 2.0 in stage 36.0 (TID 119)
18/02/28 14:20:27 INFO Executor: Running task 1.0 in stage 36.0 (TID 118)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:20:27 INFO Executor: Finished task 3.0 in stage 36.0 (TID 120). 3395 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Finished task 0.0 in stage 36.0 (TID 117). 3395 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Finished task 1.0 in stage 36.0 (TID 118). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Finished task 2.0 in stage 36.0 (TID 119). 3395 bytes result sent to driver
18/02/28 14:20:27 INFO TaskSetManager: Finished task 3.0 in stage 36.0 (TID 120) in 5 ms on localhost (executor driver) (1/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 1.0 in stage 36.0 (TID 118) in 5 ms on localhost (executor driver) (2/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 117) in 6 ms on localhost (executor driver) (3/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 2.0 in stage 36.0 (TID 119) in 6 ms on localhost (executor driver) (4/4)
18/02/28 14:20:27 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
18/02/28 14:20:27 INFO DAGScheduler: ResultStage 36 (treeAggregate at LogisticRegression.scala:1892) finished in 0.007 s
18/02/28 14:20:27 INFO DAGScheduler: Job 26 finished: treeAggregate at LogisticRegression.scala:1892, took 0.011738 s
18/02/28 14:20:27 INFO TorrentBroadcast: Destroying Broadcast(52) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:20:27 INFO LBFGS: Step Size: 1.000
18/02/28 14:20:27 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:61560 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 14:20:27 INFO LBFGS: Val and Grad Norm: 0.272252 (rel: 4.54e-05) 0.000141724
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 104.0 B, free 344.0 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.0 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:61560 (size: 186.0 B, free: 345.0 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 54 from broadcast at LogisticRegression.scala:1879
18/02/28 14:20:27 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:20:27 INFO DAGScheduler: Got job 27 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:20:27 INFO DAGScheduler: Final stage: ResultStage 37 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:20:27 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:20:27 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:27 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[101] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 74.1 KB, free 343.9 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 29.1 KB, free 343.9 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:61560 (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 37 (MapPartitionsRDD[101] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:27 INFO TaskSchedulerImpl: Adding task set 37.0 with 4 tasks
18/02/28 14:20:27 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 121, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 1.0 in stage 37.0 (TID 122, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 2.0 in stage 37.0 (TID 123, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 3.0 in stage 37.0 (TID 124, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO Executor: Running task 2.0 in stage 37.0 (TID 123)
18/02/28 14:20:27 INFO Executor: Running task 3.0 in stage 37.0 (TID 124)
18/02/28 14:20:27 INFO Executor: Running task 0.0 in stage 37.0 (TID 121)
18/02/28 14:20:27 INFO Executor: Running task 1.0 in stage 37.0 (TID 122)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:20:27 INFO Executor: Finished task 1.0 in stage 37.0 (TID 122). 3395 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Finished task 3.0 in stage 37.0 (TID 124). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Finished task 2.0 in stage 37.0 (TID 123). 3481 bytes result sent to driver
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:20:27 INFO Executor: Finished task 0.0 in stage 37.0 (TID 121). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO TaskSetManager: Finished task 1.0 in stage 37.0 (TID 122) in 8 ms on localhost (executor driver) (1/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 3.0 in stage 37.0 (TID 124) in 9 ms on localhost (executor driver) (2/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 2.0 in stage 37.0 (TID 123) in 10 ms on localhost (executor driver) (3/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 121) in 10 ms on localhost (executor driver) (4/4)
18/02/28 14:20:27 INFO DAGScheduler: ResultStage 37 (treeAggregate at LogisticRegression.scala:1892) finished in 0.011 s
18/02/28 14:20:27 INFO DAGScheduler: Job 27 finished: treeAggregate at LogisticRegression.scala:1892, took 0.015301 s
18/02/28 14:20:27 INFO TorrentBroadcast: Destroying Broadcast(54) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:20:27 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
18/02/28 14:20:27 INFO LBFGS: Step Size: 1.000
18/02/28 14:20:27 INFO LBFGS: Val and Grad Norm: 0.272252 (rel: 3.71e-07) 2.81693e-05
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 104.0 B, free 343.9 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.9 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:61560 (size: 186.0 B, free: 345.0 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 56 from broadcast at LogisticRegression.scala:1879
18/02/28 14:20:27 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:61560 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 14:20:27 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:20:27 INFO DAGScheduler: Got job 28 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:20:27 INFO DAGScheduler: Final stage: ResultStage 38 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:20:27 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:20:27 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:27 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[102] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 74.1 KB, free 343.8 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 29.1 KB, free 343.8 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:61560 (size: 29.1 KB, free: 345.0 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 38 (MapPartitionsRDD[102] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:27 INFO TaskSchedulerImpl: Adding task set 38.0 with 4 tasks
18/02/28 14:20:27 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 125, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 1.0 in stage 38.0 (TID 126, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 2.0 in stage 38.0 (TID 127, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 3.0 in stage 38.0 (TID 128, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO Executor: Running task 0.0 in stage 38.0 (TID 125)
18/02/28 14:20:27 INFO Executor: Running task 1.0 in stage 38.0 (TID 126)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:20:27 INFO Executor: Finished task 1.0 in stage 38.0 (TID 126). 3395 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Running task 2.0 in stage 38.0 (TID 127)
18/02/28 14:20:27 INFO Executor: Finished task 0.0 in stage 38.0 (TID 125). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Running task 3.0 in stage 38.0 (TID 128)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:20:27 INFO Executor: Finished task 3.0 in stage 38.0 (TID 128). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 125) in 11 ms on localhost (executor driver) (1/4)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:20:27 INFO TaskSetManager: Finished task 3.0 in stage 38.0 (TID 128) in 11 ms on localhost (executor driver) (2/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 1.0 in stage 38.0 (TID 126) in 12 ms on localhost (executor driver) (3/4)
18/02/28 14:20:27 INFO Executor: Finished task 2.0 in stage 38.0 (TID 127). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO TaskSetManager: Finished task 2.0 in stage 38.0 (TID 127) in 13 ms on localhost (executor driver) (4/4)
18/02/28 14:20:27 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
18/02/28 14:20:27 INFO DAGScheduler: ResultStage 38 (treeAggregate at LogisticRegression.scala:1892) finished in 0.013 s
18/02/28 14:20:27 INFO DAGScheduler: Job 28 finished: treeAggregate at LogisticRegression.scala:1892, took 0.019403 s
18/02/28 14:20:27 INFO TorrentBroadcast: Destroying Broadcast(56) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:20:27 INFO LBFGS: Step Size: 1.000
18/02/28 14:20:27 INFO LBFGS: Val and Grad Norm: 0.272252 (rel: 1.52e-08) 2.15936e-06
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 104.0 B, free 343.8 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.8 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:61560 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:61560 (size: 186.0 B, free: 345.0 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 58 from broadcast at LogisticRegression.scala:1879
18/02/28 14:20:27 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:20:27 INFO DAGScheduler: Got job 29 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:20:27 INFO DAGScheduler: Final stage: ResultStage 39 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:20:27 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:20:27 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:27 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[103] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 74.1 KB, free 343.7 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 29.1 KB, free 343.7 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:61560 (size: 29.1 KB, free: 344.9 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 39 (MapPartitionsRDD[103] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:27 INFO TaskSchedulerImpl: Adding task set 39.0 with 4 tasks
18/02/28 14:20:27 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 129, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 1.0 in stage 39.0 (TID 130, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 2.0 in stage 39.0 (TID 131, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 3.0 in stage 39.0 (TID 132, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO Executor: Running task 0.0 in stage 39.0 (TID 129)
18/02/28 14:20:27 INFO Executor: Running task 2.0 in stage 39.0 (TID 131)
18/02/28 14:20:27 INFO Executor: Running task 3.0 in stage 39.0 (TID 132)
18/02/28 14:20:27 INFO Executor: Running task 1.0 in stage 39.0 (TID 130)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:20:27 INFO Executor: Finished task 1.0 in stage 39.0 (TID 130). 3395 bytes result sent to driver
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:20:27 INFO Executor: Finished task 3.0 in stage 39.0 (TID 132). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO TaskSetManager: Finished task 1.0 in stage 39.0 (TID 130) in 8 ms on localhost (executor driver) (1/4)
18/02/28 14:20:27 INFO Executor: Finished task 0.0 in stage 39.0 (TID 129). 3395 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Finished task 2.0 in stage 39.0 (TID 131). 3481 bytes result sent to driver
18/02/28 14:20:27 INFO TaskSetManager: Finished task 3.0 in stage 39.0 (TID 132) in 9 ms on localhost (executor driver) (2/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 129) in 9 ms on localhost (executor driver) (3/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 2.0 in stage 39.0 (TID 131) in 10 ms on localhost (executor driver) (4/4)
18/02/28 14:20:27 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
18/02/28 14:20:27 INFO DAGScheduler: ResultStage 39 (treeAggregate at LogisticRegression.scala:1892) finished in 0.010 s
18/02/28 14:20:27 INFO DAGScheduler: Job 29 finished: treeAggregate at LogisticRegression.scala:1892, took 0.027372 s
18/02/28 14:20:27 INFO TorrentBroadcast: Destroying Broadcast(58) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:20:27 INFO LBFGS: Step Size: 1.000
18/02/28 14:20:27 INFO LBFGS: Val and Grad Norm: 0.272252 (rel: 2.37e-11) 1.69365e-06
18/02/28 14:20:27 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:61560 in memory (size: 186.0 B, free: 344.9 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 104.0 B, free 343.7 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.7 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:61560 (size: 186.0 B, free: 344.9 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 60 from broadcast at LogisticRegression.scala:1879
18/02/28 14:20:27 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:20:27 INFO DAGScheduler: Got job 30 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:20:27 INFO DAGScheduler: Final stage: ResultStage 40 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:20:27 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:20:27 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:27 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[104] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 74.1 KB, free 343.6 MB)
18/02/28 14:20:27 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 29.1 KB, free 343.6 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:61560 (size: 29.1 KB, free: 344.9 MB)
18/02/28 14:20:27 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 40 (MapPartitionsRDD[104] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:27 INFO TaskSchedulerImpl: Adding task set 40.0 with 4 tasks
18/02/28 14:20:27 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 133, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 1.0 in stage 40.0 (TID 134, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 2.0 in stage 40.0 (TID 135, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:20:27 INFO TaskSetManager: Starting task 3.0 in stage 40.0 (TID 136, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:27 INFO Executor: Running task 0.0 in stage 40.0 (TID 133)
18/02/28 14:20:27 INFO Executor: Running task 3.0 in stage 40.0 (TID 136)
18/02/28 14:20:27 INFO Executor: Running task 1.0 in stage 40.0 (TID 134)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:20:27 INFO Executor: Finished task 1.0 in stage 40.0 (TID 134). 3395 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Running task 2.0 in stage 40.0 (TID 135)
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:20:27 INFO Executor: Finished task 3.0 in stage 40.0 (TID 136). 3481 bytes result sent to driver
18/02/28 14:20:27 INFO Executor: Finished task 0.0 in stage 40.0 (TID 133). 3395 bytes result sent to driver
18/02/28 14:20:27 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:20:27 INFO Executor: Finished task 2.0 in stage 40.0 (TID 135). 3438 bytes result sent to driver
18/02/28 14:20:27 INFO TaskSetManager: Finished task 1.0 in stage 40.0 (TID 134) in 8 ms on localhost (executor driver) (1/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 3.0 in stage 40.0 (TID 136) in 12 ms on localhost (executor driver) (2/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 133) in 13 ms on localhost (executor driver) (3/4)
18/02/28 14:20:27 INFO TaskSetManager: Finished task 2.0 in stage 40.0 (TID 135) in 14 ms on localhost (executor driver) (4/4)
18/02/28 14:20:27 INFO DAGScheduler: ResultStage 40 (treeAggregate at LogisticRegression.scala:1892) finished in 0.014 s
18/02/28 14:20:27 INFO DAGScheduler: Job 30 finished: treeAggregate at LogisticRegression.scala:1892, took 0.020792 s
18/02/28 14:20:27 INFO TorrentBroadcast: Destroying Broadcast(60) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:20:27 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
18/02/28 14:20:27 INFO LBFGS: Step Size: 1.000
18/02/28 14:20:27 INFO LBFGS: Val and Grad Norm: 0.272252 (rel: 3.23e-11) 2.39812e-08
18/02/28 14:20:27 INFO LBFGS: Converged because gradient converged
18/02/28 14:20:27 INFO TorrentBroadcast: Destroying Broadcast(25) (from destroy at LogisticRegression.scala:796)
18/02/28 14:20:27 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:61560 in memory (size: 186.0 B, free: 344.9 MB)
18/02/28 14:20:27 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:61560 in memory (size: 109.0 B, free: 344.9 MB)
18/02/28 14:20:27 INFO MapPartitionsRDD: Removing RDD 85 from persistence list
18/02/28 14:20:27 INFO BlockManager: Removing RDD 85
18/02/28 14:20:27 INFO CodeGenerator: Code generated in 26.457903 ms
18/02/28 14:20:27 INFO Instrumentation: LogisticRegression-logistic_regression_2ef85b2178c2-811601224-1: training finished
18/02/28 14:20:28 INFO SparkContext: Starting job: sortByKey at BinaryClassificationMetrics.scala:155
18/02/28 14:20:28 INFO DAGScheduler: Registering RDD 109 (map at LogisticRegression.scala:1398)
18/02/28 14:20:28 INFO DAGScheduler: Got job 31 (sortByKey at BinaryClassificationMetrics.scala:155) with 4 output partitions
18/02/28 14:20:28 INFO DAGScheduler: Final stage: ResultStage 42 (sortByKey at BinaryClassificationMetrics.scala:155)
18/02/28 14:20:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
18/02/28 14:20:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 41)
18/02/28 14:20:28 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[109] at map at LogisticRegression.scala:1398), which has no missing parents
18/02/28 14:20:28 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 83.2 KB, free 343.8 MB)
18/02/28 14:20:28 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 32.7 KB, free 343.8 MB)
18/02/28 14:20:28 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:61560 (size: 32.7 KB, free: 345.2 MB)
18/02/28 14:20:28 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:28 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[109] at map at LogisticRegression.scala:1398) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:28 INFO TaskSchedulerImpl: Adding task set 41.0 with 4 tasks
18/02/28 14:20:28 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 137, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:28 INFO TaskSetManager: Starting task 1.0 in stage 41.0 (TID 138, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:28 INFO TaskSetManager: Starting task 2.0 in stage 41.0 (TID 139, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:20:28 INFO TaskSetManager: Starting task 3.0 in stage 41.0 (TID 140, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:28 INFO Executor: Running task 0.0 in stage 41.0 (TID 137)
18/02/28 14:20:28 INFO Executor: Running task 1.0 in stage 41.0 (TID 138)
18/02/28 14:20:28 INFO Executor: Running task 2.0 in stage 41.0 (TID 139)
18/02/28 14:20:28 INFO Executor: Running task 3.0 in stage 41.0 (TID 140)
18/02/28 14:20:28 INFO BlockManager: Found block rdd_48_2 locally
18/02/28 14:20:28 INFO BlockManager: Found block rdd_48_3 locally
18/02/28 14:20:28 INFO BlockManager: Found block rdd_48_0 locally
18/02/28 14:20:28 INFO BlockManager: Found block rdd_48_1 locally
18/02/28 14:20:28 INFO CodeGenerator: Code generated in 12.630032 ms
18/02/28 14:20:28 INFO CodeGenerator: Code generated in 12.597944 ms
18/02/28 14:20:28 INFO Executor: Finished task 2.0 in stage 41.0 (TID 139). 2215 bytes result sent to driver
18/02/28 14:20:28 INFO TaskSetManager: Finished task 2.0 in stage 41.0 (TID 139) in 194 ms on localhost (executor driver) (1/4)
18/02/28 14:20:28 INFO Executor: Finished task 1.0 in stage 41.0 (TID 138). 2215 bytes result sent to driver
18/02/28 14:20:28 INFO TaskSetManager: Finished task 1.0 in stage 41.0 (TID 138) in 198 ms on localhost (executor driver) (2/4)
18/02/28 14:20:28 INFO Executor: Finished task 0.0 in stage 41.0 (TID 137). 2215 bytes result sent to driver
18/02/28 14:20:28 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 137) in 202 ms on localhost (executor driver) (3/4)
18/02/28 14:20:28 INFO Executor: Finished task 3.0 in stage 41.0 (TID 140). 2215 bytes result sent to driver
18/02/28 14:20:28 INFO TaskSetManager: Finished task 3.0 in stage 41.0 (TID 140) in 205 ms on localhost (executor driver) (4/4)
18/02/28 14:20:28 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
18/02/28 14:20:28 INFO DAGScheduler: ShuffleMapStage 41 (map at LogisticRegression.scala:1398) finished in 0.205 s
18/02/28 14:20:28 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:20:28 INFO DAGScheduler: running: Set()
18/02/28 14:20:28 INFO DAGScheduler: waiting: Set(ResultStage 42)
18/02/28 14:20:28 INFO DAGScheduler: failed: Set()
18/02/28 14:20:28 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[112] at sortByKey at BinaryClassificationMetrics.scala:155), which has no missing parents
18/02/28 14:20:28 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 3.6 KB, free 343.8 MB)
18/02/28 14:20:28 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 2.0 KB, free 343.8 MB)
18/02/28 14:20:28 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:61560 (size: 2.0 KB, free: 345.2 MB)
18/02/28 14:20:28 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:28 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 42 (MapPartitionsRDD[112] at sortByKey at BinaryClassificationMetrics.scala:155) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:28 INFO TaskSchedulerImpl: Adding task set 42.0 with 4 tasks
18/02/28 14:20:28 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 141, localhost, executor driver, partition 0, ANY, 4621 bytes)
18/02/28 14:20:28 INFO TaskSetManager: Starting task 1.0 in stage 42.0 (TID 142, localhost, executor driver, partition 1, ANY, 4621 bytes)
18/02/28 14:20:28 INFO TaskSetManager: Starting task 2.0 in stage 42.0 (TID 143, localhost, executor driver, partition 2, ANY, 4621 bytes)
18/02/28 14:20:28 INFO TaskSetManager: Starting task 3.0 in stage 42.0 (TID 144, localhost, executor driver, partition 3, ANY, 4621 bytes)
18/02/28 14:20:28 INFO Executor: Running task 1.0 in stage 42.0 (TID 142)
18/02/28 14:20:28 INFO Executor: Running task 0.0 in stage 42.0 (TID 141)
18/02/28 14:20:28 INFO Executor: Running task 2.0 in stage 42.0 (TID 143)
18/02/28 14:20:28 INFO Executor: Running task 3.0 in stage 42.0 (TID 144)
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
18/02/28 14:20:28 INFO Executor: Finished task 0.0 in stage 42.0 (TID 141). 1757 bytes result sent to driver
18/02/28 14:20:28 INFO Executor: Finished task 2.0 in stage 42.0 (TID 143). 1757 bytes result sent to driver
18/02/28 14:20:28 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 141) in 26 ms on localhost (executor driver) (1/4)
18/02/28 14:20:28 INFO TaskSetManager: Finished task 2.0 in stage 42.0 (TID 143) in 27 ms on localhost (executor driver) (2/4)
18/02/28 14:20:28 INFO Executor: Finished task 3.0 in stage 42.0 (TID 144). 1714 bytes result sent to driver
18/02/28 14:20:28 INFO Executor: Finished task 1.0 in stage 42.0 (TID 142). 1757 bytes result sent to driver
18/02/28 14:20:28 INFO TaskSetManager: Finished task 3.0 in stage 42.0 (TID 144) in 33 ms on localhost (executor driver) (3/4)
18/02/28 14:20:28 INFO TaskSetManager: Finished task 1.0 in stage 42.0 (TID 142) in 33 ms on localhost (executor driver) (4/4)
18/02/28 14:20:28 INFO DAGScheduler: ResultStage 42 (sortByKey at BinaryClassificationMetrics.scala:155) finished in 0.034 s
18/02/28 14:20:28 INFO DAGScheduler: Job 31 finished: sortByKey at BinaryClassificationMetrics.scala:155, took 0.255510 s
18/02/28 14:20:28 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
18/02/28 14:20:28 INFO SparkContext: Starting job: count at BinaryClassificationMetrics.scala:163
18/02/28 14:20:28 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:61560 in memory (size: 29.1 KB, free: 345.2 MB)
18/02/28 14:20:28 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 10 is 167 bytes
18/02/28 14:20:28 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 127.0.0.1:61560 in memory (size: 29.1 KB, free: 345.3 MB)
18/02/28 14:20:28 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:61560 in memory (size: 29.1 KB, free: 345.3 MB)
18/02/28 14:20:28 INFO DAGScheduler: Registering RDD 110 (combineByKey at BinaryClassificationMetrics.scala:151)
18/02/28 14:20:28 INFO DAGScheduler: Got job 32 (count at BinaryClassificationMetrics.scala:163) with 4 output partitions
18/02/28 14:20:28 INFO DAGScheduler: Final stage: ResultStage 45 (count at BinaryClassificationMetrics.scala:163)
18/02/28 14:20:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)
18/02/28 14:20:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 44)
18/02/28 14:20:28 INFO DAGScheduler: Submitting ShuffleMapStage 44 (ShuffledRDD[110] at combineByKey at BinaryClassificationMetrics.scala:151), which has no missing parents
18/02/28 14:20:28 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 3.4 KB, free 344.1 MB)
18/02/28 14:20:28 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 1914.0 B, free 344.1 MB)
18/02/28 14:20:28 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:61560 (size: 1914.0 B, free: 345.3 MB)
18/02/28 14:20:28 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:28 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 44 (ShuffledRDD[110] at combineByKey at BinaryClassificationMetrics.scala:151) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:28 INFO TaskSchedulerImpl: Adding task set 44.0 with 4 tasks
18/02/28 14:20:28 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 145, localhost, executor driver, partition 0, ANY, 4610 bytes)
18/02/28 14:20:28 INFO BlockManager: Removing RDD 85
18/02/28 14:20:28 INFO TaskSetManager: Starting task 1.0 in stage 44.0 (TID 146, localhost, executor driver, partition 1, ANY, 4610 bytes)
18/02/28 14:20:28 INFO TaskSetManager: Starting task 2.0 in stage 44.0 (TID 147, localhost, executor driver, partition 2, ANY, 4610 bytes)
18/02/28 14:20:28 INFO TaskSetManager: Starting task 3.0 in stage 44.0 (TID 148, localhost, executor driver, partition 3, ANY, 4610 bytes)
18/02/28 14:20:28 INFO ContextCleaner: Cleaned RDD 85
18/02/28 14:20:28 INFO Executor: Running task 0.0 in stage 44.0 (TID 145)
18/02/28 14:20:28 INFO Executor: Running task 1.0 in stage 44.0 (TID 146)
18/02/28 14:20:28 INFO Executor: Running task 2.0 in stage 44.0 (TID 147)
18/02/28 14:20:28 INFO Executor: Running task 3.0 in stage 44.0 (TID 148)
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:20:28 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:61560 in memory (size: 29.1 KB, free: 345.3 MB)
18/02/28 14:20:28 INFO ContextCleaner: Cleaned accumulator 689
18/02/28 14:20:28 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 127.0.0.1:61560 in memory (size: 2.0 KB, free: 345.3 MB)
18/02/28 14:20:28 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:61560 in memory (size: 29.1 KB, free: 345.4 MB)
18/02/28 14:20:28 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 127.0.0.1:61560 in memory (size: 29.1 KB, free: 345.4 MB)
18/02/28 14:20:28 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 127.0.0.1:61560 in memory (size: 32.7 KB, free: 345.4 MB)
18/02/28 14:20:28 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:61560 in memory (size: 29.1 KB, free: 345.4 MB)
18/02/28 14:20:28 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:61560 in memory (size: 29.1 KB, free: 345.5 MB)
18/02/28 14:20:28 INFO ContextCleaner: Cleaned accumulator 688
18/02/28 14:20:28 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:61560 in memory (size: 29.1 KB, free: 345.5 MB)
18/02/28 14:20:28 INFO ContextCleaner: Cleaned accumulator 686
18/02/28 14:20:28 INFO ContextCleaner: Cleaned accumulator 687
18/02/28 14:20:28 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:61560 in memory (size: 29.1 KB, free: 345.5 MB)
18/02/28 14:20:28 INFO Executor: Finished task 1.0 in stage 44.0 (TID 146). 1239 bytes result sent to driver
18/02/28 14:20:28 INFO TaskSetManager: Finished task 1.0 in stage 44.0 (TID 146) in 88 ms on localhost (executor driver) (1/4)
18/02/28 14:20:28 INFO Executor: Finished task 3.0 in stage 44.0 (TID 148). 1239 bytes result sent to driver
18/02/28 14:20:28 INFO TaskSetManager: Finished task 3.0 in stage 44.0 (TID 148) in 109 ms on localhost (executor driver) (2/4)
18/02/28 14:20:28 INFO Executor: Finished task 0.0 in stage 44.0 (TID 145). 1239 bytes result sent to driver
18/02/28 14:20:28 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 145) in 115 ms on localhost (executor driver) (3/4)
18/02/28 14:20:28 INFO Executor: Finished task 2.0 in stage 44.0 (TID 147). 1239 bytes result sent to driver
18/02/28 14:20:28 INFO TaskSetManager: Finished task 2.0 in stage 44.0 (TID 147) in 115 ms on localhost (executor driver) (4/4)
18/02/28 14:20:28 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
18/02/28 14:20:28 INFO DAGScheduler: ShuffleMapStage 44 (combineByKey at BinaryClassificationMetrics.scala:151) finished in 0.117 s
18/02/28 14:20:28 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:20:28 INFO DAGScheduler: running: Set()
18/02/28 14:20:28 INFO DAGScheduler: waiting: Set(ResultStage 45)
18/02/28 14:20:28 INFO DAGScheduler: failed: Set()
18/02/28 14:20:28 INFO DAGScheduler: Submitting ResultStage 45 (ShuffledRDD[113] at sortByKey at BinaryClassificationMetrics.scala:155), which has no missing parents
18/02/28 14:20:28 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 3.1 KB, free 344.9 MB)
18/02/28 14:20:28 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 1868.0 B, free 344.9 MB)
18/02/28 14:20:28 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:61560 (size: 1868.0 B, free: 345.5 MB)
18/02/28 14:20:28 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:28 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 45 (ShuffledRDD[113] at sortByKey at BinaryClassificationMetrics.scala:155) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:28 INFO TaskSchedulerImpl: Adding task set 45.0 with 4 tasks
18/02/28 14:20:28 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 149, localhost, executor driver, partition 0, ANY, 4621 bytes)
18/02/28 14:20:28 INFO TaskSetManager: Starting task 1.0 in stage 45.0 (TID 150, localhost, executor driver, partition 1, ANY, 4621 bytes)
18/02/28 14:20:28 INFO TaskSetManager: Starting task 2.0 in stage 45.0 (TID 151, localhost, executor driver, partition 2, ANY, 4621 bytes)
18/02/28 14:20:28 INFO TaskSetManager: Starting task 3.0 in stage 45.0 (TID 152, localhost, executor driver, partition 3, ANY, 4621 bytes)
18/02/28 14:20:28 INFO Executor: Running task 2.0 in stage 45.0 (TID 151)
18/02/28 14:20:28 INFO Executor: Running task 0.0 in stage 45.0 (TID 149)
18/02/28 14:20:28 INFO Executor: Running task 3.0 in stage 45.0 (TID 152)
18/02/28 14:20:28 INFO Executor: Running task 1.0 in stage 45.0 (TID 150)
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:20:28 INFO Executor: Finished task 3.0 in stage 45.0 (TID 152). 1047 bytes result sent to driver
18/02/28 14:20:28 INFO Executor: Finished task 0.0 in stage 45.0 (TID 149). 1090 bytes result sent to driver
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 14:20:28 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 149) in 25 ms on localhost (executor driver) (1/4)
18/02/28 14:20:28 INFO TaskSetManager: Finished task 3.0 in stage 45.0 (TID 152) in 25 ms on localhost (executor driver) (2/4)
18/02/28 14:20:28 INFO Executor: Finished task 1.0 in stage 45.0 (TID 150). 1090 bytes result sent to driver
18/02/28 14:20:28 INFO TaskSetManager: Finished task 1.0 in stage 45.0 (TID 150) in 27 ms on localhost (executor driver) (3/4)
18/02/28 14:20:28 INFO Executor: Finished task 2.0 in stage 45.0 (TID 151). 1090 bytes result sent to driver
18/02/28 14:20:28 INFO TaskSetManager: Finished task 2.0 in stage 45.0 (TID 151) in 32 ms on localhost (executor driver) (4/4)
18/02/28 14:20:28 INFO DAGScheduler: ResultStage 45 (count at BinaryClassificationMetrics.scala:163) finished in 0.032 s
18/02/28 14:20:28 INFO DAGScheduler: Job 32 finished: count at BinaryClassificationMetrics.scala:163, took 0.178873 s
18/02/28 14:20:28 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
18/02/28 14:20:28 INFO SparkContext: Starting job: collect at BinaryClassificationMetrics.scala:192
18/02/28 14:20:28 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 10 is 167 bytes
18/02/28 14:20:28 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 11 is 171 bytes
18/02/28 14:20:28 INFO DAGScheduler: Got job 33 (collect at BinaryClassificationMetrics.scala:192) with 4 output partitions
18/02/28 14:20:28 INFO DAGScheduler: Final stage: ResultStage 48 (collect at BinaryClassificationMetrics.scala:192)
18/02/28 14:20:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47)
18/02/28 14:20:28 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:28 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[116] at mapPartitions at BinaryClassificationMetrics.scala:188), which has no missing parents
18/02/28 14:20:28 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 4.2 KB, free 344.9 MB)
18/02/28 14:20:28 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 2.3 KB, free 344.9 MB)
18/02/28 14:20:28 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:61560 (size: 2.3 KB, free: 345.5 MB)
18/02/28 14:20:28 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:28 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 48 (MapPartitionsRDD[116] at mapPartitions at BinaryClassificationMetrics.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:28 INFO TaskSchedulerImpl: Adding task set 48.0 with 4 tasks
18/02/28 14:20:28 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 153, localhost, executor driver, partition 0, ANY, 4621 bytes)
18/02/28 14:20:28 INFO TaskSetManager: Starting task 1.0 in stage 48.0 (TID 154, localhost, executor driver, partition 1, ANY, 4621 bytes)
18/02/28 14:20:28 INFO TaskSetManager: Starting task 2.0 in stage 48.0 (TID 155, localhost, executor driver, partition 2, ANY, 4621 bytes)
18/02/28 14:20:28 INFO TaskSetManager: Starting task 3.0 in stage 48.0 (TID 156, localhost, executor driver, partition 3, ANY, 4621 bytes)
18/02/28 14:20:28 INFO Executor: Running task 0.0 in stage 48.0 (TID 153)
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:20:28 INFO Executor: Running task 1.0 in stage 48.0 (TID 154)
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:20:28 INFO Executor: Finished task 0.0 in stage 48.0 (TID 153). 1217 bytes result sent to driver
18/02/28 14:20:28 INFO Executor: Running task 2.0 in stage 48.0 (TID 155)
18/02/28 14:20:28 INFO Executor: Running task 3.0 in stage 48.0 (TID 156)
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:20:28 INFO Executor: Finished task 1.0 in stage 48.0 (TID 154). 1174 bytes result sent to driver
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
18/02/28 14:20:28 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 153) in 15 ms on localhost (executor driver) (1/4)
18/02/28 14:20:28 INFO TaskSetManager: Finished task 1.0 in stage 48.0 (TID 154) in 15 ms on localhost (executor driver) (2/4)
18/02/28 14:20:28 INFO Executor: Finished task 3.0 in stage 48.0 (TID 156). 1174 bytes result sent to driver
18/02/28 14:20:28 INFO TaskSetManager: Finished task 3.0 in stage 48.0 (TID 156) in 18 ms on localhost (executor driver) (3/4)
18/02/28 14:20:28 INFO Executor: Finished task 2.0 in stage 48.0 (TID 155). 1217 bytes result sent to driver
18/02/28 14:20:28 INFO TaskSetManager: Finished task 2.0 in stage 48.0 (TID 155) in 21 ms on localhost (executor driver) (4/4)
18/02/28 14:20:28 INFO DAGScheduler: ResultStage 48 (collect at BinaryClassificationMetrics.scala:192) finished in 0.022 s
18/02/28 14:20:28 INFO DAGScheduler: Job 33 finished: collect at BinaryClassificationMetrics.scala:192, took 0.026842 s
18/02/28 14:20:28 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
18/02/28 14:20:28 INFO BinaryClassificationMetrics: Total counts: {numPos: 781, numNeg: 2377}
18/02/28 14:20:28 INFO SparkContext: Starting job: collect at SlidingRDD.scala:81
18/02/28 14:20:28 INFO DAGScheduler: Got job 34 (collect at SlidingRDD.scala:81) with 6 output partitions
18/02/28 14:20:28 INFO DAGScheduler: Final stage: ResultStage 51 (collect at SlidingRDD.scala:81)
18/02/28 14:20:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)
18/02/28 14:20:28 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:28 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[124] at mapPartitions at SlidingRDD.scala:78), which has no missing parents
18/02/28 14:20:28 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 6.3 KB, free 344.9 MB)
18/02/28 14:20:28 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 3.3 KB, free 344.9 MB)
18/02/28 14:20:28 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:61560 (size: 3.3 KB, free: 345.5 MB)
18/02/28 14:20:28 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:28 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 51 (MapPartitionsRDD[124] at mapPartitions at SlidingRDD.scala:78) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
18/02/28 14:20:28 INFO TaskSchedulerImpl: Adding task set 51.0 with 6 tasks
18/02/28 14:20:28 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 157, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:20:28 INFO TaskSetManager: Starting task 5.0 in stage 51.0 (TID 158, localhost, executor driver, partition 5, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:20:28 INFO TaskSetManager: Starting task 1.0 in stage 51.0 (TID 159, localhost, executor driver, partition 1, ANY, 4730 bytes)
18/02/28 14:20:28 INFO TaskSetManager: Starting task 2.0 in stage 51.0 (TID 160, localhost, executor driver, partition 2, ANY, 4730 bytes)
18/02/28 14:20:28 INFO Executor: Running task 0.0 in stage 51.0 (TID 157)
18/02/28 14:20:28 INFO Executor: Running task 1.0 in stage 51.0 (TID 159)
18/02/28 14:20:28 INFO Executor: Running task 2.0 in stage 51.0 (TID 160)
18/02/28 14:20:28 INFO Executor: Running task 5.0 in stage 51.0 (TID 158)
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:20:28 INFO Executor: Finished task 0.0 in stage 51.0 (TID 157). 856 bytes result sent to driver
18/02/28 14:20:28 INFO TaskSetManager: Starting task 3.0 in stage 51.0 (TID 161, localhost, executor driver, partition 3, ANY, 4730 bytes)
18/02/28 14:20:28 INFO Executor: Finished task 5.0 in stage 51.0 (TID 158). 856 bytes result sent to driver
18/02/28 14:20:28 INFO MemoryStore: Block rdd_117_1 stored as values in memory (estimated size 2.3 KB, free 344.9 MB)
18/02/28 14:20:28 INFO MemoryStore: Block rdd_117_0 stored as values in memory (estimated size 2032.0 B, free 344.9 MB)
18/02/28 14:20:28 INFO TaskSetManager: Starting task 4.0 in stage 51.0 (TID 162, localhost, executor driver, partition 4, ANY, 4730 bytes)
18/02/28 14:20:28 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 157) in 16 ms on localhost (executor driver) (1/6)
18/02/28 14:20:28 INFO TaskSetManager: Finished task 5.0 in stage 51.0 (TID 158) in 14 ms on localhost (executor driver) (2/6)
18/02/28 14:20:28 INFO Executor: Running task 4.0 in stage 51.0 (TID 162)
18/02/28 14:20:28 INFO BlockManagerInfo: Added rdd_117_1 in memory on 127.0.0.1:61560 (size: 2.3 KB, free: 345.5 MB)
18/02/28 14:20:28 INFO BlockManagerInfo: Added rdd_117_0 in memory on 127.0.0.1:61560 (size: 2032.0 B, free: 345.5 MB)
18/02/28 14:20:28 INFO Executor: Running task 3.0 in stage 51.0 (TID 161)
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:20:28 INFO Executor: Finished task 2.0 in stage 51.0 (TID 160). 1940 bytes result sent to driver
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:20:28 INFO MemoryStore: Block rdd_117_3 stored as values in memory (estimated size 2.1 KB, free 344.9 MB)
18/02/28 14:20:28 INFO BlockManagerInfo: Added rdd_117_3 in memory on 127.0.0.1:61560 (size: 2.1 KB, free: 345.5 MB)
18/02/28 14:20:28 INFO MemoryStore: Block rdd_117_2 stored as values in memory (estimated size 2.3 KB, free 344.9 MB)
18/02/28 14:20:28 INFO Executor: Finished task 1.0 in stage 51.0 (TID 159). 1983 bytes result sent to driver
18/02/28 14:20:28 INFO BlockManagerInfo: Added rdd_117_2 in memory on 127.0.0.1:61560 (size: 2.3 KB, free: 345.5 MB)
18/02/28 14:20:28 INFO TaskSetManager: Finished task 2.0 in stage 51.0 (TID 160) in 26 ms on localhost (executor driver) (3/6)
18/02/28 14:20:28 INFO TaskSetManager: Finished task 1.0 in stage 51.0 (TID 159) in 26 ms on localhost (executor driver) (4/6)
18/02/28 14:20:28 INFO Executor: Finished task 4.0 in stage 51.0 (TID 162). 1940 bytes result sent to driver
18/02/28 14:20:28 INFO Executor: Finished task 3.0 in stage 51.0 (TID 161). 1940 bytes result sent to driver
18/02/28 14:20:28 INFO TaskSetManager: Finished task 4.0 in stage 51.0 (TID 162) in 14 ms on localhost (executor driver) (5/6)
18/02/28 14:20:28 INFO TaskSetManager: Finished task 3.0 in stage 51.0 (TID 161) in 16 ms on localhost (executor driver) (6/6)
18/02/28 14:20:28 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
18/02/28 14:20:28 INFO DAGScheduler: ResultStage 51 (collect at SlidingRDD.scala:81) finished in 0.031 s
18/02/28 14:20:28 INFO DAGScheduler: Job 34 finished: collect at SlidingRDD.scala:81, took 0.037356 s
18/02/28 14:20:28 INFO SparkContext: Starting job: aggregate at AreaUnderCurve.scala:45
18/02/28 14:20:28 INFO DAGScheduler: Got job 35 (aggregate at AreaUnderCurve.scala:45) with 5 output partitions
18/02/28 14:20:28 INFO DAGScheduler: Final stage: ResultStage 54 (aggregate at AreaUnderCurve.scala:45)
18/02/28 14:20:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 53)
18/02/28 14:20:28 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:28 INFO DAGScheduler: Submitting ResultStage 54 (SlidingRDD[123] at RDD at SlidingRDD.scala:50), which has no missing parents
18/02/28 14:20:28 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 6.5 KB, free 344.9 MB)
18/02/28 14:20:28 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 3.4 KB, free 344.9 MB)
18/02/28 14:20:28 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:61560 (size: 3.4 KB, free: 345.5 MB)
18/02/28 14:20:28 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:28 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 54 (SlidingRDD[123] at RDD at SlidingRDD.scala:50) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/02/28 14:20:28 INFO TaskSchedulerImpl: Adding task set 54.0 with 5 tasks
18/02/28 14:20:28 INFO TaskSetManager: Starting task 1.0 in stage 54.0 (TID 163, localhost, executor driver, partition 1, PROCESS_LOCAL, 5269 bytes)
18/02/28 14:20:28 INFO TaskSetManager: Starting task 2.0 in stage 54.0 (TID 164, localhost, executor driver, partition 2, PROCESS_LOCAL, 5269 bytes)
18/02/28 14:20:28 INFO TaskSetManager: Starting task 3.0 in stage 54.0 (TID 165, localhost, executor driver, partition 3, PROCESS_LOCAL, 5269 bytes)
18/02/28 14:20:28 INFO TaskSetManager: Starting task 4.0 in stage 54.0 (TID 166, localhost, executor driver, partition 4, PROCESS_LOCAL, 5269 bytes)
18/02/28 14:20:28 INFO Executor: Running task 1.0 in stage 54.0 (TID 163)
18/02/28 14:20:28 INFO Executor: Running task 3.0 in stage 54.0 (TID 165)
18/02/28 14:20:28 INFO Executor: Running task 4.0 in stage 54.0 (TID 166)
18/02/28 14:20:28 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:20:28 INFO Executor: Finished task 1.0 in stage 54.0 (TID 163). 791 bytes result sent to driver
18/02/28 14:20:28 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:20:28 INFO Executor: Finished task 4.0 in stage 54.0 (TID 166). 748 bytes result sent to driver
18/02/28 14:20:28 INFO Executor: Running task 2.0 in stage 54.0 (TID 164)
18/02/28 14:20:28 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:20:28 INFO Executor: Finished task 2.0 in stage 54.0 (TID 164). 748 bytes result sent to driver
18/02/28 14:20:28 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 167, localhost, executor driver, partition 0, PROCESS_LOCAL, 5475 bytes)
18/02/28 14:20:28 INFO Executor: Running task 0.0 in stage 54.0 (TID 167)
18/02/28 14:20:28 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:20:28 INFO Executor: Finished task 3.0 in stage 54.0 (TID 165). 748 bytes result sent to driver
18/02/28 14:20:28 INFO Executor: Finished task 0.0 in stage 54.0 (TID 167). 619 bytes result sent to driver
18/02/28 14:20:28 INFO TaskSetManager: Finished task 1.0 in stage 54.0 (TID 163) in 19 ms on localhost (executor driver) (1/5)
18/02/28 14:20:28 INFO TaskSetManager: Finished task 2.0 in stage 54.0 (TID 164) in 18 ms on localhost (executor driver) (2/5)
18/02/28 14:20:28 INFO TaskSetManager: Finished task 3.0 in stage 54.0 (TID 165) in 17 ms on localhost (executor driver) (3/5)
18/02/28 14:20:28 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 167) in 5 ms on localhost (executor driver) (4/5)
18/02/28 14:20:28 INFO TaskSetManager: Finished task 4.0 in stage 54.0 (TID 166) in 18 ms on localhost (executor driver) (5/5)
18/02/28 14:20:28 INFO DAGScheduler: ResultStage 54 (aggregate at AreaUnderCurve.scala:45) finished in 0.021 s
18/02/28 14:20:28 INFO DAGScheduler: Job 35 finished: aggregate at AreaUnderCurve.scala:45, took 0.026250 s
18/02/28 14:20:28 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
18/02/28 14:20:28 INFO CodeGenerator: Code generated in 7.162707 ms
18/02/28 14:20:28 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:20:28 INFO DAGScheduler: Got job 36 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:20:28 INFO DAGScheduler: Final stage: ResultStage 57 (collect at utils.scala:211)
18/02/28 14:20:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)
18/02/28 14:20:28 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:28 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[128] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:28 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 10.4 KB, free 344.9 MB)
18/02/28 14:20:28 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.8 MB)
18/02/28 14:20:28 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:61560 (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:20:28 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:28 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 57 (MapPartitionsRDD[128] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:28 INFO TaskSchedulerImpl: Adding task set 57.0 with 4 tasks
18/02/28 14:20:28 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 168, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:28 INFO TaskSetManager: Starting task 1.0 in stage 57.0 (TID 169, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:28 INFO TaskSetManager: Starting task 2.0 in stage 57.0 (TID 170, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:28 INFO TaskSetManager: Starting task 3.0 in stage 57.0 (TID 171, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:28 INFO Executor: Running task 0.0 in stage 57.0 (TID 168)
18/02/28 14:20:28 INFO Executor: Running task 1.0 in stage 57.0 (TID 169)
18/02/28 14:20:28 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:20:28 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:20:28 INFO Executor: Running task 2.0 in stage 57.0 (TID 170)
18/02/28 14:20:28 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:20:28 INFO Executor: Running task 3.0 in stage 57.0 (TID 171)
18/02/28 14:20:28 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:20:28 INFO Executor: Finished task 3.0 in stage 57.0 (TID 171). 1581 bytes result sent to driver
18/02/28 14:20:28 INFO Executor: Finished task 0.0 in stage 57.0 (TID 168). 1556 bytes result sent to driver
18/02/28 14:20:28 INFO Executor: Finished task 2.0 in stage 57.0 (TID 170). 1614 bytes result sent to driver
18/02/28 14:20:28 INFO TaskSetManager: Finished task 3.0 in stage 57.0 (TID 171) in 10 ms on localhost (executor driver) (1/4)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 168) in 12 ms on localhost (executor driver) (2/4)
18/02/28 14:20:29 INFO Executor: Finished task 1.0 in stage 57.0 (TID 169). 1640 bytes result sent to driver
18/02/28 14:20:29 INFO TaskSetManager: Finished task 2.0 in stage 57.0 (TID 170) in 11 ms on localhost (executor driver) (3/4)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 1.0 in stage 57.0 (TID 169) in 12 ms on localhost (executor driver) (4/4)
18/02/28 14:20:29 INFO DAGScheduler: ResultStage 57 (collect at utils.scala:211) finished in 0.013 s
18/02/28 14:20:29 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
18/02/28 14:20:29 INFO DAGScheduler: Job 36 finished: collect at utils.scala:211, took 0.020265 s
18/02/28 14:20:29 INFO CodeGenerator: Code generated in 4.663358 ms
18/02/28 14:20:29 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:20:29 INFO DAGScheduler: Got job 37 (collect at utils.scala:211) with 5 output partitions
18/02/28 14:20:29 INFO DAGScheduler: Final stage: ResultStage 60 (collect at utils.scala:211)
18/02/28 14:20:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 59)
18/02/28 14:20:29 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:29 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[134] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:29 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 11.1 KB, free 344.8 MB)
18/02/28 14:20:29 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 5.3 KB, free 344.8 MB)
18/02/28 14:20:29 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:61560 (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:20:29 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:29 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 60 (MapPartitionsRDD[134] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/02/28 14:20:29 INFO TaskSchedulerImpl: Adding task set 60.0 with 5 tasks
18/02/28 14:20:29 INFO TaskSetManager: Starting task 1.0 in stage 60.0 (TID 172, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 2.0 in stage 60.0 (TID 173, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 3.0 in stage 60.0 (TID 174, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 4.0 in stage 60.0 (TID 175, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:20:29 INFO Executor: Running task 1.0 in stage 60.0 (TID 172)
18/02/28 14:20:29 INFO Executor: Running task 2.0 in stage 60.0 (TID 173)
18/02/28 14:20:29 INFO Executor: Running task 3.0 in stage 60.0 (TID 174)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:20:29 INFO Executor: Finished task 2.0 in stage 60.0 (TID 173). 1499 bytes result sent to driver
18/02/28 14:20:29 INFO Executor: Running task 4.0 in stage 60.0 (TID 175)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:20:29 INFO Executor: Finished task 3.0 in stage 60.0 (TID 174). 1618 bytes result sent to driver
18/02/28 14:20:29 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 176, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:20:29 INFO Executor: Finished task 1.0 in stage 60.0 (TID 172). 1395 bytes result sent to driver
18/02/28 14:20:29 INFO TaskSetManager: Finished task 2.0 in stage 60.0 (TID 173) in 8 ms on localhost (executor driver) (1/5)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 3.0 in stage 60.0 (TID 174) in 8 ms on localhost (executor driver) (2/5)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 1.0 in stage 60.0 (TID 172) in 9 ms on localhost (executor driver) (3/5)
18/02/28 14:20:29 INFO Executor: Running task 0.0 in stage 60.0 (TID 176)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:20:29 INFO Executor: Finished task 4.0 in stage 60.0 (TID 175). 1572 bytes result sent to driver
18/02/28 14:20:29 INFO TaskSetManager: Finished task 4.0 in stage 60.0 (TID 175) in 12 ms on localhost (executor driver) (4/5)
18/02/28 14:20:29 INFO Executor: Finished task 0.0 in stage 60.0 (TID 176). 1000 bytes result sent to driver
18/02/28 14:20:29 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 176) in 7 ms on localhost (executor driver) (5/5)
18/02/28 14:20:29 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
18/02/28 14:20:29 INFO DAGScheduler: ResultStage 60 (collect at utils.scala:211) finished in 0.013 s
18/02/28 14:20:29 INFO DAGScheduler: Job 37 finished: collect at utils.scala:211, took 0.018494 s
18/02/28 14:20:29 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:20:29 INFO DAGScheduler: Got job 38 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:20:29 INFO DAGScheduler: Final stage: ResultStage 63 (collect at utils.scala:211)
18/02/28 14:20:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 62)
18/02/28 14:20:29 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:29 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[138] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:29 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 10.3 KB, free 344.8 MB)
18/02/28 14:20:29 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.8 MB)
18/02/28 14:20:29 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 127.0.0.1:61560 (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:20:29 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:29 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 63 (MapPartitionsRDD[138] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:29 INFO TaskSchedulerImpl: Adding task set 63.0 with 4 tasks
18/02/28 14:20:29 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 177, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 1.0 in stage 63.0 (TID 178, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 2.0 in stage 63.0 (TID 179, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 3.0 in stage 63.0 (TID 180, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO Executor: Running task 0.0 in stage 63.0 (TID 177)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:20:29 INFO Executor: Finished task 0.0 in stage 63.0 (TID 177). 1294 bytes result sent to driver
18/02/28 14:20:29 INFO Executor: Running task 1.0 in stage 63.0 (TID 178)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:20:29 INFO Executor: Finished task 1.0 in stage 63.0 (TID 178). 1482 bytes result sent to driver
18/02/28 14:20:29 INFO Executor: Running task 2.0 in stage 63.0 (TID 179)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:20:29 INFO Executor: Finished task 2.0 in stage 63.0 (TID 179). 1618 bytes result sent to driver
18/02/28 14:20:29 INFO Executor: Running task 3.0 in stage 63.0 (TID 180)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:20:29 INFO Executor: Finished task 3.0 in stage 63.0 (TID 180). 1589 bytes result sent to driver
18/02/28 14:20:29 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 177) in 15 ms on localhost (executor driver) (1/4)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 1.0 in stage 63.0 (TID 178) in 15 ms on localhost (executor driver) (2/4)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 2.0 in stage 63.0 (TID 179) in 15 ms on localhost (executor driver) (3/4)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 3.0 in stage 63.0 (TID 180) in 16 ms on localhost (executor driver) (4/4)
18/02/28 14:20:29 INFO DAGScheduler: ResultStage 63 (collect at utils.scala:211) finished in 0.017 s
18/02/28 14:20:29 INFO DAGScheduler: Job 38 finished: collect at utils.scala:211, took 0.022120 s
18/02/28 14:20:29 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
18/02/28 14:20:29 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2ef81e1d24d9
18/02/28 14:20:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ef81e1d24d9` AS `zzz10`
WHERE (0 = 1)
18/02/28 14:20:29 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:20:29 INFO DAGScheduler: Got job 39 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:20:29 INFO DAGScheduler: Final stage: ResultStage 66 (collect at utils.scala:211)
18/02/28 14:20:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 65)
18/02/28 14:20:29 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:29 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[142] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:29 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 10.3 KB, free 344.8 MB)
18/02/28 14:20:29 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.8 MB)
18/02/28 14:20:29 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 127.0.0.1:61560 (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:20:29 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:29 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 66 (MapPartitionsRDD[142] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:29 INFO TaskSchedulerImpl: Adding task set 66.0 with 4 tasks
18/02/28 14:20:29 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 181, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 1.0 in stage 66.0 (TID 182, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 2.0 in stage 66.0 (TID 183, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 3.0 in stage 66.0 (TID 184, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO Executor: Running task 0.0 in stage 66.0 (TID 181)
18/02/28 14:20:29 INFO Executor: Running task 2.0 in stage 66.0 (TID 183)
18/02/28 14:20:29 INFO Executor: Running task 3.0 in stage 66.0 (TID 184)
18/02/28 14:20:29 INFO Executor: Running task 1.0 in stage 66.0 (TID 182)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:20:29 INFO Executor: Finished task 1.0 in stage 66.0 (TID 182). 1603 bytes result sent to driver
18/02/28 14:20:29 INFO Executor: Finished task 3.0 in stage 66.0 (TID 184). 1555 bytes result sent to driver
18/02/28 14:20:29 INFO TaskSetManager: Finished task 1.0 in stage 66.0 (TID 182) in 3 ms on localhost (executor driver) (1/4)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 3.0 in stage 66.0 (TID 184) in 4 ms on localhost (executor driver) (2/4)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:20:29 INFO Executor: Finished task 0.0 in stage 66.0 (TID 181). 1544 bytes result sent to driver
18/02/28 14:20:29 INFO Executor: Finished task 2.0 in stage 66.0 (TID 183). 1628 bytes result sent to driver
18/02/28 14:20:29 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 181) in 8 ms on localhost (executor driver) (3/4)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 2.0 in stage 66.0 (TID 183) in 8 ms on localhost (executor driver) (4/4)
18/02/28 14:20:29 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
18/02/28 14:20:29 INFO DAGScheduler: ResultStage 66 (collect at utils.scala:211) finished in 0.009 s
18/02/28 14:20:29 INFO DAGScheduler: Job 39 finished: collect at utils.scala:211, took 0.013390 s
18/02/28 14:20:29 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:20:29 INFO DAGScheduler: Got job 40 (collect at utils.scala:211) with 6 output partitions
18/02/28 14:20:29 INFO DAGScheduler: Final stage: ResultStage 69 (collect at utils.scala:211)
18/02/28 14:20:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 68)
18/02/28 14:20:29 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:29 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[149] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:29 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 11.2 KB, free 344.8 MB)
18/02/28 14:20:29 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 5.3 KB, free 344.8 MB)
18/02/28 14:20:29 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 127.0.0.1:61560 (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:20:29 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:29 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 69 (MapPartitionsRDD[149] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
18/02/28 14:20:29 INFO TaskSchedulerImpl: Adding task set 69.0 with 6 tasks
18/02/28 14:20:29 INFO TaskSetManager: Starting task 1.0 in stage 69.0 (TID 185, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 2.0 in stage 69.0 (TID 186, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 3.0 in stage 69.0 (TID 187, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 4.0 in stage 69.0 (TID 188, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:20:29 INFO Executor: Running task 1.0 in stage 69.0 (TID 185)
18/02/28 14:20:29 INFO Executor: Running task 2.0 in stage 69.0 (TID 186)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:20:29 INFO Executor: Finished task 1.0 in stage 69.0 (TID 185). 1384 bytes result sent to driver
18/02/28 14:20:29 INFO Executor: Running task 3.0 in stage 69.0 (TID 187)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:20:29 INFO Executor: Finished task 2.0 in stage 69.0 (TID 186). 1442 bytes result sent to driver
18/02/28 14:20:29 INFO Executor: Running task 4.0 in stage 69.0 (TID 188)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:20:29 INFO Executor: Finished task 3.0 in stage 69.0 (TID 187). 1642 bytes result sent to driver
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:20:29 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 189, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 5.0 in stage 69.0 (TID 190, localhost, executor driver, partition 5, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:20:29 INFO Executor: Finished task 4.0 in stage 69.0 (TID 188). 1547 bytes result sent to driver
18/02/28 14:20:29 INFO TaskSetManager: Finished task 1.0 in stage 69.0 (TID 185) in 10 ms on localhost (executor driver) (1/6)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 2.0 in stage 69.0 (TID 186) in 9 ms on localhost (executor driver) (2/6)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 3.0 in stage 69.0 (TID 187) in 10 ms on localhost (executor driver) (3/6)
18/02/28 14:20:29 INFO Executor: Running task 5.0 in stage 69.0 (TID 190)
18/02/28 14:20:29 INFO Executor: Running task 0.0 in stage 69.0 (TID 189)
18/02/28 14:20:29 INFO Executor: Finished task 5.0 in stage 69.0 (TID 190). 1093 bytes result sent to driver
18/02/28 14:20:29 INFO TaskSetManager: Finished task 4.0 in stage 69.0 (TID 188) in 10 ms on localhost (executor driver) (4/6)
18/02/28 14:20:29 INFO Executor: Finished task 0.0 in stage 69.0 (TID 189). 1085 bytes result sent to driver
18/02/28 14:20:29 INFO TaskSetManager: Finished task 5.0 in stage 69.0 (TID 190) in 5 ms on localhost (executor driver) (5/6)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 189) in 6 ms on localhost (executor driver) (6/6)
18/02/28 14:20:29 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
18/02/28 14:20:29 INFO DAGScheduler: ResultStage 69 (collect at utils.scala:211) finished in 0.016 s
18/02/28 14:20:29 INFO DAGScheduler: Job 40 finished: collect at utils.scala:211, took 0.025202 s
18/02/28 14:20:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 14:20:29 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2ef84c42f59
18/02/28 14:20:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ef84c42f59` AS `zzz11`
WHERE (0 = 1)
18/02/28 14:20:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ef84c42f59`
18/02/28 14:20:29 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:20:29 INFO DAGScheduler: Got job 41 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:20:29 INFO DAGScheduler: Final stage: ResultStage 72 (collect at utils.scala:211)
18/02/28 14:20:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 71)
18/02/28 14:20:29 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:29 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[152] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:29 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 10.4 KB, free 344.8 MB)
18/02/28 14:20:29 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.8 MB)
18/02/28 14:20:29 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 127.0.0.1:61560 (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:20:29 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:29 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 72 (MapPartitionsRDD[152] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:29 INFO TaskSchedulerImpl: Adding task set 72.0 with 4 tasks
18/02/28 14:20:29 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 191, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 1.0 in stage 72.0 (TID 192, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 2.0 in stage 72.0 (TID 193, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 3.0 in stage 72.0 (TID 194, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO Executor: Running task 0.0 in stage 72.0 (TID 191)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:20:29 INFO Executor: Finished task 0.0 in stage 72.0 (TID 191). 1599 bytes result sent to driver
18/02/28 14:20:29 INFO Executor: Running task 1.0 in stage 72.0 (TID 192)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:20:29 INFO Executor: Running task 2.0 in stage 72.0 (TID 193)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:20:29 INFO Executor: Running task 3.0 in stage 72.0 (TID 194)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:20:29 INFO Executor: Finished task 1.0 in stage 72.0 (TID 192). 1640 bytes result sent to driver
18/02/28 14:20:29 INFO Executor: Finished task 3.0 in stage 72.0 (TID 194). 1581 bytes result sent to driver
18/02/28 14:20:29 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 191) in 9 ms on localhost (executor driver) (1/4)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 1.0 in stage 72.0 (TID 192) in 12 ms on localhost (executor driver) (2/4)
18/02/28 14:20:29 INFO Executor: Finished task 2.0 in stage 72.0 (TID 193). 1614 bytes result sent to driver
18/02/28 14:20:29 INFO TaskSetManager: Finished task 3.0 in stage 72.0 (TID 194) in 12 ms on localhost (executor driver) (3/4)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 2.0 in stage 72.0 (TID 193) in 13 ms on localhost (executor driver) (4/4)
18/02/28 14:20:29 INFO DAGScheduler: ResultStage 72 (collect at utils.scala:211) finished in 0.013 s
18/02/28 14:20:29 INFO DAGScheduler: Job 41 finished: collect at utils.scala:211, took 0.018998 s
18/02/28 14:20:29 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
18/02/28 14:20:29 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:20:29 INFO DAGScheduler: Got job 42 (collect at utils.scala:211) with 5 output partitions
18/02/28 14:20:29 INFO DAGScheduler: Final stage: ResultStage 75 (collect at utils.scala:211)
18/02/28 14:20:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 74)
18/02/28 14:20:29 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:29 INFO DAGScheduler: Submitting ResultStage 75 (MapPartitionsRDD[155] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:29 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 11.1 KB, free 344.8 MB)
18/02/28 14:20:29 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 5.3 KB, free 344.8 MB)
18/02/28 14:20:29 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 127.0.0.1:61560 (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:20:29 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:29 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 75 (MapPartitionsRDD[155] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/02/28 14:20:29 INFO TaskSchedulerImpl: Adding task set 75.0 with 5 tasks
18/02/28 14:20:29 INFO TaskSetManager: Starting task 1.0 in stage 75.0 (TID 195, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 2.0 in stage 75.0 (TID 196, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 3.0 in stage 75.0 (TID 197, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 4.0 in stage 75.0 (TID 198, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:20:29 INFO Executor: Running task 1.0 in stage 75.0 (TID 195)
18/02/28 14:20:29 INFO Executor: Running task 2.0 in stage 75.0 (TID 196)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:20:29 INFO Executor: Finished task 1.0 in stage 75.0 (TID 195). 1395 bytes result sent to driver
18/02/28 14:20:29 INFO Executor: Running task 3.0 in stage 75.0 (TID 197)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:20:29 INFO Executor: Finished task 2.0 in stage 75.0 (TID 196). 1499 bytes result sent to driver
18/02/28 14:20:29 INFO Executor: Running task 4.0 in stage 75.0 (TID 198)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:20:29 INFO Executor: Finished task 3.0 in stage 75.0 (TID 197). 1575 bytes result sent to driver
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:20:29 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 199, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:20:29 INFO Executor: Finished task 4.0 in stage 75.0 (TID 198). 1572 bytes result sent to driver
18/02/28 14:20:29 INFO Executor: Running task 0.0 in stage 75.0 (TID 199)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 1.0 in stage 75.0 (TID 195) in 9 ms on localhost (executor driver) (1/5)
18/02/28 14:20:29 INFO Executor: Finished task 0.0 in stage 75.0 (TID 199). 1043 bytes result sent to driver
18/02/28 14:20:29 INFO TaskSetManager: Finished task 2.0 in stage 75.0 (TID 196) in 9 ms on localhost (executor driver) (2/5)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 3.0 in stage 75.0 (TID 197) in 10 ms on localhost (executor driver) (3/5)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 199) in 4 ms on localhost (executor driver) (4/5)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 4.0 in stage 75.0 (TID 198) in 10 ms on localhost (executor driver) (5/5)
18/02/28 14:20:29 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
18/02/28 14:20:29 INFO DAGScheduler: ResultStage 75 (collect at utils.scala:211) finished in 0.010 s
18/02/28 14:20:29 INFO DAGScheduler: Job 42 finished: collect at utils.scala:211, took 0.015834 s
18/02/28 14:20:29 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:20:29 INFO DAGScheduler: Got job 43 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:20:29 INFO DAGScheduler: Final stage: ResultStage 78 (collect at utils.scala:211)
18/02/28 14:20:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 77)
18/02/28 14:20:29 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:29 INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[158] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:29 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 10.3 KB, free 344.7 MB)
18/02/28 14:20:29 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.7 MB)
18/02/28 14:20:29 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 127.0.0.1:61560 (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:20:29 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:29 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 78 (MapPartitionsRDD[158] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:29 INFO TaskSchedulerImpl: Adding task set 78.0 with 4 tasks
18/02/28 14:20:29 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 200, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 1.0 in stage 78.0 (TID 201, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 2.0 in stage 78.0 (TID 202, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 3.0 in stage 78.0 (TID 203, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO Executor: Running task 0.0 in stage 78.0 (TID 200)
18/02/28 14:20:29 INFO Executor: Running task 1.0 in stage 78.0 (TID 201)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:20:29 INFO Executor: Finished task 0.0 in stage 78.0 (TID 200). 1337 bytes result sent to driver
18/02/28 14:20:29 INFO Executor: Running task 2.0 in stage 78.0 (TID 202)
18/02/28 14:20:29 INFO Executor: Running task 3.0 in stage 78.0 (TID 203)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:20:29 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 200) in 4 ms on localhost (executor driver) (1/4)
18/02/28 14:20:29 INFO Executor: Finished task 1.0 in stage 78.0 (TID 201). 1525 bytes result sent to driver
18/02/28 14:20:29 INFO TaskSetManager: Finished task 1.0 in stage 78.0 (TID 201) in 5 ms on localhost (executor driver) (2/4)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:20:29 INFO Executor: Finished task 3.0 in stage 78.0 (TID 203). 1589 bytes result sent to driver
18/02/28 14:20:29 INFO Executor: Finished task 2.0 in stage 78.0 (TID 202). 1618 bytes result sent to driver
18/02/28 14:20:29 INFO TaskSetManager: Finished task 3.0 in stage 78.0 (TID 203) in 6 ms on localhost (executor driver) (3/4)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 2.0 in stage 78.0 (TID 202) in 7 ms on localhost (executor driver) (4/4)
18/02/28 14:20:29 INFO DAGScheduler: ResultStage 78 (collect at utils.scala:211) finished in 0.007 s
18/02/28 14:20:29 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
18/02/28 14:20:29 INFO DAGScheduler: Job 43 finished: collect at utils.scala:211, took 0.011852 s
18/02/28 14:20:29 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2ef86c0e3e1b
18/02/28 14:20:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ef86c0e3e1b` AS `zzz12`
WHERE (0 = 1)
18/02/28 14:20:29 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:20:29 INFO DAGScheduler: Got job 44 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:20:29 INFO DAGScheduler: Final stage: ResultStage 81 (collect at utils.scala:211)
18/02/28 14:20:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 80)
18/02/28 14:20:29 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:29 INFO DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[161] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:29 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 10.3 KB, free 344.7 MB)
18/02/28 14:20:29 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.7 MB)
18/02/28 14:20:29 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 127.0.0.1:61560 (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:20:29 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:29 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 81 (MapPartitionsRDD[161] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:29 INFO TaskSchedulerImpl: Adding task set 81.0 with 4 tasks
18/02/28 14:20:29 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 204, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 1.0 in stage 81.0 (TID 205, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 2.0 in stage 81.0 (TID 206, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 3.0 in stage 81.0 (TID 207, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO Executor: Running task 0.0 in stage 81.0 (TID 204)
18/02/28 14:20:29 INFO Executor: Running task 1.0 in stage 81.0 (TID 205)
18/02/28 14:20:29 INFO Executor: Running task 3.0 in stage 81.0 (TID 207)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:20:29 INFO Executor: Finished task 0.0 in stage 81.0 (TID 204). 1544 bytes result sent to driver
18/02/28 14:20:29 INFO Executor: Running task 2.0 in stage 81.0 (TID 206)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:20:29 INFO Executor: Finished task 3.0 in stage 81.0 (TID 207). 1555 bytes result sent to driver
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:20:29 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 204) in 7 ms on localhost (executor driver) (1/4)
18/02/28 14:20:29 INFO Executor: Finished task 1.0 in stage 81.0 (TID 205). 1603 bytes result sent to driver
18/02/28 14:20:29 INFO TaskSetManager: Finished task 3.0 in stage 81.0 (TID 207) in 7 ms on localhost (executor driver) (2/4)
18/02/28 14:20:29 INFO Executor: Finished task 2.0 in stage 81.0 (TID 206). 1628 bytes result sent to driver
18/02/28 14:20:29 INFO TaskSetManager: Finished task 1.0 in stage 81.0 (TID 205) in 8 ms on localhost (executor driver) (3/4)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 2.0 in stage 81.0 (TID 206) in 8 ms on localhost (executor driver) (4/4)
18/02/28 14:20:29 INFO DAGScheduler: ResultStage 81 (collect at utils.scala:211) finished in 0.009 s
18/02/28 14:20:29 INFO DAGScheduler: Job 44 finished: collect at utils.scala:211, took 0.013272 s
18/02/28 14:20:29 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
18/02/28 14:20:29 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:20:29 INFO DAGScheduler: Got job 45 (collect at utils.scala:211) with 6 output partitions
18/02/28 14:20:29 INFO DAGScheduler: Final stage: ResultStage 84 (collect at utils.scala:211)
18/02/28 14:20:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 83)
18/02/28 14:20:29 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:29 INFO DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[164] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:29 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 11.2 KB, free 344.7 MB)
18/02/28 14:20:29 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 5.3 KB, free 344.7 MB)
18/02/28 14:20:29 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 127.0.0.1:61560 (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:20:29 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:29 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 84 (MapPartitionsRDD[164] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
18/02/28 14:20:29 INFO TaskSchedulerImpl: Adding task set 84.0 with 6 tasks
18/02/28 14:20:29 INFO TaskSetManager: Starting task 1.0 in stage 84.0 (TID 208, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 2.0 in stage 84.0 (TID 209, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 3.0 in stage 84.0 (TID 210, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 4.0 in stage 84.0 (TID 211, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:20:29 INFO Executor: Running task 1.0 in stage 84.0 (TID 208)
18/02/28 14:20:29 INFO Executor: Running task 2.0 in stage 84.0 (TID 209)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:20:29 INFO Executor: Finished task 1.0 in stage 84.0 (TID 208). 1341 bytes result sent to driver
18/02/28 14:20:29 INFO Executor: Running task 3.0 in stage 84.0 (TID 210)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:20:29 INFO Executor: Finished task 2.0 in stage 84.0 (TID 209). 1442 bytes result sent to driver
18/02/28 14:20:29 INFO Executor: Running task 4.0 in stage 84.0 (TID 211)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:20:29 INFO Executor: Finished task 4.0 in stage 84.0 (TID 211). 1547 bytes result sent to driver
18/02/28 14:20:29 INFO Executor: Finished task 3.0 in stage 84.0 (TID 210). 1599 bytes result sent to driver
18/02/28 14:20:29 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 212, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 5.0 in stage 84.0 (TID 213, localhost, executor driver, partition 5, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 1.0 in stage 84.0 (TID 208) in 10 ms on localhost (executor driver) (1/6)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 2.0 in stage 84.0 (TID 209) in 10 ms on localhost (executor driver) (2/6)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 4.0 in stage 84.0 (TID 211) in 10 ms on localhost (executor driver) (3/6)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 3.0 in stage 84.0 (TID 210) in 11 ms on localhost (executor driver) (4/6)
18/02/28 14:20:29 INFO Executor: Running task 0.0 in stage 84.0 (TID 212)
18/02/28 14:20:29 INFO Executor: Running task 5.0 in stage 84.0 (TID 213)
18/02/28 14:20:29 INFO Executor: Finished task 0.0 in stage 84.0 (TID 212). 999 bytes result sent to driver
18/02/28 14:20:29 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 212) in 5 ms on localhost (executor driver) (5/6)
18/02/28 14:20:29 INFO Executor: Finished task 5.0 in stage 84.0 (TID 213). 1007 bytes result sent to driver
18/02/28 14:20:29 INFO TaskSetManager: Finished task 5.0 in stage 84.0 (TID 213) in 5 ms on localhost (executor driver) (6/6)
18/02/28 14:20:29 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
18/02/28 14:20:29 INFO DAGScheduler: ResultStage 84 (collect at utils.scala:211) finished in 0.014 s
18/02/28 14:20:29 INFO DAGScheduler: Job 45 finished: collect at utils.scala:211, took 0.018875 s
18/02/28 14:20:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 14:20:29 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:20:29 INFO DAGScheduler: Got job 46 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:20:29 INFO DAGScheduler: Final stage: ResultStage 87 (collect at utils.scala:211)
18/02/28 14:20:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 86)
18/02/28 14:20:29 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:29 INFO DAGScheduler: Submitting ResultStage 87 (MapPartitionsRDD[167] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:29 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 10.4 KB, free 344.7 MB)
18/02/28 14:20:29 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.7 MB)
18/02/28 14:20:29 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 127.0.0.1:61560 (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:20:29 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:29 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 87 (MapPartitionsRDD[167] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:29 INFO TaskSchedulerImpl: Adding task set 87.0 with 4 tasks
18/02/28 14:20:29 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 214, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 1.0 in stage 87.0 (TID 215, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 2.0 in stage 87.0 (TID 216, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 3.0 in stage 87.0 (TID 217, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO Executor: Running task 0.0 in stage 87.0 (TID 214)
18/02/28 14:20:29 INFO Executor: Running task 1.0 in stage 87.0 (TID 215)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:20:29 INFO Executor: Finished task 0.0 in stage 87.0 (TID 214). 1513 bytes result sent to driver
18/02/28 14:20:29 INFO Executor: Running task 2.0 in stage 87.0 (TID 216)
18/02/28 14:20:29 INFO Executor: Running task 3.0 in stage 87.0 (TID 217)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:20:29 INFO Executor: Finished task 3.0 in stage 87.0 (TID 217). 1581 bytes result sent to driver
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:20:29 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 214) in 8 ms on localhost (executor driver) (1/4)
18/02/28 14:20:29 INFO Executor: Finished task 1.0 in stage 87.0 (TID 215). 1640 bytes result sent to driver
18/02/28 14:20:29 INFO TaskSetManager: Finished task 3.0 in stage 87.0 (TID 217) in 7 ms on localhost (executor driver) (2/4)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 1.0 in stage 87.0 (TID 215) in 8 ms on localhost (executor driver) (3/4)
18/02/28 14:20:29 INFO Executor: Finished task 2.0 in stage 87.0 (TID 216). 1614 bytes result sent to driver
18/02/28 14:20:29 INFO TaskSetManager: Finished task 2.0 in stage 87.0 (TID 216) in 8 ms on localhost (executor driver) (4/4)
18/02/28 14:20:29 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool 
18/02/28 14:20:29 INFO DAGScheduler: ResultStage 87 (collect at utils.scala:211) finished in 0.009 s
18/02/28 14:20:29 INFO DAGScheduler: Job 46 finished: collect at utils.scala:211, took 0.016316 s
18/02/28 14:20:29 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:20:29 INFO DAGScheduler: Got job 47 (collect at utils.scala:211) with 5 output partitions
18/02/28 14:20:29 INFO DAGScheduler: Final stage: ResultStage 90 (collect at utils.scala:211)
18/02/28 14:20:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 89)
18/02/28 14:20:29 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:29 INFO DAGScheduler: Submitting ResultStage 90 (MapPartitionsRDD[170] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:29 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 11.1 KB, free 344.7 MB)
18/02/28 14:20:29 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 5.3 KB, free 344.7 MB)
18/02/28 14:20:29 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 127.0.0.1:61560 (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:20:29 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:29 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 90 (MapPartitionsRDD[170] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/02/28 14:20:29 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 127.0.0.1:61560 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:20:29 INFO TaskSchedulerImpl: Adding task set 90.0 with 5 tasks
18/02/28 14:20:29 INFO TaskSetManager: Starting task 1.0 in stage 90.0 (TID 218, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 2.0 in stage 90.0 (TID 219, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 3.0 in stage 90.0 (TID 220, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 4.0 in stage 90.0 (TID 221, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:20:29 INFO Executor: Running task 1.0 in stage 90.0 (TID 218)
18/02/28 14:20:29 INFO Executor: Running task 2.0 in stage 90.0 (TID 219)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:20:29 INFO Executor: Running task 4.0 in stage 90.0 (TID 221)
18/02/28 14:20:29 INFO Executor: Finished task 1.0 in stage 90.0 (TID 218). 1395 bytes result sent to driver
18/02/28 14:20:29 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 222, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:20:29 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 127.0.0.1:61560 in memory (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:20:29 INFO Executor: Running task 3.0 in stage 90.0 (TID 220)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:20:29 INFO Executor: Finished task 4.0 in stage 90.0 (TID 221). 1572 bytes result sent to driver
18/02/28 14:20:29 INFO Executor: Finished task 2.0 in stage 90.0 (TID 219). 1499 bytes result sent to driver
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:20:29 INFO TaskSetManager: Finished task 1.0 in stage 90.0 (TID 218) in 6 ms on localhost (executor driver) (1/5)
18/02/28 14:20:29 INFO Executor: Finished task 3.0 in stage 90.0 (TID 220). 1618 bytes result sent to driver
18/02/28 14:20:29 INFO Executor: Running task 0.0 in stage 90.0 (TID 222)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 4.0 in stage 90.0 (TID 221) in 6 ms on localhost (executor driver) (2/5)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 2.0 in stage 90.0 (TID 219) in 6 ms on localhost (executor driver) (3/5)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 3.0 in stage 90.0 (TID 220) in 7 ms on localhost (executor driver) (4/5)
18/02/28 14:20:29 INFO Executor: Finished task 0.0 in stage 90.0 (TID 222). 1043 bytes result sent to driver
18/02/28 14:20:29 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 127.0.0.1:61560 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 222) in 6 ms on localhost (executor driver) (5/5)
18/02/28 14:20:29 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
18/02/28 14:20:29 INFO DAGScheduler: ResultStage 90 (collect at utils.scala:211) finished in 0.009 s
18/02/28 14:20:29 INFO DAGScheduler: Job 47 finished: collect at utils.scala:211, took 0.025681 s
18/02/28 14:20:29 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 127.0.0.1:61560 in memory (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:20:29 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 127.0.0.1:61560 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:20:29 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 127.0.0.1:61560 in memory (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:20:29 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:61560 in memory (size: 1914.0 B, free: 345.5 MB)
18/02/28 14:20:29 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 127.0.0.1:61560 in memory (size: 2.3 KB, free: 345.5 MB)
18/02/28 14:20:29 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 127.0.0.1:61560 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:20:29 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:20:29 INFO DAGScheduler: Got job 48 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:20:29 INFO DAGScheduler: Final stage: ResultStage 93 (collect at utils.scala:211)
18/02/28 14:20:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 92)
18/02/28 14:20:29 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:29 INFO DAGScheduler: Submitting ResultStage 93 (MapPartitionsRDD[173] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:29 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 10.3 KB, free 344.8 MB)
18/02/28 14:20:29 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.8 MB)
18/02/28 14:20:29 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 127.0.0.1:61560 (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:20:29 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:29 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 93 (MapPartitionsRDD[173] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:29 INFO TaskSchedulerImpl: Adding task set 93.0 with 4 tasks
18/02/28 14:20:29 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 127.0.0.1:61560 in memory (size: 1868.0 B, free: 345.5 MB)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 223, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 1.0 in stage 93.0 (TID 224, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 2.0 in stage 93.0 (TID 225, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 3.0 in stage 93.0 (TID 226, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO Executor: Running task 0.0 in stage 93.0 (TID 223)
18/02/28 14:20:29 INFO Executor: Running task 3.0 in stage 93.0 (TID 226)
18/02/28 14:20:29 INFO Executor: Running task 2.0 in stage 93.0 (TID 225)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:20:29 INFO Executor: Finished task 0.0 in stage 93.0 (TID 223). 1337 bytes result sent to driver
18/02/28 14:20:29 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 127.0.0.1:61560 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:20:29 INFO Executor: Finished task 2.0 in stage 93.0 (TID 225). 1575 bytes result sent to driver
18/02/28 14:20:29 INFO Executor: Running task 1.0 in stage 93.0 (TID 224)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:20:29 INFO Executor: Finished task 3.0 in stage 93.0 (TID 226). 1589 bytes result sent to driver
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:20:29 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 223) in 6 ms on localhost (executor driver) (1/4)
18/02/28 14:20:29 INFO Executor: Finished task 1.0 in stage 93.0 (TID 224). 1439 bytes result sent to driver
18/02/28 14:20:29 INFO TaskSetManager: Finished task 3.0 in stage 93.0 (TID 226) in 6 ms on localhost (executor driver) (2/4)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 2.0 in stage 93.0 (TID 225) in 6 ms on localhost (executor driver) (3/4)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 1.0 in stage 93.0 (TID 224) in 7 ms on localhost (executor driver) (4/4)
18/02/28 14:20:29 INFO DAGScheduler: ResultStage 93 (collect at utils.scala:211) finished in 0.007 s
18/02/28 14:20:29 INFO DAGScheduler: Job 48 finished: collect at utils.scala:211, took 0.012396 s
18/02/28 14:20:29 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool 
18/02/28 14:20:29 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 127.0.0.1:61560 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:20:29 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 127.0.0.1:61560 in memory (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:20:29 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 127.0.0.1:61560 in memory (size: 3.4 KB, free: 345.5 MB)
18/02/28 14:20:29 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 127.0.0.1:61560 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:20:29 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2ef8140918e3
18/02/28 14:20:29 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 127.0.0.1:61560 in memory (size: 3.3 KB, free: 345.5 MB)
18/02/28 14:20:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ef8140918e3` AS `zzz13`
WHERE (0 = 1)
18/02/28 14:20:29 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:20:29 INFO DAGScheduler: Got job 49 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:20:29 INFO DAGScheduler: Final stage: ResultStage 96 (collect at utils.scala:211)
18/02/28 14:20:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 95)
18/02/28 14:20:29 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:29 INFO DAGScheduler: Submitting ResultStage 96 (MapPartitionsRDD[176] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:29 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 10.3 KB, free 344.9 MB)
18/02/28 14:20:29 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.9 MB)
18/02/28 14:20:29 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 127.0.0.1:61560 (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:20:29 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:29 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 96 (MapPartitionsRDD[176] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:29 INFO TaskSchedulerImpl: Adding task set 96.0 with 4 tasks
18/02/28 14:20:29 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 227, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 1.0 in stage 96.0 (TID 228, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 2.0 in stage 96.0 (TID 229, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 3.0 in stage 96.0 (TID 230, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:20:29 INFO Executor: Running task 1.0 in stage 96.0 (TID 228)
18/02/28 14:20:29 INFO Executor: Running task 2.0 in stage 96.0 (TID 229)
18/02/28 14:20:29 INFO Executor: Running task 3.0 in stage 96.0 (TID 230)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:20:29 INFO Executor: Finished task 1.0 in stage 96.0 (TID 228). 1646 bytes result sent to driver
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:20:29 INFO Executor: Finished task 3.0 in stage 96.0 (TID 230). 1555 bytes result sent to driver
18/02/28 14:20:29 INFO TaskSetManager: Finished task 1.0 in stage 96.0 (TID 228) in 4 ms on localhost (executor driver) (1/4)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:20:29 INFO TaskSetManager: Finished task 3.0 in stage 96.0 (TID 230) in 4 ms on localhost (executor driver) (2/4)
18/02/28 14:20:29 INFO Executor: Finished task 2.0 in stage 96.0 (TID 229). 1628 bytes result sent to driver
18/02/28 14:20:29 INFO Executor: Running task 0.0 in stage 96.0 (TID 227)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 2.0 in stage 96.0 (TID 229) in 5 ms on localhost (executor driver) (3/4)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:20:29 INFO Executor: Finished task 0.0 in stage 96.0 (TID 227). 1501 bytes result sent to driver
18/02/28 14:20:29 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 227) in 7 ms on localhost (executor driver) (4/4)
18/02/28 14:20:29 INFO DAGScheduler: ResultStage 96 (collect at utils.scala:211) finished in 0.007 s
18/02/28 14:20:29 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool 
18/02/28 14:20:29 INFO DAGScheduler: Job 49 finished: collect at utils.scala:211, took 0.012574 s
18/02/28 14:20:29 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:20:29 INFO DAGScheduler: Got job 50 (collect at utils.scala:211) with 6 output partitions
18/02/28 14:20:29 INFO DAGScheduler: Final stage: ResultStage 99 (collect at utils.scala:211)
18/02/28 14:20:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 98)
18/02/28 14:20:29 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:29 INFO DAGScheduler: Submitting ResultStage 99 (MapPartitionsRDD[179] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:29 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 11.2 KB, free 344.8 MB)
18/02/28 14:20:29 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 5.3 KB, free 344.8 MB)
18/02/28 14:20:29 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 127.0.0.1:61560 (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:20:29 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:29 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 99 (MapPartitionsRDD[179] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
18/02/28 14:20:29 INFO TaskSchedulerImpl: Adding task set 99.0 with 6 tasks
18/02/28 14:20:29 INFO TaskSetManager: Starting task 1.0 in stage 99.0 (TID 231, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 2.0 in stage 99.0 (TID 232, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 3.0 in stage 99.0 (TID 233, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 4.0 in stage 99.0 (TID 234, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:20:29 INFO Executor: Running task 1.0 in stage 99.0 (TID 231)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:20:29 INFO Executor: Finished task 1.0 in stage 99.0 (TID 231). 1384 bytes result sent to driver
18/02/28 14:20:29 INFO Executor: Running task 2.0 in stage 99.0 (TID 232)
18/02/28 14:20:29 INFO Executor: Running task 3.0 in stage 99.0 (TID 233)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:20:29 INFO Executor: Running task 4.0 in stage 99.0 (TID 234)
18/02/28 14:20:29 INFO Executor: Finished task 2.0 in stage 99.0 (TID 232). 1442 bytes result sent to driver
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:20:29 INFO Executor: Finished task 4.0 in stage 99.0 (TID 234). 1504 bytes result sent to driver
18/02/28 14:20:29 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 235, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:20:29 INFO TaskSetManager: Starting task 5.0 in stage 99.0 (TID 236, localhost, executor driver, partition 5, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:20:29 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:20:29 INFO TaskSetManager: Finished task 1.0 in stage 99.0 (TID 231) in 9 ms on localhost (executor driver) (1/6)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 2.0 in stage 99.0 (TID 232) in 12 ms on localhost (executor driver) (2/6)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 4.0 in stage 99.0 (TID 234) in 13 ms on localhost (executor driver) (3/6)
18/02/28 14:20:29 INFO Executor: Finished task 3.0 in stage 99.0 (TID 233). 1642 bytes result sent to driver
18/02/28 14:20:29 INFO Executor: Running task 0.0 in stage 99.0 (TID 235)
18/02/28 14:20:29 INFO Executor: Finished task 0.0 in stage 99.0 (TID 235). 999 bytes result sent to driver
18/02/28 14:20:29 INFO Executor: Running task 5.0 in stage 99.0 (TID 236)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 3.0 in stage 99.0 (TID 233) in 17 ms on localhost (executor driver) (4/6)
18/02/28 14:20:29 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 235) in 9 ms on localhost (executor driver) (5/6)
18/02/28 14:20:29 INFO Executor: Finished task 5.0 in stage 99.0 (TID 236). 1050 bytes result sent to driver
18/02/28 14:20:29 INFO TaskSetManager: Finished task 5.0 in stage 99.0 (TID 236) in 10 ms on localhost (executor driver) (6/6)
18/02/28 14:20:29 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool 
18/02/28 14:20:29 INFO DAGScheduler: ResultStage 99 (collect at utils.scala:211) finished in 0.018 s
18/02/28 14:20:29 INFO DAGScheduler: Job 50 finished: collect at utils.scala:211, took 0.024104 s
18/02/28 14:20:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 14:20:30 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2ef858316c94
18/02/28 14:20:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ef858316c94` AS `zzz14`
WHERE (0 = 1)
18/02/28 14:20:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ef858316c94`
18/02/28 14:20:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ef86a7557ba`
18/02/28 14:20:30 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2ef832b57baf
18/02/28 14:20:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ef832b57baf` AS `zzz15`
WHERE (0 = 1)
18/02/28 14:20:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ef832b57baf`
18/02/28 14:20:30 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2ef8820d84
18/02/28 14:20:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ef8820d84` AS `zzz16`
WHERE (0 = 1)
18/02/28 14:20:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:30 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `dephour`, `prediction`, `probability`
FROM `sparklyr_tmp_2ef8820d84`
LIMIT 5
18/02/28 14:20:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:30 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `dephour`, `prediction`, `probability`
FROM `sparklyr_tmp_2ef8820d84`
LIMIT 5
18/02/28 14:20:30 INFO CodeGenerator: Code generated in 41.430369 ms
18/02/28 14:20:30 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:20:30 INFO DAGScheduler: Got job 51 (collect at utils.scala:211) with 1 output partitions
18/02/28 14:20:30 INFO DAGScheduler: Final stage: ResultStage 100 (collect at utils.scala:211)
18/02/28 14:20:30 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:20:30 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:30 INFO DAGScheduler: Submitting ResultStage 100 (MapPartitionsRDD[182] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:30 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 80.8 KB, free 344.8 MB)
18/02/28 14:20:30 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 29.8 KB, free 344.7 MB)
18/02/28 14:20:30 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 127.0.0.1:61560 (size: 29.8 KB, free: 345.5 MB)
18/02/28 14:20:30 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 100 (MapPartitionsRDD[182] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 14:20:30 INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks
18/02/28 14:20:30 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 237, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:20:30 INFO Executor: Running task 0.0 in stage 100.0 (TID 237)
18/02/28 14:20:30 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 14:20:31 INFO Executor: Finished task 0.0 in stage 100.0 (TID 237). 1948 bytes result sent to driver
18/02/28 14:20:31 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 237) in 380 ms on localhost (executor driver) (1/1)
18/02/28 14:20:31 INFO DAGScheduler: ResultStage 100 (collect at utils.scala:211) finished in 0.380 s
18/02/28 14:20:31 INFO DAGScheduler: Job 51 finished: collect at utils.scala:211, took 0.385845 s
18/02/28 14:20:31 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool 
18/02/28 14:20:31 INFO CodeGenerator: Code generated in 7.058685 ms
18/02/28 14:20:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:31 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_2ef8820d84`
GROUP BY `delayed`, `prediction`
18/02/28 14:20:31 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:20:31 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:20:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:20:31 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_2ef8820d84`
GROUP BY `delayed`, `prediction`
LIMIT 10
18/02/28 14:20:31 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:20:31 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:20:31 INFO CodeGenerator: Code generated in 15.309568 ms
18/02/28 14:20:31 INFO CodeGenerator: Code generated in 47.337408 ms
18/02/28 14:20:31 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:20:31 INFO DAGScheduler: Registering RDD 185 (collect at utils.scala:211)
18/02/28 14:20:31 INFO DAGScheduler: Got job 52 (collect at utils.scala:211) with 1 output partitions
18/02/28 14:20:31 INFO DAGScheduler: Final stage: ResultStage 102 (collect at utils.scala:211)
18/02/28 14:20:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 101)
18/02/28 14:20:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 101)
18/02/28 14:20:31 INFO DAGScheduler: Submitting ShuffleMapStage 101 (MapPartitionsRDD[185] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:31 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 79.1 KB, free 344.7 MB)
18/02/28 14:20:31 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 32.2 KB, free 344.6 MB)
18/02/28 14:20:31 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 127.0.0.1:61560 (size: 32.2 KB, free: 345.4 MB)
18/02/28 14:20:31 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:31 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 101 (MapPartitionsRDD[185] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:20:31 INFO TaskSchedulerImpl: Adding task set 101.0 with 4 tasks
18/02/28 14:20:31 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 238, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:31 INFO TaskSetManager: Starting task 1.0 in stage 101.0 (TID 239, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:31 INFO TaskSetManager: Starting task 2.0 in stage 101.0 (TID 240, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:20:31 INFO TaskSetManager: Starting task 3.0 in stage 101.0 (TID 241, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:20:31 INFO Executor: Running task 0.0 in stage 101.0 (TID 238)
18/02/28 14:20:31 INFO Executor: Running task 1.0 in stage 101.0 (TID 239)
18/02/28 14:20:31 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 14:20:31 INFO Executor: Running task 3.0 in stage 101.0 (TID 241)
18/02/28 14:20:31 INFO BlockManager: Found block rdd_13_1 locally
18/02/28 14:20:31 INFO Executor: Running task 2.0 in stage 101.0 (TID 240)
18/02/28 14:20:31 INFO BlockManager: Found block rdd_13_3 locally
18/02/28 14:20:31 INFO BlockManager: Found block rdd_13_2 locally
18/02/28 14:20:31 INFO CodeGenerator: Code generated in 11.200523 ms
18/02/28 14:20:31 INFO CodeGenerator: Code generated in 13.803894 ms
18/02/28 14:20:31 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 127.0.0.1:61560 in memory (size: 29.8 KB, free: 345.5 MB)
18/02/28 14:20:31 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 127.0.0.1:61560 in memory (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:20:31 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 127.0.0.1:61560 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:20:31 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 127.0.0.1:61560 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:20:31 INFO ContextCleaner: Cleaned accumulator 1721
18/02/28 14:20:31 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 127.0.0.1:61560 in memory (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:20:31 INFO CodeGenerator: Code generated in 23.552693 ms
18/02/28 14:20:32 INFO Executor: Finished task 1.0 in stage 101.0 (TID 239). 2411 bytes result sent to driver
18/02/28 14:20:32 INFO TaskSetManager: Finished task 1.0 in stage 101.0 (TID 239) in 1019 ms on localhost (executor driver) (1/4)
18/02/28 14:20:32 INFO Executor: Finished task 3.0 in stage 101.0 (TID 241). 2411 bytes result sent to driver
18/02/28 14:20:32 INFO TaskSetManager: Finished task 3.0 in stage 101.0 (TID 241) in 1031 ms on localhost (executor driver) (2/4)
18/02/28 14:20:32 INFO Executor: Finished task 2.0 in stage 101.0 (TID 240). 2411 bytes result sent to driver
18/02/28 14:20:32 INFO TaskSetManager: Finished task 2.0 in stage 101.0 (TID 240) in 1033 ms on localhost (executor driver) (3/4)
18/02/28 14:20:32 INFO Executor: Finished task 0.0 in stage 101.0 (TID 238). 2411 bytes result sent to driver
18/02/28 14:20:32 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 238) in 1036 ms on localhost (executor driver) (4/4)
18/02/28 14:20:32 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool 
18/02/28 14:20:32 INFO DAGScheduler: ShuffleMapStage 101 (collect at utils.scala:211) finished in 1.036 s
18/02/28 14:20:32 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:20:32 INFO DAGScheduler: running: Set()
18/02/28 14:20:32 INFO DAGScheduler: waiting: Set(ResultStage 102)
18/02/28 14:20:32 INFO DAGScheduler: failed: Set()
18/02/28 14:20:32 INFO DAGScheduler: Submitting ResultStage 102 (MapPartitionsRDD[188] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:32 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 38.1 KB, free 344.8 MB)
18/02/28 14:20:32 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 17.9 KB, free 344.7 MB)
18/02/28 14:20:32 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 127.0.0.1:61560 (size: 17.9 KB, free: 345.5 MB)
18/02/28 14:20:32 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 102 (MapPartitionsRDD[188] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 14:20:32 INFO TaskSchedulerImpl: Adding task set 102.0 with 1 tasks
18/02/28 14:20:32 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 242, localhost, executor driver, partition 0, PROCESS_LOCAL, 4726 bytes)
18/02/28 14:20:32 INFO Executor: Running task 0.0 in stage 102.0 (TID 242)
18/02/28 14:20:32 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 14:20:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:20:32 INFO Executor: Finished task 0.0 in stage 102.0 (TID 242). 2577 bytes result sent to driver
18/02/28 14:20:32 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 242) in 7 ms on localhost (executor driver) (1/1)
18/02/28 14:20:32 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool 
18/02/28 14:20:32 INFO DAGScheduler: ResultStage 102 (collect at utils.scala:211) finished in 0.008 s
18/02/28 14:20:32 INFO DAGScheduler: Job 52 finished: collect at utils.scala:211, took 1.056463 s
18/02/28 14:20:32 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:20:32 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 162 bytes
18/02/28 14:20:32 INFO DAGScheduler: Got job 53 (collect at utils.scala:211) with 3 output partitions
18/02/28 14:20:32 INFO DAGScheduler: Final stage: ResultStage 104 (collect at utils.scala:211)
18/02/28 14:20:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 103)
18/02/28 14:20:32 INFO DAGScheduler: Missing parents: List()
18/02/28 14:20:32 INFO DAGScheduler: Submitting ResultStage 104 (MapPartitionsRDD[188] at collect at utils.scala:211), which has no missing parents
18/02/28 14:20:32 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 38.1 KB, free 344.7 MB)
18/02/28 14:20:32 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 17.9 KB, free 344.7 MB)
18/02/28 14:20:32 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 127.0.0.1:61560 (size: 17.9 KB, free: 345.5 MB)
18/02/28 14:20:32 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1006
18/02/28 14:20:32 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 104 (MapPartitionsRDD[188] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(1, 2, 3))
18/02/28 14:20:32 INFO TaskSchedulerImpl: Adding task set 104.0 with 3 tasks
18/02/28 14:20:32 INFO TaskSetManager: Starting task 2.0 in stage 104.0 (TID 243, localhost, executor driver, partition 3, PROCESS_LOCAL, 4726 bytes)
18/02/28 14:20:32 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 244, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 14:20:32 INFO TaskSetManager: Starting task 1.0 in stage 104.0 (TID 245, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 14:20:32 INFO Executor: Running task 2.0 in stage 104.0 (TID 243)
18/02/28 14:20:32 INFO Executor: Running task 0.0 in stage 104.0 (TID 244)
18/02/28 14:20:32 INFO Executor: Running task 1.0 in stage 104.0 (TID 245)
18/02/28 14:20:32 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:20:32 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:20:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:20:32 INFO Executor: Finished task 0.0 in stage 104.0 (TID 244). 2597 bytes result sent to driver
18/02/28 14:20:32 INFO Executor: Finished task 1.0 in stage 104.0 (TID 245). 2623 bytes result sent to driver
18/02/28 14:20:32 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 244) in 11 ms on localhost (executor driver) (1/3)
18/02/28 14:20:32 INFO TaskSetManager: Finished task 1.0 in stage 104.0 (TID 245) in 12 ms on localhost (executor driver) (2/3)
18/02/28 14:20:32 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 14:20:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:20:32 INFO Executor: Finished task 2.0 in stage 104.0 (TID 243). 2620 bytes result sent to driver
18/02/28 14:20:32 INFO TaskSetManager: Finished task 2.0 in stage 104.0 (TID 243) in 15 ms on localhost (executor driver) (3/3)
18/02/28 14:20:32 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool 
18/02/28 14:20:32 INFO DAGScheduler: ResultStage 104 (collect at utils.scala:211) finished in 0.015 s
18/02/28 14:20:32 INFO DAGScheduler: Job 53 finished: collect at utils.scala:211, took 0.022241 s
18/02/28 14:20:32 INFO CodeGenerator: Code generated in 5.438058 ms
18/02/28 14:20:33 INFO SparkContext: Invoking stop() from shutdown hook
18/02/28 14:20:33 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
18/02/28 14:20:33 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/02/28 14:20:33 INFO MemoryStore: MemoryStore cleared
18/02/28 14:20:33 INFO BlockManager: BlockManager stopped
18/02/28 14:20:33 INFO BlockManagerMaster: BlockManagerMaster stopped
18/02/28 14:20:33 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/02/28 14:20:33 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-72c5f5e9-5b4e-4e8c-81bb-4b2be2cb0998\userFiles-f0c036d9-cd96-4d92-a179-b70bc14fa387
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-72c5f5e9-5b4e-4e8c-81bb-4b2be2cb0998\userFiles-f0c036d9-cd96-4d92-a179-b70bc14fa387
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1937)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1936)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 14:20:33 INFO SparkContext: Successfully stopped SparkContext
18/02/28 14:20:33 INFO ShutdownHookManager: Shutdown hook called
18/02/28 14:20:33 INFO ShutdownHookManager: Deleting directory C:\Users\JC\AppData\Local\Temp\spark-72c5f5e9-5b4e-4e8c-81bb-4b2be2cb0998\userFiles-f0c036d9-cd96-4d92-a179-b70bc14fa387
18/02/28 14:20:33 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-72c5f5e9-5b4e-4e8c-81bb-4b2be2cb0998\userFiles-f0c036d9-cd96-4d92-a179-b70bc14fa387
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-72c5f5e9-5b4e-4e8c-81bb-4b2be2cb0998\userFiles-f0c036d9-cd96-4d92-a179-b70bc14fa387
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 14:20:33 INFO ShutdownHookManager: Deleting directory C:\Users\JC\AppData\Local\Temp\spark-72c5f5e9-5b4e-4e8c-81bb-4b2be2cb0998
18/02/28 14:20:33 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-72c5f5e9-5b4e-4e8c-81bb-4b2be2cb0998
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-72c5f5e9-5b4e-4e8c-81bb-4b2be2cb0998
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 14:22:13 INFO SparkContext: Running Spark version 2.2.0
18/02/28 14:22:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/02/28 14:22:13 INFO SparkContext: Submitted application: sparklyr
18/02/28 14:22:13 INFO SecurityManager: Changing view acls to: JC
18/02/28 14:22:13 INFO SecurityManager: Changing modify acls to: JC
18/02/28 14:22:13 INFO SecurityManager: Changing view acls groups to: 
18/02/28 14:22:13 INFO SecurityManager: Changing modify acls groups to: 
18/02/28 14:22:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(JC); groups with view permissions: Set(); users  with modify permissions: Set(JC); groups with modify permissions: Set()
18/02/28 14:22:13 INFO Utils: Successfully started service 'sparkDriver' on port 61651.
18/02/28 14:22:13 INFO SparkEnv: Registering MapOutputTracker
18/02/28 14:22:13 INFO SparkEnv: Registering BlockManagerMaster
18/02/28 14:22:13 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/02/28 14:22:13 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/02/28 14:22:13 INFO DiskBlockManager: Created local directory at C:\Users\JC\AppData\Local\Temp\blockmgr-7c220bad-3673-4227-8c74-f0aa7995c7b9
18/02/28 14:22:13 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/02/28 14:22:13 INFO SparkEnv: Registering OutputCommitCoordinator
18/02/28 14:22:13 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
18/02/28 14:22:13 INFO Utils: Successfully started service 'SparkUI' on port 4041.
18/02/28 14:22:14 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
18/02/28 14:22:14 INFO SparkContext: Added JAR file:/C:/Users/JC/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:61651/jars/sparklyr-2.2-2.11.jar with timestamp 1519856534060
18/02/28 14:22:14 INFO Executor: Starting executor ID driver on host localhost
18/02/28 14:22:14 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61672.
18/02/28 14:22:14 INFO NettyBlockTransferService: Server created on 127.0.0.1:61672
18/02/28 14:22:14 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/02/28 14:22:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 61672, None)
18/02/28 14:22:14 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:61672 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 61672, None)
18/02/28 14:22:14 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 61672, None)
18/02/28 14:22:14 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 61672, None)
18/02/28 14:22:14 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/02/28 14:22:14 INFO SharedState: loading hive config file: file:/C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
18/02/28 14:22:14 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:\Users\JC\AppData\Local\spark\spark-2.2.0-bin-hadoop2.7\tmp\hive') to the value of spark.sql.warehouse.dir ('C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive').
18/02/28 14:22:14 INFO SharedState: Warehouse path is 'C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive'.
18/02/28 14:22:15 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
18/02/28 14:22:16 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
18/02/28 14:22:16 INFO ObjectStore: ObjectStore, initialize called
18/02/28 14:22:16 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
18/02/28 14:22:16 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
18/02/28 14:22:17 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
18/02/28 14:22:18 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 14:22:18 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 14:22:18 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 14:22:18 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 14:22:19 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
18/02/28 14:22:19 INFO ObjectStore: Initialized ObjectStore
18/02/28 14:22:19 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
18/02/28 14:22:19 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
18/02/28 14:22:19 INFO HiveMetaStore: Added admin role in metastore
18/02/28 14:22:19 INFO HiveMetaStore: Added public role in metastore
18/02/28 14:22:19 INFO HiveMetaStore: No user is added in admin role, since config is empty
18/02/28 14:22:19 INFO HiveMetaStore: 0: get_all_databases
18/02/28 14:22:19 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_all_databases	
18/02/28 14:22:19 INFO HiveMetaStore: 0: get_functions: db=default pat=*
18/02/28 14:22:19 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
18/02/28 14:22:19 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 14:22:19 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/Temp/c44ecdcc-345f-4523-839e-361f292c5b10_resources
18/02/28 14:22:19 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/c44ecdcc-345f-4523-839e-361f292c5b10
18/02/28 14:22:19 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/c44ecdcc-345f-4523-839e-361f292c5b10
18/02/28 14:22:20 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/c44ecdcc-345f-4523-839e-361f292c5b10/_tmp_space.db
18/02/28 14:22:20 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive
18/02/28 14:22:20 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:22:20 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:22:20 INFO HiveMetaStore: 0: get_database: global_temp
18/02/28 14:22:20 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: global_temp	
18/02/28 14:22:20 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
18/02/28 14:22:20 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/Temp/648b26dc-a536-48d8-bba2-20479f4effd2_resources
18/02/28 14:22:20 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/648b26dc-a536-48d8-bba2-20479f4effd2
18/02/28 14:22:20 INFO SessionState: Created local directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/648b26dc-a536-48d8-bba2-20479f4effd2
18/02/28 14:22:20 INFO SessionState: Created HDFS directory: C:/Users/JC/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/JC/648b26dc-a536-48d8-bba2-20479f4effd2/_tmp_space.db
18/02/28 14:22:20 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersJCAppDataLocalsparkspark-2.2.0-bin-hadoop2.7	mphive
18/02/28 14:22:20 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
18/02/28 14:22:20 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 14:22:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:22:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:22:22 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:22:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:22:22 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 14:22:22 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 14:22:22 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 14:22:22 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
18/02/28 14:22:22 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
18/02/28 14:22:22 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:22:22 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:22 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55), which has no missing parents
18/02/28 14:22:22 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
18/02/28 14:22:22 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
18/02/28 14:22:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:61672 (size: 3.4 KB, free: 366.3 MB)
18/02/28 14:22:22 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0))
18/02/28 14:22:22 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/02/28 14:22:22 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 14:22:22 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/02/28 14:22:22 INFO Executor: Fetching spark://127.0.0.1:61651/jars/sparklyr-2.2-2.11.jar with timestamp 1519856534060
18/02/28 14:22:22 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:61651 after 23 ms (0 ms spent in bootstraps)
18/02/28 14:22:22 INFO Utils: Fetching spark://127.0.0.1:61651/jars/sparklyr-2.2-2.11.jar to C:\Users\JC\AppData\Local\Temp\spark-ec3dec23-94c5-4beb-b0a8-5b2dc3585e69\userFiles-bda16843-ebae-4037-9234-d62dbdb49156\fetchFileTemp1900428319373915948.tmp
18/02/28 14:22:22 INFO Executor: Adding file:/C:/Users/JC/AppData/Local/Temp/spark-ec3dec23-94c5-4beb-b0a8-5b2dc3585e69/userFiles-bda16843-ebae-4037-9234-d62dbdb49156/sparklyr-2.2-2.11.jar to class loader
18/02/28 14:22:23 INFO CodeGenerator: Code generated in 225.518603 ms
18/02/28 14:22:23 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
18/02/28 14:22:23 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 735 ms on localhost (executor driver) (1/1)
18/02/28 14:22:23 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/02/28 14:22:23 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.754 s
18/02/28 14:22:23 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.902881 s
18/02/28 14:22:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:23 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 14:22:23 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:22:23 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:22:23 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:22:23 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:22:23 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 14:22:23 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 14:22:23 INFO SparkSqlParser: Parsing command: spark_flights
18/02/28 14:22:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_flights` AS `zzz1`
WHERE (0 = 1)
18/02/28 14:22:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_flights`
18/02/28 14:22:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:23 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_flights`
18/02/28 14:22:23 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:22:23 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:22:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:23 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `spark_flights`
LIMIT 10
18/02/28 14:22:23 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:22:23 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:22:24 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 14:22:24 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 14:22:24 INFO FileSourceStrategy: Output Data Schema: struct<>
18/02/28 14:22:24 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 14:22:24 INFO CodeGenerator: Code generated in 20.577664 ms
18/02/28 14:22:24 INFO CodeGenerator: Code generated in 12.755211 ms
18/02/28 14:22:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 282.5 KB, free 366.0 MB)
18/02/28 14:22:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 24.1 KB, free 366.0 MB)
18/02/28 14:22:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:61672 (size: 24.1 KB, free: 366.3 MB)
18/02/28 14:22:24 INFO SparkContext: Created broadcast 1 from collect at utils.scala:211
18/02/28 14:22:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21019222 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 14:22:24 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:22:24 INFO DAGScheduler: Registering RDD 7 (collect at utils.scala:211)
18/02/28 14:22:24 INFO DAGScheduler: Got job 1 (collect at utils.scala:211) with 1 output partitions
18/02/28 14:22:24 INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:211)
18/02/28 14:22:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
18/02/28 14:22:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
18/02/28 14:22:24 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:24 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:61672 in memory (size: 3.4 KB, free: 366.3 MB)
18/02/28 14:22:24 INFO ContextCleaner: Cleaned accumulator 0
18/02/28 14:22:24 INFO ContextCleaner: Cleaned accumulator 49
18/02/28 14:22:24 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 14.2 KB, free 366.0 MB)
18/02/28 14:22:24 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 8.0 KB, free 366.0 MB)
18/02/28 14:22:24 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:61672 (size: 8.0 KB, free: 366.3 MB)
18/02/28 14:22:24 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:24 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks
18/02/28 14:22:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:24 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:24 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:22:24 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:24 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
18/02/28 14:22:24 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
18/02/28 14:22:24 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
18/02/28 14:22:24 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
18/02/28 14:22:24 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_11.csv, range: 0-2757037, partition values: [empty row]
18/02/28 14:22:24 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_4.csv, range: 0-2830543, partition values: [empty row]
18/02/28 14:22:24 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_3.csv, range: 0-2881793, partition values: [empty row]
18/02/28 14:22:24 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_7.csv, range: 0-2938867, partition values: [empty row]
18/02/28 14:22:24 INFO CodeGenerator: Code generated in 5.035016 ms
18/02/28 14:22:24 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_1.csv, range: 0-2697256, partition values: [empty row]
18/02/28 14:22:24 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_8.csv, range: 0-2932019, partition values: [empty row]
18/02/28 14:22:24 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_5.csv, range: 0-2880181, partition values: [empty row]
18/02/28 14:22:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_6.csv, range: 0-2820227, partition values: [empty row]
18/02/28 14:22:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_10.csv, range: 0-2920629, partition values: [empty row]
18/02/28 14:22:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_12.csv, range: 0-2836468, partition values: [empty row]
18/02/28 14:22:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_9.csv, range: 0-2763076, partition values: [empty row]
18/02/28 14:22:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_2.csv, range: 0-2487144, partition values: [empty row]
18/02/28 14:22:25 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 1628 bytes result sent to driver
18/02/28 14:22:25 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1585 bytes result sent to driver
18/02/28 14:22:25 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1628 bytes result sent to driver
18/02/28 14:22:25 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1628 bytes result sent to driver
18/02/28 14:22:25 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 739 ms on localhost (executor driver) (1/4)
18/02/28 14:22:25 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 738 ms on localhost (executor driver) (2/4)
18/02/28 14:22:25 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 739 ms on localhost (executor driver) (3/4)
18/02/28 14:22:25 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 743 ms on localhost (executor driver) (4/4)
18/02/28 14:22:25 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/02/28 14:22:25 INFO DAGScheduler: ShuffleMapStage 1 (collect at utils.scala:211) finished in 0.745 s
18/02/28 14:22:25 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:22:25 INFO DAGScheduler: running: Set()
18/02/28 14:22:25 INFO DAGScheduler: waiting: Set(ResultStage 2)
18/02/28 14:22:25 INFO DAGScheduler: failed: Set()
18/02/28 14:22:25 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[10] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:25 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.9 KB, free 366.0 MB)
18/02/28 14:22:25 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.0 MB)
18/02/28 14:22:25 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:61672 (size: 3.7 KB, free: 366.3 MB)
18/02/28 14:22:25 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 14:22:25 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
18/02/28 14:22:25 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 14:22:25 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
18/02/28 14:22:25 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
18/02/28 14:22:25 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1514 bytes result sent to driver
18/02/28 14:22:25 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 41 ms on localhost (executor driver) (1/1)
18/02/28 14:22:25 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/02/28 14:22:25 INFO DAGScheduler: ResultStage 2 (collect at utils.scala:211) finished in 0.043 s
18/02/28 14:22:25 INFO DAGScheduler: Job 1 finished: collect at utils.scala:211, took 0.856103 s
18/02/28 14:22:25 INFO CodeGenerator: Code generated in 7.747698 ms
18/02/28 14:22:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:25 INFO SparkSqlParser: Parsing command: SELECT `month`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`, `sched_dep_time`, `sched_arr_time`
FROM (SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`dep_time` AS DOUBLE) AS `dep_time`, CAST(`arr_time` AS DOUBLE) AS `arr_time`, CAST(`arr_delay` AS DOUBLE) AS `arr_delay`, CAST(`dep_delay` AS DOUBLE) AS `dep_delay`, CAST(`distance` AS DOUBLE) AS `distance`, CAST(`sched_dep_time` AS DOUBLE) AS `sched_dep_time`, CAST(`sched_arr_time` AS DOUBLE) AS `sched_arr_time`
FROM (SELECT `month`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`, `sched_dep_time`, `sched_arr_time`
FROM `spark_flights`) `fjfuvvynds`) `uhzohjwlyb`
18/02/28 14:22:25 INFO SparkSqlParser: Parsing command: cached_flights
18/02/28 14:22:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights` AS `zzz2`
WHERE (0 = 1)
18/02/28 14:22:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:25 INFO SparkSqlParser: Parsing command: CACHE TABLE `cached_flights`
18/02/28 14:22:25 INFO SparkSqlParser: Parsing command: `cached_flights`
18/02/28 14:22:25 INFO FileSourceStrategy: Pruning directories with: 
18/02/28 14:22:25 INFO FileSourceStrategy: Post-Scan Filters: 
18/02/28 14:22:25 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dep_time: string, sched_dep_time: string, dep_delay: string, arr_time: string ... 6 more fields>
18/02/28 14:22:25 INFO FileSourceScanExec: Pushed Filters: 
18/02/28 14:22:25 INFO CodeGenerator: Code generated in 21.817466 ms
18/02/28 14:22:25 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 282.5 KB, free 365.7 MB)
18/02/28 14:22:25 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.7 MB)
18/02/28 14:22:25 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:61672 (size: 24.1 KB, free: 366.2 MB)
18/02/28 14:22:25 INFO SparkContext: Created broadcast 4 from sql at <unknown>:0
18/02/28 14:22:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21019222 bytes, open cost is considered as scanning 4194304 bytes.
18/02/28 14:22:25 INFO CodeGenerator: Code generated in 10.352832 ms
18/02/28 14:22:25 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 14:22:25 INFO DAGScheduler: Registering RDD 16 (sql at <unknown>:0)
18/02/28 14:22:25 INFO DAGScheduler: Got job 2 (sql at <unknown>:0) with 1 output partitions
18/02/28 14:22:25 INFO DAGScheduler: Final stage: ResultStage 4 (sql at <unknown>:0)
18/02/28 14:22:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
18/02/28 14:22:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
18/02/28 14:22:25 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[16] at sql at <unknown>:0), which has no missing parents
18/02/28 14:22:25 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 26.7 KB, free 365.6 MB)
18/02/28 14:22:25 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 11.7 KB, free 365.6 MB)
18/02/28 14:22:25 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:61672 (size: 11.7 KB, free: 366.2 MB)
18/02/28 14:22:25 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:25 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[16] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:25 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks
18/02/28 14:22:25 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:25 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:25 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 8, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:22:25 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 9, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:25 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)
18/02/28 14:22:25 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)
18/02/28 14:22:25 INFO Executor: Running task 2.0 in stage 3.0 (TID 8)
18/02/28 14:22:25 INFO Executor: Running task 3.0 in stage 3.0 (TID 9)
18/02/28 14:22:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_3.csv, range: 0-2881793, partition values: [empty row]
18/02/28 14:22:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_11.csv, range: 0-2757037, partition values: [empty row]
18/02/28 14:22:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_4.csv, range: 0-2830543, partition values: [empty row]
18/02/28 14:22:25 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_7.csv, range: 0-2938867, partition values: [empty row]
18/02/28 14:22:25 INFO CodeGenerator: Code generated in 13.58774 ms
18/02/28 14:22:26 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:61672 in memory (size: 3.7 KB, free: 366.2 MB)
18/02/28 14:22:26 INFO ContextCleaner: Cleaned accumulator 119
18/02/28 14:22:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_5.csv, range: 0-2880181, partition values: [empty row]
18/02/28 14:22:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_6.csv, range: 0-2820227, partition values: [empty row]
18/02/28 14:22:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_1.csv, range: 0-2697256, partition values: [empty row]
18/02/28 14:22:26 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_8.csv, range: 0-2932019, partition values: [empty row]
18/02/28 14:22:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_12.csv, range: 0-2836468, partition values: [empty row]
18/02/28 14:22:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_2.csv, range: 0-2487144, partition values: [empty row]
18/02/28 14:22:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_9.csv, range: 0-2763076, partition values: [empty row]
18/02/28 14:22:27 INFO FileScanRDD: Reading File path: file:///C:/Users/JC/Documents/GitHub/SFGBigData/data/flights/flights_2013_10.csv, range: 0-2920629, partition values: [empty row]
18/02/28 14:22:27 INFO MemoryStore: Block rdd_13_1 stored as values in memory (estimated size 5.2 MB, free 360.4 MB)
18/02/28 14:22:27 INFO BlockManagerInfo: Added rdd_13_1 in memory on 127.0.0.1:61672 (size: 5.2 MB, free: 361.0 MB)
18/02/28 14:22:27 INFO MemoryStore: Block rdd_13_3 stored as values in memory (estimated size 4.8 MB, free 355.6 MB)
18/02/28 14:22:27 INFO BlockManagerInfo: Added rdd_13_3 in memory on 127.0.0.1:61672 (size: 4.8 MB, free: 356.2 MB)
18/02/28 14:22:27 INFO CodeGenerator: Code generated in 5.537848 ms
18/02/28 14:22:27 INFO MemoryStore: Block rdd_13_2 stored as values in memory (estimated size 5.1 MB, free 350.5 MB)
18/02/28 14:22:27 INFO BlockManagerInfo: Added rdd_13_2 in memory on 127.0.0.1:61672 (size: 5.1 MB, free: 351.1 MB)
18/02/28 14:22:27 INFO MemoryStore: Block rdd_13_0 stored as values in memory (estimated size 5.3 MB, free 345.2 MB)
18/02/28 14:22:27 INFO BlockManagerInfo: Added rdd_13_0 in memory on 127.0.0.1:61672 (size: 5.3 MB, free: 345.8 MB)
18/02/28 14:22:27 INFO CodeGenerator: Code generated in 28.852877 ms
18/02/28 14:22:27 INFO Executor: Finished task 2.0 in stage 3.0 (TID 8). 2504 bytes result sent to driver
18/02/28 14:22:27 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 8) in 1853 ms on localhost (executor driver) (1/4)
18/02/28 14:22:27 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 2461 bytes result sent to driver
18/02/28 14:22:27 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 1860 ms on localhost (executor driver) (2/4)
18/02/28 14:22:27 INFO Executor: Finished task 3.0 in stage 3.0 (TID 9). 2461 bytes result sent to driver
18/02/28 14:22:27 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 9) in 1869 ms on localhost (executor driver) (3/4)
18/02/28 14:22:27 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 2547 bytes result sent to driver
18/02/28 14:22:27 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 1881 ms on localhost (executor driver) (4/4)
18/02/28 14:22:27 INFO DAGScheduler: ShuffleMapStage 3 (sql at <unknown>:0) finished in 1.883 s
18/02/28 14:22:27 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:22:27 INFO DAGScheduler: running: Set()
18/02/28 14:22:27 INFO DAGScheduler: waiting: Set(ResultStage 4)
18/02/28 14:22:27 INFO DAGScheduler: failed: Set()
18/02/28 14:22:27 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[19] at sql at <unknown>:0), which has no missing parents
18/02/28 14:22:27 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.0 KB, free 345.2 MB)
18/02/28 14:22:27 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.7 KB, free 345.2 MB)
18/02/28 14:22:27 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/02/28 14:22:27 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:61672 (size: 3.7 KB, free: 345.8 MB)
18/02/28 14:22:27 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 14:22:27 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
18/02/28 14:22:27 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 10, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 14:22:27 INFO Executor: Running task 0.0 in stage 4.0 (TID 10)
18/02/28 14:22:27 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 14:22:27 INFO Executor: Finished task 0.0 in stage 4.0 (TID 10). 1538 bytes result sent to driver
18/02/28 14:22:27 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 10) in 7 ms on localhost (executor driver) (1/1)
18/02/28 14:22:27 INFO DAGScheduler: ResultStage 4 (sql at <unknown>:0) finished in 0.009 s
18/02/28 14:22:27 INFO DAGScheduler: Job 2 finished: sql at <unknown>:0, took 1.921207 s
18/02/28 14:22:27 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/02/28 14:22:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:27 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `cached_flights`
18/02/28 14:22:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:22:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:22:27 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:22:27 INFO DAGScheduler: Registering RDD 22 (collect at utils.scala:211)
18/02/28 14:22:27 INFO DAGScheduler: Got job 3 (collect at utils.scala:211) with 1 output partitions
18/02/28 14:22:27 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:211)
18/02/28 14:22:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
18/02/28 14:22:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
18/02/28 14:22:27 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[22] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:27 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 26.7 KB, free 345.1 MB)
18/02/28 14:22:27 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.7 KB, free 345.1 MB)
18/02/28 14:22:27 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:61672 (size: 11.7 KB, free: 345.8 MB)
18/02/28 14:22:27 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:27 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[22] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:27 INFO TaskSchedulerImpl: Adding task set 5.0 with 4 tasks
18/02/28 14:22:27 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:27 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 12, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:27 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 13, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:22:27 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 14, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:27 INFO Executor: Running task 0.0 in stage 5.0 (TID 11)
18/02/28 14:22:27 INFO Executor: Running task 2.0 in stage 5.0 (TID 13)
18/02/28 14:22:27 INFO Executor: Running task 3.0 in stage 5.0 (TID 14)
18/02/28 14:22:27 INFO Executor: Running task 1.0 in stage 5.0 (TID 12)
18/02/28 14:22:27 INFO BlockManager: Found block rdd_13_3 locally
18/02/28 14:22:27 INFO BlockManager: Found block rdd_13_1 locally
18/02/28 14:22:27 INFO BlockManager: Found block rdd_13_2 locally
18/02/28 14:22:27 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 14:22:27 INFO Executor: Finished task 3.0 in stage 5.0 (TID 14). 1737 bytes result sent to driver
18/02/28 14:22:27 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 14) in 38 ms on localhost (executor driver) (1/4)
18/02/28 14:22:27 INFO Executor: Finished task 2.0 in stage 5.0 (TID 13). 1694 bytes result sent to driver
18/02/28 14:22:27 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 13) in 56 ms on localhost (executor driver) (2/4)
18/02/28 14:22:27 INFO Executor: Finished task 0.0 in stage 5.0 (TID 11). 1694 bytes result sent to driver
18/02/28 14:22:27 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 11) in 72 ms on localhost (executor driver) (3/4)
18/02/28 14:22:27 INFO Executor: Finished task 1.0 in stage 5.0 (TID 12). 1737 bytes result sent to driver
18/02/28 14:22:27 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 12) in 75 ms on localhost (executor driver) (4/4)
18/02/28 14:22:27 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:211) finished in 0.078 s
18/02/28 14:22:27 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/02/28 14:22:27 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:22:27 INFO DAGScheduler: running: Set()
18/02/28 14:22:27 INFO DAGScheduler: waiting: Set(ResultStage 6)
18/02/28 14:22:27 INFO DAGScheduler: failed: Set()
18/02/28 14:22:27 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:27 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.0 KB, free 345.1 MB)
18/02/28 14:22:27 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.7 KB, free 345.1 MB)
18/02/28 14:22:27 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:61672 (size: 3.7 KB, free: 345.8 MB)
18/02/28 14:22:27 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 14:22:27 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
18/02/28 14:22:27 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 15, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 14:22:27 INFO Executor: Running task 0.0 in stage 6.0 (TID 15)
18/02/28 14:22:27 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:27 INFO Executor: Finished task 0.0 in stage 6.0 (TID 15). 1495 bytes result sent to driver
18/02/28 14:22:27 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 15) in 7 ms on localhost (executor driver) (1/1)
18/02/28 14:22:27 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
18/02/28 14:22:27 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:211) finished in 0.007 s
18/02/28 14:22:27 INFO DAGScheduler: Job 3 finished: collect at utils.scala:211, took 0.106867 s
18/02/28 14:22:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:27 INFO SparkSqlParser: Parsing command: SHOW TABLES LIKE"cached_flights"
18/02/28 14:22:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:22:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:22:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:22:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:22:27 INFO HiveMetaStore: 0: get_tables: db=default pat=cached_flights
18/02/28 14:22:27 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_tables: db=default pat=cached_flights	
18/02/28 14:22:27 INFO CodeGenerator: Code generated in 9.356337 ms
18/02/28 14:22:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights` AS `zzz3`
WHERE (0 = 1)
18/02/28 14:22:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:28 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `cached_flights`
18/02/28 14:22:28 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:22:28 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:22:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:28 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `cached_flights`
LIMIT 10
18/02/28 14:22:28 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:22:28 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:22:28 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:22:28 INFO DAGScheduler: Registering RDD 28 (collect at utils.scala:211)
18/02/28 14:22:28 INFO DAGScheduler: Got job 4 (collect at utils.scala:211) with 1 output partitions
18/02/28 14:22:28 INFO DAGScheduler: Final stage: ResultStage 8 (collect at utils.scala:211)
18/02/28 14:22:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
18/02/28 14:22:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
18/02/28 14:22:28 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[28] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:28 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 26.7 KB, free 345.1 MB)
18/02/28 14:22:28 INFO ContextCleaner: Cleaned accumulator 241
18/02/28 14:22:28 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 11.7 KB, free 345.1 MB)
18/02/28 14:22:28 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:61672 (size: 11.7 KB, free: 345.7 MB)
18/02/28 14:22:28 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:28 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[28] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:28 INFO TaskSchedulerImpl: Adding task set 7.0 with 4 tasks
18/02/28 14:22:28 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:61672 in memory (size: 3.7 KB, free: 345.7 MB)
18/02/28 14:22:28 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:28 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 17, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:28 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 18, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:22:28 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 19, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:28 INFO Executor: Running task 0.0 in stage 7.0 (TID 16)
18/02/28 14:22:28 INFO Executor: Running task 1.0 in stage 7.0 (TID 17)
18/02/28 14:22:28 INFO Executor: Running task 2.0 in stage 7.0 (TID 18)
18/02/28 14:22:28 INFO BlockManager: Found block rdd_13_1 locally
18/02/28 14:22:28 INFO Executor: Running task 3.0 in stage 7.0 (TID 19)
18/02/28 14:22:28 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:61672 in memory (size: 11.7 KB, free: 345.8 MB)
18/02/28 14:22:28 INFO BlockManager: Found block rdd_13_3 locally
18/02/28 14:22:28 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 14:22:28 INFO BlockManager: Found block rdd_13_2 locally
18/02/28 14:22:28 INFO ContextCleaner: Cleaned accumulator 180
18/02/28 14:22:28 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:61672 in memory (size: 3.7 KB, free: 345.8 MB)
18/02/28 14:22:28 INFO Executor: Finished task 1.0 in stage 7.0 (TID 17). 1823 bytes result sent to driver
18/02/28 14:22:28 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 17) in 42 ms on localhost (executor driver) (1/4)
18/02/28 14:22:28 INFO Executor: Finished task 3.0 in stage 7.0 (TID 19). 1737 bytes result sent to driver
18/02/28 14:22:28 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 19) in 53 ms on localhost (executor driver) (2/4)
18/02/28 14:22:28 INFO Executor: Finished task 2.0 in stage 7.0 (TID 18). 1780 bytes result sent to driver
18/02/28 14:22:28 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 18) in 62 ms on localhost (executor driver) (3/4)
18/02/28 14:22:28 INFO Executor: Finished task 0.0 in stage 7.0 (TID 16). 1694 bytes result sent to driver
18/02/28 14:22:28 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 16) in 76 ms on localhost (executor driver) (4/4)
18/02/28 14:22:28 INFO DAGScheduler: ShuffleMapStage 7 (collect at utils.scala:211) finished in 0.077 s
18/02/28 14:22:28 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:22:28 INFO DAGScheduler: running: Set()
18/02/28 14:22:28 INFO DAGScheduler: waiting: Set(ResultStage 8)
18/02/28 14:22:28 INFO DAGScheduler: failed: Set()
18/02/28 14:22:28 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[31] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:28 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 6.9 KB, free 345.1 MB)
18/02/28 14:22:28 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.7 KB, free 345.1 MB)
18/02/28 14:22:28 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
18/02/28 14:22:28 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:61672 (size: 3.7 KB, free: 345.8 MB)
18/02/28 14:22:28 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[31] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 14:22:28 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
18/02/28 14:22:28 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 20, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 14:22:28 INFO Executor: Running task 0.0 in stage 8.0 (TID 20)
18/02/28 14:22:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:28 INFO Executor: Finished task 0.0 in stage 8.0 (TID 20). 1471 bytes result sent to driver
18/02/28 14:22:28 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 20) in 8 ms on localhost (executor driver) (1/1)
18/02/28 14:22:28 INFO DAGScheduler: ResultStage 8 (collect at utils.scala:211) finished in 0.008 s
18/02/28 14:22:28 INFO DAGScheduler: Job 4 finished: collect at utils.scala:211, took 0.115887 s
18/02/28 14:22:28 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
18/02/28 14:22:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:28 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
LIMIT 5
18/02/28 14:22:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:28 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
LIMIT 5
18/02/28 14:22:28 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:22:28 INFO DAGScheduler: Got job 5 (collect at utils.scala:211) with 1 output partitions
18/02/28 14:22:28 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:211)
18/02/28 14:22:28 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:22:28 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:28 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[33] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:28 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 22.8 KB, free 345.1 MB)
18/02/28 14:22:28 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 10.3 KB, free 345.1 MB)
18/02/28 14:22:28 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:61672 (size: 10.3 KB, free: 345.7 MB)
18/02/28 14:22:28 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[33] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 14:22:28 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
18/02/28 14:22:28 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:28 INFO Executor: Running task 0.0 in stage 9.0 (TID 21)
18/02/28 14:22:28 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 14:22:28 INFO CodeGenerator: Code generated in 27.675137 ms
18/02/28 14:22:28 INFO Executor: 1 block locks were not released by TID = 21:
[rdd_13_0]
18/02/28 14:22:28 INFO Executor: Finished task 0.0 in stage 9.0 (TID 21). 1481 bytes result sent to driver
18/02/28 14:22:28 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 21) in 71 ms on localhost (executor driver) (1/1)
18/02/28 14:22:28 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
18/02/28 14:22:28 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:211) finished in 0.071 s
18/02/28 14:22:28 INFO DAGScheduler: Job 5 finished: collect at utils.scala:211, took 0.080656 s
18/02/28 14:22:28 INFO CodeGenerator: Code generated in 11.115542 ms
18/02/28 14:22:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:28 INFO SparkSqlParser: Parsing command: SELECT `month`, count(*) AS `n()`
FROM `cached_flights`
GROUP BY `month`
18/02/28 14:22:28 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:22:28 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:22:28 INFO CodeGenerator: Code generated in 26.908195 ms
18/02/28 14:22:28 INFO CodeGenerator: Code generated in 38.195109 ms
18/02/28 14:22:28 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:22:28 INFO DAGScheduler: Registering RDD 36 (collect at utils.scala:211)
18/02/28 14:22:28 INFO DAGScheduler: Got job 6 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:22:28 INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:211)
18/02/28 14:22:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
18/02/28 14:22:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
18/02/28 14:22:28 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[36] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:28 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 37.3 KB, free 345.1 MB)
18/02/28 14:22:28 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 16.6 KB, free 345.0 MB)
18/02/28 14:22:28 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:61672 (size: 16.6 KB, free: 345.7 MB)
18/02/28 14:22:28 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:28 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[36] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:28 INFO TaskSchedulerImpl: Adding task set 10.0 with 4 tasks
18/02/28 14:22:28 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:28 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:28 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:22:28 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:28 INFO Executor: Running task 0.0 in stage 10.0 (TID 22)
18/02/28 14:22:28 INFO Executor: Running task 1.0 in stage 10.0 (TID 23)
18/02/28 14:22:28 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 14:22:28 INFO Executor: Running task 2.0 in stage 10.0 (TID 24)
18/02/28 14:22:28 INFO BlockManager: Found block rdd_13_1 locally
18/02/28 14:22:28 INFO Executor: Running task 3.0 in stage 10.0 (TID 25)
18/02/28 14:22:28 INFO BlockManager: Found block rdd_13_3 locally
18/02/28 14:22:28 INFO BlockManager: Found block rdd_13_2 locally
18/02/28 14:22:28 INFO CodeGenerator: Code generated in 32.328269 ms
18/02/28 14:22:28 INFO CodeGenerator: Code generated in 6.43138 ms
18/02/28 14:22:28 INFO CodeGenerator: Code generated in 6.926806 ms
18/02/28 14:22:28 INFO CodeGenerator: Code generated in 8.800613 ms
18/02/28 14:22:28 INFO CodeGenerator: Code generated in 34.671761 ms
18/02/28 14:22:28 INFO CodeGenerator: Code generated in 6.462057 ms
18/02/28 14:22:29 INFO Executor: Finished task 3.0 in stage 10.0 (TID 25). 2011 bytes result sent to driver
18/02/28 14:22:29 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 340 ms on localhost (executor driver) (1/4)
18/02/28 14:22:29 INFO Executor: Finished task 1.0 in stage 10.0 (TID 23). 1968 bytes result sent to driver
18/02/28 14:22:29 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 345 ms on localhost (executor driver) (2/4)
18/02/28 14:22:29 INFO Executor: Finished task 2.0 in stage 10.0 (TID 24). 1968 bytes result sent to driver
18/02/28 14:22:29 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 354 ms on localhost (executor driver) (3/4)
18/02/28 14:22:29 INFO Executor: Finished task 0.0 in stage 10.0 (TID 22). 1968 bytes result sent to driver
18/02/28 14:22:29 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 356 ms on localhost (executor driver) (4/4)
18/02/28 14:22:29 INFO DAGScheduler: ShuffleMapStage 10 (collect at utils.scala:211) finished in 0.357 s
18/02/28 14:22:29 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:22:29 INFO DAGScheduler: running: Set()
18/02/28 14:22:29 INFO DAGScheduler: waiting: Set(ResultStage 11)
18/02/28 14:22:29 INFO DAGScheduler: failed: Set()
18/02/28 14:22:29 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[39] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:29 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
18/02/28 14:22:29 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 17.6 KB, free 345.0 MB)
18/02/28 14:22:29 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 8.2 KB, free 345.0 MB)
18/02/28 14:22:29 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:61672 (size: 8.2 KB, free: 345.7 MB)
18/02/28 14:22:29 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:29 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 11 (MapPartitionsRDD[39] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:29 INFO TaskSchedulerImpl: Adding task set 11.0 with 4 tasks
18/02/28 14:22:29 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 26, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 14:22:29 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 27, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 14:22:29 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 28, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 14:22:29 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 29, localhost, executor driver, partition 3, ANY, 4726 bytes)
18/02/28 14:22:29 INFO Executor: Running task 0.0 in stage 11.0 (TID 26)
18/02/28 14:22:29 INFO Executor: Running task 1.0 in stage 11.0 (TID 27)
18/02/28 14:22:29 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 14:22:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:29 INFO Executor: Running task 3.0 in stage 11.0 (TID 29)
18/02/28 14:22:29 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:29 INFO Executor: Running task 2.0 in stage 11.0 (TID 28)
18/02/28 14:22:29 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks
18/02/28 14:22:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
18/02/28 14:22:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:29 INFO Executor: Finished task 0.0 in stage 11.0 (TID 26). 2238 bytes result sent to driver
18/02/28 14:22:29 INFO Executor: Finished task 1.0 in stage 11.0 (TID 27). 2263 bytes result sent to driver
18/02/28 14:22:29 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 26) in 26 ms on localhost (executor driver) (1/4)
18/02/28 14:22:29 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 27) in 26 ms on localhost (executor driver) (2/4)
18/02/28 14:22:29 INFO Executor: Finished task 2.0 in stage 11.0 (TID 28). 2238 bytes result sent to driver
18/02/28 14:22:29 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 28) in 31 ms on localhost (executor driver) (3/4)
18/02/28 14:22:29 INFO Executor: Finished task 3.0 in stage 11.0 (TID 29). 2340 bytes result sent to driver
18/02/28 14:22:29 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 29) in 32 ms on localhost (executor driver) (4/4)
18/02/28 14:22:29 INFO DAGScheduler: ResultStage 11 (collect at utils.scala:211) finished in 0.035 s
18/02/28 14:22:29 INFO DAGScheduler: Job 6 finished: collect at utils.scala:211, took 0.409243 s
18/02/28 14:22:29 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
18/02/28 14:22:29 INFO CodeGenerator: Code generated in 6.29668 ms
18/02/28 14:22:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cached_flights`
WHERE (NOT(((`arr_delay`) IS NULL)))
18/02/28 14:22:30 INFO SparkSqlParser: Parsing command: sparklyr_tmp_14404a6078b7
18/02/28 14:22:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_14404a6078b7` AS `zzz4`
WHERE (0 = 1)
18/02/28 14:22:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_14404a6078b7`
18/02/28 14:22:30 INFO SparkSqlParser: Parsing command: sparklyr_tmp_14404cc32d08
18/02/28 14:22:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_14404cc32d08` AS `zzz5`
WHERE (0 = 1)
18/02/28 14:22:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:30 INFO SparkSqlParser: Parsing command: SELECT `month`, `dep_time`, `arr_time`, `arr_delay`, `dep_delay`, `distance`, `sched_dep_time`, `sched_arr_time`, `delayed`, CONCAT("h", CAST(`dephour` AS INT)) AS `dephour`
FROM `sparklyr_tmp_14404cc32d08`
18/02/28 14:22:30 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:22:30 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:22:30 INFO SparkSqlParser: Parsing command: sparklyr_tmp_144047ef1d1a
18/02/28 14:22:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_144047ef1d1a` AS `zzz6`
WHERE (0 = 1)
18/02/28 14:22:30 INFO SparkSqlParser: Parsing command: sparklyr_tmp_1440251d3496
18/02/28 14:22:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1440251d3496` AS `zzz7`
WHERE (0 = 1)
18/02/28 14:22:30 INFO SparkSqlParser: Parsing command: sparklyr_tmp_14408077645
18/02/28 14:22:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_14408077645` AS `zzz8`
WHERE (0 = 1)
18/02/28 14:22:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:30 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_144047ef1d1a`
18/02/28 14:22:30 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:22:30 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:22:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:31 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM `sparklyr_tmp_144047ef1d1a`
LIMIT 10
18/02/28 14:22:31 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:22:31 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:22:31 INFO CodeGenerator: Code generated in 36.10656 ms
18/02/28 14:22:31 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:22:31 INFO DAGScheduler: Registering RDD 42 (collect at utils.scala:211)
18/02/28 14:22:31 INFO DAGScheduler: Got job 7 (collect at utils.scala:211) with 1 output partitions
18/02/28 14:22:31 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:211)
18/02/28 14:22:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
18/02/28 14:22:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
18/02/28 14:22:31 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[42] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:31 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 47.6 KB, free 345.0 MB)
18/02/28 14:22:31 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 20.6 KB, free 345.0 MB)
18/02/28 14:22:31 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:61672 (size: 20.6 KB, free: 345.7 MB)
18/02/28 14:22:31 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:31 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[42] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:31 INFO TaskSchedulerImpl: Adding task set 12.0 with 4 tasks
18/02/28 14:22:31 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:31 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 31, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:31 INFO TaskSetManager: Starting task 2.0 in stage 12.0 (TID 32, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:22:31 INFO TaskSetManager: Starting task 3.0 in stage 12.0 (TID 33, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:31 INFO Executor: Running task 0.0 in stage 12.0 (TID 30)
18/02/28 14:22:31 INFO Executor: Running task 1.0 in stage 12.0 (TID 31)
18/02/28 14:22:31 INFO Executor: Running task 2.0 in stage 12.0 (TID 32)
18/02/28 14:22:31 INFO Executor: Running task 3.0 in stage 12.0 (TID 33)
18/02/28 14:22:31 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 14:22:31 INFO BlockManager: Found block rdd_13_3 locally
18/02/28 14:22:31 INFO BlockManager: Found block rdd_13_2 locally
18/02/28 14:22:31 INFO BlockManager: Found block rdd_13_1 locally
18/02/28 14:22:31 INFO CodeGenerator: Code generated in 30.401571 ms
18/02/28 14:22:31 INFO CodeGenerator: Code generated in 12.571145 ms
18/02/28 14:22:31 INFO ContextCleaner: Cleaned accumulator 327
18/02/28 14:22:31 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:61672 in memory (size: 8.2 KB, free: 345.7 MB)
18/02/28 14:22:31 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:61672 in memory (size: 11.7 KB, free: 345.7 MB)
18/02/28 14:22:31 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:61672 in memory (size: 16.6 KB, free: 345.7 MB)
18/02/28 14:22:31 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:61672 in memory (size: 10.3 KB, free: 345.7 MB)
18/02/28 14:22:31 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:61672 in memory (size: 3.7 KB, free: 345.7 MB)
18/02/28 14:22:31 INFO ContextCleaner: Cleaned accumulator 388
18/02/28 14:22:32 INFO Executor: Finished task 1.0 in stage 12.0 (TID 31). 2408 bytes result sent to driver
18/02/28 14:22:32 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 31) in 1145 ms on localhost (executor driver) (1/4)
18/02/28 14:22:32 INFO Executor: Finished task 0.0 in stage 12.0 (TID 30). 2408 bytes result sent to driver
18/02/28 14:22:32 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 30) in 1158 ms on localhost (executor driver) (2/4)
18/02/28 14:22:32 INFO Executor: Finished task 3.0 in stage 12.0 (TID 33). 2408 bytes result sent to driver
18/02/28 14:22:32 INFO TaskSetManager: Finished task 3.0 in stage 12.0 (TID 33) in 1159 ms on localhost (executor driver) (3/4)
18/02/28 14:22:32 INFO Executor: Finished task 2.0 in stage 12.0 (TID 32). 2408 bytes result sent to driver
18/02/28 14:22:32 INFO TaskSetManager: Finished task 2.0 in stage 12.0 (TID 32) in 1165 ms on localhost (executor driver) (4/4)
18/02/28 14:22:32 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
18/02/28 14:22:32 INFO DAGScheduler: ShuffleMapStage 12 (collect at utils.scala:211) finished in 1.167 s
18/02/28 14:22:32 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:22:32 INFO DAGScheduler: running: Set()
18/02/28 14:22:32 INFO DAGScheduler: waiting: Set(ResultStage 13)
18/02/28 14:22:32 INFO DAGScheduler: failed: Set()
18/02/28 14:22:32 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[45] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:32 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 6.9 KB, free 345.1 MB)
18/02/28 14:22:32 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 345.1 MB)
18/02/28 14:22:32 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:61672 (size: 3.7 KB, free: 345.7 MB)
18/02/28 14:22:32 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[45] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 14:22:32 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
18/02/28 14:22:32 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 34, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 14:22:32 INFO Executor: Running task 0.0 in stage 13.0 (TID 34)
18/02/28 14:22:32 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:32 INFO Executor: Finished task 0.0 in stage 13.0 (TID 34). 1471 bytes result sent to driver
18/02/28 14:22:32 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 34) in 6 ms on localhost (executor driver) (1/1)
18/02/28 14:22:32 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
18/02/28 14:22:32 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:211) finished in 0.006 s
18/02/28 14:22:32 INFO DAGScheduler: Job 7 finished: collect at utils.scala:211, took 1.192615 s
18/02/28 14:22:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_144047ef1d1a`
18/02/28 14:22:32 INFO SparkSqlParser: Parsing command: training
18/02/28 14:22:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training` AS `zzz9`
WHERE (0 = 1)
18/02/28 14:22:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:32 INFO SparkSqlParser: Parsing command: CACHE TABLE `training`
18/02/28 14:22:32 INFO SparkSqlParser: Parsing command: `training`
18/02/28 14:22:32 INFO CodeGenerator: Code generated in 27.098255 ms
18/02/28 14:22:32 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 14:22:32 INFO DAGScheduler: Registering RDD 51 (sql at <unknown>:0)
18/02/28 14:22:32 INFO DAGScheduler: Got job 8 (sql at <unknown>:0) with 1 output partitions
18/02/28 14:22:32 INFO DAGScheduler: Final stage: ResultStage 15 (sql at <unknown>:0)
18/02/28 14:22:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
18/02/28 14:22:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)
18/02/28 14:22:32 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[51] at sql at <unknown>:0), which has no missing parents
18/02/28 14:22:32 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 53.6 KB, free 345.0 MB)
18/02/28 14:22:32 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 22.0 KB, free 345.0 MB)
18/02/28 14:22:32 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:61672 (size: 22.0 KB, free: 345.7 MB)
18/02/28 14:22:32 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:32 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[51] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:32 INFO TaskSchedulerImpl: Adding task set 14.0 with 4 tasks
18/02/28 14:22:32 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:32 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 36, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:32 INFO TaskSetManager: Starting task 2.0 in stage 14.0 (TID 37, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:22:32 INFO TaskSetManager: Starting task 3.0 in stage 14.0 (TID 38, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:32 INFO Executor: Running task 0.0 in stage 14.0 (TID 35)
18/02/28 14:22:32 INFO Executor: Running task 1.0 in stage 14.0 (TID 36)
18/02/28 14:22:32 INFO Executor: Running task 2.0 in stage 14.0 (TID 37)
18/02/28 14:22:32 INFO Executor: Running task 3.0 in stage 14.0 (TID 38)
18/02/28 14:22:32 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 14:22:32 INFO BlockManager: Found block rdd_13_2 locally
18/02/28 14:22:32 INFO BlockManager: Found block rdd_13_3 locally
18/02/28 14:22:32 INFO BlockManager: Found block rdd_13_1 locally
18/02/28 14:22:32 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:61672 in memory (size: 3.7 KB, free: 345.7 MB)
18/02/28 14:22:32 INFO ContextCleaner: Cleaned accumulator 462
18/02/28 14:22:33 INFO MemoryStore: Block rdd_48_2 stored as values in memory (estimated size 63.7 KB, free 331.0 MB)
18/02/28 14:22:33 INFO MemoryStore: Block rdd_48_3 stored as values in memory (estimated size 57.3 KB, free 330.9 MB)
18/02/28 14:22:33 INFO BlockManagerInfo: Added rdd_48_2 in memory on 127.0.0.1:61672 (size: 63.7 KB, free: 345.7 MB)
18/02/28 14:22:33 INFO BlockManagerInfo: Added rdd_48_3 in memory on 127.0.0.1:61672 (size: 57.3 KB, free: 345.6 MB)
18/02/28 14:22:33 INFO MemoryStore: Block rdd_48_1 stored as values in memory (estimated size 60.0 KB, free 330.9 MB)
18/02/28 14:22:33 INFO BlockManagerInfo: Added rdd_48_1 in memory on 127.0.0.1:61672 (size: 60.0 KB, free: 345.6 MB)
18/02/28 14:22:33 INFO Executor: Finished task 1.0 in stage 14.0 (TID 36). 3099 bytes result sent to driver
18/02/28 14:22:33 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 36) in 438 ms on localhost (executor driver) (1/4)
18/02/28 14:22:33 INFO Executor: Finished task 3.0 in stage 14.0 (TID 38). 3185 bytes result sent to driver
18/02/28 14:22:33 INFO TaskSetManager: Finished task 3.0 in stage 14.0 (TID 38) in 448 ms on localhost (executor driver) (2/4)
18/02/28 14:22:33 INFO Executor: Finished task 2.0 in stage 14.0 (TID 37). 3099 bytes result sent to driver
18/02/28 14:22:33 INFO TaskSetManager: Finished task 2.0 in stage 14.0 (TID 37) in 462 ms on localhost (executor driver) (3/4)
18/02/28 14:22:33 INFO MemoryStore: Block rdd_48_0 stored as values in memory (estimated size 63.8 KB, free 344.8 MB)
18/02/28 14:22:33 INFO BlockManagerInfo: Added rdd_48_0 in memory on 127.0.0.1:61672 (size: 63.8 KB, free: 345.5 MB)
18/02/28 14:22:33 INFO Executor: Finished task 0.0 in stage 14.0 (TID 35). 3142 bytes result sent to driver
18/02/28 14:22:33 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 35) in 491 ms on localhost (executor driver) (4/4)
18/02/28 14:22:33 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
18/02/28 14:22:33 INFO DAGScheduler: ShuffleMapStage 14 (sql at <unknown>:0) finished in 0.491 s
18/02/28 14:22:33 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:22:33 INFO DAGScheduler: running: Set()
18/02/28 14:22:33 INFO DAGScheduler: waiting: Set(ResultStage 15)
18/02/28 14:22:33 INFO DAGScheduler: failed: Set()
18/02/28 14:22:33 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[54] at sql at <unknown>:0), which has no missing parents
18/02/28 14:22:33 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 344.8 MB)
18/02/28 14:22:33 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KB, free 344.8 MB)
18/02/28 14:22:33 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:61672 (size: 3.7 KB, free: 345.5 MB)
18/02/28 14:22:33 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[54] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 14:22:33 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
18/02/28 14:22:33 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 39, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 14:22:33 INFO Executor: Running task 0.0 in stage 15.0 (TID 39)
18/02/28 14:22:33 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:33 INFO Executor: Finished task 0.0 in stage 15.0 (TID 39). 1452 bytes result sent to driver
18/02/28 14:22:33 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 39) in 6 ms on localhost (executor driver) (1/1)
18/02/28 14:22:33 INFO DAGScheduler: ResultStage 15 (sql at <unknown>:0) finished in 0.006 s
18/02/28 14:22:33 INFO DAGScheduler: Job 8 finished: sql at <unknown>:0, took 0.512320 s
18/02/28 14:22:33 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
18/02/28 14:22:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:33 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `training`
18/02/28 14:22:33 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:22:33 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:22:33 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:22:33 INFO DAGScheduler: Registering RDD 57 (collect at utils.scala:211)
18/02/28 14:22:33 INFO DAGScheduler: Got job 9 (collect at utils.scala:211) with 1 output partitions
18/02/28 14:22:33 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:211)
18/02/28 14:22:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
18/02/28 14:22:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)
18/02/28 14:22:33 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[57] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:33 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 53.6 KB, free 344.7 MB)
18/02/28 14:22:33 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 22.0 KB, free 344.7 MB)
18/02/28 14:22:33 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:61672 (size: 22.0 KB, free: 345.5 MB)
18/02/28 14:22:33 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:33 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[57] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:33 INFO TaskSchedulerImpl: Adding task set 16.0 with 4 tasks
18/02/28 14:22:33 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 40, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:33 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 41, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:33 INFO TaskSetManager: Starting task 2.0 in stage 16.0 (TID 42, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:22:33 INFO TaskSetManager: Starting task 3.0 in stage 16.0 (TID 43, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:33 INFO Executor: Running task 0.0 in stage 16.0 (TID 40)
18/02/28 14:22:33 INFO Executor: Running task 1.0 in stage 16.0 (TID 41)
18/02/28 14:22:33 INFO Executor: Running task 2.0 in stage 16.0 (TID 42)
18/02/28 14:22:33 INFO BlockManager: Found block rdd_48_0 locally
18/02/28 14:22:33 INFO BlockManager: Found block rdd_48_2 locally
18/02/28 14:22:33 INFO Executor: Running task 3.0 in stage 16.0 (TID 43)
18/02/28 14:22:33 INFO BlockManager: Found block rdd_48_1 locally
18/02/28 14:22:33 INFO BlockManager: Found block rdd_48_3 locally
18/02/28 14:22:33 INFO Executor: Finished task 3.0 in stage 16.0 (TID 43). 2289 bytes result sent to driver
18/02/28 14:22:33 INFO TaskSetManager: Finished task 3.0 in stage 16.0 (TID 43) in 26 ms on localhost (executor driver) (1/4)
18/02/28 14:22:33 INFO Executor: Finished task 1.0 in stage 16.0 (TID 41). 2289 bytes result sent to driver
18/02/28 14:22:33 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 41) in 34 ms on localhost (executor driver) (2/4)
18/02/28 14:22:33 INFO Executor: Finished task 0.0 in stage 16.0 (TID 40). 2332 bytes result sent to driver
18/02/28 14:22:33 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 40) in 36 ms on localhost (executor driver) (3/4)
18/02/28 14:22:33 INFO Executor: Finished task 2.0 in stage 16.0 (TID 42). 2332 bytes result sent to driver
18/02/28 14:22:33 INFO TaskSetManager: Finished task 2.0 in stage 16.0 (TID 42) in 38 ms on localhost (executor driver) (4/4)
18/02/28 14:22:33 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
18/02/28 14:22:33 INFO DAGScheduler: ShuffleMapStage 16 (collect at utils.scala:211) finished in 0.039 s
18/02/28 14:22:33 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:22:33 INFO DAGScheduler: running: Set()
18/02/28 14:22:33 INFO DAGScheduler: waiting: Set(ResultStage 17)
18/02/28 14:22:33 INFO DAGScheduler: failed: Set()
18/02/28 14:22:33 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[60] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:33 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 7.0 KB, free 344.7 MB)
18/02/28 14:22:33 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 3.7 KB, free 344.7 MB)
18/02/28 14:22:33 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:61672 (size: 3.7 KB, free: 345.5 MB)
18/02/28 14:22:33 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[60] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 14:22:33 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
18/02/28 14:22:33 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 44, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 14:22:33 INFO Executor: Running task 0.0 in stage 17.0 (TID 44)
18/02/28 14:22:33 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:33 INFO Executor: Finished task 0.0 in stage 17.0 (TID 44). 1495 bytes result sent to driver
18/02/28 14:22:33 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 44) in 7 ms on localhost (executor driver) (1/1)
18/02/28 14:22:33 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:211) finished in 0.009 s
18/02/28 14:22:33 INFO DAGScheduler: Job 9 finished: collect at utils.scala:211, took 0.065155 s
18/02/28 14:22:33 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
18/02/28 14:22:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 14:22:33 INFO CodeGenerator: Code generated in 6.243435 ms
18/02/28 14:22:33 INFO SparkContext: Starting job: countByValue at StringIndexer.scala:113
18/02/28 14:22:33 INFO DAGScheduler: Registering RDD 67 (countByValue at StringIndexer.scala:113)
18/02/28 14:22:33 INFO DAGScheduler: Got job 10 (countByValue at StringIndexer.scala:113) with 4 output partitions
18/02/28 14:22:33 INFO DAGScheduler: Final stage: ResultStage 19 (countByValue at StringIndexer.scala:113)
18/02/28 14:22:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
18/02/28 14:22:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 18)
18/02/28 14:22:33 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[67] at countByValue at StringIndexer.scala:113), which has no missing parents
18/02/28 14:22:33 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 55.3 KB, free 344.6 MB)
18/02/28 14:22:33 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 22.8 KB, free 344.6 MB)
18/02/28 14:22:33 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:61672 (size: 22.8 KB, free: 345.4 MB)
18/02/28 14:22:33 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:33 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[67] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:33 INFO TaskSchedulerImpl: Adding task set 18.0 with 4 tasks
18/02/28 14:22:33 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 45, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:33 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 46, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:33 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 47, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:22:33 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 48, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:33 INFO Executor: Running task 1.0 in stage 18.0 (TID 46)
18/02/28 14:22:33 INFO Executor: Running task 0.0 in stage 18.0 (TID 45)
18/02/28 14:22:33 INFO Executor: Running task 3.0 in stage 18.0 (TID 48)
18/02/28 14:22:33 INFO Executor: Running task 2.0 in stage 18.0 (TID 47)
18/02/28 14:22:33 INFO BlockManager: Found block rdd_48_2 locally
18/02/28 14:22:33 INFO BlockManager: Found block rdd_48_3 locally
18/02/28 14:22:33 INFO BlockManager: Found block rdd_48_0 locally
18/02/28 14:22:33 INFO BlockManager: Found block rdd_48_1 locally
18/02/28 14:22:33 INFO CodeGenerator: Code generated in 26.665595 ms
18/02/28 14:22:33 INFO CodeGenerator: Code generated in 6.479688 ms
18/02/28 14:22:34 INFO Executor: Finished task 3.0 in stage 18.0 (TID 48). 2277 bytes result sent to driver
18/02/28 14:22:34 INFO TaskSetManager: Finished task 3.0 in stage 18.0 (TID 48) in 150 ms on localhost (executor driver) (1/4)
18/02/28 14:22:34 INFO Executor: Finished task 0.0 in stage 18.0 (TID 45). 2277 bytes result sent to driver
18/02/28 14:22:34 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 45) in 151 ms on localhost (executor driver) (2/4)
18/02/28 14:22:34 INFO Executor: Finished task 2.0 in stage 18.0 (TID 47). 2277 bytes result sent to driver
18/02/28 14:22:34 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 47) in 154 ms on localhost (executor driver) (3/4)
18/02/28 14:22:34 INFO Executor: Finished task 1.0 in stage 18.0 (TID 46). 2277 bytes result sent to driver
18/02/28 14:22:34 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 46) in 158 ms on localhost (executor driver) (4/4)
18/02/28 14:22:34 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
18/02/28 14:22:34 INFO DAGScheduler: ShuffleMapStage 18 (countByValue at StringIndexer.scala:113) finished in 0.159 s
18/02/28 14:22:34 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:22:34 INFO DAGScheduler: running: Set()
18/02/28 14:22:34 INFO DAGScheduler: waiting: Set(ResultStage 19)
18/02/28 14:22:34 INFO DAGScheduler: failed: Set()
18/02/28 14:22:34 INFO DAGScheduler: Submitting ResultStage 19 (ShuffledRDD[68] at countByValue at StringIndexer.scala:113), which has no missing parents
18/02/28 14:22:34 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 3.2 KB, free 344.6 MB)
18/02/28 14:22:34 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 1963.0 B, free 344.6 MB)
18/02/28 14:22:34 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:61672 (size: 1963.0 B, free: 345.4 MB)
18/02/28 14:22:34 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:34 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 19 (ShuffledRDD[68] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:34 INFO TaskSchedulerImpl: Adding task set 19.0 with 4 tasks
18/02/28 14:22:34 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 49, localhost, executor driver, partition 0, ANY, 4621 bytes)
18/02/28 14:22:34 INFO TaskSetManager: Starting task 1.0 in stage 19.0 (TID 50, localhost, executor driver, partition 1, ANY, 4621 bytes)
18/02/28 14:22:34 INFO TaskSetManager: Starting task 2.0 in stage 19.0 (TID 51, localhost, executor driver, partition 2, ANY, 4621 bytes)
18/02/28 14:22:34 INFO TaskSetManager: Starting task 3.0 in stage 19.0 (TID 52, localhost, executor driver, partition 3, ANY, 4621 bytes)
18/02/28 14:22:34 INFO Executor: Running task 0.0 in stage 19.0 (TID 49)
18/02/28 14:22:34 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:34 INFO Executor: Running task 1.0 in stage 19.0 (TID 50)
18/02/28 14:22:34 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:34 INFO Executor: Running task 2.0 in stage 19.0 (TID 51)
18/02/28 14:22:34 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 14:22:34 INFO Executor: Running task 3.0 in stage 19.0 (TID 52)
18/02/28 14:22:34 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:34 INFO Executor: Finished task 1.0 in stage 19.0 (TID 50). 1178 bytes result sent to driver
18/02/28 14:22:34 INFO Executor: Finished task 0.0 in stage 19.0 (TID 49). 1196 bytes result sent to driver
18/02/28 14:22:34 INFO Executor: Finished task 3.0 in stage 19.0 (TID 52). 1153 bytes result sent to driver
18/02/28 14:22:34 INFO Executor: Finished task 2.0 in stage 19.0 (TID 51). 1153 bytes result sent to driver
18/02/28 14:22:34 INFO TaskSetManager: Finished task 1.0 in stage 19.0 (TID 50) in 45 ms on localhost (executor driver) (1/4)
18/02/28 14:22:34 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 49) in 47 ms on localhost (executor driver) (2/4)
18/02/28 14:22:34 INFO TaskSetManager: Finished task 2.0 in stage 19.0 (TID 51) in 45 ms on localhost (executor driver) (3/4)
18/02/28 14:22:34 INFO TaskSetManager: Finished task 3.0 in stage 19.0 (TID 52) in 44 ms on localhost (executor driver) (4/4)
18/02/28 14:22:34 INFO DAGScheduler: ResultStage 19 (countByValue at StringIndexer.scala:113) finished in 0.048 s
18/02/28 14:22:34 INFO DAGScheduler: Job 10 finished: countByValue at StringIndexer.scala:113, took 0.328036 s
18/02/28 14:22:34 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
18/02/28 14:22:34 INFO CodeGenerator: Code generated in 10.101063 ms
18/02/28 14:22:34 INFO SparkContext: Starting job: countByValue at StringIndexer.scala:113
18/02/28 14:22:34 INFO DAGScheduler: Registering RDD 75 (countByValue at StringIndexer.scala:113)
18/02/28 14:22:34 INFO DAGScheduler: Got job 11 (countByValue at StringIndexer.scala:113) with 4 output partitions
18/02/28 14:22:34 INFO DAGScheduler: Final stage: ResultStage 21 (countByValue at StringIndexer.scala:113)
18/02/28 14:22:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
18/02/28 14:22:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
18/02/28 14:22:34 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[75] at countByValue at StringIndexer.scala:113), which has no missing parents
18/02/28 14:22:34 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 56.1 KB, free 344.6 MB)
18/02/28 14:22:34 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 23.1 KB, free 344.5 MB)
18/02/28 14:22:34 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:61672 (size: 23.1 KB, free: 345.4 MB)
18/02/28 14:22:34 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:34 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[75] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:34 INFO TaskSchedulerImpl: Adding task set 20.0 with 4 tasks
18/02/28 14:22:34 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:34 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 54, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:34 INFO TaskSetManager: Starting task 2.0 in stage 20.0 (TID 55, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:22:34 INFO TaskSetManager: Starting task 3.0 in stage 20.0 (TID 56, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:34 INFO Executor: Running task 1.0 in stage 20.0 (TID 54)
18/02/28 14:22:34 INFO Executor: Running task 0.0 in stage 20.0 (TID 53)
18/02/28 14:22:34 INFO Executor: Running task 2.0 in stage 20.0 (TID 55)
18/02/28 14:22:34 INFO Executor: Running task 3.0 in stage 20.0 (TID 56)
18/02/28 14:22:34 INFO BlockManager: Found block rdd_48_0 locally
18/02/28 14:22:34 INFO BlockManager: Found block rdd_48_2 locally
18/02/28 14:22:34 INFO BlockManager: Found block rdd_48_3 locally
18/02/28 14:22:34 INFO BlockManager: Found block rdd_48_1 locally
18/02/28 14:22:34 INFO Executor: Finished task 3.0 in stage 20.0 (TID 56). 2234 bytes result sent to driver
18/02/28 14:22:34 INFO TaskSetManager: Finished task 3.0 in stage 20.0 (TID 56) in 70 ms on localhost (executor driver) (1/4)
18/02/28 14:22:34 INFO Executor: Finished task 0.0 in stage 20.0 (TID 53). 2320 bytes result sent to driver
18/02/28 14:22:34 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 53) in 81 ms on localhost (executor driver) (2/4)
18/02/28 14:22:34 INFO Executor: Finished task 2.0 in stage 20.0 (TID 55). 2234 bytes result sent to driver
18/02/28 14:22:34 INFO Executor: Finished task 1.0 in stage 20.0 (TID 54). 2277 bytes result sent to driver
18/02/28 14:22:34 INFO TaskSetManager: Finished task 2.0 in stage 20.0 (TID 55) in 87 ms on localhost (executor driver) (3/4)
18/02/28 14:22:34 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 54) in 87 ms on localhost (executor driver) (4/4)
18/02/28 14:22:34 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
18/02/28 14:22:34 INFO DAGScheduler: ShuffleMapStage 20 (countByValue at StringIndexer.scala:113) finished in 0.087 s
18/02/28 14:22:34 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:22:34 INFO DAGScheduler: running: Set()
18/02/28 14:22:34 INFO DAGScheduler: waiting: Set(ResultStage 21)
18/02/28 14:22:34 INFO DAGScheduler: failed: Set()
18/02/28 14:22:34 INFO DAGScheduler: Submitting ResultStage 21 (ShuffledRDD[76] at countByValue at StringIndexer.scala:113), which has no missing parents
18/02/28 14:22:34 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 3.2 KB, free 344.5 MB)
18/02/28 14:22:34 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 1963.0 B, free 344.5 MB)
18/02/28 14:22:34 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:61672 (size: 1963.0 B, free: 345.4 MB)
18/02/28 14:22:34 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:34 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 21 (ShuffledRDD[76] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:34 INFO TaskSchedulerImpl: Adding task set 21.0 with 4 tasks
18/02/28 14:22:34 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 57, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:34 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 58, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:34 INFO TaskSetManager: Starting task 2.0 in stage 21.0 (TID 59, localhost, executor driver, partition 2, ANY, 4621 bytes)
18/02/28 14:22:34 INFO TaskSetManager: Starting task 3.0 in stage 21.0 (TID 60, localhost, executor driver, partition 3, ANY, 4621 bytes)
18/02/28 14:22:34 INFO Executor: Running task 0.0 in stage 21.0 (TID 57)
18/02/28 14:22:34 INFO Executor: Running task 1.0 in stage 21.0 (TID 58)
18/02/28 14:22:34 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 14:22:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:34 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 14:22:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:34 INFO Executor: Finished task 1.0 in stage 21.0 (TID 58). 1048 bytes result sent to driver
18/02/28 14:22:34 INFO Executor: Finished task 0.0 in stage 21.0 (TID 57). 1005 bytes result sent to driver
18/02/28 14:22:34 INFO Executor: Running task 2.0 in stage 21.0 (TID 59)
18/02/28 14:22:34 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:34 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 58) in 12 ms on localhost (executor driver) (1/4)
18/02/28 14:22:34 INFO Executor: Running task 3.0 in stage 21.0 (TID 60)
18/02/28 14:22:34 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 57) in 15 ms on localhost (executor driver) (2/4)
18/02/28 14:22:34 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:34 INFO Executor: Finished task 3.0 in stage 21.0 (TID 60). 1197 bytes result sent to driver
18/02/28 14:22:34 INFO Executor: Finished task 2.0 in stage 21.0 (TID 59). 1154 bytes result sent to driver
18/02/28 14:22:34 INFO TaskSetManager: Finished task 3.0 in stage 21.0 (TID 60) in 35 ms on localhost (executor driver) (3/4)
18/02/28 14:22:34 INFO TaskSetManager: Finished task 2.0 in stage 21.0 (TID 59) in 36 ms on localhost (executor driver) (4/4)
18/02/28 14:22:34 INFO DAGScheduler: ResultStage 21 (countByValue at StringIndexer.scala:113) finished in 0.038 s
18/02/28 14:22:34 INFO DAGScheduler: Job 11 finished: countByValue at StringIndexer.scala:113, took 0.143219 s
18/02/28 14:22:34 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
18/02/28 14:22:34 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:61672 in memory (size: 23.1 KB, free: 345.4 MB)
18/02/28 14:22:34 INFO CodeGenerator: Code generated in 35.6538 ms
18/02/28 14:22:34 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:61672 in memory (size: 1963.0 B, free: 345.4 MB)
18/02/28 14:22:34 INFO ContextCleaner: Cleaned shuffle 8
18/02/28 14:22:34 INFO ContextCleaner: Cleaned accumulator 635
18/02/28 14:22:34 INFO ContextCleaner: Cleaned accumulator 523
18/02/28 14:22:34 INFO ContextCleaner: Cleaned accumulator 586
18/02/28 14:22:34 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:61672 in memory (size: 3.7 KB, free: 345.4 MB)
18/02/28 14:22:34 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:61672 in memory (size: 1963.0 B, free: 345.4 MB)
18/02/28 14:22:34 INFO ContextCleaner: Cleaned accumulator 636
18/02/28 14:22:34 INFO ContextCleaner: Cleaned accumulator 637
18/02/28 14:22:34 INFO ContextCleaner: Cleaned accumulator 584
18/02/28 14:22:34 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:61672 in memory (size: 22.8 KB, free: 345.5 MB)
18/02/28 14:22:34 INFO ContextCleaner: Cleaned shuffle 9
18/02/28 14:22:34 INFO ContextCleaner: Cleaned accumulator 585
18/02/28 14:22:34 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:61672 in memory (size: 22.0 KB, free: 345.5 MB)
18/02/28 14:22:34 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:61672 in memory (size: 3.7 KB, free: 345.5 MB)
18/02/28 14:22:34 INFO CodeGenerator: Code generated in 24.844328 ms
18/02/28 14:22:34 INFO Instrumentation: LogisticRegression-logistic_regression_144035267d6d-1858750619-1: training: numPartitions=4 storageLevel=StorageLevel(disk, memory, deserialized, 1 replicas)
18/02/28 14:22:34 INFO Instrumentation: LogisticRegression-logistic_regression_144035267d6d-1858750619-1: {"elasticNetParam":0.0,"fitIntercept":true,"threshold":0.5,"regParam":0.0,"tol":1.0E-6,"maxIter":100}
18/02/28 14:22:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:517
18/02/28 14:22:34 INFO DAGScheduler: Got job 12 (treeAggregate at LogisticRegression.scala:517) with 4 output partitions
18/02/28 14:22:34 INFO DAGScheduler: Final stage: ResultStage 22 (treeAggregate at LogisticRegression.scala:517)
18/02/28 14:22:34 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:22:34 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:34 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[86] at treeAggregate at LogisticRegression.scala:517), which has no missing parents
18/02/28 14:22:34 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 74.0 KB, free 344.7 MB)
18/02/28 14:22:34 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 29.2 KB, free 344.7 MB)
18/02/28 14:22:34 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:61672 (size: 29.2 KB, free: 345.5 MB)
18/02/28 14:22:34 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:34 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 22 (MapPartitionsRDD[86] at treeAggregate at LogisticRegression.scala:517) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:34 INFO TaskSchedulerImpl: Adding task set 22.0 with 4 tasks
18/02/28 14:22:34 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:34 INFO TaskSetManager: Starting task 1.0 in stage 22.0 (TID 62, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:34 INFO TaskSetManager: Starting task 2.0 in stage 22.0 (TID 63, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:22:34 INFO TaskSetManager: Starting task 3.0 in stage 22.0 (TID 64, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:34 INFO Executor: Running task 0.0 in stage 22.0 (TID 61)
18/02/28 14:22:34 INFO Executor: Running task 1.0 in stage 22.0 (TID 62)
18/02/28 14:22:34 INFO Executor: Running task 2.0 in stage 22.0 (TID 63)
18/02/28 14:22:34 INFO Executor: Running task 3.0 in stage 22.0 (TID 64)
18/02/28 14:22:34 INFO BlockManager: Found block rdd_48_1 locally
18/02/28 14:22:34 INFO BlockManager: Found block rdd_48_2 locally
18/02/28 14:22:34 INFO BlockManager: Found block rdd_48_0 locally
18/02/28 14:22:34 INFO BlockManager: Found block rdd_48_3 locally
18/02/28 14:22:34 INFO CodeGenerator: Code generated in 12.126847 ms
18/02/28 14:22:34 INFO CodeGenerator: Code generated in 10.358121 ms
18/02/28 14:22:35 INFO MemoryStore: Block rdd_85_0 stored as values in memory (estimated size 89.8 KB, free 344.6 MB)
18/02/28 14:22:35 INFO BlockManagerInfo: Added rdd_85_0 in memory on 127.0.0.1:61672 (size: 89.8 KB, free: 345.4 MB)
18/02/28 14:22:35 INFO MemoryStore: Block rdd_85_2 stored as values in memory (estimated size 90.2 KB, free 344.4 MB)
18/02/28 14:22:35 INFO MemoryStore: Block rdd_85_3 stored as values in memory (estimated size 78.7 KB, free 344.4 MB)
18/02/28 14:22:35 INFO BlockManagerInfo: Added rdd_85_3 in memory on 127.0.0.1:61672 (size: 78.7 KB, free: 345.3 MB)
18/02/28 14:22:35 INFO BlockManagerInfo: Added rdd_85_2 in memory on 127.0.0.1:61672 (size: 90.2 KB, free: 345.2 MB)
18/02/28 14:22:35 INFO Executor: Finished task 2.0 in stage 22.0 (TID 63). 3936 bytes result sent to driver
18/02/28 14:22:35 INFO Executor: Finished task 0.0 in stage 22.0 (TID 61). 3893 bytes result sent to driver
18/02/28 14:22:35 INFO TaskSetManager: Finished task 2.0 in stage 22.0 (TID 63) in 363 ms on localhost (executor driver) (1/4)
18/02/28 14:22:35 INFO Executor: Finished task 3.0 in stage 22.0 (TID 64). 3979 bytes result sent to driver
18/02/28 14:22:35 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 61) in 366 ms on localhost (executor driver) (2/4)
18/02/28 14:22:35 INFO TaskSetManager: Finished task 3.0 in stage 22.0 (TID 64) in 366 ms on localhost (executor driver) (3/4)
18/02/28 14:22:35 INFO MemoryStore: Block rdd_85_1 stored as values in memory (estimated size 89.7 KB, free 344.4 MB)
18/02/28 14:22:35 INFO BlockManagerInfo: Added rdd_85_1 in memory on 127.0.0.1:61672 (size: 89.7 KB, free: 345.1 MB)
18/02/28 14:22:35 INFO Executor: Finished task 1.0 in stage 22.0 (TID 62). 3936 bytes result sent to driver
18/02/28 14:22:35 INFO TaskSetManager: Finished task 1.0 in stage 22.0 (TID 62) in 375 ms on localhost (executor driver) (4/4)
18/02/28 14:22:35 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
18/02/28 14:22:35 INFO DAGScheduler: ResultStage 22 (treeAggregate at LogisticRegression.scala:517) finished in 0.375 s
18/02/28 14:22:35 INFO DAGScheduler: Job 12 finished: treeAggregate at LogisticRegression.scala:517, took 0.382522 s
18/02/28 14:22:35 INFO Instrumentation: LogisticRegression-logistic_regression_144035267d6d-1858750619-1: {"numClasses":2}
18/02/28 14:22:35 INFO Instrumentation: LogisticRegression-logistic_regression_144035267d6d-1858750619-1: {"numFeatures":5}
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 80.0 B, free 344.4 MB)
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 109.0 B, free 344.4 MB)
18/02/28 14:22:35 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:61672 (size: 109.0 B, free: 345.1 MB)
18/02/28 14:22:35 INFO SparkContext: Created broadcast 25 from broadcast at LogisticRegression.scala:600
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 104.0 B, free 344.4 MB)
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 154.0 B, free 344.4 MB)
18/02/28 14:22:35 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:61672 (size: 154.0 B, free: 345.1 MB)
18/02/28 14:22:35 INFO SparkContext: Created broadcast 26 from broadcast at LogisticRegression.scala:1879
18/02/28 14:22:35 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:22:35 INFO DAGScheduler: Got job 13 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:22:35 INFO DAGScheduler: Final stage: ResultStage 23 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:22:35 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:22:35 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:35 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[87] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 74.1 KB, free 344.3 MB)
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 29.2 KB, free 344.3 MB)
18/02/28 14:22:35 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:61672 (size: 29.2 KB, free: 345.1 MB)
18/02/28 14:22:35 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:35 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 23 (MapPartitionsRDD[87] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:35 INFO TaskSchedulerImpl: Adding task set 23.0 with 4 tasks
18/02/28 14:22:35 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 65, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:35 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 66, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:35 INFO TaskSetManager: Starting task 2.0 in stage 23.0 (TID 67, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:22:35 INFO TaskSetManager: Starting task 3.0 in stage 23.0 (TID 68, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:35 INFO Executor: Running task 1.0 in stage 23.0 (TID 66)
18/02/28 14:22:35 INFO Executor: Running task 0.0 in stage 23.0 (TID 65)
18/02/28 14:22:35 INFO Executor: Running task 2.0 in stage 23.0 (TID 67)
18/02/28 14:22:35 INFO Executor: Running task 3.0 in stage 23.0 (TID 68)
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:22:35 INFO Executor: Finished task 2.0 in stage 23.0 (TID 67). 3438 bytes result sent to driver
18/02/28 14:22:35 INFO Executor: Finished task 3.0 in stage 23.0 (TID 68). 3481 bytes result sent to driver
18/02/28 14:22:35 INFO Executor: Finished task 0.0 in stage 23.0 (TID 65). 3438 bytes result sent to driver
18/02/28 14:22:35 INFO TaskSetManager: Finished task 2.0 in stage 23.0 (TID 67) in 25 ms on localhost (executor driver) (1/4)
18/02/28 14:22:35 INFO Executor: Finished task 1.0 in stage 23.0 (TID 66). 3524 bytes result sent to driver
18/02/28 14:22:35 INFO TaskSetManager: Finished task 3.0 in stage 23.0 (TID 68) in 25 ms on localhost (executor driver) (2/4)
18/02/28 14:22:35 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 65) in 26 ms on localhost (executor driver) (3/4)
18/02/28 14:22:35 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 66) in 25 ms on localhost (executor driver) (4/4)
18/02/28 14:22:35 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
18/02/28 14:22:35 INFO DAGScheduler: ResultStage 23 (treeAggregate at LogisticRegression.scala:1892) finished in 0.028 s
18/02/28 14:22:35 INFO DAGScheduler: Job 13 finished: treeAggregate at LogisticRegression.scala:1892, took 0.036078 s
18/02/28 14:22:35 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
18/02/28 14:22:35 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
18/02/28 14:22:35 INFO TorrentBroadcast: Destroying Broadcast(26) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:22:35 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:61672 in memory (size: 154.0 B, free: 345.1 MB)
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 104.0 B, free 344.3 MB)
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.3 MB)
18/02/28 14:22:35 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:61672 (size: 186.0 B, free: 345.1 MB)
18/02/28 14:22:35 INFO SparkContext: Created broadcast 28 from broadcast at LogisticRegression.scala:1879
18/02/28 14:22:35 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:22:35 INFO DAGScheduler: Got job 14 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:22:35 INFO DAGScheduler: Final stage: ResultStage 24 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:22:35 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:22:35 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:35 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[88] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 74.1 KB, free 344.2 MB)
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 29.2 KB, free 344.2 MB)
18/02/28 14:22:35 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:61672 (size: 29.2 KB, free: 345.1 MB)
18/02/28 14:22:35 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:35 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 24 (MapPartitionsRDD[88] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:35 INFO TaskSchedulerImpl: Adding task set 24.0 with 4 tasks
18/02/28 14:22:35 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 69, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:35 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 70, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:35 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 71, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:22:35 INFO TaskSetManager: Starting task 3.0 in stage 24.0 (TID 72, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:35 INFO Executor: Running task 1.0 in stage 24.0 (TID 70)
18/02/28 14:22:35 INFO Executor: Running task 2.0 in stage 24.0 (TID 71)
18/02/28 14:22:35 INFO Executor: Running task 3.0 in stage 24.0 (TID 72)
18/02/28 14:22:35 INFO Executor: Running task 0.0 in stage 24.0 (TID 69)
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:22:35 INFO Executor: Finished task 3.0 in stage 24.0 (TID 72). 3481 bytes result sent to driver
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:22:35 INFO Executor: Finished task 0.0 in stage 24.0 (TID 69). 3438 bytes result sent to driver
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:22:35 INFO Executor: Finished task 2.0 in stage 24.0 (TID 71). 3481 bytes result sent to driver
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:22:35 INFO TaskSetManager: Finished task 3.0 in stage 24.0 (TID 72) in 15 ms on localhost (executor driver) (1/4)
18/02/28 14:22:35 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 69) in 16 ms on localhost (executor driver) (2/4)
18/02/28 14:22:35 INFO Executor: Finished task 1.0 in stage 24.0 (TID 70). 3438 bytes result sent to driver
18/02/28 14:22:35 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 71) in 18 ms on localhost (executor driver) (3/4)
18/02/28 14:22:35 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 70) in 19 ms on localhost (executor driver) (4/4)
18/02/28 14:22:35 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
18/02/28 14:22:35 INFO DAGScheduler: ResultStage 24 (treeAggregate at LogisticRegression.scala:1892) finished in 0.019 s
18/02/28 14:22:35 INFO DAGScheduler: Job 14 finished: treeAggregate at LogisticRegression.scala:1892, took 0.025718 s
18/02/28 14:22:35 INFO TorrentBroadcast: Destroying Broadcast(28) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:22:35 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:61672 in memory (size: 186.0 B, free: 345.1 MB)
18/02/28 14:22:35 INFO LBFGS: Step Size: 1.000
18/02/28 14:22:35 INFO LBFGS: Val and Grad Norm: 0.466797 (rel: 0.118) 0.202637
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 104.0 B, free 344.2 MB)
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.2 MB)
18/02/28 14:22:35 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:61672 (size: 186.0 B, free: 345.1 MB)
18/02/28 14:22:35 INFO SparkContext: Created broadcast 30 from broadcast at LogisticRegression.scala:1879
18/02/28 14:22:35 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:22:35 INFO DAGScheduler: Got job 15 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:22:35 INFO DAGScheduler: Final stage: ResultStage 25 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:22:35 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:22:35 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:35 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[89] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 74.1 KB, free 344.1 MB)
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 29.2 KB, free 344.1 MB)
18/02/28 14:22:35 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:61672 (size: 29.2 KB, free: 345.0 MB)
18/02/28 14:22:35 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:35 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 25 (MapPartitionsRDD[89] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:35 INFO TaskSchedulerImpl: Adding task set 25.0 with 4 tasks
18/02/28 14:22:35 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 73, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:35 INFO TaskSetManager: Starting task 1.0 in stage 25.0 (TID 74, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:35 INFO TaskSetManager: Starting task 2.0 in stage 25.0 (TID 75, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:22:35 INFO TaskSetManager: Starting task 3.0 in stage 25.0 (TID 76, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:35 INFO Executor: Running task 0.0 in stage 25.0 (TID 73)
18/02/28 14:22:35 INFO Executor: Running task 1.0 in stage 25.0 (TID 74)
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:22:35 INFO Executor: Finished task 1.0 in stage 25.0 (TID 74). 3481 bytes result sent to driver
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:22:35 INFO Executor: Running task 2.0 in stage 25.0 (TID 75)
18/02/28 14:22:35 INFO Executor: Finished task 0.0 in stage 25.0 (TID 73). 3524 bytes result sent to driver
18/02/28 14:22:35 INFO Executor: Running task 3.0 in stage 25.0 (TID 76)
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:22:35 INFO Executor: Finished task 2.0 in stage 25.0 (TID 75). 3481 bytes result sent to driver
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:22:35 INFO Executor: Finished task 3.0 in stage 25.0 (TID 76). 3438 bytes result sent to driver
18/02/28 14:22:35 INFO TaskSetManager: Finished task 1.0 in stage 25.0 (TID 74) in 26 ms on localhost (executor driver) (1/4)
18/02/28 14:22:35 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 73) in 27 ms on localhost (executor driver) (2/4)
18/02/28 14:22:35 INFO TaskSetManager: Finished task 2.0 in stage 25.0 (TID 75) in 27 ms on localhost (executor driver) (3/4)
18/02/28 14:22:35 INFO TaskSetManager: Finished task 3.0 in stage 25.0 (TID 76) in 28 ms on localhost (executor driver) (4/4)
18/02/28 14:22:35 INFO DAGScheduler: ResultStage 25 (treeAggregate at LogisticRegression.scala:1892) finished in 0.029 s
18/02/28 14:22:35 INFO DAGScheduler: Job 15 finished: treeAggregate at LogisticRegression.scala:1892, took 0.040036 s
18/02/28 14:22:35 INFO TorrentBroadcast: Destroying Broadcast(30) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:22:35 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
18/02/28 14:22:35 INFO LBFGS: Step Size: 1.000
18/02/28 14:22:35 INFO LBFGS: Val and Grad Norm: 0.340621 (rel: 0.270) 0.0822789
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 104.0 B, free 344.1 MB)
18/02/28 14:22:35 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:61672 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.1 MB)
18/02/28 14:22:35 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:61672 (size: 186.0 B, free: 345.0 MB)
18/02/28 14:22:35 INFO SparkContext: Created broadcast 32 from broadcast at LogisticRegression.scala:1879
18/02/28 14:22:35 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:22:35 INFO DAGScheduler: Got job 16 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:22:35 INFO DAGScheduler: Final stage: ResultStage 26 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:22:35 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:22:35 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:35 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[90] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 74.1 KB, free 344.0 MB)
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 29.2 KB, free 344.0 MB)
18/02/28 14:22:35 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:61672 (size: 29.2 KB, free: 345.0 MB)
18/02/28 14:22:35 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:35 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 26 (MapPartitionsRDD[90] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:35 INFO TaskSchedulerImpl: Adding task set 26.0 with 4 tasks
18/02/28 14:22:35 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 77, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:35 INFO TaskSetManager: Starting task 1.0 in stage 26.0 (TID 78, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:35 INFO TaskSetManager: Starting task 2.0 in stage 26.0 (TID 79, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:22:35 INFO TaskSetManager: Starting task 3.0 in stage 26.0 (TID 80, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:35 INFO Executor: Running task 0.0 in stage 26.0 (TID 77)
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:22:35 INFO Executor: Finished task 0.0 in stage 26.0 (TID 77). 3481 bytes result sent to driver
18/02/28 14:22:35 INFO Executor: Running task 2.0 in stage 26.0 (TID 79)
18/02/28 14:22:35 INFO Executor: Running task 1.0 in stage 26.0 (TID 78)
18/02/28 14:22:35 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 77) in 12 ms on localhost (executor driver) (1/4)
18/02/28 14:22:35 INFO Executor: Running task 3.0 in stage 26.0 (TID 80)
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:22:35 INFO Executor: Finished task 2.0 in stage 26.0 (TID 79). 3438 bytes result sent to driver
18/02/28 14:22:35 INFO Executor: Finished task 1.0 in stage 26.0 (TID 78). 3438 bytes result sent to driver
18/02/28 14:22:35 INFO TaskSetManager: Finished task 2.0 in stage 26.0 (TID 79) in 15 ms on localhost (executor driver) (2/4)
18/02/28 14:22:35 INFO TaskSetManager: Finished task 1.0 in stage 26.0 (TID 78) in 15 ms on localhost (executor driver) (3/4)
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:22:35 INFO Executor: Finished task 3.0 in stage 26.0 (TID 80). 3481 bytes result sent to driver
18/02/28 14:22:35 INFO TaskSetManager: Finished task 3.0 in stage 26.0 (TID 80) in 17 ms on localhost (executor driver) (4/4)
18/02/28 14:22:35 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
18/02/28 14:22:35 INFO DAGScheduler: ResultStage 26 (treeAggregate at LogisticRegression.scala:1892) finished in 0.018 s
18/02/28 14:22:35 INFO DAGScheduler: Job 16 finished: treeAggregate at LogisticRegression.scala:1892, took 0.025003 s
18/02/28 14:22:35 INFO TorrentBroadcast: Destroying Broadcast(32) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:22:35 INFO LBFGS: Step Size: 1.000
18/02/28 14:22:35 INFO LBFGS: Val and Grad Norm: 0.302276 (rel: 0.113) 0.0482409
18/02/28 14:22:35 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:61672 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 104.0 B, free 344.0 MB)
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.0 MB)
18/02/28 14:22:35 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:61672 (size: 186.0 B, free: 345.0 MB)
18/02/28 14:22:35 INFO SparkContext: Created broadcast 34 from broadcast at LogisticRegression.scala:1879
18/02/28 14:22:35 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:22:35 INFO DAGScheduler: Got job 17 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:22:35 INFO DAGScheduler: Final stage: ResultStage 27 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:22:35 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:22:35 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:35 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[91] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 74.1 KB, free 343.9 MB)
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 29.2 KB, free 343.9 MB)
18/02/28 14:22:35 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:61672 (size: 29.2 KB, free: 345.0 MB)
18/02/28 14:22:35 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:35 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 27 (MapPartitionsRDD[91] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:35 INFO TaskSchedulerImpl: Adding task set 27.0 with 4 tasks
18/02/28 14:22:35 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 81, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:35 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 82, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:35 INFO TaskSetManager: Starting task 2.0 in stage 27.0 (TID 83, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:22:35 INFO TaskSetManager: Starting task 3.0 in stage 27.0 (TID 84, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:35 INFO Executor: Running task 1.0 in stage 27.0 (TID 82)
18/02/28 14:22:35 INFO Executor: Running task 0.0 in stage 27.0 (TID 81)
18/02/28 14:22:35 INFO Executor: Running task 2.0 in stage 27.0 (TID 83)
18/02/28 14:22:35 INFO Executor: Running task 3.0 in stage 27.0 (TID 84)
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:22:35 INFO Executor: Finished task 0.0 in stage 27.0 (TID 81). 3438 bytes result sent to driver
18/02/28 14:22:35 INFO Executor: Finished task 2.0 in stage 27.0 (TID 83). 3481 bytes result sent to driver
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:22:35 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 81) in 10 ms on localhost (executor driver) (1/4)
18/02/28 14:22:35 INFO Executor: Finished task 1.0 in stage 27.0 (TID 82). 3481 bytes result sent to driver
18/02/28 14:22:35 INFO Executor: Finished task 3.0 in stage 27.0 (TID 84). 3524 bytes result sent to driver
18/02/28 14:22:35 INFO TaskSetManager: Finished task 2.0 in stage 27.0 (TID 83) in 12 ms on localhost (executor driver) (2/4)
18/02/28 14:22:35 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 82) in 12 ms on localhost (executor driver) (3/4)
18/02/28 14:22:35 INFO TaskSetManager: Finished task 3.0 in stage 27.0 (TID 84) in 12 ms on localhost (executor driver) (4/4)
18/02/28 14:22:35 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
18/02/28 14:22:35 INFO DAGScheduler: ResultStage 27 (treeAggregate at LogisticRegression.scala:1892) finished in 0.012 s
18/02/28 14:22:35 INFO DAGScheduler: Job 17 finished: treeAggregate at LogisticRegression.scala:1892, took 0.019460 s
18/02/28 14:22:35 INFO TorrentBroadcast: Destroying Broadcast(34) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:22:35 INFO LBFGS: Step Size: 1.000
18/02/28 14:22:35 INFO LBFGS: Val and Grad Norm: 0.274043 (rel: 0.0934) 0.0337261
18/02/28 14:22:35 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:61672 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 104.0 B, free 343.9 MB)
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.9 MB)
18/02/28 14:22:35 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:61672 (size: 186.0 B, free: 345.0 MB)
18/02/28 14:22:35 INFO SparkContext: Created broadcast 36 from broadcast at LogisticRegression.scala:1879
18/02/28 14:22:35 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:22:35 INFO DAGScheduler: Got job 18 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:22:35 INFO DAGScheduler: Final stage: ResultStage 28 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:22:35 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:22:35 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:35 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[92] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 74.1 KB, free 343.8 MB)
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 29.2 KB, free 343.8 MB)
18/02/28 14:22:35 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:61672 (size: 29.2 KB, free: 344.9 MB)
18/02/28 14:22:35 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:35 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 28 (MapPartitionsRDD[92] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:35 INFO TaskSchedulerImpl: Adding task set 28.0 with 4 tasks
18/02/28 14:22:35 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 85, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:35 INFO TaskSetManager: Starting task 1.0 in stage 28.0 (TID 86, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:35 INFO TaskSetManager: Starting task 2.0 in stage 28.0 (TID 87, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:22:35 INFO TaskSetManager: Starting task 3.0 in stage 28.0 (TID 88, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:35 INFO Executor: Running task 1.0 in stage 28.0 (TID 86)
18/02/28 14:22:35 INFO Executor: Running task 3.0 in stage 28.0 (TID 88)
18/02/28 14:22:35 INFO Executor: Running task 2.0 in stage 28.0 (TID 87)
18/02/28 14:22:35 INFO Executor: Running task 0.0 in stage 28.0 (TID 85)
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:22:35 INFO Executor: Finished task 1.0 in stage 28.0 (TID 86). 3481 bytes result sent to driver
18/02/28 14:22:35 INFO Executor: Finished task 3.0 in stage 28.0 (TID 88). 3481 bytes result sent to driver
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:22:35 INFO Executor: Finished task 2.0 in stage 28.0 (TID 87). 3438 bytes result sent to driver
18/02/28 14:22:35 INFO TaskSetManager: Finished task 1.0 in stage 28.0 (TID 86) in 9 ms on localhost (executor driver) (1/4)
18/02/28 14:22:35 INFO TaskSetManager: Finished task 3.0 in stage 28.0 (TID 88) in 8 ms on localhost (executor driver) (2/4)
18/02/28 14:22:35 INFO Executor: Finished task 0.0 in stage 28.0 (TID 85). 3438 bytes result sent to driver
18/02/28 14:22:35 INFO TaskSetManager: Finished task 2.0 in stage 28.0 (TID 87) in 10 ms on localhost (executor driver) (3/4)
18/02/28 14:22:35 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 85) in 11 ms on localhost (executor driver) (4/4)
18/02/28 14:22:35 INFO DAGScheduler: ResultStage 28 (treeAggregate at LogisticRegression.scala:1892) finished in 0.012 s
18/02/28 14:22:35 INFO DAGScheduler: Job 18 finished: treeAggregate at LogisticRegression.scala:1892, took 0.022006 s
18/02/28 14:22:35 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
18/02/28 14:22:35 INFO TorrentBroadcast: Destroying Broadcast(36) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:22:35 INFO LBFGS: Step Size: 1.000
18/02/28 14:22:35 INFO LBFGS: Val and Grad Norm: 0.264675 (rel: 0.0342) 0.0104269
18/02/28 14:22:35 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:61672 in memory (size: 186.0 B, free: 344.9 MB)
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 104.0 B, free 343.8 MB)
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.8 MB)
18/02/28 14:22:35 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:61672 (size: 186.0 B, free: 344.9 MB)
18/02/28 14:22:35 INFO SparkContext: Created broadcast 38 from broadcast at LogisticRegression.scala:1879
18/02/28 14:22:35 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:22:35 INFO DAGScheduler: Got job 19 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:22:35 INFO DAGScheduler: Final stage: ResultStage 29 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:22:35 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:22:35 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:35 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[93] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 74.1 KB, free 343.7 MB)
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 29.2 KB, free 343.7 MB)
18/02/28 14:22:35 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:61672 (size: 29.2 KB, free: 344.9 MB)
18/02/28 14:22:35 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:35 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 29 (MapPartitionsRDD[93] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:35 INFO TaskSchedulerImpl: Adding task set 29.0 with 4 tasks
18/02/28 14:22:35 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 89, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:35 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 90, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:35 INFO TaskSetManager: Starting task 2.0 in stage 29.0 (TID 91, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:22:35 INFO TaskSetManager: Starting task 3.0 in stage 29.0 (TID 92, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:35 INFO Executor: Running task 0.0 in stage 29.0 (TID 89)
18/02/28 14:22:35 INFO Executor: Running task 1.0 in stage 29.0 (TID 90)
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:22:35 INFO Executor: Running task 2.0 in stage 29.0 (TID 91)
18/02/28 14:22:35 INFO Executor: Running task 3.0 in stage 29.0 (TID 92)
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:22:35 INFO Executor: Finished task 0.0 in stage 29.0 (TID 89). 3481 bytes result sent to driver
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:22:35 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 89) in 16 ms on localhost (executor driver) (1/4)
18/02/28 14:22:35 INFO Executor: Finished task 1.0 in stage 29.0 (TID 90). 3481 bytes result sent to driver
18/02/28 14:22:35 INFO Executor: Finished task 3.0 in stage 29.0 (TID 92). 3438 bytes result sent to driver
18/02/28 14:22:35 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 90) in 16 ms on localhost (executor driver) (2/4)
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:22:35 INFO TaskSetManager: Finished task 3.0 in stage 29.0 (TID 92) in 17 ms on localhost (executor driver) (3/4)
18/02/28 14:22:35 INFO Executor: Finished task 2.0 in stage 29.0 (TID 91). 3438 bytes result sent to driver
18/02/28 14:22:35 INFO TaskSetManager: Finished task 2.0 in stage 29.0 (TID 91) in 20 ms on localhost (executor driver) (4/4)
18/02/28 14:22:35 INFO DAGScheduler: ResultStage 29 (treeAggregate at LogisticRegression.scala:1892) finished in 0.021 s
18/02/28 14:22:35 INFO DAGScheduler: Job 19 finished: treeAggregate at LogisticRegression.scala:1892, took 0.027173 s
18/02/28 14:22:35 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
18/02/28 14:22:35 INFO TorrentBroadcast: Destroying Broadcast(38) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:22:35 INFO LBFGS: Step Size: 1.000
18/02/28 14:22:35 INFO LBFGS: Val and Grad Norm: 0.262236 (rel: 0.00922) 0.00481215
18/02/28 14:22:35 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:61672 in memory (size: 186.0 B, free: 344.9 MB)
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 104.0 B, free 343.7 MB)
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.7 MB)
18/02/28 14:22:35 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:61672 (size: 186.0 B, free: 344.9 MB)
18/02/28 14:22:35 INFO SparkContext: Created broadcast 40 from broadcast at LogisticRegression.scala:1879
18/02/28 14:22:35 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:22:35 INFO DAGScheduler: Got job 20 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:22:35 INFO DAGScheduler: Final stage: ResultStage 30 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:22:35 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:22:35 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:35 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[94] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 74.1 KB, free 343.6 MB)
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 29.2 KB, free 343.6 MB)
18/02/28 14:22:35 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:61672 (size: 29.2 KB, free: 344.9 MB)
18/02/28 14:22:35 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:35 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 30 (MapPartitionsRDD[94] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:35 INFO TaskSchedulerImpl: Adding task set 30.0 with 4 tasks
18/02/28 14:22:35 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 93, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:35 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 94, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:35 INFO TaskSetManager: Starting task 2.0 in stage 30.0 (TID 95, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:22:35 INFO TaskSetManager: Starting task 3.0 in stage 30.0 (TID 96, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:35 INFO Executor: Running task 2.0 in stage 30.0 (TID 95)
18/02/28 14:22:35 INFO Executor: Running task 3.0 in stage 30.0 (TID 96)
18/02/28 14:22:35 INFO Executor: Running task 1.0 in stage 30.0 (TID 94)
18/02/28 14:22:35 INFO Executor: Running task 0.0 in stage 30.0 (TID 93)
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:22:35 INFO Executor: Finished task 3.0 in stage 30.0 (TID 96). 3438 bytes result sent to driver
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:22:35 INFO Executor: Finished task 2.0 in stage 30.0 (TID 95). 3438 bytes result sent to driver
18/02/28 14:22:35 INFO Executor: Finished task 0.0 in stage 30.0 (TID 93). 3438 bytes result sent to driver
18/02/28 14:22:35 INFO TaskSetManager: Finished task 3.0 in stage 30.0 (TID 96) in 6 ms on localhost (executor driver) (1/4)
18/02/28 14:22:35 INFO TaskSetManager: Finished task 2.0 in stage 30.0 (TID 95) in 7 ms on localhost (executor driver) (2/4)
18/02/28 14:22:35 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:22:35 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 93) in 8 ms on localhost (executor driver) (3/4)
18/02/28 14:22:35 INFO Executor: Finished task 1.0 in stage 30.0 (TID 94). 3438 bytes result sent to driver
18/02/28 14:22:35 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 94) in 10 ms on localhost (executor driver) (4/4)
18/02/28 14:22:35 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
18/02/28 14:22:35 INFO DAGScheduler: ResultStage 30 (treeAggregate at LogisticRegression.scala:1892) finished in 0.010 s
18/02/28 14:22:35 INFO DAGScheduler: Job 20 finished: treeAggregate at LogisticRegression.scala:1892, took 0.016421 s
18/02/28 14:22:35 INFO TorrentBroadcast: Destroying Broadcast(40) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:22:35 INFO LBFGS: Step Size: 1.000
18/02/28 14:22:35 INFO LBFGS: Val and Grad Norm: 0.261606 (rel: 0.00240) 0.00662251
18/02/28 14:22:35 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:61672 in memory (size: 186.0 B, free: 344.9 MB)
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 104.0 B, free 343.6 MB)
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.6 MB)
18/02/28 14:22:35 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:61672 (size: 186.0 B, free: 344.9 MB)
18/02/28 14:22:35 INFO SparkContext: Created broadcast 42 from broadcast at LogisticRegression.scala:1879
18/02/28 14:22:35 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:22:35 INFO DAGScheduler: Got job 21 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:22:35 INFO DAGScheduler: Final stage: ResultStage 31 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:22:35 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:22:35 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:35 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[95] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:22:35 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 74.1 KB, free 343.5 MB)
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 29.2 KB, free 343.4 MB)
18/02/28 14:22:36 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:61672 (size: 29.2 KB, free: 344.9 MB)
18/02/28 14:22:36 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:36 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 31 (MapPartitionsRDD[95] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:36 INFO TaskSchedulerImpl: Adding task set 31.0 with 4 tasks
18/02/28 14:22:36 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 97, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 1.0 in stage 31.0 (TID 98, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 2.0 in stage 31.0 (TID 99, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 3.0 in stage 31.0 (TID 100, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:36 INFO Executor: Running task 1.0 in stage 31.0 (TID 98)
18/02/28 14:22:36 INFO Executor: Running task 3.0 in stage 31.0 (TID 100)
18/02/28 14:22:36 INFO Executor: Running task 2.0 in stage 31.0 (TID 99)
18/02/28 14:22:36 INFO Executor: Running task 0.0 in stage 31.0 (TID 97)
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:22:36 INFO Executor: Finished task 3.0 in stage 31.0 (TID 100). 3438 bytes result sent to driver
18/02/28 14:22:36 INFO Executor: Finished task 2.0 in stage 31.0 (TID 99). 3438 bytes result sent to driver
18/02/28 14:22:36 INFO Executor: Finished task 1.0 in stage 31.0 (TID 98). 3438 bytes result sent to driver
18/02/28 14:22:36 INFO TaskSetManager: Finished task 3.0 in stage 31.0 (TID 100) in 7 ms on localhost (executor driver) (1/4)
18/02/28 14:22:36 INFO TaskSetManager: Finished task 1.0 in stage 31.0 (TID 98) in 20 ms on localhost (executor driver) (2/4)
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:22:36 INFO Executor: Finished task 0.0 in stage 31.0 (TID 97). 3481 bytes result sent to driver
18/02/28 14:22:36 INFO TaskSetManager: Finished task 2.0 in stage 31.0 (TID 99) in 25 ms on localhost (executor driver) (3/4)
18/02/28 14:22:36 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 97) in 25 ms on localhost (executor driver) (4/4)
18/02/28 14:22:36 INFO DAGScheduler: ResultStage 31 (treeAggregate at LogisticRegression.scala:1892) finished in 0.027 s
18/02/28 14:22:36 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:61672 in memory (size: 29.2 KB, free: 344.9 MB)
18/02/28 14:22:36 INFO DAGScheduler: Job 21 finished: treeAggregate at LogisticRegression.scala:1892, took 0.031103 s
18/02/28 14:22:36 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
18/02/28 14:22:36 INFO TorrentBroadcast: Destroying Broadcast(42) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:22:36 INFO LBFGS: Step Size: 1.000
18/02/28 14:22:36 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:61672 in memory (size: 29.2 KB, free: 344.9 MB)
18/02/28 14:22:36 INFO LBFGS: Val and Grad Norm: 0.261168 (rel: 0.00168) 0.00395239
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 104.0 B, free 343.7 MB)
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.7 MB)
18/02/28 14:22:36 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:61672 in memory (size: 186.0 B, free: 344.9 MB)
18/02/28 14:22:36 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:61672 (size: 186.0 B, free: 344.9 MB)
18/02/28 14:22:36 INFO SparkContext: Created broadcast 44 from broadcast at LogisticRegression.scala:1879
18/02/28 14:22:36 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:61672 in memory (size: 29.2 KB, free: 344.9 MB)
18/02/28 14:22:36 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:61672 in memory (size: 29.2 KB, free: 345.0 MB)
18/02/28 14:22:36 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:61672 in memory (size: 29.2 KB, free: 345.0 MB)
18/02/28 14:22:36 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:61672 in memory (size: 29.2 KB, free: 345.0 MB)
18/02/28 14:22:36 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:22:36 INFO DAGScheduler: Got job 22 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:22:36 INFO DAGScheduler: Final stage: ResultStage 32 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:22:36 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:22:36 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:36 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[96] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 74.1 KB, free 344.0 MB)
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 29.2 KB, free 344.0 MB)
18/02/28 14:22:36 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:61672 (size: 29.2 KB, free: 345.0 MB)
18/02/28 14:22:36 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:36 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 32 (MapPartitionsRDD[96] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:36 INFO TaskSchedulerImpl: Adding task set 32.0 with 4 tasks
18/02/28 14:22:36 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:61672 in memory (size: 29.2 KB, free: 345.0 MB)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 101, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 102, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 2.0 in stage 32.0 (TID 103, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 3.0 in stage 32.0 (TID 104, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:36 INFO Executor: Running task 0.0 in stage 32.0 (TID 101)
18/02/28 14:22:36 INFO Executor: Running task 1.0 in stage 32.0 (TID 102)
18/02/28 14:22:36 INFO Executor: Running task 2.0 in stage 32.0 (TID 103)
18/02/28 14:22:36 INFO Executor: Running task 3.0 in stage 32.0 (TID 104)
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:22:36 INFO Executor: Finished task 2.0 in stage 32.0 (TID 103). 3438 bytes result sent to driver
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:22:36 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:61672 in memory (size: 29.2 KB, free: 345.1 MB)
18/02/28 14:22:36 INFO Executor: Finished task 1.0 in stage 32.0 (TID 102). 3438 bytes result sent to driver
18/02/28 14:22:36 INFO TaskSetManager: Finished task 2.0 in stage 32.0 (TID 103) in 10 ms on localhost (executor driver) (1/4)
18/02/28 14:22:36 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 102) in 10 ms on localhost (executor driver) (2/4)
18/02/28 14:22:36 INFO Executor: Finished task 3.0 in stage 32.0 (TID 104). 3438 bytes result sent to driver
18/02/28 14:22:36 INFO TaskSetManager: Finished task 3.0 in stage 32.0 (TID 104) in 11 ms on localhost (executor driver) (3/4)
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:22:36 INFO Executor: Finished task 0.0 in stage 32.0 (TID 101). 3524 bytes result sent to driver
18/02/28 14:22:36 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:61672 in memory (size: 29.2 KB, free: 345.1 MB)
18/02/28 14:22:36 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 101) in 19 ms on localhost (executor driver) (4/4)
18/02/28 14:22:36 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
18/02/28 14:22:36 INFO DAGScheduler: ResultStage 32 (treeAggregate at LogisticRegression.scala:1892) finished in 0.020 s
18/02/28 14:22:36 INFO DAGScheduler: Job 22 finished: treeAggregate at LogisticRegression.scala:1892, took 0.027199 s
18/02/28 14:22:36 INFO TorrentBroadcast: Destroying Broadcast(44) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:22:36 INFO LBFGS: Step Size: 1.000
18/02/28 14:22:36 INFO LBFGS: Val and Grad Norm: 0.260695 (rel: 0.00181) 0.00264968
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 104.0 B, free 344.3 MB)
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.3 MB)
18/02/28 14:22:36 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:61672 (size: 186.0 B, free: 345.1 MB)
18/02/28 14:22:36 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:61672 in memory (size: 186.0 B, free: 345.1 MB)
18/02/28 14:22:36 INFO SparkContext: Created broadcast 46 from broadcast at LogisticRegression.scala:1879
18/02/28 14:22:36 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:22:36 INFO DAGScheduler: Got job 23 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:22:36 INFO DAGScheduler: Final stage: ResultStage 33 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:22:36 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:22:36 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:36 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[97] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 74.1 KB, free 344.2 MB)
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 29.2 KB, free 344.2 MB)
18/02/28 14:22:36 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:61672 (size: 29.2 KB, free: 345.1 MB)
18/02/28 14:22:36 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:36 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 33 (MapPartitionsRDD[97] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:36 INFO TaskSchedulerImpl: Adding task set 33.0 with 4 tasks
18/02/28 14:22:36 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 105, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 1.0 in stage 33.0 (TID 106, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 2.0 in stage 33.0 (TID 107, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 3.0 in stage 33.0 (TID 108, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:36 INFO Executor: Running task 0.0 in stage 33.0 (TID 105)
18/02/28 14:22:36 INFO Executor: Running task 1.0 in stage 33.0 (TID 106)
18/02/28 14:22:36 INFO Executor: Running task 2.0 in stage 33.0 (TID 107)
18/02/28 14:22:36 INFO Executor: Running task 3.0 in stage 33.0 (TID 108)
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:22:36 INFO Executor: Finished task 1.0 in stage 33.0 (TID 106). 3524 bytes result sent to driver
18/02/28 14:22:36 INFO Executor: Finished task 3.0 in stage 33.0 (TID 108). 3481 bytes result sent to driver
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:22:36 INFO Executor: Finished task 2.0 in stage 33.0 (TID 107). 3481 bytes result sent to driver
18/02/28 14:22:36 INFO TaskSetManager: Finished task 1.0 in stage 33.0 (TID 106) in 8 ms on localhost (executor driver) (1/4)
18/02/28 14:22:36 INFO TaskSetManager: Finished task 3.0 in stage 33.0 (TID 108) in 8 ms on localhost (executor driver) (2/4)
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:22:36 INFO TaskSetManager: Finished task 2.0 in stage 33.0 (TID 107) in 9 ms on localhost (executor driver) (3/4)
18/02/28 14:22:36 INFO Executor: Finished task 0.0 in stage 33.0 (TID 105). 3438 bytes result sent to driver
18/02/28 14:22:36 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 105) in 12 ms on localhost (executor driver) (4/4)
18/02/28 14:22:36 INFO DAGScheduler: ResultStage 33 (treeAggregate at LogisticRegression.scala:1892) finished in 0.013 s
18/02/28 14:22:36 INFO DAGScheduler: Job 23 finished: treeAggregate at LogisticRegression.scala:1892, took 0.020104 s
18/02/28 14:22:36 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
18/02/28 14:22:36 INFO TorrentBroadcast: Destroying Broadcast(46) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:22:36 INFO LBFGS: Step Size: 1.000
18/02/28 14:22:36 INFO LBFGS: Val and Grad Norm: 0.260425 (rel: 0.00104) 0.00266028
18/02/28 14:22:36 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:61672 in memory (size: 186.0 B, free: 345.1 MB)
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 104.0 B, free 344.2 MB)
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.2 MB)
18/02/28 14:22:36 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:61672 (size: 186.0 B, free: 345.1 MB)
18/02/28 14:22:36 INFO SparkContext: Created broadcast 48 from broadcast at LogisticRegression.scala:1879
18/02/28 14:22:36 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:22:36 INFO DAGScheduler: Got job 24 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:22:36 INFO DAGScheduler: Final stage: ResultStage 34 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:22:36 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:22:36 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:36 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[98] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 74.1 KB, free 344.1 MB)
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 29.2 KB, free 344.1 MB)
18/02/28 14:22:36 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:61672 (size: 29.2 KB, free: 345.0 MB)
18/02/28 14:22:36 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:36 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 34 (MapPartitionsRDD[98] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:36 INFO TaskSchedulerImpl: Adding task set 34.0 with 4 tasks
18/02/28 14:22:36 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 109, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 1.0 in stage 34.0 (TID 110, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 2.0 in stage 34.0 (TID 111, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 3.0 in stage 34.0 (TID 112, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:36 INFO Executor: Running task 0.0 in stage 34.0 (TID 109)
18/02/28 14:22:36 INFO Executor: Running task 1.0 in stage 34.0 (TID 110)
18/02/28 14:22:36 INFO Executor: Running task 2.0 in stage 34.0 (TID 111)
18/02/28 14:22:36 INFO Executor: Running task 3.0 in stage 34.0 (TID 112)
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:22:36 INFO Executor: Finished task 1.0 in stage 34.0 (TID 110). 3481 bytes result sent to driver
18/02/28 14:22:36 INFO Executor: Finished task 0.0 in stage 34.0 (TID 109). 3438 bytes result sent to driver
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:22:36 INFO Executor: Finished task 2.0 in stage 34.0 (TID 111). 3438 bytes result sent to driver
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:22:36 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 109) in 8 ms on localhost (executor driver) (1/4)
18/02/28 14:22:36 INFO Executor: Finished task 3.0 in stage 34.0 (TID 112). 3438 bytes result sent to driver
18/02/28 14:22:36 INFO TaskSetManager: Finished task 2.0 in stage 34.0 (TID 111) in 7 ms on localhost (executor driver) (2/4)
18/02/28 14:22:36 INFO TaskSetManager: Finished task 1.0 in stage 34.0 (TID 110) in 8 ms on localhost (executor driver) (3/4)
18/02/28 14:22:36 INFO TaskSetManager: Finished task 3.0 in stage 34.0 (TID 112) in 8 ms on localhost (executor driver) (4/4)
18/02/28 14:22:36 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
18/02/28 14:22:36 INFO DAGScheduler: ResultStage 34 (treeAggregate at LogisticRegression.scala:1892) finished in 0.010 s
18/02/28 14:22:36 INFO DAGScheduler: Job 24 finished: treeAggregate at LogisticRegression.scala:1892, took 0.015517 s
18/02/28 14:22:36 INFO TorrentBroadcast: Destroying Broadcast(48) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:22:36 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:61672 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 104.0 B, free 344.1 MB)
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.1 MB)
18/02/28 14:22:36 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:61672 (size: 186.0 B, free: 345.0 MB)
18/02/28 14:22:36 INFO SparkContext: Created broadcast 50 from broadcast at LogisticRegression.scala:1879
18/02/28 14:22:36 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:22:36 INFO DAGScheduler: Got job 25 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:22:36 INFO DAGScheduler: Final stage: ResultStage 35 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:22:36 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:22:36 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:36 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[99] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 74.1 KB, free 344.0 MB)
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 29.2 KB, free 344.0 MB)
18/02/28 14:22:36 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:61672 (size: 29.2 KB, free: 345.0 MB)
18/02/28 14:22:36 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:36 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 35 (MapPartitionsRDD[99] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:36 INFO TaskSchedulerImpl: Adding task set 35.0 with 4 tasks
18/02/28 14:22:36 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 113, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 1.0 in stage 35.0 (TID 114, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 2.0 in stage 35.0 (TID 115, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 3.0 in stage 35.0 (TID 116, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:36 INFO Executor: Running task 0.0 in stage 35.0 (TID 113)
18/02/28 14:22:36 INFO Executor: Running task 2.0 in stage 35.0 (TID 115)
18/02/28 14:22:36 INFO Executor: Running task 1.0 in stage 35.0 (TID 114)
18/02/28 14:22:36 INFO Executor: Running task 3.0 in stage 35.0 (TID 116)
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:22:36 INFO Executor: Finished task 0.0 in stage 35.0 (TID 113). 3438 bytes result sent to driver
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:22:36 INFO Executor: Finished task 3.0 in stage 35.0 (TID 116). 3438 bytes result sent to driver
18/02/28 14:22:36 INFO Executor: Finished task 2.0 in stage 35.0 (TID 115). 3438 bytes result sent to driver
18/02/28 14:22:36 INFO Executor: Finished task 1.0 in stage 35.0 (TID 114). 3438 bytes result sent to driver
18/02/28 14:22:36 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 113) in 7 ms on localhost (executor driver) (1/4)
18/02/28 14:22:36 INFO TaskSetManager: Finished task 3.0 in stage 35.0 (TID 116) in 7 ms on localhost (executor driver) (2/4)
18/02/28 14:22:36 INFO TaskSetManager: Finished task 1.0 in stage 35.0 (TID 114) in 8 ms on localhost (executor driver) (3/4)
18/02/28 14:22:36 INFO TaskSetManager: Finished task 2.0 in stage 35.0 (TID 115) in 8 ms on localhost (executor driver) (4/4)
18/02/28 14:22:36 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
18/02/28 14:22:36 INFO DAGScheduler: ResultStage 35 (treeAggregate at LogisticRegression.scala:1892) finished in 0.008 s
18/02/28 14:22:36 INFO DAGScheduler: Job 25 finished: treeAggregate at LogisticRegression.scala:1892, took 0.014336 s
18/02/28 14:22:36 INFO TorrentBroadcast: Destroying Broadcast(50) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:22:36 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:61672 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 14:22:36 INFO StrongWolfeLineSearch: Line search t: 0.3937684805173288 fval: 0.26038715683120905 rhs: 0.26042495368401464 cdd: 4.83406566235663E-9
18/02/28 14:22:36 INFO LBFGS: Step Size: 0.3938
18/02/28 14:22:36 INFO LBFGS: Val and Grad Norm: 0.260387 (rel: 0.000145) 0.00113389
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 104.0 B, free 344.0 MB)
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 186.0 B, free 344.0 MB)
18/02/28 14:22:36 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:61672 (size: 186.0 B, free: 345.0 MB)
18/02/28 14:22:36 INFO SparkContext: Created broadcast 52 from broadcast at LogisticRegression.scala:1879
18/02/28 14:22:36 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:22:36 INFO DAGScheduler: Got job 26 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:22:36 INFO DAGScheduler: Final stage: ResultStage 36 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:22:36 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:22:36 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:36 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[100] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 74.1 KB, free 343.9 MB)
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 29.2 KB, free 343.9 MB)
18/02/28 14:22:36 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:61672 (size: 29.2 KB, free: 345.0 MB)
18/02/28 14:22:36 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:36 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 36 (MapPartitionsRDD[100] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:36 INFO TaskSchedulerImpl: Adding task set 36.0 with 4 tasks
18/02/28 14:22:36 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 117, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 1.0 in stage 36.0 (TID 118, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 2.0 in stage 36.0 (TID 119, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 3.0 in stage 36.0 (TID 120, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:36 INFO Executor: Running task 1.0 in stage 36.0 (TID 118)
18/02/28 14:22:36 INFO Executor: Running task 3.0 in stage 36.0 (TID 120)
18/02/28 14:22:36 INFO Executor: Running task 2.0 in stage 36.0 (TID 119)
18/02/28 14:22:36 INFO Executor: Running task 0.0 in stage 36.0 (TID 117)
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:22:36 INFO Executor: Finished task 3.0 in stage 36.0 (TID 120). 3395 bytes result sent to driver
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:22:36 INFO Executor: Finished task 1.0 in stage 36.0 (TID 118). 3438 bytes result sent to driver
18/02/28 14:22:36 INFO TaskSetManager: Finished task 3.0 in stage 36.0 (TID 120) in 5 ms on localhost (executor driver) (1/4)
18/02/28 14:22:36 INFO Executor: Finished task 0.0 in stage 36.0 (TID 117). 3438 bytes result sent to driver
18/02/28 14:22:36 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 117) in 7 ms on localhost (executor driver) (2/4)
18/02/28 14:22:36 INFO TaskSetManager: Finished task 1.0 in stage 36.0 (TID 118) in 7 ms on localhost (executor driver) (3/4)
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:22:36 INFO Executor: Finished task 2.0 in stage 36.0 (TID 119). 3438 bytes result sent to driver
18/02/28 14:22:36 INFO TaskSetManager: Finished task 2.0 in stage 36.0 (TID 119) in 11 ms on localhost (executor driver) (4/4)
18/02/28 14:22:36 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
18/02/28 14:22:36 INFO DAGScheduler: ResultStage 36 (treeAggregate at LogisticRegression.scala:1892) finished in 0.012 s
18/02/28 14:22:36 INFO DAGScheduler: Job 26 finished: treeAggregate at LogisticRegression.scala:1892, took 0.019251 s
18/02/28 14:22:36 INFO TorrentBroadcast: Destroying Broadcast(52) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:22:36 INFO LBFGS: Step Size: 1.000
18/02/28 14:22:36 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:61672 in memory (size: 186.0 B, free: 345.0 MB)
18/02/28 14:22:36 INFO LBFGS: Val and Grad Norm: 0.260378 (rel: 3.69e-05) 0.000250725
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 104.0 B, free 343.9 MB)
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.9 MB)
18/02/28 14:22:36 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:61672 (size: 186.0 B, free: 345.0 MB)
18/02/28 14:22:36 INFO SparkContext: Created broadcast 54 from broadcast at LogisticRegression.scala:1879
18/02/28 14:22:36 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:22:36 INFO DAGScheduler: Got job 27 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:22:36 INFO DAGScheduler: Final stage: ResultStage 37 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:22:36 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:22:36 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:36 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[101] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 74.1 KB, free 343.8 MB)
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 29.2 KB, free 343.8 MB)
18/02/28 14:22:36 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:61672 (size: 29.2 KB, free: 344.9 MB)
18/02/28 14:22:36 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:36 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 37 (MapPartitionsRDD[101] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:36 INFO TaskSchedulerImpl: Adding task set 37.0 with 4 tasks
18/02/28 14:22:36 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 121, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 1.0 in stage 37.0 (TID 122, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 2.0 in stage 37.0 (TID 123, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 3.0 in stage 37.0 (TID 124, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:36 INFO Executor: Running task 0.0 in stage 37.0 (TID 121)
18/02/28 14:22:36 INFO Executor: Running task 3.0 in stage 37.0 (TID 124)
18/02/28 14:22:36 INFO Executor: Running task 2.0 in stage 37.0 (TID 123)
18/02/28 14:22:36 INFO Executor: Running task 1.0 in stage 37.0 (TID 122)
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:22:36 INFO Executor: Finished task 2.0 in stage 37.0 (TID 123). 3438 bytes result sent to driver
18/02/28 14:22:36 INFO Executor: Finished task 1.0 in stage 37.0 (TID 122). 3438 bytes result sent to driver
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:22:36 INFO TaskSetManager: Finished task 2.0 in stage 37.0 (TID 123) in 7 ms on localhost (executor driver) (1/4)
18/02/28 14:22:36 INFO TaskSetManager: Finished task 1.0 in stage 37.0 (TID 122) in 7 ms on localhost (executor driver) (2/4)
18/02/28 14:22:36 INFO Executor: Finished task 0.0 in stage 37.0 (TID 121). 3438 bytes result sent to driver
18/02/28 14:22:36 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 121) in 9 ms on localhost (executor driver) (3/4)
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:22:36 INFO Executor: Finished task 3.0 in stage 37.0 (TID 124). 3438 bytes result sent to driver
18/02/28 14:22:36 INFO TaskSetManager: Finished task 3.0 in stage 37.0 (TID 124) in 10 ms on localhost (executor driver) (4/4)
18/02/28 14:22:36 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
18/02/28 14:22:36 INFO DAGScheduler: ResultStage 37 (treeAggregate at LogisticRegression.scala:1892) finished in 0.010 s
18/02/28 14:22:36 INFO DAGScheduler: Job 27 finished: treeAggregate at LogisticRegression.scala:1892, took 0.015713 s
18/02/28 14:22:36 INFO TorrentBroadcast: Destroying Broadcast(54) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:22:36 INFO LBFGS: Step Size: 1.000
18/02/28 14:22:36 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:61672 in memory (size: 186.0 B, free: 344.9 MB)
18/02/28 14:22:36 INFO LBFGS: Val and Grad Norm: 0.260377 (rel: 2.38e-06) 1.88138e-05
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 104.0 B, free 343.8 MB)
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.8 MB)
18/02/28 14:22:36 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:61672 (size: 186.0 B, free: 344.9 MB)
18/02/28 14:22:36 INFO SparkContext: Created broadcast 56 from broadcast at LogisticRegression.scala:1879
18/02/28 14:22:36 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:22:36 INFO DAGScheduler: Got job 28 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:22:36 INFO DAGScheduler: Final stage: ResultStage 38 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:22:36 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:22:36 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:36 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[102] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 74.1 KB, free 343.7 MB)
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 29.2 KB, free 343.7 MB)
18/02/28 14:22:36 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:61672 (size: 29.2 KB, free: 344.9 MB)
18/02/28 14:22:36 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:36 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 38 (MapPartitionsRDD[102] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:36 INFO TaskSchedulerImpl: Adding task set 38.0 with 4 tasks
18/02/28 14:22:36 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 125, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 1.0 in stage 38.0 (TID 126, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 2.0 in stage 38.0 (TID 127, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 3.0 in stage 38.0 (TID 128, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:36 INFO Executor: Running task 0.0 in stage 38.0 (TID 125)
18/02/28 14:22:36 INFO Executor: Running task 1.0 in stage 38.0 (TID 126)
18/02/28 14:22:36 INFO Executor: Running task 3.0 in stage 38.0 (TID 128)
18/02/28 14:22:36 INFO Executor: Running task 2.0 in stage 38.0 (TID 127)
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:22:36 INFO Executor: Finished task 0.0 in stage 38.0 (TID 125). 3481 bytes result sent to driver
18/02/28 14:22:36 INFO Executor: Finished task 1.0 in stage 38.0 (TID 126). 3481 bytes result sent to driver
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:22:36 INFO Executor: Finished task 3.0 in stage 38.0 (TID 128). 3438 bytes result sent to driver
18/02/28 14:22:36 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 125) in 14 ms on localhost (executor driver) (1/4)
18/02/28 14:22:36 INFO TaskSetManager: Finished task 1.0 in stage 38.0 (TID 126) in 15 ms on localhost (executor driver) (2/4)
18/02/28 14:22:36 INFO Executor: Finished task 2.0 in stage 38.0 (TID 127). 3438 bytes result sent to driver
18/02/28 14:22:36 INFO TaskSetManager: Finished task 3.0 in stage 38.0 (TID 128) in 16 ms on localhost (executor driver) (3/4)
18/02/28 14:22:36 INFO TaskSetManager: Finished task 2.0 in stage 38.0 (TID 127) in 16 ms on localhost (executor driver) (4/4)
18/02/28 14:22:36 INFO DAGScheduler: ResultStage 38 (treeAggregate at LogisticRegression.scala:1892) finished in 0.017 s
18/02/28 14:22:36 INFO DAGScheduler: Job 28 finished: treeAggregate at LogisticRegression.scala:1892, took 0.022700 s
18/02/28 14:22:36 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
18/02/28 14:22:36 INFO TorrentBroadcast: Destroying Broadcast(56) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:22:36 INFO LBFGS: Step Size: 1.000
18/02/28 14:22:36 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:61672 in memory (size: 186.0 B, free: 344.9 MB)
18/02/28 14:22:36 INFO LBFGS: Val and Grad Norm: 0.260377 (rel: 1.12e-08) 1.87495e-06
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 104.0 B, free 343.7 MB)
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.7 MB)
18/02/28 14:22:36 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:61672 (size: 186.0 B, free: 344.9 MB)
18/02/28 14:22:36 INFO SparkContext: Created broadcast 58 from broadcast at LogisticRegression.scala:1879
18/02/28 14:22:36 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:22:36 INFO DAGScheduler: Got job 29 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:22:36 INFO DAGScheduler: Final stage: ResultStage 39 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:22:36 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:22:36 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:36 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[103] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 74.1 KB, free 343.6 MB)
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 29.2 KB, free 343.6 MB)
18/02/28 14:22:36 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:61672 (size: 29.2 KB, free: 344.9 MB)
18/02/28 14:22:36 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:36 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 39 (MapPartitionsRDD[103] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:36 INFO TaskSchedulerImpl: Adding task set 39.0 with 4 tasks
18/02/28 14:22:36 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 129, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 1.0 in stage 39.0 (TID 130, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 2.0 in stage 39.0 (TID 131, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 3.0 in stage 39.0 (TID 132, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:36 INFO Executor: Running task 0.0 in stage 39.0 (TID 129)
18/02/28 14:22:36 INFO Executor: Running task 3.0 in stage 39.0 (TID 132)
18/02/28 14:22:36 INFO Executor: Running task 2.0 in stage 39.0 (TID 131)
18/02/28 14:22:36 INFO Executor: Running task 1.0 in stage 39.0 (TID 130)
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:22:36 INFO Executor: Finished task 0.0 in stage 39.0 (TID 129). 3481 bytes result sent to driver
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:22:36 INFO Executor: Finished task 1.0 in stage 39.0 (TID 130). 3481 bytes result sent to driver
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:22:36 INFO Executor: Finished task 2.0 in stage 39.0 (TID 131). 3438 bytes result sent to driver
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:22:36 INFO Executor: Finished task 3.0 in stage 39.0 (TID 132). 3481 bytes result sent to driver
18/02/28 14:22:36 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 129) in 13 ms on localhost (executor driver) (1/4)
18/02/28 14:22:36 INFO TaskSetManager: Finished task 2.0 in stage 39.0 (TID 131) in 13 ms on localhost (executor driver) (2/4)
18/02/28 14:22:36 INFO TaskSetManager: Finished task 1.0 in stage 39.0 (TID 130) in 13 ms on localhost (executor driver) (3/4)
18/02/28 14:22:36 INFO TaskSetManager: Finished task 3.0 in stage 39.0 (TID 132) in 13 ms on localhost (executor driver) (4/4)
18/02/28 14:22:36 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
18/02/28 14:22:36 INFO DAGScheduler: ResultStage 39 (treeAggregate at LogisticRegression.scala:1892) finished in 0.014 s
18/02/28 14:22:36 INFO DAGScheduler: Job 29 finished: treeAggregate at LogisticRegression.scala:1892, took 0.026654 s
18/02/28 14:22:36 INFO TorrentBroadcast: Destroying Broadcast(58) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:22:36 INFO LBFGS: Step Size: 1.000
18/02/28 14:22:36 INFO LBFGS: Val and Grad Norm: 0.260377 (rel: 7.93e-11) 7.27970e-07
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 104.0 B, free 343.6 MB)
18/02/28 14:22:36 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:61672 in memory (size: 186.0 B, free: 344.9 MB)
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 186.0 B, free 343.6 MB)
18/02/28 14:22:36 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:61672 (size: 186.0 B, free: 344.9 MB)
18/02/28 14:22:36 INFO SparkContext: Created broadcast 60 from broadcast at LogisticRegression.scala:1879
18/02/28 14:22:36 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
18/02/28 14:22:36 INFO DAGScheduler: Got job 30 (treeAggregate at LogisticRegression.scala:1892) with 4 output partitions
18/02/28 14:22:36 INFO DAGScheduler: Final stage: ResultStage 40 (treeAggregate at LogisticRegression.scala:1892)
18/02/28 14:22:36 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:22:36 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:36 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[104] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 74.1 KB, free 343.5 MB)
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 29.2 KB, free 343.4 MB)
18/02/28 14:22:36 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:61672 (size: 29.2 KB, free: 344.9 MB)
18/02/28 14:22:36 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:36 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 40 (MapPartitionsRDD[104] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:36 INFO TaskSchedulerImpl: Adding task set 40.0 with 4 tasks
18/02/28 14:22:36 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 133, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 1.0 in stage 40.0 (TID 134, localhost, executor driver, partition 1, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 2.0 in stage 40.0 (TID 135, localhost, executor driver, partition 2, PROCESS_LOCAL, 5534 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 3.0 in stage 40.0 (TID 136, localhost, executor driver, partition 3, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:36 INFO Executor: Running task 0.0 in stage 40.0 (TID 133)
18/02/28 14:22:36 INFO Executor: Running task 1.0 in stage 40.0 (TID 134)
18/02/28 14:22:36 INFO Executor: Running task 2.0 in stage 40.0 (TID 135)
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_1 locally
18/02/28 14:22:36 INFO Executor: Finished task 1.0 in stage 40.0 (TID 134). 3481 bytes result sent to driver
18/02/28 14:22:36 INFO Executor: Running task 3.0 in stage 40.0 (TID 136)
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_3 locally
18/02/28 14:22:36 INFO Executor: Finished task 3.0 in stage 40.0 (TID 136). 3395 bytes result sent to driver
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_2 locally
18/02/28 14:22:36 INFO BlockManager: Found block rdd_85_0 locally
18/02/28 14:22:36 INFO Executor: Finished task 2.0 in stage 40.0 (TID 135). 3481 bytes result sent to driver
18/02/28 14:22:36 INFO Executor: Finished task 0.0 in stage 40.0 (TID 133). 3438 bytes result sent to driver
18/02/28 14:22:36 INFO TaskSetManager: Finished task 1.0 in stage 40.0 (TID 134) in 14 ms on localhost (executor driver) (1/4)
18/02/28 14:22:36 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 133) in 14 ms on localhost (executor driver) (2/4)
18/02/28 14:22:36 INFO TaskSetManager: Finished task 3.0 in stage 40.0 (TID 136) in 13 ms on localhost (executor driver) (3/4)
18/02/28 14:22:36 INFO TaskSetManager: Finished task 2.0 in stage 40.0 (TID 135) in 14 ms on localhost (executor driver) (4/4)
18/02/28 14:22:36 INFO DAGScheduler: ResultStage 40 (treeAggregate at LogisticRegression.scala:1892) finished in 0.015 s
18/02/28 14:22:36 INFO DAGScheduler: Job 30 finished: treeAggregate at LogisticRegression.scala:1892, took 0.021278 s
18/02/28 14:22:36 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
18/02/28 14:22:36 INFO TorrentBroadcast: Destroying Broadcast(60) (from destroy at LogisticRegression.scala:1933)
18/02/28 14:22:36 INFO LBFGS: Step Size: 1.000
18/02/28 14:22:36 INFO LBFGS: Val and Grad Norm: 0.260377 (rel: 9.63e-12) 2.96375e-08
18/02/28 14:22:36 INFO LBFGS: Converged because gradient converged
18/02/28 14:22:36 INFO TorrentBroadcast: Destroying Broadcast(25) (from destroy at LogisticRegression.scala:796)
18/02/28 14:22:36 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:61672 in memory (size: 186.0 B, free: 344.9 MB)
18/02/28 14:22:36 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:61672 in memory (size: 109.0 B, free: 344.9 MB)
18/02/28 14:22:36 INFO MapPartitionsRDD: Removing RDD 85 from persistence list
18/02/28 14:22:36 INFO BlockManager: Removing RDD 85
18/02/28 14:22:36 INFO CodeGenerator: Code generated in 29.997472 ms
18/02/28 14:22:36 INFO Instrumentation: LogisticRegression-logistic_regression_144035267d6d-1858750619-1: training finished
18/02/28 14:22:36 INFO SparkContext: Starting job: sortByKey at BinaryClassificationMetrics.scala:155
18/02/28 14:22:36 INFO DAGScheduler: Registering RDD 109 (map at LogisticRegression.scala:1398)
18/02/28 14:22:36 INFO DAGScheduler: Got job 31 (sortByKey at BinaryClassificationMetrics.scala:155) with 4 output partitions
18/02/28 14:22:36 INFO DAGScheduler: Final stage: ResultStage 42 (sortByKey at BinaryClassificationMetrics.scala:155)
18/02/28 14:22:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
18/02/28 14:22:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 41)
18/02/28 14:22:36 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[109] at map at LogisticRegression.scala:1398), which has no missing parents
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 83.2 KB, free 343.7 MB)
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 32.7 KB, free 343.7 MB)
18/02/28 14:22:36 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:61672 (size: 32.7 KB, free: 345.2 MB)
18/02/28 14:22:36 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:36 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[109] at map at LogisticRegression.scala:1398) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:36 INFO TaskSchedulerImpl: Adding task set 41.0 with 4 tasks
18/02/28 14:22:36 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 137, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 1.0 in stage 41.0 (TID 138, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 2.0 in stage 41.0 (TID 139, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 3.0 in stage 41.0 (TID 140, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:36 INFO Executor: Running task 1.0 in stage 41.0 (TID 138)
18/02/28 14:22:36 INFO Executor: Running task 0.0 in stage 41.0 (TID 137)
18/02/28 14:22:36 INFO Executor: Running task 2.0 in stage 41.0 (TID 139)
18/02/28 14:22:36 INFO Executor: Running task 3.0 in stage 41.0 (TID 140)
18/02/28 14:22:36 INFO BlockManager: Found block rdd_48_3 locally
18/02/28 14:22:36 INFO BlockManager: Found block rdd_48_1 locally
18/02/28 14:22:36 INFO BlockManager: Found block rdd_48_2 locally
18/02/28 14:22:36 INFO BlockManager: Found block rdd_48_0 locally
18/02/28 14:22:36 INFO CodeGenerator: Code generated in 16.580047 ms
18/02/28 14:22:36 INFO CodeGenerator: Code generated in 8.343268 ms
18/02/28 14:22:36 INFO Executor: Finished task 1.0 in stage 41.0 (TID 138). 2258 bytes result sent to driver
18/02/28 14:22:36 INFO TaskSetManager: Finished task 1.0 in stage 41.0 (TID 138) in 165 ms on localhost (executor driver) (1/4)
18/02/28 14:22:36 INFO Executor: Finished task 2.0 in stage 41.0 (TID 139). 2215 bytes result sent to driver
18/02/28 14:22:36 INFO TaskSetManager: Finished task 2.0 in stage 41.0 (TID 139) in 176 ms on localhost (executor driver) (2/4)
18/02/28 14:22:36 INFO Executor: Finished task 3.0 in stage 41.0 (TID 140). 2215 bytes result sent to driver
18/02/28 14:22:36 INFO TaskSetManager: Finished task 3.0 in stage 41.0 (TID 140) in 177 ms on localhost (executor driver) (3/4)
18/02/28 14:22:36 INFO Executor: Finished task 0.0 in stage 41.0 (TID 137). 2258 bytes result sent to driver
18/02/28 14:22:36 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 137) in 180 ms on localhost (executor driver) (4/4)
18/02/28 14:22:36 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
18/02/28 14:22:36 INFO DAGScheduler: ShuffleMapStage 41 (map at LogisticRegression.scala:1398) finished in 0.181 s
18/02/28 14:22:36 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:22:36 INFO DAGScheduler: running: Set()
18/02/28 14:22:36 INFO DAGScheduler: waiting: Set(ResultStage 42)
18/02/28 14:22:36 INFO DAGScheduler: failed: Set()
18/02/28 14:22:36 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[112] at sortByKey at BinaryClassificationMetrics.scala:155), which has no missing parents
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 3.6 KB, free 343.7 MB)
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 2.0 KB, free 343.7 MB)
18/02/28 14:22:36 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:61672 (size: 2.0 KB, free: 345.2 MB)
18/02/28 14:22:36 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:36 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 42 (MapPartitionsRDD[112] at sortByKey at BinaryClassificationMetrics.scala:155) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:36 INFO TaskSchedulerImpl: Adding task set 42.0 with 4 tasks
18/02/28 14:22:36 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 141, localhost, executor driver, partition 0, ANY, 4621 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 1.0 in stage 42.0 (TID 142, localhost, executor driver, partition 1, ANY, 4621 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 2.0 in stage 42.0 (TID 143, localhost, executor driver, partition 2, ANY, 4621 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 3.0 in stage 42.0 (TID 144, localhost, executor driver, partition 3, ANY, 4621 bytes)
18/02/28 14:22:36 INFO Executor: Running task 1.0 in stage 42.0 (TID 142)
18/02/28 14:22:36 INFO Executor: Running task 0.0 in stage 42.0 (TID 141)
18/02/28 14:22:36 INFO Executor: Running task 2.0 in stage 42.0 (TID 143)
18/02/28 14:22:36 INFO Executor: Running task 3.0 in stage 42.0 (TID 144)
18/02/28 14:22:36 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:36 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:36 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:36 INFO Executor: Finished task 1.0 in stage 42.0 (TID 142). 1757 bytes result sent to driver
18/02/28 14:22:36 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:36 INFO Executor: Finished task 2.0 in stage 42.0 (TID 143). 1714 bytes result sent to driver
18/02/28 14:22:36 INFO Executor: Finished task 0.0 in stage 42.0 (TID 141). 1714 bytes result sent to driver
18/02/28 14:22:36 INFO Executor: Finished task 3.0 in stage 42.0 (TID 144). 1757 bytes result sent to driver
18/02/28 14:22:36 INFO TaskSetManager: Finished task 1.0 in stage 42.0 (TID 142) in 53 ms on localhost (executor driver) (1/4)
18/02/28 14:22:36 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 141) in 54 ms on localhost (executor driver) (2/4)
18/02/28 14:22:36 INFO TaskSetManager: Finished task 2.0 in stage 42.0 (TID 143) in 55 ms on localhost (executor driver) (3/4)
18/02/28 14:22:36 INFO TaskSetManager: Finished task 3.0 in stage 42.0 (TID 144) in 56 ms on localhost (executor driver) (4/4)
18/02/28 14:22:36 INFO DAGScheduler: ResultStage 42 (sortByKey at BinaryClassificationMetrics.scala:155) finished in 0.057 s
18/02/28 14:22:36 INFO DAGScheduler: Job 31 finished: sortByKey at BinaryClassificationMetrics.scala:155, took 0.254583 s
18/02/28 14:22:36 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
18/02/28 14:22:36 INFO SparkContext: Starting job: count at BinaryClassificationMetrics.scala:163
18/02/28 14:22:36 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 10 is 170 bytes
18/02/28 14:22:36 INFO DAGScheduler: Registering RDD 110 (combineByKey at BinaryClassificationMetrics.scala:151)
18/02/28 14:22:36 INFO DAGScheduler: Got job 32 (count at BinaryClassificationMetrics.scala:163) with 4 output partitions
18/02/28 14:22:36 INFO DAGScheduler: Final stage: ResultStage 45 (count at BinaryClassificationMetrics.scala:163)
18/02/28 14:22:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)
18/02/28 14:22:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 44)
18/02/28 14:22:36 INFO DAGScheduler: Submitting ShuffleMapStage 44 (ShuffledRDD[110] at combineByKey at BinaryClassificationMetrics.scala:151), which has no missing parents
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 3.4 KB, free 343.7 MB)
18/02/28 14:22:36 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 1914.0 B, free 343.7 MB)
18/02/28 14:22:36 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:61672 (size: 1914.0 B, free: 345.2 MB)
18/02/28 14:22:36 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:36 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 44 (ShuffledRDD[110] at combineByKey at BinaryClassificationMetrics.scala:151) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:36 INFO TaskSchedulerImpl: Adding task set 44.0 with 4 tasks
18/02/28 14:22:36 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 145, localhost, executor driver, partition 0, ANY, 4610 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 1.0 in stage 44.0 (TID 146, localhost, executor driver, partition 1, ANY, 4610 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 2.0 in stage 44.0 (TID 147, localhost, executor driver, partition 2, ANY, 4610 bytes)
18/02/28 14:22:36 INFO TaskSetManager: Starting task 3.0 in stage 44.0 (TID 148, localhost, executor driver, partition 3, ANY, 4610 bytes)
18/02/28 14:22:36 INFO Executor: Running task 0.0 in stage 44.0 (TID 145)
18/02/28 14:22:36 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:36 INFO Executor: Running task 1.0 in stage 44.0 (TID 146)
18/02/28 14:22:36 INFO Executor: Running task 2.0 in stage 44.0 (TID 147)
18/02/28 14:22:36 INFO Executor: Running task 3.0 in stage 44.0 (TID 148)
18/02/28 14:22:36 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:36 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:36 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:36 INFO Executor: Finished task 1.0 in stage 44.0 (TID 146). 1196 bytes result sent to driver
18/02/28 14:22:36 INFO TaskSetManager: Finished task 1.0 in stage 44.0 (TID 146) in 100 ms on localhost (executor driver) (1/4)
18/02/28 14:22:37 INFO Executor: Finished task 3.0 in stage 44.0 (TID 148). 1239 bytes result sent to driver
18/02/28 14:22:37 INFO TaskSetManager: Finished task 3.0 in stage 44.0 (TID 148) in 132 ms on localhost (executor driver) (2/4)
18/02/28 14:22:37 INFO Executor: Finished task 0.0 in stage 44.0 (TID 145). 1239 bytes result sent to driver
18/02/28 14:22:37 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 145) in 160 ms on localhost (executor driver) (3/4)
18/02/28 14:22:37 INFO Executor: Finished task 2.0 in stage 44.0 (TID 147). 1239 bytes result sent to driver
18/02/28 14:22:37 INFO TaskSetManager: Finished task 2.0 in stage 44.0 (TID 147) in 167 ms on localhost (executor driver) (4/4)
18/02/28 14:22:37 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
18/02/28 14:22:37 INFO DAGScheduler: ShuffleMapStage 44 (combineByKey at BinaryClassificationMetrics.scala:151) finished in 0.168 s
18/02/28 14:22:37 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:22:37 INFO DAGScheduler: running: Set()
18/02/28 14:22:37 INFO DAGScheduler: waiting: Set(ResultStage 45)
18/02/28 14:22:37 INFO DAGScheduler: failed: Set()
18/02/28 14:22:37 INFO DAGScheduler: Submitting ResultStage 45 (ShuffledRDD[113] at sortByKey at BinaryClassificationMetrics.scala:155), which has no missing parents
18/02/28 14:22:37 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 3.1 KB, free 343.7 MB)
18/02/28 14:22:37 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 1868.0 B, free 343.7 MB)
18/02/28 14:22:37 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:61672 (size: 1868.0 B, free: 345.2 MB)
18/02/28 14:22:37 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:37 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 45 (ShuffledRDD[113] at sortByKey at BinaryClassificationMetrics.scala:155) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:37 INFO TaskSchedulerImpl: Adding task set 45.0 with 4 tasks
18/02/28 14:22:37 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 149, localhost, executor driver, partition 0, ANY, 4621 bytes)
18/02/28 14:22:37 INFO TaskSetManager: Starting task 1.0 in stage 45.0 (TID 150, localhost, executor driver, partition 1, ANY, 4621 bytes)
18/02/28 14:22:37 INFO TaskSetManager: Starting task 2.0 in stage 45.0 (TID 151, localhost, executor driver, partition 2, ANY, 4621 bytes)
18/02/28 14:22:37 INFO TaskSetManager: Starting task 3.0 in stage 45.0 (TID 152, localhost, executor driver, partition 3, ANY, 4621 bytes)
18/02/28 14:22:37 INFO Executor: Running task 1.0 in stage 45.0 (TID 150)
18/02/28 14:22:37 INFO Executor: Running task 3.0 in stage 45.0 (TID 152)
18/02/28 14:22:37 INFO Executor: Running task 2.0 in stage 45.0 (TID 151)
18/02/28 14:22:37 INFO Executor: Running task 0.0 in stage 45.0 (TID 149)
18/02/28 14:22:37 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:37 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 14:22:37 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:37 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:37 INFO Executor: Finished task 1.0 in stage 45.0 (TID 150). 1090 bytes result sent to driver
18/02/28 14:22:37 INFO Executor: Finished task 0.0 in stage 45.0 (TID 149). 1133 bytes result sent to driver
18/02/28 14:22:37 INFO Executor: Finished task 2.0 in stage 45.0 (TID 151). 1090 bytes result sent to driver
18/02/28 14:22:37 INFO Executor: Finished task 3.0 in stage 45.0 (TID 152). 1090 bytes result sent to driver
18/02/28 14:22:37 INFO TaskSetManager: Finished task 1.0 in stage 45.0 (TID 150) in 37 ms on localhost (executor driver) (1/4)
18/02/28 14:22:37 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 149) in 37 ms on localhost (executor driver) (2/4)
18/02/28 14:22:37 INFO TaskSetManager: Finished task 2.0 in stage 45.0 (TID 151) in 38 ms on localhost (executor driver) (3/4)
18/02/28 14:22:37 INFO TaskSetManager: Finished task 3.0 in stage 45.0 (TID 152) in 38 ms on localhost (executor driver) (4/4)
18/02/28 14:22:37 INFO DAGScheduler: ResultStage 45 (count at BinaryClassificationMetrics.scala:163) finished in 0.038 s
18/02/28 14:22:37 INFO DAGScheduler: Job 32 finished: count at BinaryClassificationMetrics.scala:163, took 0.226578 s
18/02/28 14:22:37 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
18/02/28 14:22:37 INFO SparkContext: Starting job: collect at BinaryClassificationMetrics.scala:192
18/02/28 14:22:37 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 10 is 170 bytes
18/02/28 14:22:37 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 11 is 171 bytes
18/02/28 14:22:37 INFO DAGScheduler: Got job 33 (collect at BinaryClassificationMetrics.scala:192) with 4 output partitions
18/02/28 14:22:37 INFO DAGScheduler: Final stage: ResultStage 48 (collect at BinaryClassificationMetrics.scala:192)
18/02/28 14:22:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47)
18/02/28 14:22:37 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:37 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[116] at mapPartitions at BinaryClassificationMetrics.scala:188), which has no missing parents
18/02/28 14:22:37 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 4.2 KB, free 343.7 MB)
18/02/28 14:22:37 INFO ContextCleaner: Cleaned accumulator 688
18/02/28 14:22:37 INFO ContextCleaner: Cleaned accumulator 686
18/02/28 14:22:37 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 2.3 KB, free 343.7 MB)
18/02/28 14:22:37 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:61672 (size: 2.3 KB, free: 345.2 MB)
18/02/28 14:22:37 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:37 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 48 (MapPartitionsRDD[116] at mapPartitions at BinaryClassificationMetrics.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:37 INFO TaskSchedulerImpl: Adding task set 48.0 with 4 tasks
18/02/28 14:22:37 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 153, localhost, executor driver, partition 0, ANY, 4621 bytes)
18/02/28 14:22:37 INFO TaskSetManager: Starting task 1.0 in stage 48.0 (TID 154, localhost, executor driver, partition 1, ANY, 4621 bytes)
18/02/28 14:22:37 INFO TaskSetManager: Starting task 2.0 in stage 48.0 (TID 155, localhost, executor driver, partition 2, ANY, 4621 bytes)
18/02/28 14:22:37 INFO TaskSetManager: Starting task 3.0 in stage 48.0 (TID 156, localhost, executor driver, partition 3, ANY, 4621 bytes)
18/02/28 14:22:37 INFO Executor: Running task 0.0 in stage 48.0 (TID 153)
18/02/28 14:22:37 INFO Executor: Running task 1.0 in stage 48.0 (TID 154)
18/02/28 14:22:37 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 14:22:37 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:37 INFO Executor: Running task 2.0 in stage 48.0 (TID 155)
18/02/28 14:22:37 INFO Executor: Running task 3.0 in stage 48.0 (TID 156)
18/02/28 14:22:37 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:37 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:37 INFO Executor: Finished task 1.0 in stage 48.0 (TID 154). 1174 bytes result sent to driver
18/02/28 14:22:37 INFO Executor: Finished task 0.0 in stage 48.0 (TID 153). 1217 bytes result sent to driver
18/02/28 14:22:37 INFO TaskSetManager: Finished task 1.0 in stage 48.0 (TID 154) in 23 ms on localhost (executor driver) (1/4)
18/02/28 14:22:37 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 153) in 24 ms on localhost (executor driver) (2/4)
18/02/28 14:22:37 INFO Executor: Finished task 2.0 in stage 48.0 (TID 155). 1174 bytes result sent to driver
18/02/28 14:22:37 INFO TaskSetManager: Finished task 2.0 in stage 48.0 (TID 155) in 27 ms on localhost (executor driver) (3/4)
18/02/28 14:22:37 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:61672 in memory (size: 29.2 KB, free: 345.2 MB)
18/02/28 14:22:37 INFO Executor: Finished task 3.0 in stage 48.0 (TID 156). 1131 bytes result sent to driver
18/02/28 14:22:37 INFO TaskSetManager: Finished task 3.0 in stage 48.0 (TID 156) in 31 ms on localhost (executor driver) (4/4)
18/02/28 14:22:37 INFO DAGScheduler: ResultStage 48 (collect at BinaryClassificationMetrics.scala:192) finished in 0.033 s
18/02/28 14:22:37 INFO DAGScheduler: Job 33 finished: collect at BinaryClassificationMetrics.scala:192, took 0.047318 s
18/02/28 14:22:37 INFO BinaryClassificationMetrics: Total counts: {numPos: 740, numNeg: 2598}
18/02/28 14:22:37 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
18/02/28 14:22:37 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:61672 in memory (size: 29.2 KB, free: 345.2 MB)
18/02/28 14:22:37 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 127.0.0.1:61672 in memory (size: 29.2 KB, free: 345.2 MB)
18/02/28 14:22:37 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 127.0.0.1:61672 in memory (size: 29.2 KB, free: 345.3 MB)
18/02/28 14:22:37 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:61672 in memory (size: 29.2 KB, free: 345.3 MB)
18/02/28 14:22:37 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 127.0.0.1:61672 in memory (size: 1868.0 B, free: 345.3 MB)
18/02/28 14:22:37 INFO ContextCleaner: Cleaned accumulator 689
18/02/28 14:22:37 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:61672 in memory (size: 1914.0 B, free: 345.3 MB)
18/02/28 14:22:37 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 127.0.0.1:61672 in memory (size: 32.7 KB, free: 345.3 MB)
18/02/28 14:22:37 INFO SparkContext: Starting job: collect at SlidingRDD.scala:81
18/02/28 14:22:37 INFO DAGScheduler: Got job 34 (collect at SlidingRDD.scala:81) with 6 output partitions
18/02/28 14:22:37 INFO DAGScheduler: Final stage: ResultStage 51 (collect at SlidingRDD.scala:81)
18/02/28 14:22:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)
18/02/28 14:22:37 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:37 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[124] at mapPartitions at SlidingRDD.scala:78), which has no missing parents
18/02/28 14:22:37 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 6.3 KB, free 344.4 MB)
18/02/28 14:22:37 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 3.3 KB, free 344.4 MB)
18/02/28 14:22:37 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:61672 in memory (size: 29.2 KB, free: 345.4 MB)
18/02/28 14:22:37 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:61672 (size: 3.3 KB, free: 345.4 MB)
18/02/28 14:22:37 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:37 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 51 (MapPartitionsRDD[124] at mapPartitions at SlidingRDD.scala:78) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
18/02/28 14:22:37 INFO TaskSchedulerImpl: Adding task set 51.0 with 6 tasks
18/02/28 14:22:37 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 157, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:22:37 INFO TaskSetManager: Starting task 5.0 in stage 51.0 (TID 158, localhost, executor driver, partition 5, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:22:37 INFO TaskSetManager: Starting task 1.0 in stage 51.0 (TID 159, localhost, executor driver, partition 1, ANY, 4730 bytes)
18/02/28 14:22:37 INFO TaskSetManager: Starting task 2.0 in stage 51.0 (TID 160, localhost, executor driver, partition 2, ANY, 4730 bytes)
18/02/28 14:22:37 INFO Executor: Running task 0.0 in stage 51.0 (TID 157)
18/02/28 14:22:37 INFO Executor: Running task 5.0 in stage 51.0 (TID 158)
18/02/28 14:22:37 INFO Executor: Running task 1.0 in stage 51.0 (TID 159)
18/02/28 14:22:37 INFO Executor: Running task 2.0 in stage 51.0 (TID 160)
18/02/28 14:22:37 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:37 INFO Executor: Finished task 5.0 in stage 51.0 (TID 158). 899 bytes result sent to driver
18/02/28 14:22:37 INFO TaskSetManager: Starting task 3.0 in stage 51.0 (TID 161, localhost, executor driver, partition 3, ANY, 4730 bytes)
18/02/28 14:22:37 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:37 INFO MemoryStore: Block rdd_117_1 stored as values in memory (estimated size 1952.0 B, free 344.4 MB)
18/02/28 14:22:37 INFO MemoryStore: Block rdd_117_0 stored as values in memory (estimated size 2.2 KB, free 344.4 MB)
18/02/28 14:22:37 INFO Executor: Finished task 0.0 in stage 51.0 (TID 157). 856 bytes result sent to driver
18/02/28 14:22:37 INFO BlockManagerInfo: Added rdd_117_1 in memory on 127.0.0.1:61672 (size: 1952.0 B, free: 345.4 MB)
18/02/28 14:22:37 INFO BlockManagerInfo: Added rdd_117_0 in memory on 127.0.0.1:61672 (size: 2.2 KB, free: 345.4 MB)
18/02/28 14:22:37 INFO TaskSetManager: Starting task 4.0 in stage 51.0 (TID 162, localhost, executor driver, partition 4, ANY, 4730 bytes)
18/02/28 14:22:37 INFO TaskSetManager: Finished task 5.0 in stage 51.0 (TID 158) in 28 ms on localhost (executor driver) (1/6)
18/02/28 14:22:37 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 157) in 34 ms on localhost (executor driver) (2/6)
18/02/28 14:22:37 INFO Executor: Running task 3.0 in stage 51.0 (TID 161)
18/02/28 14:22:37 INFO Executor: Running task 4.0 in stage 51.0 (TID 162)
18/02/28 14:22:37 INFO BlockManager: Removing RDD 85
18/02/28 14:22:37 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:37 INFO MemoryStore: Block rdd_117_2 stored as values in memory (estimated size 2.1 KB, free 344.4 MB)
18/02/28 14:22:37 INFO Executor: Finished task 2.0 in stage 51.0 (TID 160). 1940 bytes result sent to driver
18/02/28 14:22:37 INFO BlockManagerInfo: Added rdd_117_2 in memory on 127.0.0.1:61672 (size: 2.1 KB, free: 345.4 MB)
18/02/28 14:22:37 INFO Executor: Finished task 1.0 in stage 51.0 (TID 159). 1940 bytes result sent to driver
18/02/28 14:22:37 INFO TaskSetManager: Finished task 2.0 in stage 51.0 (TID 160) in 47 ms on localhost (executor driver) (3/6)
18/02/28 14:22:37 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 14:22:37 INFO ContextCleaner: Cleaned RDD 85
18/02/28 14:22:37 INFO Executor: Finished task 3.0 in stage 51.0 (TID 161). 1983 bytes result sent to driver
18/02/28 14:22:37 INFO TaskSetManager: Finished task 1.0 in stage 51.0 (TID 159) in 50 ms on localhost (executor driver) (4/6)
18/02/28 14:22:37 INFO TaskSetManager: Finished task 3.0 in stage 51.0 (TID 161) in 35 ms on localhost (executor driver) (5/6)
18/02/28 14:22:37 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:61672 in memory (size: 29.2 KB, free: 345.4 MB)
18/02/28 14:22:37 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:61672 in memory (size: 29.2 KB, free: 345.4 MB)
18/02/28 14:22:37 INFO MemoryStore: Block rdd_117_3 stored as values in memory (estimated size 2.3 KB, free 344.6 MB)
18/02/28 14:22:37 INFO BlockManagerInfo: Added rdd_117_3 in memory on 127.0.0.1:61672 (size: 2.3 KB, free: 345.4 MB)
18/02/28 14:22:37 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:61672 in memory (size: 29.2 KB, free: 345.4 MB)
18/02/28 14:22:37 INFO Executor: Finished task 4.0 in stage 51.0 (TID 162). 1983 bytes result sent to driver
18/02/28 14:22:37 INFO TaskSetManager: Finished task 4.0 in stage 51.0 (TID 162) in 30 ms on localhost (executor driver) (6/6)
18/02/28 14:22:37 INFO DAGScheduler: ResultStage 51 (collect at SlidingRDD.scala:81) finished in 0.062 s
18/02/28 14:22:37 INFO DAGScheduler: Job 34 finished: collect at SlidingRDD.scala:81, took 0.076367 s
18/02/28 14:22:37 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:61672 in memory (size: 29.2 KB, free: 345.5 MB)
18/02/28 14:22:37 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
18/02/28 14:22:37 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 127.0.0.1:61672 in memory (size: 2.0 KB, free: 345.5 MB)
18/02/28 14:22:37 INFO ContextCleaner: Cleaned accumulator 687
18/02/28 14:22:37 INFO SparkContext: Starting job: aggregate at AreaUnderCurve.scala:45
18/02/28 14:22:37 INFO DAGScheduler: Got job 35 (aggregate at AreaUnderCurve.scala:45) with 5 output partitions
18/02/28 14:22:37 INFO DAGScheduler: Final stage: ResultStage 54 (aggregate at AreaUnderCurve.scala:45)
18/02/28 14:22:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 53)
18/02/28 14:22:37 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:37 INFO DAGScheduler: Submitting ResultStage 54 (SlidingRDD[123] at RDD at SlidingRDD.scala:50), which has no missing parents
18/02/28 14:22:37 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 6.5 KB, free 344.8 MB)
18/02/28 14:22:37 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 3.4 KB, free 344.8 MB)
18/02/28 14:22:37 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:61672 (size: 3.4 KB, free: 345.5 MB)
18/02/28 14:22:37 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:37 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 54 (SlidingRDD[123] at RDD at SlidingRDD.scala:50) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/02/28 14:22:37 INFO TaskSchedulerImpl: Adding task set 54.0 with 5 tasks
18/02/28 14:22:37 INFO TaskSetManager: Starting task 1.0 in stage 54.0 (TID 163, localhost, executor driver, partition 1, PROCESS_LOCAL, 5269 bytes)
18/02/28 14:22:37 INFO TaskSetManager: Starting task 2.0 in stage 54.0 (TID 164, localhost, executor driver, partition 2, PROCESS_LOCAL, 5269 bytes)
18/02/28 14:22:37 INFO TaskSetManager: Starting task 3.0 in stage 54.0 (TID 165, localhost, executor driver, partition 3, PROCESS_LOCAL, 5269 bytes)
18/02/28 14:22:37 INFO TaskSetManager: Starting task 4.0 in stage 54.0 (TID 166, localhost, executor driver, partition 4, PROCESS_LOCAL, 5269 bytes)
18/02/28 14:22:37 INFO Executor: Running task 3.0 in stage 54.0 (TID 165)
18/02/28 14:22:37 INFO Executor: Running task 4.0 in stage 54.0 (TID 166)
18/02/28 14:22:37 INFO Executor: Running task 1.0 in stage 54.0 (TID 163)
18/02/28 14:22:37 INFO Executor: Running task 2.0 in stage 54.0 (TID 164)
18/02/28 14:22:37 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:22:37 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:22:37 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:22:37 INFO Executor: Finished task 1.0 in stage 54.0 (TID 163). 748 bytes result sent to driver
18/02/28 14:22:37 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:22:37 INFO Executor: Finished task 3.0 in stage 54.0 (TID 165). 748 bytes result sent to driver
18/02/28 14:22:37 INFO Executor: Finished task 4.0 in stage 54.0 (TID 166). 748 bytes result sent to driver
18/02/28 14:22:37 INFO Executor: Finished task 2.0 in stage 54.0 (TID 164). 748 bytes result sent to driver
18/02/28 14:22:37 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 167, localhost, executor driver, partition 0, PROCESS_LOCAL, 5475 bytes)
18/02/28 14:22:37 INFO Executor: Running task 0.0 in stage 54.0 (TID 167)
18/02/28 14:22:37 INFO TaskSetManager: Finished task 3.0 in stage 54.0 (TID 165) in 10 ms on localhost (executor driver) (1/5)
18/02/28 14:22:37 INFO TaskSetManager: Finished task 4.0 in stage 54.0 (TID 166) in 11 ms on localhost (executor driver) (2/5)
18/02/28 14:22:37 INFO TaskSetManager: Finished task 2.0 in stage 54.0 (TID 164) in 12 ms on localhost (executor driver) (3/5)
18/02/28 14:22:37 INFO TaskSetManager: Finished task 1.0 in stage 54.0 (TID 163) in 16 ms on localhost (executor driver) (4/5)
18/02/28 14:22:37 INFO Executor: Finished task 0.0 in stage 54.0 (TID 167). 662 bytes result sent to driver
18/02/28 14:22:37 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 167) in 4 ms on localhost (executor driver) (5/5)
18/02/28 14:22:37 INFO DAGScheduler: ResultStage 54 (aggregate at AreaUnderCurve.scala:45) finished in 0.017 s
18/02/28 14:22:37 INFO DAGScheduler: Job 35 finished: aggregate at AreaUnderCurve.scala:45, took 0.023806 s
18/02/28 14:22:37 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
18/02/28 14:22:37 INFO CodeGenerator: Code generated in 7.934586 ms
18/02/28 14:22:37 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:22:37 INFO DAGScheduler: Got job 36 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:22:37 INFO DAGScheduler: Final stage: ResultStage 57 (collect at utils.scala:211)
18/02/28 14:22:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)
18/02/28 14:22:37 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:37 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[128] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:37 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 10.4 KB, free 344.8 MB)
18/02/28 14:22:37 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.7 MB)
18/02/28 14:22:37 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:61672 (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:22:37 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:37 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 57 (MapPartitionsRDD[128] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:37 INFO TaskSchedulerImpl: Adding task set 57.0 with 4 tasks
18/02/28 14:22:37 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 168, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:37 INFO TaskSetManager: Starting task 1.0 in stage 57.0 (TID 169, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:37 INFO TaskSetManager: Starting task 2.0 in stage 57.0 (TID 170, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:37 INFO TaskSetManager: Starting task 3.0 in stage 57.0 (TID 171, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:37 INFO Executor: Running task 0.0 in stage 57.0 (TID 168)
18/02/28 14:22:37 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:22:37 INFO Executor: Running task 1.0 in stage 57.0 (TID 169)
18/02/28 14:22:37 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:22:37 INFO Executor: Running task 2.0 in stage 57.0 (TID 170)
18/02/28 14:22:37 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:22:37 INFO Executor: Finished task 0.0 in stage 57.0 (TID 168). 1653 bytes result sent to driver
18/02/28 14:22:37 INFO Executor: Running task 3.0 in stage 57.0 (TID 171)
18/02/28 14:22:37 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:22:37 INFO Executor: Finished task 3.0 in stage 57.0 (TID 171). 1587 bytes result sent to driver
18/02/28 14:22:37 INFO Executor: Finished task 2.0 in stage 57.0 (TID 170). 1563 bytes result sent to driver
18/02/28 14:22:37 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 168) in 16 ms on localhost (executor driver) (1/4)
18/02/28 14:22:37 INFO TaskSetManager: Finished task 3.0 in stage 57.0 (TID 171) in 15 ms on localhost (executor driver) (2/4)
18/02/28 14:22:37 INFO TaskSetManager: Finished task 2.0 in stage 57.0 (TID 170) in 16 ms on localhost (executor driver) (3/4)
18/02/28 14:22:37 INFO Executor: Finished task 1.0 in stage 57.0 (TID 169). 1592 bytes result sent to driver
18/02/28 14:22:37 INFO TaskSetManager: Finished task 1.0 in stage 57.0 (TID 169) in 23 ms on localhost (executor driver) (4/4)
18/02/28 14:22:37 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
18/02/28 14:22:37 INFO DAGScheduler: ResultStage 57 (collect at utils.scala:211) finished in 0.026 s
18/02/28 14:22:37 INFO DAGScheduler: Job 36 finished: collect at utils.scala:211, took 0.032294 s
18/02/28 14:22:37 INFO CodeGenerator: Code generated in 5.299832 ms
18/02/28 14:22:37 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:22:37 INFO DAGScheduler: Got job 37 (collect at utils.scala:211) with 5 output partitions
18/02/28 14:22:37 INFO DAGScheduler: Final stage: ResultStage 60 (collect at utils.scala:211)
18/02/28 14:22:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 59)
18/02/28 14:22:37 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:37 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[134] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:37 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 11.1 KB, free 344.7 MB)
18/02/28 14:22:37 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 5.3 KB, free 344.7 MB)
18/02/28 14:22:37 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:61672 (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:22:37 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:37 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 60 (MapPartitionsRDD[134] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/02/28 14:22:37 INFO TaskSchedulerImpl: Adding task set 60.0 with 5 tasks
18/02/28 14:22:37 INFO TaskSetManager: Starting task 1.0 in stage 60.0 (TID 172, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:22:37 INFO TaskSetManager: Starting task 2.0 in stage 60.0 (TID 173, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:22:37 INFO TaskSetManager: Starting task 3.0 in stage 60.0 (TID 174, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:22:37 INFO TaskSetManager: Starting task 4.0 in stage 60.0 (TID 175, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:22:37 INFO Executor: Running task 1.0 in stage 60.0 (TID 172)
18/02/28 14:22:37 INFO Executor: Running task 2.0 in stage 60.0 (TID 173)
18/02/28 14:22:37 INFO Executor: Running task 3.0 in stage 60.0 (TID 174)
18/02/28 14:22:37 INFO Executor: Running task 4.0 in stage 60.0 (TID 175)
18/02/28 14:22:37 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:22:37 INFO Executor: Finished task 1.0 in stage 60.0 (TID 172). 1376 bytes result sent to driver
18/02/28 14:22:37 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:22:37 INFO Executor: Finished task 2.0 in stage 60.0 (TID 173). 1362 bytes result sent to driver
18/02/28 14:22:37 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 176, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:22:37 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:22:37 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:22:37 INFO Executor: Finished task 4.0 in stage 60.0 (TID 175). 1675 bytes result sent to driver
18/02/28 14:22:37 INFO Executor: Finished task 3.0 in stage 60.0 (TID 174). 1609 bytes result sent to driver
18/02/28 14:22:37 INFO Executor: Running task 0.0 in stage 60.0 (TID 176)
18/02/28 14:22:37 INFO TaskSetManager: Finished task 1.0 in stage 60.0 (TID 172) in 11 ms on localhost (executor driver) (1/5)
18/02/28 14:22:37 INFO TaskSetManager: Finished task 2.0 in stage 60.0 (TID 173) in 10 ms on localhost (executor driver) (2/5)
18/02/28 14:22:37 INFO TaskSetManager: Finished task 4.0 in stage 60.0 (TID 175) in 11 ms on localhost (executor driver) (3/5)
18/02/28 14:22:37 INFO TaskSetManager: Finished task 3.0 in stage 60.0 (TID 174) in 11 ms on localhost (executor driver) (4/5)
18/02/28 14:22:37 INFO Executor: Finished task 0.0 in stage 60.0 (TID 176). 1043 bytes result sent to driver
18/02/28 14:22:37 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 176) in 7 ms on localhost (executor driver) (5/5)
18/02/28 14:22:37 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
18/02/28 14:22:37 INFO DAGScheduler: ResultStage 60 (collect at utils.scala:211) finished in 0.015 s
18/02/28 14:22:37 INFO DAGScheduler: Job 37 finished: collect at utils.scala:211, took 0.020038 s
18/02/28 14:22:37 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:22:37 INFO DAGScheduler: Got job 38 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:22:37 INFO DAGScheduler: Final stage: ResultStage 63 (collect at utils.scala:211)
18/02/28 14:22:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 62)
18/02/28 14:22:37 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:37 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[138] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:37 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 10.3 KB, free 344.7 MB)
18/02/28 14:22:37 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.7 MB)
18/02/28 14:22:37 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 127.0.0.1:61672 (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:22:37 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:37 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 63 (MapPartitionsRDD[138] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:37 INFO TaskSchedulerImpl: Adding task set 63.0 with 4 tasks
18/02/28 14:22:37 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 177, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:37 INFO TaskSetManager: Starting task 1.0 in stage 63.0 (TID 178, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:37 INFO TaskSetManager: Starting task 2.0 in stage 63.0 (TID 179, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:37 INFO TaskSetManager: Starting task 3.0 in stage 63.0 (TID 180, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:37 INFO Executor: Running task 1.0 in stage 63.0 (TID 178)
18/02/28 14:22:37 INFO Executor: Running task 3.0 in stage 63.0 (TID 180)
18/02/28 14:22:37 INFO Executor: Running task 2.0 in stage 63.0 (TID 179)
18/02/28 14:22:37 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:22:37 INFO Executor: Finished task 2.0 in stage 63.0 (TID 179). 1569 bytes result sent to driver
18/02/28 14:22:37 INFO Executor: Running task 0.0 in stage 63.0 (TID 177)
18/02/28 14:22:37 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:22:37 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:22:37 INFO Executor: Finished task 3.0 in stage 63.0 (TID 180). 1646 bytes result sent to driver
18/02/28 14:22:37 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:22:37 INFO TaskSetManager: Finished task 2.0 in stage 63.0 (TID 179) in 6 ms on localhost (executor driver) (1/4)
18/02/28 14:22:37 INFO TaskSetManager: Finished task 3.0 in stage 63.0 (TID 180) in 6 ms on localhost (executor driver) (2/4)
18/02/28 14:22:37 INFO Executor: Finished task 1.0 in stage 63.0 (TID 178). 1401 bytes result sent to driver
18/02/28 14:22:37 INFO Executor: Finished task 0.0 in stage 63.0 (TID 177). 1412 bytes result sent to driver
18/02/28 14:22:37 INFO TaskSetManager: Finished task 1.0 in stage 63.0 (TID 178) in 9 ms on localhost (executor driver) (3/4)
18/02/28 14:22:37 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 177) in 9 ms on localhost (executor driver) (4/4)
18/02/28 14:22:37 INFO DAGScheduler: ResultStage 63 (collect at utils.scala:211) finished in 0.009 s
18/02/28 14:22:37 INFO DAGScheduler: Job 38 finished: collect at utils.scala:211, took 0.015210 s
18/02/28 14:22:37 INFO SparkSqlParser: Parsing command: sparklyr_tmp_1440395d2caa
18/02/28 14:22:37 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
18/02/28 14:22:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1440395d2caa` AS `zzz10`
WHERE (0 = 1)
18/02/28 14:22:37 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:22:37 INFO DAGScheduler: Got job 39 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:22:37 INFO DAGScheduler: Final stage: ResultStage 66 (collect at utils.scala:211)
18/02/28 14:22:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 65)
18/02/28 14:22:37 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:37 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[142] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:37 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 10.3 KB, free 344.7 MB)
18/02/28 14:22:37 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.7 MB)
18/02/28 14:22:37 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 127.0.0.1:61672 (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:22:37 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:37 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 66 (MapPartitionsRDD[142] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:37 INFO TaskSchedulerImpl: Adding task set 66.0 with 4 tasks
18/02/28 14:22:37 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 181, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:37 INFO TaskSetManager: Starting task 1.0 in stage 66.0 (TID 182, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:37 INFO TaskSetManager: Starting task 2.0 in stage 66.0 (TID 183, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:37 INFO TaskSetManager: Starting task 3.0 in stage 66.0 (TID 184, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:37 INFO Executor: Running task 0.0 in stage 66.0 (TID 181)
18/02/28 14:22:37 INFO Executor: Running task 1.0 in stage 66.0 (TID 182)
18/02/28 14:22:37 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:22:37 INFO Executor: Finished task 1.0 in stage 66.0 (TID 182). 1497 bytes result sent to driver
18/02/28 14:22:37 INFO Executor: Running task 2.0 in stage 66.0 (TID 183)
18/02/28 14:22:37 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:22:37 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:22:37 INFO Executor: Finished task 2.0 in stage 66.0 (TID 183). 1529 bytes result sent to driver
18/02/28 14:22:37 INFO Executor: Finished task 0.0 in stage 66.0 (TID 181). 1586 bytes result sent to driver
18/02/28 14:22:37 INFO TaskSetManager: Finished task 1.0 in stage 66.0 (TID 182) in 7 ms on localhost (executor driver) (1/4)
18/02/28 14:22:37 INFO TaskSetManager: Finished task 2.0 in stage 66.0 (TID 183) in 8 ms on localhost (executor driver) (2/4)
18/02/28 14:22:37 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 181) in 11 ms on localhost (executor driver) (3/4)
18/02/28 14:22:37 INFO Executor: Running task 3.0 in stage 66.0 (TID 184)
18/02/28 14:22:37 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:22:37 INFO Executor: Finished task 3.0 in stage 66.0 (TID 184). 1612 bytes result sent to driver
18/02/28 14:22:37 INFO TaskSetManager: Finished task 3.0 in stage 66.0 (TID 184) in 14 ms on localhost (executor driver) (4/4)
18/02/28 14:22:37 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
18/02/28 14:22:37 INFO DAGScheduler: ResultStage 66 (collect at utils.scala:211) finished in 0.015 s
18/02/28 14:22:37 INFO DAGScheduler: Job 39 finished: collect at utils.scala:211, took 0.037643 s
18/02/28 14:22:37 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:22:37 INFO DAGScheduler: Got job 40 (collect at utils.scala:211) with 6 output partitions
18/02/28 14:22:37 INFO DAGScheduler: Final stage: ResultStage 69 (collect at utils.scala:211)
18/02/28 14:22:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 68)
18/02/28 14:22:37 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:37 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[149] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:37 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 11.2 KB, free 344.7 MB)
18/02/28 14:22:37 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 5.3 KB, free 344.7 MB)
18/02/28 14:22:37 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 127.0.0.1:61672 (size: 5.3 KB, free: 345.4 MB)
18/02/28 14:22:37 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:37 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 69 (MapPartitionsRDD[149] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
18/02/28 14:22:37 INFO TaskSchedulerImpl: Adding task set 69.0 with 6 tasks
18/02/28 14:22:37 INFO TaskSetManager: Starting task 1.0 in stage 69.0 (TID 185, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:22:37 INFO TaskSetManager: Starting task 2.0 in stage 69.0 (TID 186, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:22:37 INFO TaskSetManager: Starting task 3.0 in stage 69.0 (TID 187, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:22:37 INFO TaskSetManager: Starting task 4.0 in stage 69.0 (TID 188, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:22:37 INFO Executor: Running task 1.0 in stage 69.0 (TID 185)
18/02/28 14:22:37 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:22:37 INFO Executor: Finished task 1.0 in stage 69.0 (TID 185). 1409 bytes result sent to driver
18/02/28 14:22:37 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 189, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:22:37 INFO Executor: Running task 4.0 in stage 69.0 (TID 188)
18/02/28 14:22:37 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:22:37 INFO Executor: Finished task 4.0 in stage 69.0 (TID 188). 1651 bytes result sent to driver
18/02/28 14:22:37 INFO TaskSetManager: Starting task 5.0 in stage 69.0 (TID 190, localhost, executor driver, partition 5, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:22:37 INFO TaskSetManager: Finished task 1.0 in stage 69.0 (TID 185) in 10 ms on localhost (executor driver) (1/6)
18/02/28 14:22:37 INFO TaskSetManager: Finished task 4.0 in stage 69.0 (TID 188) in 9 ms on localhost (executor driver) (2/6)
18/02/28 14:22:37 INFO Executor: Running task 0.0 in stage 69.0 (TID 189)
18/02/28 14:22:37 INFO Executor: Running task 3.0 in stage 69.0 (TID 187)
18/02/28 14:22:37 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:22:37 INFO Executor: Running task 5.0 in stage 69.0 (TID 190)
18/02/28 14:22:37 INFO Executor: Finished task 3.0 in stage 69.0 (TID 187). 1546 bytes result sent to driver
18/02/28 14:22:37 INFO Executor: Running task 2.0 in stage 69.0 (TID 186)
18/02/28 14:22:37 INFO Executor: Finished task 5.0 in stage 69.0 (TID 190). 1007 bytes result sent to driver
18/02/28 14:22:37 INFO Executor: Finished task 0.0 in stage 69.0 (TID 189). 999 bytes result sent to driver
18/02/28 14:22:37 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:22:37 INFO Executor: Finished task 2.0 in stage 69.0 (TID 186). 1341 bytes result sent to driver
18/02/28 14:22:37 INFO TaskSetManager: Finished task 3.0 in stage 69.0 (TID 187) in 19 ms on localhost (executor driver) (3/6)
18/02/28 14:22:37 INFO TaskSetManager: Finished task 5.0 in stage 69.0 (TID 190) in 11 ms on localhost (executor driver) (4/6)
18/02/28 14:22:37 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 189) in 15 ms on localhost (executor driver) (5/6)
18/02/28 14:22:37 INFO TaskSetManager: Finished task 2.0 in stage 69.0 (TID 186) in 20 ms on localhost (executor driver) (6/6)
18/02/28 14:22:37 INFO DAGScheduler: ResultStage 69 (collect at utils.scala:211) finished in 0.021 s
18/02/28 14:22:37 INFO DAGScheduler: Job 40 finished: collect at utils.scala:211, took 0.028609 s
18/02/28 14:22:37 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
18/02/28 14:22:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 14:22:38 INFO SparkSqlParser: Parsing command: sparklyr_tmp_144054d22c4e
18/02/28 14:22:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_144054d22c4e` AS `zzz11`
WHERE (0 = 1)
18/02/28 14:22:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_144054d22c4e`
18/02/28 14:22:38 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:22:38 INFO DAGScheduler: Got job 41 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:22:38 INFO DAGScheduler: Final stage: ResultStage 72 (collect at utils.scala:211)
18/02/28 14:22:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 71)
18/02/28 14:22:38 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:38 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[152] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:38 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 10.4 KB, free 344.7 MB)
18/02/28 14:22:38 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.7 MB)
18/02/28 14:22:38 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 127.0.0.1:61672 (size: 4.9 KB, free: 345.4 MB)
18/02/28 14:22:38 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:38 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 72 (MapPartitionsRDD[152] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:38 INFO TaskSchedulerImpl: Adding task set 72.0 with 4 tasks
18/02/28 14:22:38 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 191, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 1.0 in stage 72.0 (TID 192, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 2.0 in stage 72.0 (TID 193, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 3.0 in stage 72.0 (TID 194, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:38 INFO Executor: Running task 1.0 in stage 72.0 (TID 192)
18/02/28 14:22:38 INFO Executor: Running task 0.0 in stage 72.0 (TID 191)
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:22:38 INFO Executor: Running task 3.0 in stage 72.0 (TID 194)
18/02/28 14:22:38 INFO Executor: Running task 2.0 in stage 72.0 (TID 193)
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:22:38 INFO Executor: Finished task 0.0 in stage 72.0 (TID 191). 1610 bytes result sent to driver
18/02/28 14:22:38 INFO Executor: Finished task 3.0 in stage 72.0 (TID 194). 1630 bytes result sent to driver
18/02/28 14:22:38 INFO Executor: Finished task 2.0 in stage 72.0 (TID 193). 1520 bytes result sent to driver
18/02/28 14:22:38 INFO Executor: Finished task 1.0 in stage 72.0 (TID 192). 1549 bytes result sent to driver
18/02/28 14:22:38 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 191) in 8 ms on localhost (executor driver) (1/4)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 2.0 in stage 72.0 (TID 193) in 7 ms on localhost (executor driver) (2/4)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 3.0 in stage 72.0 (TID 194) in 7 ms on localhost (executor driver) (3/4)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 1.0 in stage 72.0 (TID 192) in 9 ms on localhost (executor driver) (4/4)
18/02/28 14:22:38 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
18/02/28 14:22:38 INFO DAGScheduler: ResultStage 72 (collect at utils.scala:211) finished in 0.012 s
18/02/28 14:22:38 INFO DAGScheduler: Job 41 finished: collect at utils.scala:211, took 0.029173 s
18/02/28 14:22:38 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:22:38 INFO DAGScheduler: Got job 42 (collect at utils.scala:211) with 5 output partitions
18/02/28 14:22:38 INFO DAGScheduler: Final stage: ResultStage 75 (collect at utils.scala:211)
18/02/28 14:22:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 74)
18/02/28 14:22:38 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:38 INFO DAGScheduler: Submitting ResultStage 75 (MapPartitionsRDD[155] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:38 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 11.1 KB, free 344.7 MB)
18/02/28 14:22:38 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 5.3 KB, free 344.7 MB)
18/02/28 14:22:38 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 127.0.0.1:61672 (size: 5.3 KB, free: 345.4 MB)
18/02/28 14:22:38 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:38 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 75 (MapPartitionsRDD[155] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/02/28 14:22:38 INFO TaskSchedulerImpl: Adding task set 75.0 with 5 tasks
18/02/28 14:22:38 INFO TaskSetManager: Starting task 1.0 in stage 75.0 (TID 195, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 2.0 in stage 75.0 (TID 196, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 3.0 in stage 75.0 (TID 197, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 4.0 in stage 75.0 (TID 198, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:22:38 INFO Executor: Running task 2.0 in stage 75.0 (TID 196)
18/02/28 14:22:38 INFO Executor: Running task 3.0 in stage 75.0 (TID 197)
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:22:38 INFO Executor: Finished task 2.0 in stage 75.0 (TID 196). 1448 bytes result sent to driver
18/02/28 14:22:38 INFO Executor: Running task 4.0 in stage 75.0 (TID 198)
18/02/28 14:22:38 INFO Executor: Finished task 3.0 in stage 75.0 (TID 197). 1609 bytes result sent to driver
18/02/28 14:22:38 INFO Executor: Running task 1.0 in stage 75.0 (TID 195)
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:22:38 INFO Executor: Finished task 4.0 in stage 75.0 (TID 198). 1632 bytes result sent to driver
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:22:38 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 199, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:22:38 INFO Executor: Finished task 1.0 in stage 75.0 (TID 195). 1419 bytes result sent to driver
18/02/28 14:22:38 INFO Executor: Running task 0.0 in stage 75.0 (TID 199)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 3.0 in stage 75.0 (TID 197) in 6 ms on localhost (executor driver) (1/5)
18/02/28 14:22:38 INFO Executor: Finished task 0.0 in stage 75.0 (TID 199). 1043 bytes result sent to driver
18/02/28 14:22:38 INFO TaskSetManager: Finished task 2.0 in stage 75.0 (TID 196) in 9 ms on localhost (executor driver) (2/5)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 1.0 in stage 75.0 (TID 195) in 9 ms on localhost (executor driver) (3/5)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 199) in 4 ms on localhost (executor driver) (4/5)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 4.0 in stage 75.0 (TID 198) in 9 ms on localhost (executor driver) (5/5)
18/02/28 14:22:38 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
18/02/28 14:22:38 INFO DAGScheduler: ResultStage 75 (collect at utils.scala:211) finished in 0.011 s
18/02/28 14:22:38 INFO DAGScheduler: Job 42 finished: collect at utils.scala:211, took 0.016064 s
18/02/28 14:22:38 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:22:38 INFO DAGScheduler: Got job 43 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:22:38 INFO DAGScheduler: Final stage: ResultStage 78 (collect at utils.scala:211)
18/02/28 14:22:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 77)
18/02/28 14:22:38 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:38 INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[158] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:38 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 10.3 KB, free 344.6 MB)
18/02/28 14:22:38 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.6 MB)
18/02/28 14:22:38 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 127.0.0.1:61672 (size: 4.9 KB, free: 345.4 MB)
18/02/28 14:22:38 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:38 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 78 (MapPartitionsRDD[158] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:38 INFO TaskSchedulerImpl: Adding task set 78.0 with 4 tasks
18/02/28 14:22:38 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 200, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 1.0 in stage 78.0 (TID 201, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 2.0 in stage 78.0 (TID 202, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 3.0 in stage 78.0 (TID 203, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:38 INFO Executor: Running task 0.0 in stage 78.0 (TID 200)
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:22:38 INFO Executor: Finished task 0.0 in stage 78.0 (TID 200). 1369 bytes result sent to driver
18/02/28 14:22:38 INFO Executor: Running task 1.0 in stage 78.0 (TID 201)
18/02/28 14:22:38 INFO Executor: Running task 2.0 in stage 78.0 (TID 202)
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:22:38 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 200) in 12 ms on localhost (executor driver) (1/4)
18/02/28 14:22:38 INFO Executor: Running task 3.0 in stage 78.0 (TID 203)
18/02/28 14:22:38 INFO Executor: Finished task 1.0 in stage 78.0 (TID 201). 1358 bytes result sent to driver
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:22:38 INFO Executor: Finished task 2.0 in stage 78.0 (TID 202). 1569 bytes result sent to driver
18/02/28 14:22:38 INFO Executor: Finished task 3.0 in stage 78.0 (TID 203). 1689 bytes result sent to driver
18/02/28 14:22:38 INFO TaskSetManager: Finished task 1.0 in stage 78.0 (TID 201) in 15 ms on localhost (executor driver) (2/4)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 3.0 in stage 78.0 (TID 203) in 15 ms on localhost (executor driver) (3/4)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 2.0 in stage 78.0 (TID 202) in 16 ms on localhost (executor driver) (4/4)
18/02/28 14:22:38 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
18/02/28 14:22:38 INFO DAGScheduler: ResultStage 78 (collect at utils.scala:211) finished in 0.016 s
18/02/28 14:22:38 INFO DAGScheduler: Job 43 finished: collect at utils.scala:211, took 0.021092 s
18/02/28 14:22:38 INFO SparkSqlParser: Parsing command: sparklyr_tmp_1440765f2b3b
18/02/28 14:22:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1440765f2b3b` AS `zzz12`
WHERE (0 = 1)
18/02/28 14:22:38 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:22:38 INFO DAGScheduler: Got job 44 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:22:38 INFO DAGScheduler: Final stage: ResultStage 81 (collect at utils.scala:211)
18/02/28 14:22:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 80)
18/02/28 14:22:38 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:38 INFO DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[161] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:38 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 10.3 KB, free 344.6 MB)
18/02/28 14:22:38 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.6 MB)
18/02/28 14:22:38 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 127.0.0.1:61672 (size: 4.9 KB, free: 345.4 MB)
18/02/28 14:22:38 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:38 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 81 (MapPartitionsRDD[161] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:38 INFO TaskSchedulerImpl: Adding task set 81.0 with 4 tasks
18/02/28 14:22:38 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 204, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 1.0 in stage 81.0 (TID 205, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 2.0 in stage 81.0 (TID 206, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 3.0 in stage 81.0 (TID 207, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:38 INFO Executor: Running task 0.0 in stage 81.0 (TID 204)
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:22:38 INFO Executor: Finished task 0.0 in stage 81.0 (TID 204). 1543 bytes result sent to driver
18/02/28 14:22:38 INFO Executor: Running task 1.0 in stage 81.0 (TID 205)
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:22:38 INFO Executor: Finished task 1.0 in stage 81.0 (TID 205). 1497 bytes result sent to driver
18/02/28 14:22:38 INFO Executor: Running task 2.0 in stage 81.0 (TID 206)
18/02/28 14:22:38 INFO Executor: Running task 3.0 in stage 81.0 (TID 207)
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:22:38 INFO Executor: Finished task 3.0 in stage 81.0 (TID 207). 1655 bytes result sent to driver
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:22:38 INFO Executor: Finished task 2.0 in stage 81.0 (TID 206). 1572 bytes result sent to driver
18/02/28 14:22:38 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 204) in 12 ms on localhost (executor driver) (1/4)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 1.0 in stage 81.0 (TID 205) in 12 ms on localhost (executor driver) (2/4)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 3.0 in stage 81.0 (TID 207) in 12 ms on localhost (executor driver) (3/4)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 2.0 in stage 81.0 (TID 206) in 13 ms on localhost (executor driver) (4/4)
18/02/28 14:22:38 INFO DAGScheduler: ResultStage 81 (collect at utils.scala:211) finished in 0.014 s
18/02/28 14:22:38 INFO DAGScheduler: Job 44 finished: collect at utils.scala:211, took 0.019223 s
18/02/28 14:22:38 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
18/02/28 14:22:38 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:22:38 INFO DAGScheduler: Got job 45 (collect at utils.scala:211) with 6 output partitions
18/02/28 14:22:38 INFO DAGScheduler: Final stage: ResultStage 84 (collect at utils.scala:211)
18/02/28 14:22:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 83)
18/02/28 14:22:38 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:38 INFO DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[164] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:38 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 11.2 KB, free 344.6 MB)
18/02/28 14:22:38 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 5.3 KB, free 344.6 MB)
18/02/28 14:22:38 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 127.0.0.1:61672 (size: 5.3 KB, free: 345.4 MB)
18/02/28 14:22:38 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:38 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 84 (MapPartitionsRDD[164] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
18/02/28 14:22:38 INFO TaskSchedulerImpl: Adding task set 84.0 with 6 tasks
18/02/28 14:22:38 INFO TaskSetManager: Starting task 1.0 in stage 84.0 (TID 208, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 2.0 in stage 84.0 (TID 209, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 3.0 in stage 84.0 (TID 210, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 4.0 in stage 84.0 (TID 211, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:22:38 INFO Executor: Running task 1.0 in stage 84.0 (TID 208)
18/02/28 14:22:38 INFO Executor: Running task 2.0 in stage 84.0 (TID 209)
18/02/28 14:22:38 INFO Executor: Running task 3.0 in stage 84.0 (TID 210)
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:22:38 INFO Executor: Finished task 3.0 in stage 84.0 (TID 210). 1546 bytes result sent to driver
18/02/28 14:22:38 INFO Executor: Running task 4.0 in stage 84.0 (TID 211)
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:22:38 INFO Executor: Finished task 1.0 in stage 84.0 (TID 208). 1409 bytes result sent to driver
18/02/28 14:22:38 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 212, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 5.0 in stage 84.0 (TID 213, localhost, executor driver, partition 5, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:22:38 INFO Executor: Finished task 4.0 in stage 84.0 (TID 211). 1608 bytes result sent to driver
18/02/28 14:22:38 INFO TaskSetManager: Finished task 3.0 in stage 84.0 (TID 210) in 7 ms on localhost (executor driver) (1/6)
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:22:38 INFO TaskSetManager: Finished task 1.0 in stage 84.0 (TID 208) in 7 ms on localhost (executor driver) (2/6)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 4.0 in stage 84.0 (TID 211) in 6 ms on localhost (executor driver) (3/6)
18/02/28 14:22:38 INFO Executor: Running task 0.0 in stage 84.0 (TID 212)
18/02/28 14:22:38 INFO Executor: Running task 5.0 in stage 84.0 (TID 213)
18/02/28 14:22:38 INFO Executor: Finished task 2.0 in stage 84.0 (TID 209). 1427 bytes result sent to driver
18/02/28 14:22:38 INFO Executor: Finished task 0.0 in stage 84.0 (TID 212). 999 bytes result sent to driver
18/02/28 14:22:38 INFO Executor: Finished task 5.0 in stage 84.0 (TID 213). 1007 bytes result sent to driver
18/02/28 14:22:38 INFO TaskSetManager: Finished task 2.0 in stage 84.0 (TID 209) in 10 ms on localhost (executor driver) (4/6)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 212) in 5 ms on localhost (executor driver) (5/6)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 5.0 in stage 84.0 (TID 213) in 6 ms on localhost (executor driver) (6/6)
18/02/28 14:22:38 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
18/02/28 14:22:38 INFO DAGScheduler: ResultStage 84 (collect at utils.scala:211) finished in 0.011 s
18/02/28 14:22:38 INFO DAGScheduler: Job 45 finished: collect at utils.scala:211, took 0.016158 s
18/02/28 14:22:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 14:22:38 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:22:38 INFO DAGScheduler: Got job 46 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:22:38 INFO DAGScheduler: Final stage: ResultStage 87 (collect at utils.scala:211)
18/02/28 14:22:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 86)
18/02/28 14:22:38 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:38 INFO DAGScheduler: Submitting ResultStage 87 (MapPartitionsRDD[167] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:38 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 10.4 KB, free 344.6 MB)
18/02/28 14:22:38 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.6 MB)
18/02/28 14:22:38 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 127.0.0.1:61672 (size: 4.9 KB, free: 345.4 MB)
18/02/28 14:22:38 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:38 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 87 (MapPartitionsRDD[167] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:38 INFO TaskSchedulerImpl: Adding task set 87.0 with 4 tasks
18/02/28 14:22:38 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 214, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 1.0 in stage 87.0 (TID 215, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 2.0 in stage 87.0 (TID 216, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 3.0 in stage 87.0 (TID 217, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:38 INFO Executor: Running task 0.0 in stage 87.0 (TID 214)
18/02/28 14:22:38 INFO Executor: Running task 1.0 in stage 87.0 (TID 215)
18/02/28 14:22:38 INFO Executor: Running task 2.0 in stage 87.0 (TID 216)
18/02/28 14:22:38 INFO Executor: Running task 3.0 in stage 87.0 (TID 217)
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:22:38 INFO Executor: Finished task 3.0 in stage 87.0 (TID 217). 1587 bytes result sent to driver
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:22:38 INFO Executor: Finished task 2.0 in stage 87.0 (TID 216). 1563 bytes result sent to driver
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:22:38 INFO Executor: Finished task 1.0 in stage 87.0 (TID 215). 1549 bytes result sent to driver
18/02/28 14:22:38 INFO Executor: Finished task 0.0 in stage 87.0 (TID 214). 1610 bytes result sent to driver
18/02/28 14:22:38 INFO TaskSetManager: Finished task 3.0 in stage 87.0 (TID 217) in 13 ms on localhost (executor driver) (1/4)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 2.0 in stage 87.0 (TID 216) in 13 ms on localhost (executor driver) (2/4)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 1.0 in stage 87.0 (TID 215) in 14 ms on localhost (executor driver) (3/4)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 214) in 15 ms on localhost (executor driver) (4/4)
18/02/28 14:22:38 INFO DAGScheduler: ResultStage 87 (collect at utils.scala:211) finished in 0.015 s
18/02/28 14:22:38 INFO DAGScheduler: Job 46 finished: collect at utils.scala:211, took 0.033626 s
18/02/28 14:22:38 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool 
18/02/28 14:22:38 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:22:38 INFO DAGScheduler: Got job 47 (collect at utils.scala:211) with 5 output partitions
18/02/28 14:22:38 INFO DAGScheduler: Final stage: ResultStage 90 (collect at utils.scala:211)
18/02/28 14:22:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 89)
18/02/28 14:22:38 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:38 INFO DAGScheduler: Submitting ResultStage 90 (MapPartitionsRDD[170] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:38 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 11.1 KB, free 344.6 MB)
18/02/28 14:22:38 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 5.3 KB, free 344.6 MB)
18/02/28 14:22:38 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 127.0.0.1:61672 (size: 5.3 KB, free: 345.4 MB)
18/02/28 14:22:38 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:38 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 90 (MapPartitionsRDD[170] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/02/28 14:22:38 INFO TaskSchedulerImpl: Adding task set 90.0 with 5 tasks
18/02/28 14:22:38 INFO TaskSetManager: Starting task 1.0 in stage 90.0 (TID 218, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 2.0 in stage 90.0 (TID 219, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 3.0 in stage 90.0 (TID 220, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 4.0 in stage 90.0 (TID 221, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:22:38 INFO Executor: Running task 4.0 in stage 90.0 (TID 221)
18/02/28 14:22:38 INFO Executor: Running task 1.0 in stage 90.0 (TID 218)
18/02/28 14:22:38 INFO Executor: Running task 2.0 in stage 90.0 (TID 219)
18/02/28 14:22:38 INFO Executor: Running task 3.0 in stage 90.0 (TID 220)
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:22:38 INFO Executor: Finished task 3.0 in stage 90.0 (TID 220). 1566 bytes result sent to driver
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:22:38 INFO Executor: Finished task 4.0 in stage 90.0 (TID 221). 1632 bytes result sent to driver
18/02/28 14:22:38 INFO Executor: Finished task 2.0 in stage 90.0 (TID 219). 1405 bytes result sent to driver
18/02/28 14:22:38 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 222, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:22:38 INFO Executor: Finished task 1.0 in stage 90.0 (TID 218). 1419 bytes result sent to driver
18/02/28 14:22:38 INFO Executor: Running task 0.0 in stage 90.0 (TID 222)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 3.0 in stage 90.0 (TID 220) in 4 ms on localhost (executor driver) (1/5)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 4.0 in stage 90.0 (TID 221) in 5 ms on localhost (executor driver) (2/5)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 2.0 in stage 90.0 (TID 219) in 5 ms on localhost (executor driver) (3/5)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 1.0 in stage 90.0 (TID 218) in 6 ms on localhost (executor driver) (4/5)
18/02/28 14:22:38 INFO Executor: Finished task 0.0 in stage 90.0 (TID 222). 1086 bytes result sent to driver
18/02/28 14:22:38 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 222) in 3 ms on localhost (executor driver) (5/5)
18/02/28 14:22:38 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
18/02/28 14:22:38 INFO DAGScheduler: ResultStage 90 (collect at utils.scala:211) finished in 0.008 s
18/02/28 14:22:38 INFO DAGScheduler: Job 47 finished: collect at utils.scala:211, took 0.013450 s
18/02/28 14:22:38 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:22:38 INFO DAGScheduler: Got job 48 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:22:38 INFO DAGScheduler: Final stage: ResultStage 93 (collect at utils.scala:211)
18/02/28 14:22:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 92)
18/02/28 14:22:38 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:38 INFO DAGScheduler: Submitting ResultStage 93 (MapPartitionsRDD[173] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:38 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 10.3 KB, free 344.6 MB)
18/02/28 14:22:38 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.6 MB)
18/02/28 14:22:38 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 127.0.0.1:61672 (size: 4.9 KB, free: 345.4 MB)
18/02/28 14:22:38 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:38 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 93 (MapPartitionsRDD[173] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:38 INFO TaskSchedulerImpl: Adding task set 93.0 with 4 tasks
18/02/28 14:22:38 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 223, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 1.0 in stage 93.0 (TID 224, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 2.0 in stage 93.0 (TID 225, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 3.0 in stage 93.0 (TID 226, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:38 INFO Executor: Running task 2.0 in stage 93.0 (TID 225)
18/02/28 14:22:38 INFO Executor: Running task 3.0 in stage 93.0 (TID 226)
18/02/28 14:22:38 INFO Executor: Running task 1.0 in stage 93.0 (TID 224)
18/02/28 14:22:38 INFO Executor: Running task 0.0 in stage 93.0 (TID 223)
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:22:38 INFO Executor: Finished task 3.0 in stage 93.0 (TID 226). 1646 bytes result sent to driver
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:22:38 INFO Executor: Finished task 2.0 in stage 93.0 (TID 225). 1569 bytes result sent to driver
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:22:38 INFO Executor: Finished task 1.0 in stage 93.0 (TID 224). 1358 bytes result sent to driver
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:22:38 INFO TaskSetManager: Finished task 3.0 in stage 93.0 (TID 226) in 6 ms on localhost (executor driver) (1/4)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 2.0 in stage 93.0 (TID 225) in 7 ms on localhost (executor driver) (2/4)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 1.0 in stage 93.0 (TID 224) in 7 ms on localhost (executor driver) (3/4)
18/02/28 14:22:38 INFO Executor: Finished task 0.0 in stage 93.0 (TID 223). 1369 bytes result sent to driver
18/02/28 14:22:38 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 223) in 7 ms on localhost (executor driver) (4/4)
18/02/28 14:22:38 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool 
18/02/28 14:22:38 INFO DAGScheduler: ResultStage 93 (collect at utils.scala:211) finished in 0.007 s
18/02/28 14:22:38 INFO DAGScheduler: Job 48 finished: collect at utils.scala:211, took 0.012001 s
18/02/28 14:22:38 INFO SparkSqlParser: Parsing command: sparklyr_tmp_1440ff11db0
18/02/28 14:22:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1440ff11db0` AS `zzz13`
WHERE (0 = 1)
18/02/28 14:22:38 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:22:38 INFO DAGScheduler: Got job 49 (collect at utils.scala:211) with 4 output partitions
18/02/28 14:22:38 INFO DAGScheduler: Final stage: ResultStage 96 (collect at utils.scala:211)
18/02/28 14:22:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 95)
18/02/28 14:22:38 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:38 INFO DAGScheduler: Submitting ResultStage 96 (MapPartitionsRDD[176] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:38 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 10.3 KB, free 344.6 MB)
18/02/28 14:22:38 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 4.9 KB, free 344.6 MB)
18/02/28 14:22:38 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 127.0.0.1:61672 (size: 4.9 KB, free: 345.4 MB)
18/02/28 14:22:38 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:38 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 96 (MapPartitionsRDD[176] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:38 INFO TaskSchedulerImpl: Adding task set 96.0 with 4 tasks
18/02/28 14:22:38 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 227, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 1.0 in stage 96.0 (TID 228, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 2.0 in stage 96.0 (TID 229, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 3.0 in stage 96.0 (TID 230, localhost, executor driver, partition 3, PROCESS_LOCAL, 4621 bytes)
18/02/28 14:22:38 INFO Executor: Running task 2.0 in stage 96.0 (TID 229)
18/02/28 14:22:38 INFO Executor: Running task 0.0 in stage 96.0 (TID 227)
18/02/28 14:22:38 INFO Executor: Running task 3.0 in stage 96.0 (TID 230)
18/02/28 14:22:38 INFO Executor: Running task 1.0 in stage 96.0 (TID 228)
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:22:38 INFO Executor: Finished task 3.0 in stage 96.0 (TID 230). 1569 bytes result sent to driver
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:22:38 INFO Executor: Finished task 1.0 in stage 96.0 (TID 228). 1583 bytes result sent to driver
18/02/28 14:22:38 INFO Executor: Finished task 0.0 in stage 96.0 (TID 227). 1586 bytes result sent to driver
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:22:38 INFO Executor: Finished task 2.0 in stage 96.0 (TID 229). 1572 bytes result sent to driver
18/02/28 14:22:38 INFO TaskSetManager: Finished task 3.0 in stage 96.0 (TID 230) in 8 ms on localhost (executor driver) (1/4)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 1.0 in stage 96.0 (TID 228) in 9 ms on localhost (executor driver) (2/4)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 227) in 9 ms on localhost (executor driver) (3/4)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 2.0 in stage 96.0 (TID 229) in 9 ms on localhost (executor driver) (4/4)
18/02/28 14:22:38 INFO DAGScheduler: ResultStage 96 (collect at utils.scala:211) finished in 0.010 s
18/02/28 14:22:38 INFO DAGScheduler: Job 49 finished: collect at utils.scala:211, took 0.016652 s
18/02/28 14:22:38 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool 
18/02/28 14:22:38 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:22:38 INFO DAGScheduler: Got job 50 (collect at utils.scala:211) with 6 output partitions
18/02/28 14:22:38 INFO DAGScheduler: Final stage: ResultStage 99 (collect at utils.scala:211)
18/02/28 14:22:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 98)
18/02/28 14:22:38 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:38 INFO DAGScheduler: Submitting ResultStage 99 (MapPartitionsRDD[179] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:38 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 11.2 KB, free 344.5 MB)
18/02/28 14:22:38 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 5.3 KB, free 344.5 MB)
18/02/28 14:22:38 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 127.0.0.1:61672 (size: 5.3 KB, free: 345.4 MB)
18/02/28 14:22:38 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:38 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 99 (MapPartitionsRDD[179] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
18/02/28 14:22:38 INFO TaskSchedulerImpl: Adding task set 99.0 with 6 tasks
18/02/28 14:22:38 INFO TaskSetManager: Starting task 1.0 in stage 99.0 (TID 231, localhost, executor driver, partition 1, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 2.0 in stage 99.0 (TID 232, localhost, executor driver, partition 2, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 3.0 in stage 99.0 (TID 233, localhost, executor driver, partition 3, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 4.0 in stage 99.0 (TID 234, localhost, executor driver, partition 4, PROCESS_LOCAL, 4730 bytes)
18/02/28 14:22:38 INFO Executor: Running task 1.0 in stage 99.0 (TID 231)
18/02/28 14:22:38 INFO Executor: Running task 4.0 in stage 99.0 (TID 234)
18/02/28 14:22:38 INFO Executor: Running task 3.0 in stage 99.0 (TID 233)
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_3 locally
18/02/28 14:22:38 INFO Executor: Finished task 4.0 in stage 99.0 (TID 234). 1608 bytes result sent to driver
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_2 locally
18/02/28 14:22:38 INFO Executor: Running task 2.0 in stage 99.0 (TID 232)
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_0 locally
18/02/28 14:22:38 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 235, localhost, executor driver, partition 0, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:22:38 INFO BlockManager: Found block rdd_117_1 locally
18/02/28 14:22:38 INFO Executor: Finished task 2.0 in stage 99.0 (TID 232). 1384 bytes result sent to driver
18/02/28 14:22:38 INFO Executor: Running task 0.0 in stage 99.0 (TID 235)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 4.0 in stage 99.0 (TID 234) in 6 ms on localhost (executor driver) (1/6)
18/02/28 14:22:38 INFO TaskSetManager: Starting task 5.0 in stage 99.0 (TID 236, localhost, executor driver, partition 5, PROCESS_LOCAL, 5058 bytes)
18/02/28 14:22:38 INFO Executor: Finished task 3.0 in stage 99.0 (TID 233). 1546 bytes result sent to driver
18/02/28 14:22:38 INFO Executor: Finished task 0.0 in stage 99.0 (TID 235). 999 bytes result sent to driver
18/02/28 14:22:38 INFO Executor: Finished task 1.0 in stage 99.0 (TID 231). 1409 bytes result sent to driver
18/02/28 14:22:38 INFO Executor: Running task 5.0 in stage 99.0 (TID 236)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 2.0 in stage 99.0 (TID 232) in 12 ms on localhost (executor driver) (2/6)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 235) in 6 ms on localhost (executor driver) (3/6)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 3.0 in stage 99.0 (TID 233) in 12 ms on localhost (executor driver) (4/6)
18/02/28 14:22:38 INFO TaskSetManager: Finished task 1.0 in stage 99.0 (TID 231) in 14 ms on localhost (executor driver) (5/6)
18/02/28 14:22:38 INFO Executor: Finished task 5.0 in stage 99.0 (TID 236). 1007 bytes result sent to driver
18/02/28 14:22:38 INFO TaskSetManager: Finished task 5.0 in stage 99.0 (TID 236) in 7 ms on localhost (executor driver) (6/6)
18/02/28 14:22:38 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool 
18/02/28 14:22:38 INFO DAGScheduler: ResultStage 99 (collect at utils.scala:211) finished in 0.016 s
18/02/28 14:22:38 INFO DAGScheduler: Job 50 finished: collect at utils.scala:211, took 0.021847 s
18/02/28 14:22:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `training`
18/02/28 14:22:38 INFO SparkSqlParser: Parsing command: sparklyr_tmp_14405326393c
18/02/28 14:22:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_14405326393c` AS `zzz14`
WHERE (0 = 1)
18/02/28 14:22:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_14405326393c`
18/02/28 14:22:38 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 127.0.0.1:61672 in memory (size: 4.9 KB, free: 345.4 MB)
18/02/28 14:22:38 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 127.0.0.1:61672 in memory (size: 4.9 KB, free: 345.4 MB)
18/02/28 14:22:38 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 127.0.0.1:61672 in memory (size: 4.9 KB, free: 345.4 MB)
18/02/28 14:22:38 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 127.0.0.1:61672 in memory (size: 5.3 KB, free: 345.4 MB)
18/02/28 14:22:38 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 127.0.0.1:61672 in memory (size: 5.3 KB, free: 345.4 MB)
18/02/28 14:22:38 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 127.0.0.1:61672 in memory (size: 5.3 KB, free: 345.4 MB)
18/02/28 14:22:38 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 127.0.0.1:61672 in memory (size: 4.9 KB, free: 345.4 MB)
18/02/28 14:22:38 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 127.0.0.1:61672 in memory (size: 4.9 KB, free: 345.4 MB)
18/02/28 14:22:38 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 127.0.0.1:61672 in memory (size: 2.3 KB, free: 345.4 MB)
18/02/28 14:22:38 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 127.0.0.1:61672 in memory (size: 4.9 KB, free: 345.4 MB)
18/02/28 14:22:38 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 127.0.0.1:61672 in memory (size: 3.3 KB, free: 345.4 MB)
18/02/28 14:22:38 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 127.0.0.1:61672 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:22:38 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 127.0.0.1:61672 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:22:38 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 127.0.0.1:61672 in memory (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:22:38 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 127.0.0.1:61672 in memory (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:22:38 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 127.0.0.1:61672 in memory (size: 3.4 KB, free: 345.5 MB)
18/02/28 14:22:38 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 127.0.0.1:61672 in memory (size: 4.9 KB, free: 345.5 MB)
18/02/28 14:22:38 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 127.0.0.1:61672 in memory (size: 5.3 KB, free: 345.5 MB)
18/02/28 14:22:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1440251d3496`
18/02/28 14:22:39 INFO SparkSqlParser: Parsing command: sparklyr_tmp_144010372939
18/02/28 14:22:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_144010372939` AS `zzz15`
WHERE (0 = 1)
18/02/28 14:22:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_144010372939`
18/02/28 14:22:39 INFO SparkSqlParser: Parsing command: sparklyr_tmp_144015a7e6e
18/02/28 14:22:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_144015a7e6e` AS `zzz16`
WHERE (0 = 1)
18/02/28 14:22:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:39 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `dephour`, `prediction`, `probability`
FROM `sparklyr_tmp_144015a7e6e`
LIMIT 5
18/02/28 14:22:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:39 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `dephour`, `prediction`, `probability`
FROM `sparklyr_tmp_144015a7e6e`
LIMIT 5
18/02/28 14:22:39 INFO CodeGenerator: Code generated in 39.364387 ms
18/02/28 14:22:39 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:22:39 INFO DAGScheduler: Got job 51 (collect at utils.scala:211) with 1 output partitions
18/02/28 14:22:39 INFO DAGScheduler: Final stage: ResultStage 100 (collect at utils.scala:211)
18/02/28 14:22:39 INFO DAGScheduler: Parents of final stage: List()
18/02/28 14:22:39 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:39 INFO DAGScheduler: Submitting ResultStage 100 (MapPartitionsRDD[182] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:39 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 80.8 KB, free 344.7 MB)
18/02/28 14:22:39 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 29.8 KB, free 344.7 MB)
18/02/28 14:22:39 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 127.0.0.1:61672 (size: 29.8 KB, free: 345.5 MB)
18/02/28 14:22:39 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 100 (MapPartitionsRDD[182] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 14:22:39 INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks
18/02/28 14:22:39 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 237, localhost, executor driver, partition 0, PROCESS_LOCAL, 5535 bytes)
18/02/28 14:22:39 INFO Executor: Running task 0.0 in stage 100.0 (TID 237)
18/02/28 14:22:39 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 14:22:39 INFO Executor: Finished task 0.0 in stage 100.0 (TID 237). 1988 bytes result sent to driver
18/02/28 14:22:39 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 237) in 343 ms on localhost (executor driver) (1/1)
18/02/28 14:22:39 INFO DAGScheduler: ResultStage 100 (collect at utils.scala:211) finished in 0.343 s
18/02/28 14:22:39 INFO DAGScheduler: Job 51 finished: collect at utils.scala:211, took 0.352191 s
18/02/28 14:22:39 INFO CodeGenerator: Code generated in 7.600305 ms
18/02/28 14:22:39 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool 
18/02/28 14:22:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:40 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_144015a7e6e`
GROUP BY `delayed`, `prediction`
18/02/28 14:22:40 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:22:40 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:22:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 14:22:40 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_144015a7e6e`
GROUP BY `delayed`, `prediction`
LIMIT 10
18/02/28 14:22:40 INFO HiveMetaStore: 0: get_database: default
18/02/28 14:22:40 INFO audit: ugi=JC	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 14:22:40 INFO CodeGenerator: Code generated in 20.76984 ms
18/02/28 14:22:40 INFO CodeGenerator: Code generated in 44.243899 ms
18/02/28 14:22:40 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:22:40 INFO DAGScheduler: Registering RDD 185 (collect at utils.scala:211)
18/02/28 14:22:40 INFO DAGScheduler: Got job 52 (collect at utils.scala:211) with 1 output partitions
18/02/28 14:22:40 INFO DAGScheduler: Final stage: ResultStage 102 (collect at utils.scala:211)
18/02/28 14:22:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 101)
18/02/28 14:22:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 101)
18/02/28 14:22:40 INFO DAGScheduler: Submitting ShuffleMapStage 101 (MapPartitionsRDD[185] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:40 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 79.1 KB, free 344.6 MB)
18/02/28 14:22:40 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 32.2 KB, free 344.6 MB)
18/02/28 14:22:40 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 127.0.0.1:61672 (size: 32.2 KB, free: 345.4 MB)
18/02/28 14:22:40 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:40 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 101 (MapPartitionsRDD[185] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/02/28 14:22:40 INFO TaskSchedulerImpl: Adding task set 101.0 with 4 tasks
18/02/28 14:22:40 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 238, localhost, executor driver, partition 0, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:40 INFO TaskSetManager: Starting task 1.0 in stage 101.0 (TID 239, localhost, executor driver, partition 1, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:40 INFO TaskSetManager: Starting task 2.0 in stage 101.0 (TID 240, localhost, executor driver, partition 2, PROCESS_LOCAL, 5523 bytes)
18/02/28 14:22:40 INFO TaskSetManager: Starting task 3.0 in stage 101.0 (TID 241, localhost, executor driver, partition 3, PROCESS_LOCAL, 5524 bytes)
18/02/28 14:22:40 INFO Executor: Running task 0.0 in stage 101.0 (TID 238)
18/02/28 14:22:40 INFO Executor: Running task 1.0 in stage 101.0 (TID 239)
18/02/28 14:22:40 INFO BlockManager: Found block rdd_13_0 locally
18/02/28 14:22:40 INFO Executor: Running task 3.0 in stage 101.0 (TID 241)
18/02/28 14:22:40 INFO Executor: Running task 2.0 in stage 101.0 (TID 240)
18/02/28 14:22:40 INFO BlockManager: Found block rdd_13_1 locally
18/02/28 14:22:40 INFO BlockManager: Found block rdd_13_3 locally
18/02/28 14:22:40 INFO BlockManager: Found block rdd_13_2 locally
18/02/28 14:22:40 INFO CodeGenerator: Code generated in 6.191953 ms
18/02/28 14:22:40 INFO CodeGenerator: Code generated in 13.197745 ms
18/02/28 14:22:40 INFO CodeGenerator: Code generated in 27.325341 ms
18/02/28 14:22:40 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 127.0.0.1:61672 in memory (size: 29.8 KB, free: 345.4 MB)
18/02/28 14:22:41 INFO Executor: Finished task 1.0 in stage 101.0 (TID 239). 2411 bytes result sent to driver
18/02/28 14:22:41 INFO TaskSetManager: Finished task 1.0 in stage 101.0 (TID 239) in 986 ms on localhost (executor driver) (1/4)
18/02/28 14:22:41 INFO Executor: Finished task 3.0 in stage 101.0 (TID 241). 2411 bytes result sent to driver
18/02/28 14:22:41 INFO TaskSetManager: Finished task 3.0 in stage 101.0 (TID 241) in 987 ms on localhost (executor driver) (2/4)
18/02/28 14:22:41 INFO Executor: Finished task 2.0 in stage 101.0 (TID 240). 2454 bytes result sent to driver
18/02/28 14:22:41 INFO TaskSetManager: Finished task 2.0 in stage 101.0 (TID 240) in 991 ms on localhost (executor driver) (3/4)
18/02/28 14:22:41 INFO Executor: Finished task 0.0 in stage 101.0 (TID 238). 2411 bytes result sent to driver
18/02/28 14:22:41 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 238) in 996 ms on localhost (executor driver) (4/4)
18/02/28 14:22:41 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool 
18/02/28 14:22:41 INFO DAGScheduler: ShuffleMapStage 101 (collect at utils.scala:211) finished in 0.996 s
18/02/28 14:22:41 INFO DAGScheduler: looking for newly runnable stages
18/02/28 14:22:41 INFO DAGScheduler: running: Set()
18/02/28 14:22:41 INFO DAGScheduler: waiting: Set(ResultStage 102)
18/02/28 14:22:41 INFO DAGScheduler: failed: Set()
18/02/28 14:22:41 INFO DAGScheduler: Submitting ResultStage 102 (MapPartitionsRDD[188] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:41 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 38.1 KB, free 344.6 MB)
18/02/28 14:22:41 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 17.9 KB, free 344.6 MB)
18/02/28 14:22:41 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 127.0.0.1:61672 (size: 17.9 KB, free: 345.4 MB)
18/02/28 14:22:41 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 102 (MapPartitionsRDD[188] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 14:22:41 INFO TaskSchedulerImpl: Adding task set 102.0 with 1 tasks
18/02/28 14:22:41 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 242, localhost, executor driver, partition 0, PROCESS_LOCAL, 4726 bytes)
18/02/28 14:22:41 INFO Executor: Running task 0.0 in stage 102.0 (TID 242)
18/02/28 14:22:41 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 14:22:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 14:22:41 INFO Executor: Finished task 0.0 in stage 102.0 (TID 242). 2577 bytes result sent to driver
18/02/28 14:22:41 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 242) in 8 ms on localhost (executor driver) (1/1)
18/02/28 14:22:41 INFO DAGScheduler: ResultStage 102 (collect at utils.scala:211) finished in 0.009 s
18/02/28 14:22:41 INFO DAGScheduler: Job 52 finished: collect at utils.scala:211, took 1.024525 s
18/02/28 14:22:41 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool 
18/02/28 14:22:41 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 14:22:41 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 155 bytes
18/02/28 14:22:41 INFO DAGScheduler: Got job 53 (collect at utils.scala:211) with 3 output partitions
18/02/28 14:22:41 INFO DAGScheduler: Final stage: ResultStage 104 (collect at utils.scala:211)
18/02/28 14:22:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 103)
18/02/28 14:22:41 INFO DAGScheduler: Missing parents: List()
18/02/28 14:22:41 INFO DAGScheduler: Submitting ResultStage 104 (MapPartitionsRDD[188] at collect at utils.scala:211), which has no missing parents
18/02/28 14:22:41 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 38.1 KB, free 344.6 MB)
18/02/28 14:22:41 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 17.9 KB, free 344.6 MB)
18/02/28 14:22:41 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 127.0.0.1:61672 (size: 17.9 KB, free: 345.4 MB)
18/02/28 14:22:41 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1006
18/02/28 14:22:41 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 104 (MapPartitionsRDD[188] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(1, 2, 3))
18/02/28 14:22:41 INFO TaskSchedulerImpl: Adding task set 104.0 with 3 tasks
18/02/28 14:22:41 INFO TaskSetManager: Starting task 2.0 in stage 104.0 (TID 243, localhost, executor driver, partition 3, PROCESS_LOCAL, 4726 bytes)
18/02/28 14:22:41 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 244, localhost, executor driver, partition 1, ANY, 4726 bytes)
18/02/28 14:22:41 INFO TaskSetManager: Starting task 1.0 in stage 104.0 (TID 245, localhost, executor driver, partition 2, ANY, 4726 bytes)
18/02/28 14:22:41 INFO Executor: Running task 2.0 in stage 104.0 (TID 243)
18/02/28 14:22:41 INFO Executor: Running task 0.0 in stage 104.0 (TID 244)
18/02/28 14:22:41 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 14:22:41 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 4 blocks
18/02/28 14:22:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:41 INFO Executor: Finished task 2.0 in stage 104.0 (TID 243). 2577 bytes result sent to driver
18/02/28 14:22:41 INFO Executor: Running task 1.0 in stage 104.0 (TID 245)
18/02/28 14:22:41 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/02/28 14:22:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 14:22:41 INFO Executor: Finished task 0.0 in stage 104.0 (TID 244). 2597 bytes result sent to driver
18/02/28 14:22:41 INFO TaskSetManager: Finished task 2.0 in stage 104.0 (TID 243) in 19 ms on localhost (executor driver) (1/3)
18/02/28 14:22:41 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 244) in 18 ms on localhost (executor driver) (2/3)
18/02/28 14:22:41 INFO Executor: Finished task 1.0 in stage 104.0 (TID 245). 2666 bytes result sent to driver
18/02/28 14:22:41 INFO TaskSetManager: Finished task 1.0 in stage 104.0 (TID 245) in 19 ms on localhost (executor driver) (3/3)
18/02/28 14:22:41 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool 
18/02/28 14:22:41 INFO DAGScheduler: ResultStage 104 (collect at utils.scala:211) finished in 0.020 s
18/02/28 14:22:41 INFO DAGScheduler: Job 53 finished: collect at utils.scala:211, took 0.036273 s
18/02/28 14:22:41 INFO CodeGenerator: Code generated in 5.36683 ms
18/02/28 14:22:42 INFO SparkContext: Invoking stop() from shutdown hook
18/02/28 14:22:43 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
18/02/28 14:22:43 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/02/28 14:22:43 INFO MemoryStore: MemoryStore cleared
18/02/28 14:22:43 INFO BlockManager: BlockManager stopped
18/02/28 14:22:43 INFO BlockManagerMaster: BlockManagerMaster stopped
18/02/28 14:22:43 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/02/28 14:22:43 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-ec3dec23-94c5-4beb-b0a8-5b2dc3585e69\userFiles-bda16843-ebae-4037-9234-d62dbdb49156
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-ec3dec23-94c5-4beb-b0a8-5b2dc3585e69\userFiles-bda16843-ebae-4037-9234-d62dbdb49156
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1937)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1936)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 14:22:43 INFO SparkContext: Successfully stopped SparkContext
18/02/28 14:22:43 INFO ShutdownHookManager: Shutdown hook called
18/02/28 14:22:43 INFO ShutdownHookManager: Deleting directory C:\Users\JC\AppData\Local\Temp\spark-ec3dec23-94c5-4beb-b0a8-5b2dc3585e69
18/02/28 14:22:43 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-ec3dec23-94c5-4beb-b0a8-5b2dc3585e69
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-ec3dec23-94c5-4beb-b0a8-5b2dc3585e69
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
18/02/28 14:22:43 INFO ShutdownHookManager: Deleting directory C:\Users\JC\AppData\Local\Temp\spark-ec3dec23-94c5-4beb-b0a8-5b2dc3585e69\userFiles-bda16843-ebae-4037-9234-d62dbdb49156
18/02/28 14:22:43 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\JC\AppData\Local\Temp\spark-ec3dec23-94c5-4beb-b0a8-5b2dc3585e69\userFiles-bda16843-ebae-4037-9234-d62dbdb49156
java.io.IOException: Failed to delete: C:\Users\JC\AppData\Local\Temp\spark-ec3dec23-94c5-4beb-b0a8-5b2dc3585e69\userFiles-bda16843-ebae-4037-9234-d62dbdb49156
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
